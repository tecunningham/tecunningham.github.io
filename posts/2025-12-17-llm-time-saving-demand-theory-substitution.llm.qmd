---
title: "LLM Time-Saving, Demand Theory, and the Cadillac Tasks"
author: "Tom Cunningham (METR)"
date: today
citation: true
reference-location: document
bibliography: ai.bib
format:
  html:
    toc: true
    toc-depth: 3
execute:
  echo: false
  warning: false
  error: false
  cache: true
---

## Results-first summary

This note reframes LLM time-saving as a *price index* problem in a time-allocation model, then adds a discrete extensive margin for “Cadillac tasks.” The continuous and discrete cases behave very differently, so I keep them separate.

**Continuous (intensive-margin) case:** treat each task’s time requirement as a price $p_i$, with LLM speedup $\beta_i$ implying $p_i' = p_i/\beta_i$. Under homothetic preferences, the output index is $v(p)=1/P(p)$ where $P(p)=e(p,1)$ is the unit time-expenditure function. Equivalent/compensating variation become time-index ratios, and small changes are share-weighted. Large changes require the *area under the compensated demand curve*. (Citations: @caves1982indexnumbers; @hausman1981exact; @willig1976consumerssurplus.)

**Discrete (extensive-margin) case:** tasks can require setup time or be unit-demand. Then LLM speedups change *which* tasks are done, not just *how much* of each task. This is the home of “Cadillac tasks” (tasks you’d never do absent the LLM) and the *worked example* below. Constant-elasticity formulas can fail here.

## Setup: time prices and speedups

**Objects.** Tasks $i=1,\dots,n$, outputs $x_i\ge 0$, time endowment normalized to $1$, time prices $p_i>0$ (time per unit of task output), and LLM speedups $\beta_i>0$ so $p_i' = p_i/\beta_i$.

We interpret $u(x)$ as an *output index* or “effective work accomplished,” with time prices defining the budget:
\[
\sum_i p_i x_i \le 1.
\]

The important split is:

1. **Continuous intensive margin:** choose continuous $x_i$ (smooth substitution).
2. **Discrete extensive margin:** choose which tasks to activate (unit demand or setup costs).

I treat these separately because the logic, formulas, and data requirements diverge.

## Continuous (intensive-margin) model

### Primal, dual, and the time price index

The primal problem is
\[
v(p)\;=\;\max_{x\ge 0} u(x) \quad\text{s.t.}\quad \sum_i p_i x_i\le 1.
\]

Define the expenditure function
\[
e(p,\bar u)=\min_{x\ge 0} \Big\{\sum_i p_i x_i: u(x)\ge \bar u\Big\}.
\]

If $u(\cdot)$ is homothetic and degree-1 homogeneous, then $e(p,\bar u)=\bar u\,e(p,1)$. Define the **unit time price index**
\[
P(p)\equiv e(p,1)\quad\Rightarrow\quad v(p)=\frac{1}{P(p)}.
\]

This is the classic index-number framing applied to time prices. @caves1982indexnumbers

### EV/CV in time units

Let $p^0\to p^1$ and $u^k=v(p^k)$. Equivalent and compensating variation (measured in *time*) are
\[
EV=e(p^0,u^1)-1,\qquad CV=e(p^1,u^0)-1.
\]

Under homotheticity,
\[
EV=\frac{P(p^0)}{P(p^1)}-1,\qquad CV=\frac{P(p^1)}{P(p^0)}-1.
\]

This is the cleanest way to translate LLM time savings into a welfare measure. @hausman1981exact

### Small changes (share-weighted)

Let $t_i(p)\equiv p_i x_i^*(p)$ be optimal time shares. For small changes in time prices,
\[
d\ln v\;=\;-d\ln P\;\approx\;\sum_i t_i\,d\ln \beta_i.
\]

This is the time-allocation analog of share-weighted Hulten-style approximations. @hulten1978growth

### Large changes (area under compensated demand)

When LLM gains are large, constant-elasticity approximations are dangerous. Using Hicksian (compensated) shares $s_i^H(p)$,
\[
d\ln P(p)=\sum_i s_i^H(p)\,d\ln p_i.
\]

For a single changing price $p_2$,
\[
\ln\frac{P(p^1)}{P(p^0)}=\int s_2^H(p_2)\,d\ln p_2,
\]

i.e., exact welfare is the **area under the compensated demand curve**. @willig1976consumerssurplus

### CES specialization (closed-form)

For a CES aggregator
\[
u(x)=\left(\sum_i \alpha_i x_i^{\frac{\sigma-1}{\sigma}}\right)^{\frac{\sigma}{\sigma-1}},\quad\sigma>0,
\]

the price index and time shares are
\[
P(p)=\left(\sum_i \alpha_i^{\sigma}p_i^{1-\sigma}\right)^{\frac{1}{1-\sigma}},\qquad
 t_i(p)=\frac{\alpha_i^{\sigma}p_i^{1-\sigma}}{\sum_j \alpha_j^{\sigma}p_j^{1-\sigma}}.
\]

In the two-task case, if task 2 speeds up by $\beta$ and its ex-ante share is $s_0$, then
\[
\frac{y'}{y}=\left((1-s_0)+s_0\,\beta^{\varepsilon-1}\right)^{\frac{1}{\varepsilon-1}},\qquad \varepsilon\equiv\sigma.
\]

This is the continuous benchmark; I will **not** use it for Cadillac tasks, which are discrete. @caves1982indexnumbers

#### Proposition (Lamport-style): CES output response

**Claim.** For two-task CES with ex-ante share $s_0$ on task 2 and speedup $\beta$, the optimized output ratio is
\[
\frac{y'}{y}=\left((1-s_0)+s_0\,\beta^{\varepsilon-1}\right)^{\frac{1}{\varepsilon-1}}.
\]

**Proof (Lamport style).**

1. *Given* CES price index $P(p)=\left(\alpha_1^{\varepsilon}p_1^{1-\varepsilon}+\alpha_2^{\varepsilon}p_2^{1-\varepsilon}\right)^{\frac{1}{1-\varepsilon}}$ and output $v(p)=1/P(p)$.
2. *Let* $p_2' = p_2/\beta$ while $p_1$ is fixed.
3. *Then* the output ratio is
   \[
   \frac{y'}{y}=\frac{P(p^0)}{P(p^1)}=
   \left(\frac{\alpha_1^{\varepsilon}p_1^{1-\varepsilon}+\alpha_2^{\varepsilon}p_2^{1-\varepsilon}}{\alpha_1^{\varepsilon}p_1^{1-\varepsilon}+\alpha_2^{\varepsilon}(p_2/\beta)^{1-\varepsilon}}\right)^{\frac{1}{\varepsilon-1}}.
   \]
4. *Define* the ex-ante share
   \[
   s_0\equiv\frac{\alpha_2^{\varepsilon}p_2^{1-\varepsilon}}{\alpha_1^{\varepsilon}p_1^{1-\varepsilon}+\alpha_2^{\varepsilon}p_2^{1-\varepsilon}}.
   \]
5. *Substitute* into Step 3 to obtain
   \[
   \frac{y'}{y}=\left((1-s_0)+s_0\,\beta^{\varepsilon-1}\right)^{\frac{1}{\varepsilon-1}}.
   \]
6. **QED.**

## Discrete (extensive-margin) model: Cadillac tasks live here

The continuous model assumes you always do *some* of each task. That is wrong when tasks are lumpy, have setup costs, or are unit-demand. In those cases, LLMs can create **newly affordable tasks**, meaning the major effect is *selection*, not *intensive* time reallocation.

### Unit-demand formulation

Let each task have payoff $u_i$ and required time $w_i(p)$, with decision $q_i\in\{0,1\}$. Then
\[
\max_{q\in\{0,1\}^n}\sum_i u_i q_i\quad\text{s.t.}\quad \sum_i w_i(p) q_i\le 1.
\]

Speedups change $w_i$ by $\beta_i$, which can **turn tasks on** once a threshold is crossed. This is exactly the “Cadillac tasks” phenomenon: tasks that were too time-expensive become attractive after the LLM. The usual CES elasticity is not a good summary in this regime.

### Setup-cost variant (bridging discrete and continuous)

Add a fixed setup time $\phi_i$ and a continuous intensity $x_i$:
\[
\max_{q,x}\;u(x)\quad\text{s.t.}\quad \sum_i \phi_i q_i + \sum_i p_i x_i \le 1,\; x_i=0\;\text{if }q_i=0.
\]

If $\phi_i=0$, we recover the continuous model. If $\phi_i>0$, large LLM speedups mostly expand the active set $\{i:q_i=1\}$, not the intensive shares.

### Worked example (discrete, not continuous)

**Example.** Suppose you can pick *one* task (unit-demand). Task A yields value $u_A=10$ and takes 1 hour. Task B yields $u_B=12$ and takes 2 hours. Without LLMs you choose A. Now an LLM speeds up task B so it takes 1 hour. You switch to B.

- **Upper bound on time-equivalent gain:** 1 hour (if the extra value $u_B-u_A$ is “worth” a full hour).
- **Lower bound:** 0 hours (if the extra value is just a small quality bump).

So the *observed* reallocation does not identify a precise time-savings without modeling discrete choice. This is why elasticity-of-substitution estimates are weak in the Cadillac regime.

### Cadillac tasks (discrete interpretation)

Cadillac tasks are those you would not do *at all* without the LLM, but you do once their time cost drops. Examples:

- literature reviews you previously would not attempt,
- custom data visualizations,
- long-form proofreading or refactoring.

In a unit-demand or setup-cost model, these tasks appear as **newly activated $q_i=1$ choices**, not as marginal increases in $x_i$. This is a discrete effect, so apply discrete logic—not the continuous CES approximation.

## Practical examples (grounding)

- **Query-level time savings:** If a chatbot is used for 10% of tasks and yields 5x speedups, naive share-weighted estimates imply large gains. But if those tasks are Cadillac tasks (discrete selection), the aggregate gain is much smaller. @anthropic2025estimatingproductivitygains
- **RCTs with task selection:** In uplift experiments, participants may choose different tasks once AI is available. That makes comparisons tricky unless you model the discrete choice margin. @becker2025uplift
- **Time allocation as a resource constraint:** Classic time-allocation models already interpret time as a shadow price. @deserpa1971time

## Diagrams

### Unified map (assumptions → objects → results)

```{mermaid}
graph TD
  A[Primitives: tasks i=1..n, time endowment=1] --> B[Technology: time prices p_i; AI => p_i' = p_i/β_i]
  B --> C[Choice: allocate time/output s.t. Σ p_i x_i ≤ 1]

  C --> D{Preference/output aggregator u(x)}
  D --> D1[Homothetic (continuous)]
  D --> D2[CES]
  D --> D3[Discrete or setup-cost tasks]

  D1 --> E[Price index P(p)=e(p,1)]
  E --> F[Indirect output v(p)=1/P(p)]
  F --> G[EV/CV = ratios of P(p)]
  F --> H[Local: d ln v = Σ t_i d ln β_i]

  D2 --> I[Closed forms for P(p), shares]
  I --> J[Two-task formula]

  D3 --> K[Activation/threshold effects]
  K --> L[Cadillac tasks, discrete selection]
```

### Threshold diagram (discrete activation)

```{tikz}
#| fig-cap: "Discrete activation: speedups switch on tasks"
#| fig-align: center
\begin{tikzpicture}[scale=1.0]
  \draw[->] (0,0) -- (4.2,0) node[below] {time cost};
  \draw[->] (0,0) -- (0,3.2) node[left] {task value};

  \draw[dashed] (0,1.5) -- (4,1.5) node[right] {value threshold};

  \fill[black] (1,2.2) circle[radius=2pt] node[above] {task A};
  \fill[black] (3.2,2.7) circle[radius=2pt] node[above] {task B};

  \draw[blue,->] (3.2,2.7) -- (2.0,2.7) node[midway,above] {LLM speedup};
  \node[blue] at (2.2,2.1) {activation};
\end{tikzpicture}
```

## Checklist for the desiderata

- **Bibliography validity:** citations are included and checked against `ai.bib`. See the tests.
- **Citation faithfulness:** the LLM-based test asks a model to flag any suspicious claim-to-citation mismatches.
- **Lamport-style proofs:** proofs are structured with numbered steps and a QED marker.
- **Legible diagrams:** one Mermaid flowchart + one TikZ threshold figure.
- **Practical examples:** see the query-level and RCT examples above.

## Related literature (short pointers)

- Index-number theory for price changes and substitution. @caves1982indexnumbers
- Exact welfare measures and integrable demand systems. @hausman1981exact; @deaton1980aids
- Time allocation and shadow pricing. @deserpa1971time
- Task-based technological change. @autor2003skill; @acemoglu2011handbook

