---
title: Too Much Good News is Bad News
author: Tom Cunningham
date: today
# draft: true
execute:
  echo: false
  cache: true # caches chunk output
reference-location: document
citation-location: document
fontsize: 14pt
format: html
engine: knitr
editor:
  render-on-save: true
---

Here are two nice pieces of Bayesian logic observations that help explain everyday intuitions:

1. When an outcome is the sum of two components then your belief about the contribution of the thinner-tailed component will be first increasing then decreasing in the realization of the outcome.
2. When you observe an outlier in some process, which is the sum of multiple components, then:
   - If the components are thin-tailed, then the outlier implies each of the components is elevated.
   - If the components are fat-tailed, then the outlier implies just one of the components is elevated and the others are at their ordinary levels.

#        Too Much Good News is Often Bad News

In many cases a signal which is good news eventually starts to become bad news:

1. The longer you wait for a bus the likelier it is to be about to arrive, until at some point it's more likely that you've missed it.
2. The lower the price the better the value until it becomes suspiciously cheap.
3. If a drug is associated with a 5% higher rate of birth defects it's probably a selection effect, if it's associated with a 500% higher rate of birth defects it's probably causal.^[Bradford-Hill: "the mortality of chimney sweeps from scrotal cancer was some 200 times that of workers who were not specially exposed to tar or mineral oils."]
<!-- 5. The fewer cars on a street the better it is for parking until there are suspiciously few cars, meaning it's probably street-cleaning day. -->
1. If an AB test shows an effect of +2% ($\pm$ 1%) it's very persuasive, but if it shows a an effect of +50%  ($\pm$ 1%) then the experiment was probably misconfigured, and it's not at all persuasive.^[This case is somewhat subtle: we generally think that treatment effects are fat-tailed, and we can be confident that noise is Normal because it's the sum of many IID variables. However there's an additional source of noise from implementation error which has even fatter tails than the distribution of treatment effects.]
2. When reading a biography each detail makes the the subject seem more impressive until you start to doubt the neutrality of the biographer.

In each of these cases I think it's because the noise has a fatter-tailed distribution than the signal. As a consequence when you see a very-high observation you conclude it's mostly noise, which implies that after a certain point an increase in the observed outcome becomes bad news instead of good news.

#       Outliers Usually Have One Cause, Not Many

This is a related but slightly different point. Scott Sumner argued ["extreme events generally have multiple causes"](https://www.themoneyillusion.com/author/ssumner/page/183/), with a few examples:

1. Italy's very high COVID death rates are probably due to a number of different factors, not one.
2. The great depression was due to "multiple policy errors, on both the supply side and the demand side."
3. Bob Beamon's record long-jump in 1968 was probably a coincidence of multiple causes.^[*"While Beamon received mostly accolades, there also were detractors. The critics harped on the conditions — a following wind of 2.0 meters per second (the maximum allowable velocity for a record), a lightning fast runway and, most important, the thin air of Mexico City. Beamon’s defenders point out that the other competitors, which included the world record co-holders, had the same factors going for them and they didn’t jump close to Beamon."*]

I think Sumner is wrong in his generalization: extreme events typically have a single cause, not multiple causes. Formally (following Nair, Weierman and Zwart below), extreme draws from a sum of thin-tailed influences tend to have many causes, but extreme draws from a sum of fat-tailed influences tend to have one cause.

We often cannot observe the distributions of the individual components but we can observe the distribution of the final aggregate outcome, and if the final outcome is fat-tailed then at least some of the components must be fat-tailed.

I'm not sure about Italy's COVID and the great depression, but for Bob Beamon's jump in 1968 it looks like a non-Normal outlier, not the sum of orthogonal influences (see the spike on the blue line at right). Thus from this evidence we should expect, all else equal, that Beamon's 8.9 metres was due to one big cause not many small ones.

:::{.column-margin}
![](images/2024-12-26-07-59-52.png)
:::

<!-- #        Practical Implications

Implications for data science.
: When we see outliers in data (e.g. Algeria's DAU is below forecast). 

Implications for economics.
: Many academic papers try to explain deviations in aggregate economic variables, e.g. they say "our mechanism can explain 25% of the increase in markups since 2003." It is hard to assess these claims because there are typically many other factors that can cause swings in the outcome variable. -->

#        Formalizing This

We can summarize the theory with three observations.
: Suppose you observe a variable that is a sum of multiple components. Then:
: 1. If components are IID and thin-tailed: outliers are due to many small causes ("conspiracy").
: 2. If components are IID and fat-tailed: outliers are due to a few big causes ("catastrophe").
: 3. If components are a mixture of thin-tailed and fat-tailed: low observations are due to the thin-tailed components, high observations are due to the fat-tailed components ("rejection").



**Literature.** De Finetti wrote a paper in 1961, "The Bayesian Approach to the Rejection of Outliers", giving a simple example where, with fat-tailed noise, a Bayesian will discount outliers.

There seem to be two modern strands of this literature that use somewhat different terminology:

1. Anthony O’Hagan and Luis Pericchi (2012) [Bayesian heavy-tailed models and conflict resolution: a review](https://projecteuclid.org/download/pdfview_1/euclid.bjps/1341320249). They give a number of conditions under which you get "conflict resolution" or "rejection of outliers", broadly speaking when the noise has fatter tails than the signal. The critical condition is the relative speed of decline of the tails of the distributions of signal and noise.

2. Nair, Weierman and Zwart have a chapter "Catastrophes, conspiracies, and subexponential distributions" in their book ["The Fundamentals of Heavy Tails"](https://adamwierman.com/wp-content/uploads/2021/05/book-05-11.pdf). 

   - Suppose you observe the sum of a set of $N$ IID random variables. They discuss two polar ways in which your posteriors about the components will depend on the sum:
   - If the components are heavy tailed you get the "catastrophe principle": the probability that the sum exceeds some value $t$ will be approximately equal to the probability that the maximum of $N$ components exceeds $t$, as $t\rightarrow\infty$.
   - If the components are light-tailed you get the "conspiracy principle": the probability that the sum exceeds some value $t$ $t$ dominates the probability of the maximum exceeding $t$, as $t\rightarrow\infty$.
   - Applications of the catastrophe principle: If a certain year has many earthquake deaths then probably there was one large earthquake, not many small ones. If a random group of people has a high average number of Twitter followers, probably one member of the group is a big outlier, and the others have an ordinary number.
   - Applications of the conspiracy principle: if a random group of people has a high average height then probably each individual is tall.


<!-- They talk about the Swedish mathematician Harald Cramer modelling the insurance business: the income is regular, but the payments are highly skew. We want to know what the distribution looks like as you aggregate many claims. -->

<!-- Specific distributions.
: I was curious if there are assumptions on priors which give you a simple closed-form expression for the posterior. The papers above mostly just give asymptotic behavior as $t\rightarrow\infty$. This table shows my rough understanding but I'm not confident yet on these:


| signal                 | noise  | posterior shape | posterior expression |
| ---------------------- | :----: | :-------------: | :------------------: |
| Normal                 | Normal |    monotonic    |       analytic       |
| Discrete               | Normal |    monotonic    |       analytic       |
| Normal                 | Cauchy |    monotonic    |          ?           |
| Discrete               | Cauchy |  non-monotonic  |       analytic       |
| Spike-and-uniform slab | Normal |  non-monotonic  |     not analytic     |
| Spike-and-uniform slab | Cauchy |  non-monotonic  |       analytic       | -->


<!-- Tweedie's formula.
: Tweedie's formula gives us the posterior from the empirical distribution as long as the noise is from an exponential family. First we'll do it with Normal noise: we observe $x=v+u$, signal $v$ is drawn from some distribution $g$ and noise is Normal:
   $$\begin{aligned}
      v \sim g(.) \text{  and  } x|v \sim N(v,\sigma^2) \\
   \end{aligned}$$
: Tweedie tells us:
   $$E[v|x] = x + \sigma^2 \frac{d}{dx}\log f(x)$$

: We want to find non-monotonicities:
   $$\begin{aligned}
      \frac{dE[v|x]}{dx} = 1 + \sigma^2 \frac{d^2}{dx^2}\log f(x) &< 0 \\
      \frac{d^2}{dx^2}\log f(x) &< -\frac{1}{\sigma^2} 
   \end{aligned}$$
: So we'll get non-monotonicities in the neighborhood of highly concave parts of the empirical distribution of observations. 

HOWEVER -- it might be that even if g(.) is pointwise distribution there's still not a non-montonicity. 

-->
