
@article{bai2022constitutional,
  title   = {Constitutional ai: Harmlessness from ai feedback},
  author  = {Bai, Yuntao and Kadavath, Saurav and Kundu, Sandipan and Askell, Amanda and Kernion, Jackson and Jones, Andy and Chen, Anna and Goldie, Anna and Mirhoseini, Azalia and McKinnon, Cameron and others},
  journal = {arXiv preprint arXiv:2212.08073},
  year    = {2022}
}

@misc{bai2023persuade,
  title     = {Artificial Intelligence Can Persuade Humans on Political Issues},
  url       = {osf.io/stakv},
  doi       = {10.31219/osf.io/stakv},
  publisher = {OSF Preprints},
  author    = {Bai, Hui and Voelkel, Jan G and Eichstaedt, johannes C and Willer, Robb},
  year      = {2023},
  month     = {Feb}
}


@article{bowman2023eight,
  title   = {Eight things to know about large language models},
  author  = {Bowman, Samuel R},
  journal = {arXiv preprint arXiv:2304.00612},
  year    = {2023}
}

@misc{chen2022profanity,
  title  = {Holy $#!t: Are popular toxicity models simply profanity detectors?},
  author = {Edwin Chen},
  year   = {2022},
  url    = {https://www.surgehq.ai/blog/are-popular-toxicity-models-simply-profanity-detectors}
}

@article{cundy2023sequencematch,
  title   = {SequenceMatch: Imitation Learning for Autoregressive Sequence Modelling with Backtracking},
  author  = {Cundy, Chris and Ermon, Stefano},
  journal = {arXiv preprint arXiv:2306.05426},
  year    = {2023}
}

@misc{cunningham2023ranking,
  year   = {2023},
  author = {Tom Cunningham},
  title  = {Ranking by Engagement},
  url    = {http://tecunningham.github.io/2023-04-28-ranking-by-engagement.html}
}

@misc{evgeniou2023navigating,
  url    = {https://knowledge.insead.edu/operations/navigating-trust-and-safety-world-generative-ai},
  author = {Theodoros Evgeniou, Jeff Dunn and Alice Hunsberger},
  title  = {Navigating Trust and Safety in the World of Generative AI}
}

@misc{goldstein2023persuasive,
  title     = {Can AI  Write Persuasive Propaganda?},
  url       = {osf.io/preprints/socarxiv/fp87b},
  doi       = {10.31235/osf.io/fp87b},
  publisher = {SocArXiv},
  author    = {Goldstein, Josh A and Chao, Jason and Grossman, Shelby and Stamos, Alex and Tomz, Michael},
  year      = {2023},
  month     = {Apr}
}

@misc{grondahl2018need,
  title         = {All You Need is "Love": Evading Hate-speech Detection},
  author        = {Tommi Gröndahl and Luca Pajola and Mika Juuti and Mauro Conti and N. Asokan},
  year          = {2018},
  eprint        = {1808.09115},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}

@misc{hackenburg2023persuasive,
  title     = {Evaluating the persuasive influence of political microtargeting with large language models},
  url       = {osf.io/wnt8b},
  doi       = {10.31219/osf.io/wnt8b},
  publisher = {OSF Preprints},
  author    = {Hackenburg, Kobi and Margetts, Helen},
  year      = {2023},
  month     = {Aug}
}

@inproceedings{han2020fortifying,
  title     = {Fortifying Toxic Speech Detectors Against Veiled Toxicity},
  author    = {Han, Xiaochuang  and
               Tsvetkov, Yulia},
  booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  month     = nov,
  year      = {2020},
  address   = {Online},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2020.emnlp-main.622},
  doi       = {10.18653/v1/2020.emnlp-main.622},
  pages     = {7732--7739},
  abstract  = {Modern toxic speech detectors are incompetent in recognizing disguised offensive language, such as adversarial attacks that deliberately avoid known toxic lexicons, or manifestations of implicit bias. Building a large annotated dataset for such veiled toxicity can be very expensive. In this work, we propose a framework aimed at fortifying existing toxic speech detectors without a large labeled corpus of veiled toxicity. Just a handful of probing examples are used to surface orders of magnitude more disguised offenses. We augment the toxic speech detector{'}s training data with these discovered offensive examples, thereby making it more robust to veiled toxicity while preserving its utility in detecting overt toxicity.}
}


@article{hendrycks2021measuring,
  title   = {Measuring mathematical problem solving with the math dataset},
  author  = {Hendrycks, Dan and Burns, Collin and Kadavath, Saurav and Arora, Akul and Basart, Steven and Tang, Eric and Song, Dawn and Steinhardt, Jacob},
  journal = {arXiv preprint arXiv:2103.03874},
  year    = {2021}
}

@misc{heiner2022toxic,
  url    = {https://www.surgehq.ai/blog/25-examples-of-twitters-content-moderation-failures},
  year   = {2022},
  author = {Scott Heiner},
  title  = {Real-World ML Failures: The Violence, Racism, and Sexism Uncaught by Twitter's Content Moderation Systems}
}

@article{Jungherr2023artificial,
  author   = {Jungherr, Andreas and Schroeder, Ralph},
  title    = {{Artificial intelligence and the public arena}},
  journal  = {Communication Theory},
  volume   = {33},
  number   = {2-3},
  pages    = {164-173},
  year     = {2023},
  month    = {06},
  abstract = {{The public arena relies on artificial intelligence (AI) to ever greater degrees. Media structures hosting the public arena—such as Facebook, TikTok, Twitter, and YouTube—increasingly rely on AI-enabled applications to shape information environments, autonomously generate content, and communicate with people. These applications affect the public arena’s functions: make society visible to itself and provide spaces for the formation of publics and counterpublics. We offer a framework that allows for the conceptualization and empirical examination of AI’s structural impact on the public arena. Based on this perspective, we argue that the growing uses of AI will lead to a strengthening of intermediary structures that can exercise a greater degree of control over the public arena. In addition, the data-driven nature of most AI-applications threatens to push challenges to the political status quo out of sight and obstruct the assessability of AI-enabled interventions.}},
  issn     = {1468-2885},
  doi      = {10.1093/ct/qtad006},
  url      = {https://doi.org/10.1093/ct/qtad006},
  eprint   = {https://academic.oup.com/ct/article-pdf/33/2-3/164/50997940/qtad006.pdf}
}

@misc{kapoor2023prepare,
  url    = {https://knightcolumbia.org/content/how-to-prepare-for-the-deluge-of-generative-ai-on-social-media},
  author = {Sayash Kapoor & Arvind Narayanan},
  title  = {How to Prepare for the Deluge of Generative AI on Social Media},
  year   = {2023},
  month  = {06}
}


@article{kiela2021dynabench,
  title   = {Dynabench: Rethinking benchmarking in NLP},
  author  = {Kiela, Douwe and Bartolo, Max and Nie, Yixin and Kaushik, Divyansh and Geiger, Atticus and Wu, Zhengxuan and Vidgen, Bertie and Prasad, Grusha and Singh, Amanpreet and Ringshia, Pratik and others},
  journal = {arXiv preprint arXiv:2104.14337},
  year    = {2021}
}

@article{kiela2023plottingprogress,
  author  = {Kiela, Douwe and Thrush, Tristan and Ethayarajh, Kawin and Singh, Amanpreet},
  title   = {Plotting Progress in AI},
  journal = {Contextual AI Blog},
  year    = {2023},
  note    = {https://contextual.ai/blog/plotting-progress}
}

@article{koivisto2023creativity,
  abstract      = {Creativity has traditionally been considered an ability exclusive to human beings. However, the rapid development of artificial intelligence (AI) has resulted in generative AI chatbots that can produce high-quality artworks, raising questions about the differences between human and machine creativity. In this study, we compared the creativity of humans (n = 256) with that of three current AI chatbots using the alternate uses task (AUT), which is the most used divergent thinking task. Participants were asked to generate uncommon and creative uses for everyday objects. On average, the AI chatbots outperformed human participants. While human responses included poor-quality ideas, the chatbots generally produced more creative responses. However, the best human ideas still matched or exceed those of the chatbots. While this study highlights the potential of AI as a tool to enhance creativity, it also underscores the unique and complex nature of human creativity that may be difficult to fully replicate or surpass with AI technology. The study provides insights into the relationship between human and machine creativity, which is related to important questions about the future of creative work in the age of AI.},
  author        = {Koivisto, Mika and Grassini, Simone},
  date          = {2023/09/14},
  date-added    = {2023-09-15 12:08:16 -0700},
  date-modified = {2023-09-15 12:08:16 -0700},
  doi           = {10.1038/s41598-023-40858-3},
  id            = {Koivisto2023},
  isbn          = {2045-2322},
  journal       = {Scientific Reports},
  number        = {1},
  pages         = {13601},
  title         = {Best humans still outperform artificial intelligence in a creative divergent thinking task},
  url           = {https://doi.org/10.1038/s41598-023-40858-3},
  volume        = {13},
  year          = {2023},
  bdsk-url-1    = {https://doi.org/10.1038/s41598-023-40858-3}
}

@inproceedings{lees2021capturing,
  title     = {Capturing Covertly Toxic Speech via Crowdsourcing},
  author    = {Lees, Alyssa  and
               Borkan, Daniel  and
               Kivlichan, Ian  and
               Nario, Jorge  and
               Goyal, Tesh},
  booktitle = {Proceedings of the First Workshop on Bridging Human{--}Computer Interaction and Natural Language Processing},
  month     = apr,
  year      = {2021},
  address   = {Online},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2021.hcinlp-1.3},
  pages     = {14--20},
  abstract  = {We study the task of labeling covert or veiled toxicity in online conversations. Prior research has highlighted the difficulty in creating language models that recognize nuanced toxicity such as microaggressions. Our investigations further underscore the difficulty in parsing such labels reliably from raters via crowdsourcing. We introduce an initial dataset, COVERTTOXICITY, which aims to identify and categorize such comments from a refined rater template. Finally, we fine-tune a comment-domain BERT model to classify covertly offensive comments and compare against existing baselines.}
}

@article{lee2023rlaif,
  title   = {RLAIF: Scaling Reinforcement Learning from Human Feedback with AI Feedback},
  author  = {Lee, Harrison and Phatale, Samrat and Mansoor, Hassan and Lu, Kellie and Mesnard, Thomas and Bishop, Colton and Carbune, Victor and Rastogi, Abhinav},
  journal = {arXiv preprint arXiv:2309.00267},
  year    = {2023}
}

@misc{weng2023gpt4moderation,
  title  = {Using GPT-4 for content moderation},
  author = {Lilian Weng and Vik Goel and Andrea Vallone},
  year   = {2023},
  url    = {https://openai.com/blog/using-gpt-4-for-content-moderation}
}

@inproceedings{whitlocklees2022perspective,
  title  = {A New Generation of Perspective API: Efficient Multilingual Character-level Transformers},
  author = {Alyssa Whitlock Lees and Vinh Q. Tran and Yi Tay and Jeffrey Scott Sorensen and Jai Gupta and Donald Metzler and Lucy Vasserman},
  year   = {2022},
  url    = {https://dl.acm.org/doi/10.1145/3534678.3539147}
}


@misc{matz2023personalized,
  title     = {The Potential of Generative AI for Personalized Persuasion at Scale},
  url       = {psyarxiv.com/rn97c},
  doi       = {10.31234/osf.io/rn97c},
  publisher = {PsyArXiv},
  author    = {Matz, Sandra and Teeny, Jake and Vaid, Sumer S and Harari, Gabriella M and Cerf, Moran},
  year      = {2023},
  month     = {Apr}
}

@article{ouyang2022training,
  title   = {Training language models to follow instructions with human feedback},
  author  = {Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal = {Advances in Neural Information Processing Systems},
  volume  = {35},
  pages   = {27730--27744},
  year    = {2022}
}

@techreport{palmer2023large,
  title       = {Large Language Models Can Argue in Convincing and Novel Ways About Politics: Evidence from Experiments and Human Judgement},
  author      = {Palmer, Alexis and Spirling, Arthur},
  year        = {2023},
  institution = {Working paper), Technical report}
}

@misc{qin2023large,
  title         = {Large Language Models are Effective Text Rankers with Pairwise Ranking Prompting},
  author        = {Zhen Qin and Rolf Jagerman and Kai Hui and Honglei Zhuang and Junru Wu and Jiaming Shen and Tianqi Liu and Jialu Liu and Donald Metzler and Xuanhui Wang and Michael Bendersky},
  year          = {2023},
  eprint        = {2306.17563},
  archiveprefix = {arXiv},
  primaryclass  = {cs.IR}
}

@misc{searles2023empirical,
  title         = {An Empirical Study & Evaluation of Modern CAPTCHAs},
  author        = {Andrew Searles and Yoshimichi Nakatsuka and Ercan Ozturk and Andrew Paverd and Gene Tsudik and Ai Enkoji},
  year          = {2023},
  eprint        = {2307.12108},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CR}
}

@article{tedeschi2023s,
  title   = {What's the Meaning of Superhuman Performance in Today's NLU?},
  author  = {Tedeschi, Simone and Bos, Johan and Declerck, Thierry and Hajic, Jan and Hershcovich, Daniel and Hovy, Eduard H and Koller, Alexander and Krek, Simon and Schockaert, Steven and Sennrich, Rico and others},
  journal = {arXiv preprint arXiv:2305.08414},
  year    = {2023}
}

@article{thiel2023generative,
  title  = {Generative ML and CSAM: Implications and Mitigations},
  author = {Thiel, David and Stroebel, Melissa and Portnoff, Rebecca},
  year   = {2023}
}