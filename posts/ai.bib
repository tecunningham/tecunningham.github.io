
@misc{armengolestape2021multilingual,
  title         = {On the Multilingual Capabilities of Very Large-Scale English Language Models},
  author        = {Jordi Armengol-Estapé and Ona de Gibert Bonet and Maite Melero},
  year          = {2021},
  eprint        = {2108.13349},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}


@article{towler2023facial,
  abstract      = {Facial recognition errors can jeopardize national security, criminal justice, public safety and civil rights. Here, we compare the most accurate humans and facial recognition technology in a detailed lab-based evaluation and international proficiency test for forensic scientists involving 27 forensic departments from 14 countries. We find striking cognitive and perceptual diversity between naturally skilled super-recognizers, trained forensic examiners and deep neural networks, despite them achieving equivalent accuracy. Clear differences emerged in super-recognizers'and forensic examiners'perceptual processing, errors, and response patterns: super-recognizers were fast, biased to respond `same person'and misidentified people with extreme confidence, whereas forensic examiners were slow, unbiased and strategically avoided misidentification errors. Further, these human experts and deep neural networks disagreed on the similarity of faces, pointing to differences in their representations of faces. Our findings therefore reveal multiple types of facial recognition expertise, with each type lending itself to particular facial recognition roles in operational settings. Finally, we show that harnessing the diversity between individual experts provides a robust method of maximizing facial recognition accuracy. This can be achieved either via collaboration between experts in forensic laboratories, or most promisingly, by statistical fusion of match scores provided by different types of expert.},
  author        = {Towler, Alice and Dunn, James D. and Castro Mart{\'\i}nez, Sergio and Moreton, Reuben and Ekl{\"o}f, Fredrick and Ruifrok, Arnout and Kemp, Richard I. and White, David},
  date          = {2023/07/14},
  date-added    = {2023-10-07 06:55:09 -0700},
  date-modified = {2023-10-07 06:55:09 -0700},
  doi           = {10.1038/s41598-023-28632-x},
  id            = {Towler2023},
  isbn          = {2045-2322},
  journal       = {Scientific Reports},
  number        = {1},
  pages         = {11396},
  title         = {Diverse types of expertise in facial recognition},
  url           = {https://doi.org/10.1038/s41598-023-28632-x},
  volume        = {13},
  year          = {2023},
  bdsk-url-1    = {https://doi.org/10.1038/s41598-023-28632-x}
}


@article{bai2022constitutional,
  title   = {Constitutional ai: Harmlessness from ai feedback},
  author  = {Bai, Yuntao and Kadavath, Saurav and Kundu, Sandipan and Askell, Amanda and Kernion, Jackson and Jones, Andy and Chen, Anna and Goldie, Anna and Mirhoseini, Azalia and McKinnon, Cameron and others},
  journal = {arXiv preprint arXiv:2212.08073},
  year    = {2022}
}

@misc{bai2023persuade,
  title     = {Artificial Intelligence Can Persuade Humans on Political Issues},
  url       = {osf.io/stakv},
  doi       = {10.31219/osf.io/stakv},
  publisher = {OSF Preprints},
  author    = {Bai, Hui and Voelkel, Jan G and Eichstaedt, johannes C and Willer, Robb},
  year      = {2023},
  month     = {Feb}
}

@article{bowman2023eight,
  title   = {Eight things to know about large language models},
  author  = {Bowman, Samuel R},
  journal = {arXiv preprint arXiv:2304.00612},
  year    = {2023}
}

@inproceedings{camerer1991processperformance,
  title  = {The process-performance paradox in expert judgment - How can experts know so much and predict so badly?},
  author = {Colin Camerer and Eric J. Johnson},
  year   = {1991},
  url    = {https://api.semanticscholar.org/CorpusID:67971809}
}

@misc{chen2022profanity,
  title  = {Holy $#!t: Are popular toxicity models simply profanity detectors?},
  author = {Edwin Chen},
  year   = {2022},
  url    = {https://www.surgehq.ai/blog/are-popular-toxicity-models-simply-profanity-detectors}
}

@article{cundy2023sequencematch,
  title   = {SequenceMatch: Imitation Learning for Autoregressive Sequence Modelling with Backtracking},
  author  = {Cundy, Chris and Ermon, Stefano},
  journal = {arXiv preprint arXiv:2306.05426},
  year    = {2023}
}

@article{cunningham2015hierarchical,
  title   = {Hierarchical aggregation of information and decision-making},
  author  = {Cunningham, Tom},
  journal = {Unpublished Manuscript, Columbia University},
  year    = {2015}
}

@article{cunningham2022implicit,
  title     = {Implicit preferences},
  author    = {Cunningham, Tom and De Quidt, Jonathan},
  year      = {2022},
  publisher = {CEPR Discussion Paper No. DP17343},
  url       = {http://jondequidt.com/pdfs/paper_implicit.pdf}
}

@misc{cunningham2023ranking,
  year   = {2023},
  author = {Tom Cunningham},
  title  = {Ranking by Engagement},
  url    = {http://tecunningham.github.io/2023-04-28-ranking-by-engagement.html}
}

@article{dijkstra2005foolishness,
  title     = {On the foolishness of “natural language programming”},
  author    = {Dijkstra, Edsger W},
  journal   = {Program Construction: International Summer School},
  pages     = {51--53},
  year      = {2005},
  publisher = {Springer}
}

@misc{evgeniou2023navigating,
  url    = {https://knowledge.insead.edu/operations/navigating-trust-and-safety-world-generative-ai},
  author = {Theodoros Evgeniou, Jeff Dunn and Alice Hunsberger},
  title  = {Navigating Trust and Safety in the World of Generative AI}
}

@misc{goldstein2023persuasive,
  title     = {Can AI  Write Persuasive Propaganda?},
  url       = {osf.io/preprints/socarxiv/fp87b},
  doi       = {10.31235/osf.io/fp87b},
  publisher = {SocArXiv},
  author    = {Goldstein, Josh A and Chao, Jason and Grossman, Shelby and Stamos, Alex and Tomz, Michael},
  year      = {2023},
  month     = {Apr}
}

@misc{grondahl2018need,
  title         = {All You Need is "Love": Evading Hate-speech Detection},
  author        = {Tommi Gröndahl and Luca Pajola and Mika Juuti and Mauro Conti and N. Asokan},
  year          = {2018},
  eprint        = {1808.09115},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}

@misc{hackenburg2023persuasive,
  title     = {Evaluating the persuasive influence of political microtargeting with large language models},
  url       = {osf.io/wnt8b},
  doi       = {10.31219/osf.io/wnt8b},
  publisher = {OSF Preprints},
  author    = {Hackenburg, Kobi and Margetts, Helen},
  year      = {2023},
  month     = {Aug}
}

@inproceedings{han2020fortifying,
  title     = {Fortifying Toxic Speech Detectors Against Veiled Toxicity},
  author    = {Han, Xiaochuang  and
               Tsvetkov, Yulia},
  booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  month     = nov,
  year      = {2020},
  address   = {Online},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2020.emnlp-main.622},
  doi       = {10.18653/v1/2020.emnlp-main.622},
  pages     = {7732--7739},
  abstract  = {Modern toxic speech detectors are incompetent in recognizing disguised offensive language, such as adversarial attacks that deliberately avoid known toxic lexicons, or manifestations of implicit bias. Building a large annotated dataset for such veiled toxicity can be very expensive. In this work, we propose a framework aimed at fortifying existing toxic speech detectors without a large labeled corpus of veiled toxicity. Just a handful of probing examples are used to surface orders of magnitude more disguised offenses. We augment the toxic speech detector{'}s training data with these discovered offensive examples, thereby making it more robust to veiled toxicity while preserving its utility in detecting overt toxicity.}
}


@misc{heiner2022toxic,
  url    = {https://www.surgehq.ai/blog/25-examples-of-twitters-content-moderation-failures},
  year   = {2022},
  author = {Scott Heiner},
  title  = {Real-World ML Failures: The Violence, Racism, and Sexism Uncaught by Twitter's Content Moderation Systems}
}

@article{hendrycks2021measuring,
  title   = {Measuring mathematical problem solving with the math dataset},
  author  = {Hendrycks, Dan and Burns, Collin and Kadavath, Saurav and Arora, Akul and Basart, Steven and Tang, Eric and Song, Dawn and Steinhardt, Jacob},
  journal = {arXiv preprint arXiv:2103.03874},
  year    = {2021}
}

@article{Jungherr2023artificial,
  author   = {Jungherr, Andreas and Schroeder, Ralph},
  title    = {{Artificial intelligence and the public arena}},
  journal  = {Communication Theory},
  volume   = {33},
  number   = {2-3},
  pages    = {164-173},
  year     = {2023},
  month    = {06},
  abstract = {{The public arena relies on artificial intelligence (AI) to ever greater degrees. Media structures hosting the public arena—such as Facebook, TikTok, Twitter, and YouTube—increasingly rely on AI-enabled applications to shape information environments, autonomously generate content, and communicate with people. These applications affect the public arena’s functions: make society visible to itself and provide spaces for the formation of publics and counterpublics. We offer a framework that allows for the conceptualization and empirical examination of AI’s structural impact on the public arena. Based on this perspective, we argue that the growing uses of AI will lead to a strengthening of intermediary structures that can exercise a greater degree of control over the public arena. In addition, the data-driven nature of most AI-applications threatens to push challenges to the political status quo out of sight and obstruct the assessability of AI-enabled interventions.}},
  issn     = {1468-2885},
  doi      = {10.1093/ct/qtad006},
  url      = {https://doi.org/10.1093/ct/qtad006},
  eprint   = {https://academic.oup.com/ct/article-pdf/33/2-3/164/50997940/qtad006.pdf}
}

@misc{kapoor2023prepare,
  url    = {https://knightcolumbia.org/content/how-to-prepare-for-the-deluge-of-generative-ai-on-social-media},
  author = {Sayash Kapoor & Arvind Narayanan},
  title  = {How to Prepare for the Deluge of Generative AI on Social Media},
  year   = {2023},
  month  = {06}
}


@article{kiela2021dynabench,
  title   = {Dynabench: Rethinking benchmarking in NLP},
  author  = {Kiela, Douwe and Bartolo, Max and Nie, Yixin and Kaushik, Divyansh and Geiger, Atticus and Wu, Zhengxuan and Vidgen, Bertie and Prasad, Grusha and Singh, Amanpreet and Ringshia, Pratik and others},
  journal = {arXiv preprint arXiv:2104.14337},
  year    = {2021}
}

@article{kiela2023plottingprogress,
  author  = {Kiela, Douwe and Thrush, Tristan and Ethayarajh, Kawin and Singh, Amanpreet},
  title   = {Plotting Progress in AI},
  journal = {Contextual AI Blog},
  year    = {2023},
  note    = {https://contextual.ai/blog/plotting-progress}
}

@article{koivisto2023creativity,
  abstract      = {Creativity has traditionally been considered an ability exclusive to human beings. However, the rapid development of artificial intelligence (AI) has resulted in generative AI chatbots that can produce high-quality artworks, raising questions about the differences between human and machine creativity. In this study, we compared the creativity of humans (n = 256) with that of three current AI chatbots using the alternate uses task (AUT), which is the most used divergent thinking task. Participants were asked to generate uncommon and creative uses for everyday objects. On average, the AI chatbots outperformed human participants. While human responses included poor-quality ideas, the chatbots generally produced more creative responses. However, the best human ideas still matched or exceed those of the chatbots. While this study highlights the potential of AI as a tool to enhance creativity, it also underscores the unique and complex nature of human creativity that may be difficult to fully replicate or surpass with AI technology. The study provides insights into the relationship between human and machine creativity, which is related to important questions about the future of creative work in the age of AI.},
  author        = {Koivisto, Mika and Grassini, Simone},
  date          = {2023/09/14},
  date-added    = {2023-09-15 12:08:16 -0700},
  date-modified = {2023-09-15 12:08:16 -0700},
  doi           = {10.1038/s41598-023-40858-3},
  id            = {Koivisto2023},
  isbn          = {2045-2322},
  journal       = {Scientific Reports},
  number        = {1},
  pages         = {13601},
  title         = {Best humans still outperform artificial intelligence in a creative divergent thinking task},
  url           = {https://doi.org/10.1038/s41598-023-40858-3},
  volume        = {13},
  year          = {2023},
  bdsk-url-1    = {https://doi.org/10.1038/s41598-023-40858-3}
}

@article{lee2023rlaif,
  title   = {RLAIF: Scaling Reinforcement Learning from Human Feedback with AI Feedback},
  author  = {Lee, Harrison and Phatale, Samrat and Mansoor, Hassan and Lu, Kellie and Mesnard, Thomas and Bishop, Colton and Carbune, Victor and Rastogi, Abhinav},
  journal = {arXiv preprint arXiv:2309.00267},
  year    = {2023}
}

@inproceedings{lees2021capturing,
  title     = {Capturing Covertly Toxic Speech via Crowdsourcing},
  author    = {Lees, Alyssa  and
               Borkan, Daniel  and
               Kivlichan, Ian  and
               Nario, Jorge  and
               Goyal, Tesh},
  booktitle = {Proceedings of the First Workshop on Bridging Human{--}Computer Interaction and Natural Language Processing},
  month     = apr,
  year      = {2021},
  address   = {Online},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2021.hcinlp-1.3},
  pages     = {14--20},
  abstract  = {We study the task of labeling covert or veiled toxicity in online conversations. Prior research has highlighted the difficulty in creating language models that recognize nuanced toxicity such as microaggressions. Our investigations further underscore the difficulty in parsing such labels reliably from raters via crowdsourcing. We introduce an initial dataset, COVERTTOXICITY, which aims to identify and categorize such comments from a refined rater template. Finally, we fine-tune a comment-domain BERT model to classify covertly offensive comments and compare against existing baselines.}
}

@article{macdougall1904recognition,
  title   = {Recognition and recall},
  author  = {MacDougall, Robert},
  journal = {The Journal of Philosophy, Psychology and Scientific Methods},
  volume  = {1},
  number  = {9},
  pages   = {229--233},
  year    = {1904}
}

@misc{matz2023personalized,
  title     = {The Potential of Generative AI for Personalized Persuasion at Scale},
  url       = {psyarxiv.com/rn97c},
  doi       = {10.31234/osf.io/rn97c},
  publisher = {PsyArXiv},
  author    = {Matz, Sandra and Teeny, Jake and Vaid, Sumer S and Harari, Gabriella M and Cerf, Moran},
  year      = {2023},
  month     = {Apr}
}

@article{ouyang2022training,
  title   = {Training language models to follow instructions with human feedback},
  author  = {Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal = {Advances in Neural Information Processing Systems},
  volume  = {35},
  pages   = {27730--27744},
  year    = {2022}
}

@techreport{palmer2023large,
  title       = {Large Language Models Can Argue in Convincing and Novel Ways About Politics: Evidence from Experiments and Human Judgement},
  author      = {Palmer, Alexis and Spirling, Arthur},
  year        = {2023},
  institution = {Working paper), Technical report}
}

@misc{qin2023large,
  title         = {Large Language Models are Effective Text Rankers with Pairwise Ranking Prompting},
  author        = {Zhen Qin and Rolf Jagerman and Kai Hui and Honglei Zhuang and Junru Wu and Jiaming Shen and Tianqi Liu and Jialu Liu and Donald Metzler and Xuanhui Wang and Michael Bendersky},
  year          = {2023},
  eprint        = {2306.17563},
  archiveprefix = {arXiv},
  primaryclass  = {cs.IR}
}

@misc{searles2023empirical,
  title         = {An Empirical Study & Evaluation of Modern CAPTCHAs},
  author        = {Andrew Searles and Yoshimichi Nakatsuka and Ercan Ozturk and Andrew Paverd and Gene Tsudik and Ai Enkoji},
  year          = {2023},
  eprint        = {2307.12108},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CR}
}

@article{simon2023misinformation,
  title   = {Misinformation reloaded? Fears about the impact of generative AI on misinformation are overblown},
  author  = {Simon, Felix M and Altay, Sacha and Mercier, Hugo},
  journal = {Harvard Kennedy School Misinformation Review},
  year    = {2023}
}


@misc{stiennon2022learning,
  title         = {Learning to summarize from human feedback},
  author        = {Nisan Stiennon and Long Ouyang and Jeff Wu and Daniel M. Ziegler and Ryan Lowe and Chelsea Voss and Alec Radford and Dario Amodei and Paul Christiano},
  year          = {2022},
  eprint        = {2009.01325},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}

@article{tedeschi2023s,
  title   = {What's the Meaning of Superhuman Performance in Today's NLU?},
  author  = {Tedeschi, Simone and Bos, Johan and Declerck, Thierry and Hajic, Jan and Hershcovich, Daniel and Hovy, Eduard H and Koller, Alexander and Krek, Simon and Schockaert, Steven and Sennrich, Rico and others},
  journal = {arXiv preprint arXiv:2305.08414},
  year    = {2023}
}

@article{thiel2023generative,
  title  = {Generative ML and CSAM: Implications and Mitigations},
  author = {Thiel, David and Stroebel, Melissa and Portnoff, Rebecca},
  year   = {2023}
}

@misc{weng2023gpt4moderation,
  title  = {Using GPT-4 for content moderation},
  author = {Lilian Weng and Vik Goel and Andrea Vallone},
  year   = {2023},
  url    = {https://openai.com/blog/using-gpt-4-for-content-moderation}
}

@inproceedings{whitlocklees2022perspective,
  title  = {A New Generation of Perspective API: Efficient Multilingual Character-level Transformers},
  author = {Alyssa Whitlock Lees and Vinh Q. Tran and Yi Tay and Jeffrey Scott Sorensen and Jai Gupta and Donald Metzler and Lucy Vasserman},
  year   = {2022},
  url    = {https://dl.acm.org/doi/10.1145/3534678.3539147}
}

@article{zhang2023multimodal,
  title   = {Multimodal chain-of-thought reasoning in language models},
  author  = {Zhang, Zhuosheng and Zhang, Aston and Li, Mu and Zhao, Hai and Karypis, George and Smola, Alex},
  journal = {arXiv preprint arXiv:2302.00923},
  year    = {2023}
}