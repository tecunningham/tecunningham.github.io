
$$\bm{a}$$

$$\xymatrix{a&b}$$

**PRIORITY**

# heading 1


asdfjkl

#  heading 2



# heading 3

$$\begin{aligned}
   P(x_i=1|spam) &= p \\ 
   P(x_i=1|nonspam) &= .5 \\
   P(spam|x_i=1) &= \frac{p\mu}{p\mu+.5(1-\mu)}\\
   P(spam|x_i=0) &= \frac{(1-p)\mu}{(1-p)\mu+.5(1-\mu)}\\\\
   P(m\text{ of }n|spam) &= \frac{p^m(1-p)^{n-m}\mu}{p^m(1-p)^{n-m}\mu+.5^m(1-\mu)}
\end{aligned}
$$


# heading 4


##       Bender et al., Stochastic Parrots

Bender, Gebru, McMillan-Major, Mitchell (2021, FAccT) ["On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?"](https://dl.acm.org/doi/pdf/10.1145/3442188.3445922)

   > "LMs are not performing natural language understanding (NLU), and only have success in tasks that can be approached by manipulating linguistic form [14]. "

   > "the tendency of human interlocutors to impute meaning where there is none can mislead both NLP researchers and the general public into taking synthetic text as meaningful."

   > "Combined with the ability of LMs to pick up on both subtle biases and overtly abusive language patterns in training data, this leads to risks of harms, including encountering derogatory language and experiencing discrimination at the hands of others who reproduce racist, sexist, ableist, extremist or other harmful ideologies reinforced through interactions with synthetic language."

   **Coherence in the Eye of the Beholder.** It produces "apparently" coherent text but not really coherent.

   **Risks and Harms.** Generally: absorbing hegemonic worldview. E.g.:
      1. Assuming doctor will be male, nurse female;
      2. Outputting abusive language; 
      3. Generate meaningless text & used, e.g., to recruit terrorists.
      
      Especially this point: *apparent* fluency will mislead people into thinking that there's some genuine content.
      
      > *"the human tendency to attribute meaning to text, in combination with large LMs’ ability to learn patterns of forms that humans associate with various biases and other harmful attitudes, leads to risks of real-world harm."*

   **Also discuss environmental cost.**

   **Proposal.** Value-sensitive design.

2023-02: Goldstein et al. ["Generative Language Models and Automated Influence Operations: Emerging Threats and Potential Mitigations"](https://cdn.openai.com/papers/forecasting-misuse.pdf) 
   - ![](images/2023-02-07-17-15-00.png)

- [Arms race in google search SEO](https://www.theverge.com/23753963/google-seo-shopify-small-business-ai)

Low trust in the 19th century:

  - David Henkin book: in 19th century NY 40pct of banknotes circulating were fake.
  - Adulterated foods
  - Partisan news

Benson (2023, Wired) ["Humans Aren’t Mentally Ready for an AI-Saturated ‘Post-Truth World’"](https://www.wired.com/story/generative-ai-deepfakes-disinformation-psychology/) --- quotes from psychologists saying things like "Anxiety is just going to ratchet up as we’re faced with this unknown thing in our world."

Alex Rosenblatt (2023) ["Human Review is no Longer the Gold Standard"](https://www.linkedin.com/posts/alexrosenblatt_human-review-is-no-longer-the-gold-standard-activity-7083957264402808832-QjYV)

Prediction that LLMs will be used for Spear Phishing: https://twitter.com/emollick/status/1681374663505575936

Glukhov et al. (2023) [LLM CENSORSHIP: A MACHINE LEARNING CHALLENGE OR A COMPUTER SECURITY PROBLEM?](https://www.cl.cam.ac.uk/~is410/Papers/llm_censorship.pdf)



# heading 5


- https://www.metaculus.com/questions/10955/ai-generated-film-ranked-1-in-streaming/
- https://www.metaculus.com/questions/17447/ai-generated-movie-accomplishments/
- https://www.metaculus.com/questions/8403/25-top-100-songs-made-by-ai-by-2050/ -->



**Each questions asks the probability of significant intentional damage caused with the use of AI.** 

**I think a reasonable starting point would be 50% of the historical base-rate of each type of damage.** Assume (1) AI will help attackers and defenders about equally, so total successful attacks will be constant; (2) AI will be used in 50% of successful attacks. Then we'd expect the future rate of AI-assisted successful attacks to be 50% of the historical rate of total successful attacks.

**There have been many substantial prior technological shifts:** postal service, photographs, newspapers, telegraph, telephone, television, internet. Each helped both defenders and attackers.

## Will a deepfake cause damage & make the front page of a major news source in 2023?    10%

The technology to create "deepfakes" started to emerge around 2018. (Nancy Pelosi video)

The Metaculus prediction shot up from 40% to 80% in May after a fake image of a Pentagon bombing began to circulate on Twitter.


[In 2023 will a successful deepfake attempt causing real damage make the front page of a major news source?](https://www.metaculus.com/questions/14277/deepfake-attempt-in-major-news-in-2023/)

## Will a deepfake be blamed by G20 politician for an election loss?         2025

[Will a politician claim they lost a major election due to a "deepfake" image, video, or audio recording in a G20 country before 2025?](https://www.metaculus.com/questions/17180/deepfake-costs-election-before-2025/)


## Will AI be used in an attack on infrastructure costing >$1B?           2025

[Will a infrastructure disaster costing >$1B in a G20 country be widely attributed to an AI cyberattack before 2025?](https://www.metaculus.com/questions/17179/infrastructure-disaster-from-ai-before-2025/)

## Will AI be used in a theft of intellectual property cost >$10M?        2025

[Will a theft of >$10M of intellectual property be widely attributed to an AI cyberattack before 2025?](https://www.metaculus.com/questions/17178/ip-theft-from-ai-before-2025/)

## Will AI cause a stock exchange to halt trading for >24 hours?          2025

[Will a stock exchange halt trading for >24 hours with a cause widely attributed to AI before 2025?](https://www.metaculus.com/questions/17176/ai-takes-down-stock-exchange-before-2025/)


## Will AI be used in a major attack on voting systems in G20?            2025

[Will a major attack on voting systems in a G20 country be widely attributed to an AI before 2025?](https://www.metaculus.com/questions/17177/election-hack-before-2025/)

## Resolved Predictions

[Will a "Deepfake" video about a national U.S. political candidate running for office in 2018 get 2M+ views?](https://www.metaculus.com/questions/1335/will-a-deepfake-video-about-a-national-us-political-candidate-running-for-office-in-2018-get-2m-views/)

Resolved No, was at 20% for a couple of months around August.

[By late 2017, will there be a wide-scale hoax be created using video-alteration technology to put words in a famous figure's mouth?](https://www.metaculus.com/questions/204/a-is-in-the-i-of-the-beholder-1-wait-is-this-video-for-real/)

Resvolved No, was 50% for a long time.


# heading 6

##    jsdfklsjadfk

asdfjdfksl

##    sdjfakfjdlks

# heading 7

```{r}
```


#           8

**A common thread unifies many of the predictions above: internal vs external properties.** I say an "internal" property of a piece of content is one where the ground truth is human judgment of that content without reference to any external facts. An "external" property depend on some external fact, e.g. about provenance of the content (who created it, how it was made), or about the accuracy of what the content claims or depicts.


| property                                        | internal/external | detection method            | obfuscation methods     |
|-------------------------------------------------|-------------------|-----------------------------|-------------------------|
| whether text contains a curse/slur              | internal          | string matching             | misspell, neologisms    |
| whether text contains criticism of government   | internal          | string matching             | indirect language       |
| whether text is match against database          | internal          | plagiarism detector (Chegg) | misspell, reword        |
| whether photo contains nudity                   | internal          |                             | add noise, transform    |
| whether media is match against database         | internal          | PhotoDNA                    | add noise, transform    |
| whether image contains a specific watermark     |                   |                             |                         |
| whether a message is signed by a public key     | internal          |                             |                         |
|                                                 |                   |                             |                         |
| whether a picture looks good                    | internal          |                             |                         |
| whether a joke is funny                         | internal          |                             |                         |
| whether user will engage (like, comment, share) | internal          |                             |                         |
|                                                 |                   |                             |                         |
| whether email is mass and unsolicited (spam)    | external          | naive Bayes                 |                         |
| whether message is from a real human (vs bot)   | external          | naive Bayes                 |                         |
| whether artwork is by a specific person         | external          |                             |                         |
| whether writing is by a specific person         | external          | stylometry                  |                         |
| whether media has been altered                  | external          |                             |                         |
| whether media is synthetic (deepfake)           | external          |                             |                         |
| whether text is generated by an LLM             | external          |                             |                         |
| whether user behavior is by a bot               | external          | CAPTCHA                     |                         |
| whether an article is misinformation            | external          |                             |                         |
| whether a photo is misleading                   | external          |                             |                         |
| whether content is retentive                    | external          |                             |                         |
| whether a web page answers a query              | external          | PageRank, embedding         | content farm, synthetic |
| whether audio matches someone's voice           | external          |                             |                         |
| whether a user is over 18                       | external          |                             |                         |
| whether nude photo subject is under 18          | external          |                             |                         |


**On-demand filtering is not the primary tool.** Even if we have highly imperfect ways of detecting a property, whether internal or external, still we can drive down prevalence through using metadata and repeated interactions, and arguably that's been the primary reason for the decline.

##          Observations on Internal Properties

- **Historically it was feasible to do filtering with human judgment.** The technology of mass media means that a small amount of content was shown to a large audience (books, magazines, radio, television, movies), which made it feasible to have a human censor who manually reviewed the majority of content. 
- **Filtering with crude classifier.** Motivated senders will be able to cheaply obfuscate their content to get around the classifier.
- **Filtering with good classifier.** Receiver will be able to filter perfectly, content will be eliminated. 
- **Selecting with crude classifier.** Suppose you want to select posts that are pretty, funny, clickable, etc.. In these cases the incentives are more likely to be aligned: I can't think of many cases where a sender wishes to be classified as having some good property, but also prefers to not actually have that property.
- **Selecting with good classifier.** This should eliminate the Goodhart problem.

##          Observations on External Properties

- **Controlling on external properties typically uses metadata.** The primary method for controlling spam is not using content-based classifiers but instead maintaining blacklists of servers: Reiley and Rao (2012) say "[t]he single most effective weapon in the spam-blocking arsenal turns out to be blacklisting an email server." Similarly for misinformation: the most effective measures have not been proactive classifiers (typically low precision, e.g. 10%) or third-party-fact checking (typically high latency). Instead it has been discouragements to posting misinformation, and changes in the overall ranking system.
- **Cryptographically signing messages.** It still means you must trust *someone*. Digital signing always had limited uptake for email and for SSL on websites: the attention tradeoff implies that it's better if an intermediary does the validation. 

##          A model of both
- There's a set of features 1,...,n, a model can be defined as the number of features that you condition on. We can then characterize three parties with an integer representing the number of features: (1) human, (2) sender, (3) receiver.
- ground truth is all features - as classifier gets better u get squeezed ; 
- sender has to hide a "1" from the classifier , gradually get squeezed ; 
- other adversarial : putting police around town to prevent crime (don't post it publicly), auditing tax returns , applying antibiotics ; (there's some dynamics : try to wipe out population). 
- key is whether sender has a constraint in state space ; but conditional independence won't hold 
- human affairs : jigsaw puzzle it's all there ; vs human things it's all empirical vs theory ;

#           8B


[ ] #1: Reduced prevalence may not be enough given scale and contagion effects across platforms. 0.001% error can still lead to significant individual or societal harm depending on the distribution esp. if fundamental sense-making and credibility norms erode
[ ] Not following the reduced censorship claim of prediction 1
[ ] Say more about the implications of #5/6 (consolidation opportunity?). Importance of info literacy and contextual info to counter in distinguishable synthetic media. Will industry standards emerge to combat this at the actor- or domain-level?
[ ] #7: optimistic assumptions around media literacy and not pessimistic enough about the risk of epistemically collapse. Outside democracies with mature and independent press, fake media risks are real and will be exploited to shape information ecosystems, gain power and distortf civic processes. We grossly overestimate the share of the population that engages in media literacy, provenance and fact checking. Podcast comment about being hopeful. Hope is grounded on the mediating role of institutions ie publishers. Leaning on journalistic standards but what if those start waning as the orgs wither and citizen journalism rises. Fact check program have been shown to be rather ineffective.
[ ] Say more on #8, isn’t plausibility the superpower of LLMs? Counter evidence from SIO already: https://youtu.be/Wbl9XU82Rc8 
[ ] Specialization is inevitable. There will be fine-tuned models trained to persuade either in general or persuade a subset of the population once sufficient training data is available. Also content persuasiveness is only one small factor in the overall success of an IO. Impersonation and concealing identity are larger factors that this new world enables. 
[ ] Implications of #9: anonymity/ pseudonymity will be increasingly rare and incumbent lock-in (not good for competition or dynamism)

#           Heading 9

- https://www.metaculus.com/questions/10955/ai-generated-film-ranked-1-in-streaming/
- https://www.metaculus.com/questions/17447/ai-generated-movie-accomplishments/
- https://www.metaculus.com/questions/8403/25-top-100-songs-made-by-ai-by-2050/ -->



**Each questions asks the probability of significant intentional damage caused with the use of AI.** 

**I think a reasonable starting point would be 50% of the historical base-rate of each type of damage.** Assume (1) AI will help attackers and defenders about equally, so total successful attacks will be constant; (2) AI will be used in 50% of successful attacks. Then we'd expect the future rate of AI-assisted successful attacks to be 50% of the historical rate of total successful attacks.

**There have been many substantial prior technological shifts:** postal service, photographs, newspapers, telegraph, telephone, television, internet. Each helped both defenders and attackers.

## Will a deepfake cause damage & make the front page of a major news source in 2023?    10%

The technology to create "deepfakes" started to emerge around 2018. (Nancy Pelosi video)

The Metaculus prediction shot up from 40% to 80% in May after a fake image of a Pentagon bombing began to circulate on Twitter.


[In 2023 will a successful deepfake attempt causing real damage make the front page of a major news source?](https://www.metaculus.com/questions/14277/deepfake-attempt-in-major-news-in-2023/)

## Will a deepfake be blamed by G20 politician for an election loss?         2025

[Will a politician claim they lost a major election due to a "deepfake" image, video, or audio recording in a G20 country before 2025?](https://www.metaculus.com/questions/17180/deepfake-costs-election-before-2025/)


## Will AI be used in an attack on infrastructure costing >$1B?           2025

[Will a infrastructure disaster costing >$1B in a G20 country be widely attributed to an AI cyberattack before 2025?](https://www.metaculus.com/questions/17179/infrastructure-disaster-from-ai-before-2025/)

## Will AI be used in a theft of intellectual property cost >$10M?        2025

[Will a theft of >$10M of intellectual property be widely attributed to an AI cyberattack before 2025?](https://www.metaculus.com/questions/17178/ip-theft-from-ai-before-2025/)

## Will AI cause a stock exchange to halt trading for >24 hours?          2025

[Will a stock exchange halt trading for >24 hours with a cause widely attributed to AI before 2025?](https://www.metaculus.com/questions/17176/ai-takes-down-stock-exchange-before-2025/)


## Will AI be used in a major attack on voting systems in G20?            2025

[Will a major attack on voting systems in a G20 country be widely attributed to an AI before 2025?](https://www.metaculus.com/questions/17177/election-hack-before-2025/)

## Resolved Predictions

[Will a "Deepfake" video about a national U.S. political candidate running for office in 2018 get 2M+ views?](https://www.metaculus.com/questions/1335/will-a-deepfake-video-about-a-national-us-political-candidate-running-for-office-in-2018-get-2m-views/)

Resolved No, was at 20% for a couple of months around August.

[By late 2017, will there be a wide-scale hoax be created using video-alteration technology to put words in a famous figure's mouth?](https://www.metaculus.com/questions/204/a-is-in-the-i-of-the-beholder-1-wait-is-this-video-for-real/)

Resvolved No, was 50% for a long time.


#              Heading 10

**Laure X Cast:** Trust in unsourced content will decline, and so network of communication will get *smaller*. You won't trust people who you don't have a direct connection with. / Laure X Cast made this argument that networks will get smaller.

**Jimmy Charité:** People who don't already have public name or public following will find it harder to get traction and influence.

**Cryptographic signing won't get widely adopted.** AI will make it easier to trick people by spoofing, e.g. spoof videos by celebrities advertising a cryptocurrency, spoof phone calls from your cousin asking for money. One response could be greater adoption of cryptographic signing to verify identity: you would have a public key for the celebrity, and for your cousin, and you would verify incoming messages against that key.


**TO ADD: documentary evidence in mundane situations.** -- E.g. using photos and videos as proof in ordinary disputes or criminal trials. 

**TO ADD: flooding journals and publishers with submission.** E.g. letters to the editor, journal submissions: can no longer use superficial coherence as a proxy for underlying quality.

**TO ADD: deeper limits on generative AI.** limits on the classifiers, types of content which they cannot recognize or cannot synthesize to human level. E.g. chess with new rules. 

**TO ADD: ambiguous / bistable content.**

**Things will get weird: chimeras:**
   - [Beast of the sea](https://en.wikipedia.org/wiki/The_Beast_(Revelation))
   - Constant conjunction ; 
   - There will be an earthquake and we will see what’s holding buildings together 