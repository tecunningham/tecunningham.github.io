% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  10pt,
  letterpaper,
  DIV=11,
  numbers=noendperiod]{scrartcl}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage[]{libertinus}
\ifPDFTeX\else  
    % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage[margin=0.75in]{geometry}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother


\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
% definitions for citeproc citations
\NewDocumentCommand\citeproctext{}{}
\NewDocumentCommand\citeproc{mm}{%
  \begingroup\def\citeproctext{#2}\cite{#1}\endgroup}
\makeatletter
 % allow citations to break across lines
 \let\@cite@ofmt\@firstofone
 % avoid brackets around text for \cite:
 \def\@biblabel#1{}
 \def\@cite#1#2{{#1\if@tempswa , #2\fi}}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2] % #1 hanging-indent, #2 entry-spacing
 {\begin{list}{}{%
  \setlength{\itemindent}{0pt}
  \setlength{\leftmargin}{0pt}
  \setlength{\parsep}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
   \setlength{\leftmargin}{\cslhangindent}
   \setlength{\itemindent}{-1\cslhangindent}
  \fi
  % set entry spacing
  \setlength{\itemsep}{#2\baselineskip}}}
 {\end{list}}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{\hfill\break\parbox[t]{\linewidth}{\strut\ignorespaces#1\strut}}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

\KOMAoption{captions}{tableheading}
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother

\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage{bookmark}

\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={LLM Time-Saving and Demand Theory},
  pdfauthor={Tom Cunningham},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}


\title{LLM Time-Saving and Demand Theory}
\author{Tom Cunningham (METR)\footnote{with many thanks to Elsie Jang}}
\date{2026-01-17}

\begin{document}
\maketitle


\begin{description}
\item[Suppose an LLM speeds you up by factor \(\beta\) on tasks that are
a share \(s\) of your time.]
What is your overall increase in output for a given time? Should we
expect it to be \(s\times(\beta-1)\), or larger or smaller?

How does the answer change if you measure the time-share \(s\) before vs
after you start using LLMs?

If we can observe the time-shares both before and after LLMs, does that
help with estimating the overall efficiency gain?
\item[Economic theory has crisp answers to these questions.]
These questions are all equivalent to classic economic questions of how
people change expenditure in response to changes in prices. Below I give
a cheat sheet, a lookup table, derivations, and some brief survey of
different relevant literatures (there are surprisingly many related
literatures).
\item[My guess is that LLMs are mostly substitutes.]
LLMs let me complete 16 hours of work in an 8 hour day, but the LLM is
mostly accelerating me on things that I wouldn't otherwise spend my time
on (e.g.~fact checking, literature reviews, visualizations), meaning
they are substitutes, and so my effective productivity lift is much
lower than a doubling of time.
\end{description}

\subsection{Cheat Sheet}\label{cheat-sheet}

\begin{description}
\item[Assume people spend their time rationally.]
We will assume people allocate time between sped-up and non-sped-up
tasks rationally, trying to maximize their overall output.
\item[The output gain will be between \(\frac{1}{(1-s)+s/\beta}\) and
\(\beta\).]
We can put upper and lower bounds on the effect on aggregate output (for
a fixed time input):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  If the tasks are perfect substitutes: \(\beta\).
\item
  If the tasks are perfect complements: \(\frac{1}{(1-s)+s/\beta}\)
\end{enumerate}
\item[The percent gain is simple in two cases.]
We can apply the small-change approximation
\(y'/y \approx 1 + s(\beta-1)\) if either of two cases holds:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Most tasks are affected by the speedup (\(s\simeq 1\))
\item
  The productivity increase is small (\(\beta\simeq 1\)) (AKA Hulten's
  theorem)
\end{enumerate}

In these two cases we can estimate the aggregate productivity
improvement without knowing the degree of substitutability between
tasks.
\item[If the time-savings are somewhat small then you can use elasticity
of substitution.]
If you know the elasticity of substitution between sped-up tasks and
other tasks, \(\varepsilon\), then we can write an expression for the
aggregate increase:
\[\frac{y'}{y} = \left((1-s) + s\,\beta^{\varepsilon-1}\right)^{1/(\varepsilon-1)}\]
\item[If the time-savings are large, use the area under the demand
curve.]
If the time-savings are large then it's more dangerous to assume a
constant elasticity. Instead we ideally want to trace out the entire
demand curve (i.e.~how time-allocated to a task changes as the
efficiency increases), and the speed-up will be proportional to the area
under the demand curve.
\item[Using pre-LLM shares will under-estimate value for substitutes
(and over-estimate for complements).]
If using the simple \(s\times(\beta-1)\) estimate, then using pre-LLM
shares will under-estimate productivity improvements when tasks are
substitutes, while using post-LLM time-shares will over-estimate; the
direction flips when tasks are complements.
\item[Observing pre-LLM and post-LLM shares helps.]
If you observe the time-share both pre-LLM and post-LLM then you can
back out the elasticity of substitution, and thus the aggregate
efficiency improvement. Graphically, if we observe the change in budget
constraint, and change in consumption point, we can infer
substitutability, and therefore aggregate productivity improvement.
\end{description}

\subsection{Applications}\label{applications}

\begin{description}
\item[Estimating productivity improvements from query-level
time-savings.]
Anthropic (2025) samples a range of tasks from Claude chatbot logs and
estimates the time required for each task both with and without AI
assistance.

My understanding of their calculation:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Claude is used for around 25\% of tasks, \(s=0.25\) (pre-LLM
  distribution of tasks).
\item
  When Claude is used, time-required falls by 80\%, \(\beta=5\).
\item
  Therefore the total time-saving is around 20\% (using the fixed-share
  calculation \(s(1-1/\beta)\) with these numbers; this is the
  small-change/Hulten-style approximation).
\end{enumerate}

However as we discussed above, Hulten's theorem only applies for
\emph{small} efficiency changes, but these are large changes (80\%), so
this conclusion requires assuming Cobb-Douglas substitution, i.e.~that
time-shares are constant.

\textbf{==my guess: people are doing tasks they wouldn't otherwise
do.==}
\item[Estimating time-savings in an RCT.]
Becker et al. (2025) report an RCT, where software engineers first
choose tasks, then get assigned to either with-AI or without-AI
conditions. In this case the subjects mostly were \emph{not} using AI,
but in follow-up studies they \emph{will} be using AI. This makes it
hard to think about interpreting uplift studies over time, insofar as AI
causes them to change the task distribution. It would be nice to have a
good clear language here.
\end{description}

\subsection{Lookup Tables}\label{lookup-tables}

\textbf{Output increase using \emph{ex-ante} time shares}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.5049}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.1650}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.1650}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.1650}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
1.1X speedup on 50\%
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
2X speedup on 10\%
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
5X speedup on 10\%
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(\varepsilon=0\) (perfect complements/Amdahl) & 4.8\% & 5.3\% &
8.7\% \\
\(\varepsilon=1/2\) (complements) & 4.8\% & 6.1\% & 12.0\% \\
\(\varepsilon=1\) (Cobb-Douglas/Hulten) & 4.9\% & 7.2\% & 17.5\% \\
\(\varepsilon=2\) (substitutes) & 5.0\% & 10.0\% & 40.0\% \\
\(\varepsilon\rightarrow\infty\) (perfect substitutes) & 10.0\% &
100.0\% & 400.0\% \\
\end{longtable}

\textbf{Output increase using \emph{ex-post} time shares:}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.5049}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.1650}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.1650}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.1650}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
1.1X speedup on 50\%
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
2X speedup on 10\%
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
5X speedup on 10\%
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(\varepsilon=0\) (perfect complements/Amdahl) & 5.0\% & 10.0\% &
40.0\% \\
\(\varepsilon=1/2\) (complements) & 4.9\% & 8.5\% & 26.2\% \\
\(\varepsilon=1\) (Cobb-Douglas/Hulten) & 4.9\% & 7.2\% & 17.5\% \\
\(\varepsilon=2\) (substitutes) & 4.8\% & 5.3\% & 8.7\% \\
\(\varepsilon\rightarrow\infty\) (perfect substitutes) & N/A & N/A &
N/A \\
\end{longtable}

\begin{description}
\tightlist
\item[How these are calculated:]
\begin{itemize}
\tightlist
\item[]
\item
  \textbf{``X\% saving''} means task-2 productivity increases so that
  time-per-unit falls by factor \((1-X)\), i.e., \(\beta = 1/(1-X)\). So
  10\% saving → \(\beta = 1.11\); 50\% saving → \(\beta = 2\); 80\%
  saving → \(\beta = 5\).
\item
  \textbf{``Y\% of work''} means the time share on task 2 is \(s = Y\).
\item
  \textbf{Output gain} from the CES formula:
  \[\frac{y'}{y} = \left((1-s_0) + s_0\,\beta^{\varepsilon-1}\right)^{1/(\varepsilon-1)}\]
  where \(s_0\) is the \emph{ex-ante} share. The reported numbers are
  \((y'/y-1)\times 100\%\).
\item
  \textbf{Table 1:} The column header specifies the ex-ante share
  \(s_0\) directly. Compute the output gain and report the percent
  increase.
\item
  \textbf{Table 2:} The column header specifies the ex-post share
  \(s_1\). First back out the implied ex-ante share using:
  \[\frac{s_0}{1-s_0} = \frac{s_1}{1-s_1} \cdot \beta^{1-\varepsilon}\]
  Then compute the true output gain using \(s_0\).
\item
  \textbf{Perfect substitutes (Table 2):} After any productivity
  improvement, you reallocate entirely to the better task, so the
  ex-post share is always 100\%. Specifying it as 10\% or 50\% is
  inconsistent with optimization---hence N/A.
\end{itemize}
\end{description}

\subsection{Other Points}\label{other-points}

\begin{description}
\item[An analogy: we're turning lead into gold.]
Suppose I invent a technology to turn lead into gold, so that the price
of gold falls by 99\%. I'd like to quantify my welfare increase in terms
of equivalent income. I could apply a simple share-weighted price-change
rule in two ways:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  If I use \emph{ex ante} expenditure the effect looks small: my
  expenditure share on gold is \textasciitilde0\%, so even a 100\% price
  decrease has a negligible effect on my effective income.
\item
  If I use \emph{ex post} expenditure the effect looks large: if gold is
  sufficiently cheap then I'll start buying many things which are made
  of gold. Suppose I now spend 1\% of my income on gold, then it looks
  like the price reduction has doubled my effective income, because at
  the original price of gold I would've had to have twice as much income
  to afford my new basket.
\end{enumerate}

This discrepancy between \emph{ex ante} and \emph{ex post} values arises
because of the high substituability between gold and other materials
(steel, bronze). However I'm not confident that we would see that
elasticity at \emph{current} prices, it would only occur when gold's
price gets sufficiently low, meaning that estimating a CES function
wouldn't be sufficient to give a good estimate of the value. To get a
realistic estimate we need to map elasticities at different prices,
i.e.~draw the entire demand function.
\item[Sensitivity to CES.]
I give bounds on aggregate time-savings with a CES model below, but I'm
not sure whether you'd get wider bounds if you relax the CES assumption,
e.g.~account for second-order effects.
\item[Non-homotheticities.]
In demand theory there can be significant effects from
non-homotheticities.
\item[Tasks are fake.]
(\ldots)
\end{description}

\section{Model}\label{model}

We set up a two-task CES production problem and derive the optimal time
split, the implied output, and the response to productivity changes,
with limits for common special cases.

\textbf{Practical implications (at a glance)}

Let \(s\equiv t_2^*\) denote the optimal time share on task 2 (and
\(1-s=t_1^*\)). Express all effects as log-changes
\(\Delta\ln y^*=\ln\!\big(y^{*'}/y^*\big)\) when task-2 productivity
moves from \(A_2\) to \(A_2'=\beta A_2\). The last column plugs in
\(s=0.1\) and \(\beta=2\).

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.2419}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.3302}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.2186}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.2093}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Case
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Output effect (\(\Delta\ln y^*\))
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Intuition
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example \(\Delta\ln y^*\) (\(s=0.1,\ \beta=2\))
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
General finite change &
\(\dfrac{1}{\varepsilon-1}\ln\!\big((1-s)+s\,\beta^{\varepsilon-1}\big)\)
& CES-weighted average of the shock &
\(\dfrac{1}{\varepsilon-1}\ln\!\big(0.9+0.1\times2^{\varepsilon-1}\big)\)
(depends on \(\varepsilon\)) \\
Perfect substitutes (\(\varepsilon\rightarrow\infty\)) & \(\ln \beta\) &
All time moves to the better task & \(\approx 0.69\) \\
Cobb--Douglas (\(\varepsilon=1\)) & \(s\,\ln \beta\) & Log-linear
weighting by the task share & \(\approx 0.069\) \\
Perfect complements (\(\varepsilon\rightarrow0\)) &
\(-\ln\!\big((1-s)+s/\beta\big)\) & Bottlenecked by the slow task &
\(\approx 0.051\) \\
Infinitesimal change (Hulten) & \(s\,d\ln A_2\) & Percent gain equals
time share on improved task & \(0.1\times\ln 2\approx 0.069\) \\
\end{longtable}

\textbf{Setup and parameters}

\begin{itemize}
\tightlist
\item
  Time endowment is \(1\); choose \(t_1\in[0,1]\) and \(t_2=1-t_1\).
\item
  Productivities: \(A_1>0\) for task \(1\), \(A_2>0\) for task \(2\).
\item
  Taste weight: \(\alpha\in(0,1)\) on task \(1\).
\item
  Substitution parameter: \(\varepsilon>0\); take \(\varepsilon\neq1\)
  for the algebra and then send \(\varepsilon\rightarrow1\) for the
  Cobb--Douglas limit.
\item
  Output aggregator (CES):
  \[y(t_1,t_2)=\left(\alpha(A_1 t_1)^{\frac{\varepsilon-1}{\varepsilon}}+(1-\alpha)(A_2 t_2)^{\frac{\varepsilon-1}{\varepsilon}}\right)^{\frac{\varepsilon}{\varepsilon-1}}.\]
\end{itemize}

\textbf{Assumptions}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Feasible set: \(t_1\in[0,1]\), \(t_2=1-t_1\).
\item
  Parameters satisfy \(A_i>0\) and \(\alpha\in(0,1)\).
\item
  Decision problem: choose \(t_1\) to maximise \(y(t_1,1-t_1)\).
\end{enumerate}

\textbf{Proposition 1 (optimal time split).} The interior optimum is
\[t_1^*=\frac{1}{1+\left(\frac{1-\alpha}{\alpha}\right)^{\varepsilon}\left(\frac{A_2}{A_1}\right)^{\varepsilon-1}},\qquad t_2^*=1-t_1^*.\]

\emph{Proof (explicit)}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Write the Lagrangian \(\mathcal{L}=y(t_1,t_2)+\lambda(1-t_1-t_2)\)
  with \(y\) as above.
\item
  First-order conditions (interior):
  \(\partial\mathcal{L}/\partial t_1=0\) and
  \(\partial\mathcal{L}/\partial t_2=0\) give
  \[\lambda=\alpha\,A_1^{\frac{\varepsilon-1}{\varepsilon}}\,t_1^{-\frac{1}{\varepsilon}}\,y^{\frac{1}{\varepsilon}}=(1-\alpha)\,A_2^{\frac{\varepsilon-1}{\varepsilon}}\,t_2^{-\frac{1}{\varepsilon}}\,y^{\frac{1}{\varepsilon}}.\]
\item
  Cancel \(y^{\frac{1}{\varepsilon}}\) and rearrange to obtain
  \(\frac{t_2}{t_1}=\left(\frac{1-\alpha}{\alpha}\right)^{\varepsilon}\left(\frac{A_2}{A_1}\right)^{\varepsilon-1}\).
\item
  Impose \(t_1+t_2=1\) and solve for \(t_1^*\); set \(t_2^*=1-t_1^*\).
\item
  The interior solution is valid for \(\varepsilon>0\) with finite
  \(A_i\); only the perfect-substitutes limit
  \(\varepsilon\rightarrow\infty\) or \(A_i\rightarrow0\) forces a
  corner.
\end{enumerate}

\textbf{Proposition 2 (indirect output).} At \(t_1^*,t_2^*\) the output
is
\[y^*=\Big(\alpha^{\varepsilon}A_1^{\varepsilon-1}+(1-\alpha)^{\varepsilon}A_2^{\varepsilon-1}\Big)^{\frac{1}{\varepsilon-1}}.\]

\emph{Proof (explicit)}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Substitute \(t_1^*,t_2^*\) from Proposition 1 into \(y(t_1,t_2)\).
\item
  Factor out
  \(\alpha^{\varepsilon}A_1^{\varepsilon-1}+(1-\alpha)^{\varepsilon}A_2^{\varepsilon-1}\)
  inside the braces; the exponent \(\frac{\varepsilon}{\varepsilon-1}\)
  collapses to the stated form.
\end{enumerate}

\textbf{Proposition 3 (infinitesimal productivity change).} Holding
\(A_1\) fixed, a small change in \(A_2\) satisfies
\[\frac{dy^*}{y^*}=t_2^*\,\frac{dA_2}{A_2}.\]

\emph{Proof (explicit)}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Take
  \(\log y^*=\frac{1}{\varepsilon-1}\log\big(\alpha^{\varepsilon}A_1^{\varepsilon-1}+(1-\alpha)^{\varepsilon}A_2^{\varepsilon-1}\big)\).
\item
  Differentiate with respect to \(\log A_2\):
  \[\frac{dy^*}{y^*}=\frac{(1-\alpha)^{\varepsilon}A_2^{\varepsilon-1}}{\alpha^{\varepsilon}A_1^{\varepsilon-1}+(1-\alpha)^{\varepsilon}A_2^{\varepsilon-1}}\cdot\frac{dA_2}{A_2}.\]
\item
  The fraction equals \(t_2^*\) from Proposition 1, so the result
  follows.
\end{enumerate}

\textbf{Proposition 4 (finite productivity change on task 2).} If
\(A_2'=\beta A_2\) with \(\beta>0\), then
\[\frac{y^{*'}}{y^*}=\left(t_1^*+(1-t_1^*)\beta^{\varepsilon-1}\right)^{\frac{1}{\varepsilon-1}}.\]

\emph{Proof (explicit)}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Replace \(A_2\) by \(\beta A_2\) in \(y^*\) from Proposition 2:
  \[y^{*'}=\Big(\alpha^{\varepsilon}A_1^{\varepsilon-1}+(1-\alpha)^{\varepsilon}(\beta A_2)^{\varepsilon-1}\Big)^{\frac{1}{\varepsilon-1}}.\]
\item
  Factor out the old level \(y^*\) to form a ratio; the remaining
  weights inside the braces are \(t_1^*\) and \(t_2^*=1-t_1^*\), giving
  the stated expression.
\end{enumerate}

\textbf{Proposition 5 (canonical limits).} Take limits of Proposition 4:

\begin{itemize}
\tightlist
\item
  Cobb--Douglas (\(\varepsilon\rightarrow1\)):
  \(\frac{y^{*'}}{y^*}\rightarrow \beta^{1-\alpha}\) and \(t_i^*\) is
  unchanged.
\item
  Perfect complements (\(\varepsilon\rightarrow0\)):
  \(\frac{y^{*'}}{y^*}\rightarrow \frac{1}{t_1^*+t_2^*/\beta}\).
\item
  Perfect substitutes (\(\varepsilon\rightarrow\infty\)):
  \(\frac{y^{*'}}{y^*}\rightarrow \beta\) with \(t_2^*\rightarrow1\) if
  \(\beta A_2>A_1\).
\end{itemize}

\emph{Proof sketch} For \(\varepsilon\rightarrow1\) apply L'Hôpital to
the CES form. For \(\varepsilon\rightarrow0\) the CES aggregator
converges to \(\min\{A_1 t_1,A_2 t_2\}\). For
\(\varepsilon\rightarrow\infty\) it converges to
\(\max\{A_1 t_1,A_2 t_2\}\). Substitute these limits into Proposition 4
and simplify.

\section{Related Theory}\label{related-theory}

I don't consider myself an expert on these literatures, take this survey
at your own risk.

\begin{description}
\tightlist
\item[The index numbers problem.]
There's a very old literature on calculating an aggregate price index in
a way that accounts for substitutability between different goods. The
same theory can be applied to change in goods-prices or
task-productivities, see Caves, Christensen, and Diewert (1982).

\begin{itemize}
\tightlist
\item
  The Laspeyres index uses base-period weights, and will understate
  gains when a shock makes you reallocate toward the lower-price good.
\end{itemize}

\begin{itemize}
\tightlist
\item
  The Paasche index uses end-period weights, and will overstate gains
  when a shock makes you reallocate toward the lower-price good.
\end{itemize}

\begin{itemize}
\tightlist
\item
  A Divisia index is a path integral of share-weighted growth rates.
  Discrete indices (e.g., Fisher/Törnqvist) are designed to approximate
  that integral.
\end{itemize}
\item[Consumer surplus / welfare for large ``price'' (time-cost)
changes]
The classic consumer surplus measure from a price change is the area
under the demand curve, however this measures the Marshallian consumer
surplus, which will approximate the welfare-relevant Hicksian surplus
only when there are negligible income effects. Willig (1976) gives
approximation bounds.

This literature distinguishes between Equivalent Variation (EV), the
change in income that would have the same welfare effect as the price
change, and Compensating Variation (CV), the change in income which
could \emph{accompany} the price change and restore your utility.

Hausman (1981) shows how to compute exact welfare measures (EV/CV,
deadweight loss) from an estimated demand curve by imposing
integrability (i.e., that the demand actually comes from some underlying
utility/expenditure function). Deaton and Muellbauer (1980) provides a
standard integrable demand system (AIDS) that flexibly captures income
and substitution patterns.
\item[Economics of time allocation (time is a scarce input with shadow
prices)]
DeSerpa (1971) is a classic reference on time allocation, and
time-saving innovations as relaxing the budget constraint.
\item[Task substitution and computerization as task-specific technology
shocks]
Autor, Levy, and Murnane (2003) gives the modern ``tasks'' approach:
computerization substitutes for routine tasks and complements
non-routine tasks, shifting task content within occupations and
generating distributional consequences (e.g., polarization). You cannot
summarize tech change as ``labor-augmenting'' in the aggregate.

Acemoglu and Autor (2011) synthesizes and formalizes this task-based
view. A central message is that the impact of a task-specific
productivity shock depends on: (i) which tasks are affected, (ii) how
substitutable tasks are, and (iii) how the economy re-optimizes task
assignment across workers/technologies.
\item[Hulten's theorem and when first-order share-weighting breaks]
Hulten (1978) shows (in a competitive, CRS setting with intermediates)
that a \emph{small} productivity shock's effect on aggregate
productivity can be summarized by share-weighted sectoral TFP growth
(Domar/revenue-share weights). The key takeaway is the legitimacy of
first-order share weighting---but only locally.

Baqaee and Farhi (2019) shows that in production networks, micro shocks
can have macro consequences and nonlinearities/higher-order terms
matter.

Baqaee and Burstein (2021) and Comin, Lashkari, and Mestieri (2021) take
into account income effects.
\item[Amdahl's law as the perfect-complements benchmark]
Amdahl's law in computer science says the speedup from improving one
component is bounded by the unimproved fraction. This corresponds to the
perfect-complements case.
\end{description}

\section{Illustrations}\label{illustrations}

\subsection{Indifference Curve}\label{indifference-curve}

\begin{figure}[H]

{\centering \includegraphics{2025-12-17-llm-time-saving-demand-theory-substitution_files/figure-pdf/unnamed-chunk-1-1.pdf}

}

\caption{Budget constraint and optimal allocations under different
elasticities}

\end{figure}%

\subsection{Demand Curve}\label{demand-curve}

\begin{figure}[H]

{\centering \includegraphics{2025-12-17-llm-time-saving-demand-theory-substitution_files/figure-pdf/unnamed-chunk-2-1.pdf}

}

\caption{Demand curves with different price elasticities}

\end{figure}%

\phantomsection\label{refs}
\begin{CSLReferences}{1}{0}
\bibitem[\citeproctext]{ref-acemoglu2011handbook}
Acemoglu, Daron, and David Autor. 2011. {``Skills, Tasks and
Technologies: Implications for Employment and Earnings.''} In, edited by
David Card and Orley Ashenfelter, 4:1043--1171. Handbook of Labor
Economics. Elsevier.
https://doi.org/\url{https://doi.org/10.1016/S0169-7218(11)02410-5}.

\bibitem[\citeproctext]{ref-anthropic2025estimatingproductivitygains}
Anthropic. 2025. {``Estimating AI Productivity Gains from Claude
Conversations.''} 2025.
\url{https://www.anthropic.com/research/estimating-productivity-gains}.

\bibitem[\citeproctext]{ref-autor2003skill}
Autor, David, Frank Levy, and Richard J Murnane. 2003. {``The Skill
Content of Recent Technological Change: An Empirical Exploration.''}
\emph{The Quarterly Journal of Economics} 118 (4): 1279--1333.
\url{https://doi.org/10.3386/w8337}.

\bibitem[\citeproctext]{ref-baqaeeBurstein2021incomeeffects}
Baqaee, David Rezza, and Ariel Burstein. 2021. {``Welfare and Output
with Income Effects and Demand Instability.''} Working Paper.
\url{https://www.semanticscholar.org/search?q=Welfare\%20and\%20Output\%20with\%20Income\%20Effects\%20and\%20Demand\%20Instability}.

\bibitem[\citeproctext]{ref-baqaee2019macro}
Baqaee, David Rezza, and Emmanuel Farhi. 2019. {``The Macroeconomic
Impact of Microeconomic Shocks: Beyond Hulten's Theorem.''}
\emph{Econometrica} 87 (4): 1155--1206.
\url{https://doi.org/10.3982/ecta15202}.

\bibitem[\citeproctext]{ref-becker2025uplift}
Becker, Joel, Nate Rush, Elizabeth Barnes, and David Rein. 2025.
{``Measuring the Impact of Early-2025 AI on Experienced Open-Source
Developer Productivity.''} \url{https://arxiv.org/pdf/2507.09089.pdf}.

\bibitem[\citeproctext]{ref-caves1982indexnumbers}
Caves, Douglas W., Laurits R. Christensen, and W. Erwin Diewert. 1982.
{``The Economic Theory of Index Numbers and the Measurement of Input,
Output, and Productivity.''} \emph{Econometrica} 50 (6): 1393--1414.
\url{https://www.jstor.org/stable/1913382}.

\bibitem[\citeproctext]{ref-cominLashkariMestieri2021structuralchange}
Comin, Diego, Danial Lashkari, and Martı́n Mestieri. 2021. {``Structural
Change with Long-Run Income and Price Effects.''} Working Paper.
\url{https://doi.org/10.3982/ecta16317}.

\bibitem[\citeproctext]{ref-deaton1980aids}
Deaton, Angus, and John Muellbauer. 1980. {``An Almost Ideal Demand
System.''} \emph{American Economic Review} 70 (3): 312--26.
\url{https://www.semanticscholar.org/search?q=An\%20Almost\%20Ideal\%20Demand\%20System}.

\bibitem[\citeproctext]{ref-deserpa1971time}
DeSerpa, Allan C. 1971. {``A Theory of the Economics of Time.''}
\emph{The Economic Journal} 81 (324): 828--46.
\url{https://doi.org/10.2307/2230320}.

\bibitem[\citeproctext]{ref-hausman1981exact}
Hausman, Jerry A. 1981. {``Exact Consumer's Surplus and Deadweight
Loss.''} \emph{American Economic Review} 71 (4): 662--76.
\url{https://www.semanticscholar.org/search?q=Exact\%20Consumer\%27s\%20Surplus\%20and\%20Deadweight\%20Loss}.

\bibitem[\citeproctext]{ref-hulten1978growth}
Hulten, Charles R. 1978. {``Growth Accounting with Intermediate
Inputs.''} \emph{The Review of Economic Studies} 45 (3): 511--18.
\url{https://doi.org/10.2307/2297252}.

\bibitem[\citeproctext]{ref-willig1976consumerssurplus}
Willig, Robert D. 1976. {``Consumer's Surplus Without Apology.''}
\emph{American Economic Review} 66 (4): 589--97.
\url{https://www.semanticscholar.org/paper/745fa39279d59c6f6b14dce4a38bcf098774c2ad}.

\end{CSLReferences}




\end{document}
