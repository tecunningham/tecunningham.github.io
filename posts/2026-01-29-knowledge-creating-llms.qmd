---
title: Knowledge-Creating LLMs
author: Tom Cunningham, METR
engine: knitr
bibliography: ai.bib
draft: true
# execute:
#   keep-md: true
---

<!-- https://tecunningham.github.io/posts/2026-01-29-knowledge-creating-llms.html -->

<!-- TODO:
1. ~~Add references to my own work~~
2. Better graph with fewer humans
3. ~~Acknowledgements, thanks to Zoe, Parker~~
4. Parker point: compare with existing research labs, but much more on fixed costs.
5. Zoe point: "ie i’m not sure about this distinction : “Thus labs will prefer to restrict output, e.g. by selling the knowledge to just one firm, instead of selling the ability to generate knowledge.”"
6. Zoe point distillation:
7. Trade costs imply some home production just behind the frontier
8. Differences in benchmarks between old & new LLMs
9.  Quotes about how LLMs are now creating new knowledge
10. Send to: Eddie ; 
 -->

*Thanks to Zoë Hitzig & Parker Whitfill for helpful comments.*

Knowledge-creating LLMs have distinct economic implications.
: There has recently been a burst of excitement about LLMs which are advancing the frontiers of human knowledge. I think there are some distinct economic implications of knowledge-creation LLMs that I haven't seen described elsewhere:
:   1. **Knowledge-sharing LLMs will be used by *non-experts*,** and will be widely available.
    1. **Knowledge-creating LLMs will be used by *experts*,** and will be closely held by the labs, or sold with exclusive licenses.

      Below I give a general argument, then a very simple formal model.

      A notable implication for AI safety: labs may stop releasing their frontier models publicly, as the economic incentive to sell access diminishes.

**[Sarah Friar, OpenAI's CFO, January 2026.](https://openai.com/index/a-business-that-scales-with-the-value-of-intelligence/)**

: > *"As intelligence moves into scientific research, drug discovery, energy systems, and financial modeling, new economic models will emerge. Licensing, IP-based agreements, and outcome-based pricing will share in the value created."*

A visual explanation.
: Below we illustrate a set of humans, and their cost to do different tasks. Here each human has a speciality, i.e. a set of tasks at which they have the lowest cost.

      We can visualize a knowledge-sharing LLM assistant as equalizing knowledge, and therefore achieving the minimum-cost across all humans. However a knowledge-creating LLM achieves even lower costs.

```{tikz}
#| fig-align: center
\begin{tikzpicture}[x=10cm,y=6cm]
  % Dip shape parameters
  % - \w controls dip width: larger => broader specializations / flatter envelope
  % - all human curves share the same minimum value \mmin at their dip
  \def\w{0.012}
  \def\mmin{0.34}

  % Per-human baseline levels (far from each dip) and implied dip depths.
  % Setting depth_i = baseline_i - \mmin forces all minima to equal \mmin,
  % while keeping the baselines separated to reduce overlap.
  \def\bAaron{0.86}
  \def\bBeatrice{0.88}
  \def\bCarlos{0.90}
  \def\bDiana{0.92}
  \def\bEthan{0.94}
  \def\bFatima{0.96}
  \pgfmathsetmacro{\aAaron}{\bAaron-\mmin}
  \pgfmathsetmacro{\aBeatrice}{\bBeatrice-\mmin}
  \pgfmathsetmacro{\aCarlos}{\bCarlos-\mmin}
  \pgfmathsetmacro{\aDiana}{\bDiana-\mmin}
  \pgfmathsetmacro{\aEthan}{\bEthan-\mmin}
  \pgfmathsetmacro{\aFatima}{\bFatima-\mmin}
  % Axes
  \draw[->, line width=0.8pt] (0,0) -- node[midway,below] {task type} (1.0,0);
  \draw[->, line width=0.8pt] (0,0) -- (0,1.18) node[midway,above,rotate=90] {cost (lower is better)};
  % Second y-axis at x=1 (no labels, just a guide)
  \draw[->, gray!60, line width=0.8pt] (1,0) -- (1,1.18);

  % Ticks
  % \foreach \x/\lab in {0/0, 0.5/0.5, 1/1} {
  %  \draw[line width=0.8pt] (\x,0) -- (\x,-0.02) node[below] {\lab};
  % }

  % Individual agent cost curves (mostly flat with a narrow dip).
  % The dip minima are equally spaced along x.
  % (The denominator \w controls dip width; larger => broader, more overlap.)
  \draw[blue!70!black, line width=1.6pt]
    plot[domain=0:1, samples=350] (\x,{\bAaron - \aAaron*exp(-((\x-0.10)^2)/\w)});

  \draw[red!70!black, line width=1.6pt]
    plot[domain=0:1, samples=350] (\x,{\bBeatrice - \aBeatrice*exp(-((\x-0.26)^2)/\w)});

  \draw[green!50!black, line width=1.6pt]
    plot[domain=0:1, samples=350] (\x,{\bCarlos - \aCarlos*exp(-((\x-0.42)^2)/\w)});

  \draw[purple!70!black, line width=1.6pt]
    plot[domain=0:1, samples=350] (\x,{\bDiana - \aDiana*exp(-((\x-0.58)^2)/\w)});

  \draw[orange!80!black, line width=1.6pt]
    plot[domain=0:1, samples=350] (\x,{\bEthan - \aEthan*exp(-((\x-0.74)^2)/\w)});

  \draw[teal!70!black, line width=1.6pt]
    plot[domain=0:1, samples=350] (\x,{\bFatima - \aFatima*exp(-((\x-0.90)^2)/\w)});

  % old LLM curve: lower envelope of the agent curves
  \draw[black, dotted, opacity=0.65, line width=3.2pt]
    plot[domain=0:1, samples=350] (\x,{
      min(
        min(
          min(
            \bAaron - \aAaron*exp(-((\x-0.10)^2)/\w),
            \bBeatrice - \aBeatrice*exp(-((\x-0.26)^2)/\w)
          ),
          min(
            \bCarlos - \aCarlos*exp(-((\x-0.42)^2)/\w),
            \bDiana - \aDiana*exp(-((\x-0.58)^2)/\w)
          )
        ),
        min(
          \bEthan - \aEthan*exp(-((\x-0.74)^2)/\w),
          \bFatima - \aFatima*exp(-((\x-0.90)^2)/\w)
        )
      )
    });

   % new LLM curve: old LLM curve shifted down
  \draw[black, dotted, opacity=0.65, line width=3.2pt]
    plot[domain=0:1, samples=350] (\x,{
      min(
        min(
          min(
            \bAaron - \aAaron*exp(-((\x-0.10)^2)/\w),
            \bBeatrice - \aBeatrice*exp(-((\x-0.26)^2)/\w)
          ),
          min(
            \bCarlos - \aCarlos*exp(-((\x-0.42)^2)/\w),
            \bDiana - \aDiana*exp(-((\x-0.58)^2)/\w)
          )
        ),
        min(
          \bEthan - \aEthan*exp(-((\x-0.74)^2)/\w),
          \bFatima - \aFatima*exp(-((\x-0.90)^2)/\w)
        )
      )-0.1
    });

  % RHS labels (x=1): keep only the envelope labels
  \pgfmathsetmacro{\yAaron}{\bAaron - \aAaron*exp(-((1-0.10)^2)/\w)}
  \pgfmathsetmacro{\yBeatrice}{\bBeatrice - \aBeatrice*exp(-((1-0.26)^2)/\w)}
  \pgfmathsetmacro{\yCarlos}{\bCarlos - \aCarlos*exp(-((1-0.42)^2)/\w)}
  \pgfmathsetmacro{\yDiana}{\bDiana - \aDiana*exp(-((1-0.58)^2)/\w)}
  \pgfmathsetmacro{\yEthan}{\bEthan - \aEthan*exp(-((1-0.74)^2)/\w)}
  \pgfmathsetmacro{\yFatima}{\bFatima - \aFatima*exp(-((1-0.90)^2)/\w)}
  \pgfmathsetmacro{\yOldLLM}{min(min(min(\yAaron,\yBeatrice),min(\yCarlos,\yDiana)),min(\yEthan,\yFatima))}
  \pgfmathsetmacro{\yNewLLM}{\yOldLLM - 0.1}

  \node[anchor=west] at (1.012,0.98) {human cost curves};

  \draw[black!55, line width=0.6pt]           (1,{\yOldLLM})   -- (1.010,0.74);
  \node[anchor=west]                         at (1.012,0.74) {old LLM\\(minimum across humans)};

  \draw[black!55, line width=0.6pt]           (1,{\yNewLLM})   -- (1.010,0.66);
  \node[anchor=west]                         at (1.012,0.66) {new LLM\\(superhuman)};
\end{tikzpicture}
```


##       Model of LLMs for Discovery

It's useful to distinguish between two types of LLMs:
:   1. **LLMs that share existing knowledge (old LLMs)**-- they are trained on human-produced and human-judged data.
    1. **LLMs that discover new knowledge (new LLMs)** -- they are trained against new data directly from the real world, e.g. math, verifiable problems, computer use, actions in the world.

Knowledge-sharing LLMs.
:     Traditionally LLMs are trained with human judgment as the ground truth, using labels from paid raters, or from LLM users. As a consequence they can answer questions and solve problems up to the limits of human expertise but rarely beyond.

      I have elsewhere argued that it's useful to think of LLMs as sharing existing knowledge ([one](https://tecunningham.github.io/posts/2023-09-05-model-of-ai-imitation.html), [two](https://tecunningham.github.io/posts/2025-09-19-transformative-AI-notes.html)).

      An implication: they will be used by people outside their areas of expertise, and by firms that are followers, to catch up to the frontier.
      
      As a consequence they decrease knowledge rents -- people and firms whose value is from their existing knowledge.
      
      They increase home production (you can solve problems yourself instead of paying for it), and so decrease GDP.
      
      They decrease the returns to innovation (and news-gathering), insofar as they cause new knowledge to diffuse more quickly.

      This business has high fixed costs -- collecting all the knowledge to train the model -- and relatively low marginal costs in sharing that knowledge.

      
<!-- (more speculative) they decrease firm size, because you don't need an in-house specialist anymore. -->

Knowledge-creating LLMs.
:     Over the past year there have been various announcements of LLMs used to advance the state-of-the-art on various specific problems, i.e. creating new knowledge. 

      They will be mostly used by *leader* firms instead of followers, and will be used *inside* their area of expertise instead of at the fringes.
      
      We should expect much higher variable costs, i.e. expenditure on advancing the state of konwledge on a single problem.
      
      The demand for new knowledge is much less elastic than the demand for existing knowledge. Selling knowledge to one person is much more valuable than selling to two people. Thus labs will prefer to restrict output, e.g. by selling the knowledge to just one firm, instead of selling the ability to generate knowledge.
      
      Our benchmarks for new LLMs will be qualitatively different. Instead of seeing if they can answer questions which we already know the answer to, we want them to answer *new* questions, e.g. Erdos problems, or setting records on optimization benchmarks.

      Examples of knowledge-creating LLM applications:

      - Predict stock prices
      - Optimize algorithms
      - Optimize technology
      - Solve scientific problems
      - Create a movie

#           An Economic Model

<!-- notes on models: https://chatgpt.com/share/697cd5b5-74f4-8013-a58d-e41dc7f3a319 -->

Baseline: everyone buys from the person who knows the best recipe.
: Everyone has a unit of labor. There's one consumption good, but various recipes for producing it, $r\in R$, which determine the labor-cost of producing the good, $c(r)$. In equilibrium the person who knows the lowest-cost recipe ($c_1$) will sell the good in return for others' labor. Their margins are equal to the difference to the next-lowest-cost recipe, $c_2-c_1$ (assume Bertrand competition).

Knowledge-sharing LLMs eliminate rents.
: Now you invent a knowledge-sharing LLM, which can reveal the lowest-cost known recipe, $c_1$. You cannot make substantial profits from this knowledge: once two producers have the same cost then margins will be driven to zero. Assuming the recipe does diffuse, total output remains the same but the surplus is now distributed equally. If we additionally assumed some trade cost $\delta$ then the knowledge will have value equal to $\delta$, but notably there's no value to *exclusively* license your LLM. Also notably the returns to innovation fall: there's much less incentive to discover a new low-cost recipe if that knowledge will be immediately shared.

Knowledge-creating LLMs generate additional surplus.
: Next we introduce a knowledge-creating LLM, which generates a new recipe $c_0<c_1$. The inventor can monetize this either by producing the good themselves or licensing the recipe to a single producer. Now exclusivity is important: if they sold the recipe to *two* producers then profits will be driven to zero, and the value of the recipe will be zero. In equilibrium total output increases, the extra surplus is split between consumers and the owner of the new recipe.


The model can be extended to multiple goods. 
: If people have Cobb-Douglas preferences across goods then they will spend a fixed fraction of labor on each good, and so each good's market can be treated as independent.

      You can visualize the distribution of costs as follows:

      - Old LLMs are the minimum cost among existing humans.
      - New LLMs *lower* the cost.

<!-- Q: does this hold with exchange? -->

<!-- 
|                         | LLM that shares knowledge | LLM creates knowledge  |
| ----------------------- | ------------------------- | ---------------------- |
|                         |                           |                        |
| Superhuman performance? | Only in special cases     | Often                  |
| Who uses it?            | Followers in an industry  | Leaders in an industry |
| What types of use?      | Specializations           | Non-specializations    |
|                         |                           |                        | 
-->


#           More to Do

There are obvious implications for intellectual property.

: A specific worry: if we maintain the same intellectual property law then there will be a land-grab, firms will rush to be the first to discover new technologies, and will then get an exclusive license, but that exclusivity will be inefficient (i.e. it wasn't necessary to motivate the research, the technology would've been discovered anyway).


It would be more satisfying to have a generative model.
: I'd really like to sketch out a very simple model in which both humans and LLMs learn recipes from experimenting against the real world.



#           Recent Examples of Knowledge-Advancing AI [UNFINISHED]


@yuksekgonul2026learning, "Learning to Discover at Test Time"
: > "We report results for every problem we attempted, across mathematics, GPU kernel engineering, algorithm design, and biology. TTT-Discover sets the new state of the art in almost all of them: (i) Erdős’ minimum overlap problem and an autocorrelation inequality; (ii) a GPUMode kernel competition (up to 2×faster than prior art); (iii) past AtCoder algorithm competitions; and (iv) denoising problem in single-cell analysis. Our solutions are reviewed by experts or the organizers."


# Literature Review: Economic Models

This post is trying to separate two economic objects that are often conflated:
: (i) *diffusing existing knowledge* vs (ii) *creating new knowledge*. There are several modeling traditions that map naturally onto this distinction.

## Knowledge diffusion and catch-up

Lucas & Moll (2014) treat knowledge growth as a time-allocation problem.
: > "Agents divide their time between two activities: producing goods and interacting with others in search of new, productivity-increasing ideas." [@lucas2014knowledge]

Benhabib--Perla--Tonetti (2014) generate growth with an endogenous split between frontier innovation and imitation/catch-up.
: > "The resulting equilibrium is an endogenous segmentation between innovators and imitators." [@benhabib2014catchup]

Connection to "knowledge-sharing LLMs":
: These models make it natural to interpret "old LLMs" as reducing the effective costs/frictions of searching, matching, and imitating (and therefore compressing knowledge rents).

## Endogenous growth: ideas as (partly) nonrival inputs

Romer (1990) frames technology as a special kind of input.
: > "The distinguishing feature of the technology as an input is that it is a nonrival, partially excludable good." [@romer1990endogenous]

Jones (1995) emphasizes that many R\&D-based models predict strong scale effects that are not borne out empirically.
: > "This paper argues that the "scale effects" prediction of many recent R\&D-based models of growth is inconsistent with the time-series evidence from industrialized economies." [@jones1995rd]

Bloom--Jones--Van Reenen--Webb (2020) document declining research productivity ("ideas getting harder to find").
: > "More generally, everywhere we look we find that ideas, and the exponential growth they imply, are getting harder to find." [@bloom2020ideas]

Connection to "knowledge-creating LLMs":
: In this language, "new LLMs" plausibly shift the idea production function itself (not just the diffusion of existing ideas), which re-raises the standard questions of appropriability and market structure.

## Appropriability, IP, and licensing

Arrow (1962) is a canonical statement of why private incentives and social value can diverge for invention/knowledge.
: > "INVENTION is here interpreted broadly as the production of knowledge." [@arrow1962welfare]

Katz \& Shapiro (1985) analyze when a patent holder chooses to license versus exclude.
: > "We find that major innovations will not be licensed, but that equally efficient firms will tend to license minor innovations." [@katz1985licensing]

Arora--Fosfuri--Gambardella (2001) describe how a market for technology changes firms' strategic choices.
: > "Markets for technology increase the strategy space: firms can choose to license in the technology instead of developing it in-house." [@arora2001markets]

Kamien--Oren--Tauman (1992) compare licensing mechanisms (e.g. auctions vs uniform royalties).
: > "Proposition 6 asserts that for both the patentee and consumers a uniform royalty is inferior to an auction." [@kamien1992licensing]

Connection to this post's core claim:
: If "new LLMs" reliably generate *valuable, appropriable* new recipes, then the equilibrium object may be closer to exclusive licensing / restricted access (or secrecy) than to wide diffusion of a general-purpose tool.
