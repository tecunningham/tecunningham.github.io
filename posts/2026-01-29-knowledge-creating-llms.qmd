---
title: Knowledge-Creating LLMs
date: today
author:
  - name: Tom Cunningham
    affiliation: METR
    affiliation-url: https://metr.org/
reference-location: document
citation: true
engine: knitr
bibliography: ai.bib
draft: true
---
<!-- 
https://tecunningham.github.io/posts/2026-01-29-knowledge-creating-llms.html
see also - 2026-01-31-knowledge-creating-model.md 
-->

::: {.column-margin}
   Thanks to Zoë Hitzig & Parker Whitfill for helpful comments.
:::

It's useful to make a distinction between two types of LLMs:

: **Knowledge-sharing LLMs.** Traditionally LLMs have been trained with human judgment as the ground truth, as a consequence they rarely exhibit superhuman performance. Their economic value mainly comes from sharing existing knowledge, and the natural business model is to sell access broadly.
  
    **Knowledge-creating LLMs.** Recently LLMs have been trained against the real world, as a consequence they can extend the limits of human knowledge. The demand for new knowledge is different from the demand for old knowledge, and there's reason to expect LLM-creators to sell access *exclusively*.

    Below I give a longer discussion of this distinction, a simple economic model, implications for IP, and a galaxy-brain theory that there are only a few dozen deep problems in the world.


<!-- An LLM that shares existing knowledge will be adopted by people outside their area of expertise, and LLM-developers will want to sell access at a low cost. In contrast an LLM that can discover new knowledge will be adopted by experts, and LLM-developers will wish to strictly limit access. -->

<!-- 

To add:
:     1. Better graph
      1. Add some predictions about 2026
      2. Parker point: compare with existing research labs, but much more on fixed costs.
      3. Zoe point: "ie i’m not sure about this distinction : “Thus labs will prefer to restrict output, e.g. by selling the knowledge to just one firm, instead of selling the ability to generate knowledge.”"
      4. Zoe point about distillation
      5. Trade costs imply some home production just behind the frontier
      6. ~~Differences in benchmarks between old & new LLMs~~
      7. ~~Quotes about how LLMs are now creating new knowledge~~
      8.  Send to: Eddie, Erik B, Josh Gans. 
      9.  It would be more satisfying to have a generative model. I'd really like to sketch out a very simple model in which both humans and LLMs learn recipes from experimenting against the real world.
-->


#       Knowledge-Sharing vs Knowledge-Creating LLMs

<!-- It's useful to distinguish between two types of LLMs:
:   1. **Knowledge-sharing LLMs.**-- they are trained on human-produced and human-judged data.
    1. **Knowledge-creating LLMs.** -- they are trained against new data directly from the real world, e.g. math, verifiable problems, computer use, actions in the world. -->


Knowledge-sharing LLMs.
:     I find it is useful to think of LLMs as lowering the price of sharing existing human knowledge (see some of my previous writing on this: [AI & Imitation](https://tecunningham.github.io/posts/2023-09-05-model-of-ai-imitation.html), [a pocket model of AI][transformative]).

      Traditionally LLMs have been trained with human judgment as the ground truth, using labels from paid raters or from customers. As a consequence they can answer questions and solve problems up to the limits of human expertise but rarely beyond (with some exceptions, see the literature on LLM "Transcendence", @abreu2025taxonomytranscendence).

      If we model the economic effects of LLMs as coming from sharing existing knowledge this has a number of implications that seem to fit the data.[^sharing]

      - LLMs use will be higher among those junior in their careers, facing problems that are new to them.
      
      - LLMs will be dispropportionately used by people outside their area of expertise, e.g. lawyers will use them relatively more for medical questions, doctors will use them relatively more for legal questions.
      
      - LLMs will be disproportionately used in well-documented domains, e.g. relatively more for popular programming languages than for proprietary programming languages.
      
      - LLMs will decrease knowledge rents -- the premium earned by people and firms whose value comes from knowledge.
      
      - LLMs will increase home production -- LLMs let you solve problems yourself (see my ChatGPT paper, @chatterji2025chatgpt), insofar as this substitutes for market-provided knowledge this can decrease measured GDP.

      - LLMs decrease the returns to innovation and news-gathering, because they increase the speed of knowledge diffusion and thus diminish the rents that can earned from new knowledge.
      
      - LLM use has high fixed costs (collecting the knowledge) and low marginal costs (sharing the knowledge). The returns to tokens on an individual problem rapidly diminish when you hit the frontier of existing knowledge. One ChatGPT query can tell me what an expert would think about my problem, additional ChatGPT queries have much less use.


[^sharing]: Many other technologies share knowledge -- speaking, writing, printing, the internet -- LLMs just continue this progression but further lower the costs of sharing.

      
<!-- (more speculative) they decrease firm size, because you don't need an in-house specialist anymore. -->

Knowledge-creating LLMs.
:     
    Over the past 18 months it has become much more popular to train LLMs directly against a source of ground truth, e.g. Reinforcement Learning against Verifiable Rewards (RLVR). Accompanying this there has been a steadily increasing stream of announcements of new discoveries by LLMs.

    New LLM-based discovery techniques (e.g. AlphaEvolve (@novikov2025alphaevolve), TTT-Discover (@yuksekgonul2026learning)) are distinct from prior AI discovery applications (e.g. AlphaFold, AlphaTensor) in that they are *general* methods, they can relatively quickly be adapted to any arbitrary optimization problem.

     Knowledge-creating LLMs will differ from knowledge-sharing LLMs in a number of ways:

     - Knowledge-creating LLMs will have qualitatively different benchmarks: instead of seeing if they can answer questions which we already know the answer to (most existing benchmarks), we want them to answer *new* questions, e.g. solve an unsolved mathematical problem ([FrontierMath Open Problems](https://epoch.ai/frontiermath/open-problems)) or set a new record on an optimization problem (e.g. GSO-bench). We can use these new frontier benchmarks are indices for capability, but they are more challenging to interpret because the frontier is always moving.

     - Knowledge-creating LLMs have high returns to compute on individual problems, unlike knowledge-sharing LLMs for which returns asymptote quickly. It can be worth spending billions of tokens to solve a single problem if the solution is generally applicable.

     - Knowledge-creating LLMs will be adopted by leader firms more than followers.
      
     - The demand for new knowledge is much less elastic than the demand for existing knowledge because there are high returns to *exclusivity* of new knowledge. Thus LLM-providers are likely to license their technology exclusively rather than expose them through a general-purpose API. Sarah Friar, OpenAI's CFO, said in [January 2026](https://openai.com/index/a-business-that-scales-with-the-value-of-intelligence/):

      > *"As intelligence moves into scientific research, drug discovery, energy systems, and financial modeling, new economic models will emerge. Licensing, IP-based agreements, and outcome-based pricing will share in the value created."*

Will knowledge-creation be bottlenecked on data?
: 
    A common claim is that AI knowledge-creation will be bottlenecked on the ability to run new experiments. E.g. an automated biologist still needs a lab (@amodei2024machines), and an automated AI researcher will still need a lot of GPUs to do experiments. Whether this is true depends on the shape of the optimization landscape. If the world is intrinsically high-dimensional, then there is no substitute for collecting data. But if there exists a low-dimensional structure then there are high returns to just thinking harder (more discussion in an [earlier post][transformative]). We have found many domains which appeared to be high-dimensional, but turned out to be intrinsically low-dimensional.

<!--
Applications for knowledge-creating LLMs:
:    
    - Optimizing algorithms.
    - Drug discovery. 
    - AI R&D.
    - Predict stock prices.
-->

#           A Visual Illustration


Here we draw the cost for a set of 3 humans across a range of tasks, assuming each has a specialty area where they have the lowest labor-cost. The knowledge-sharing LLM aggregates knowledge, and so is the lower bound across all three agents.

```{tikz}
#| fig-align: center
\begin{tikzpicture}[x=10cm,y=6cm]
  \def\w{0.042}      % dip width
  \def\mmin{0.34}    % dip depth

  \def\bAaron{0.86}
  \def\bCarlos{0.90}
  \def\bEthan{0.94}
  \pgfmathsetmacro{\aAaron}{\bAaron-\mmin}
  \pgfmathsetmacro{\aCarlos}{\bCarlos-\mmin}
  \pgfmathsetmacro{\aEthan}{\bEthan-\mmin}

  % Helper functions
  \pgfmathdeclarefunction{costAaron}{1}{\pgfmathparse{\bAaron - \aAaron*exp(-((#1-0.10)^2)/\w)}}
  \pgfmathdeclarefunction{costCarlos}{1}{\pgfmathparse{\bCarlos - \aCarlos*exp(-((#1-0.42)^2)/\w)}}
  \pgfmathdeclarefunction{costEthan}{1}{\pgfmathparse{\bEthan - \aEthan*exp(-((#1-0.74)^2)/\w)}}
  \pgfmathdeclarefunction{oldllm}{1}{\pgfmathparse{min(min(costAaron(#1),costCarlos(#1)),costEthan(#1))}}
  % New LLM: only improves the "Ethan/rightmost" domain (where Ethan is the envelope)
  \pgfmathdeclarefunction{newllm}{1}{\pgfmathparse{
    ifthenelse(
      costEthan(#1) <= min(costAaron(#1),costCarlos(#1)),
      oldllm(#1)-0.1,
      oldllm(#1)
    )
  }}

  % Axes
  \draw[->, line width=0.8pt] (0,0) -- node[midway,below] {task type} (1.0,0);
  \draw[->, line width=0.8pt] (0,0) -- (0,1.18) node[midway,above,rotate=90] {cost (lower is better)};

  \draw[->, gray!60, line width=0.8pt] (1,0) -- (1,1.18);

  % Individual agent cost curves (mostly flat with a narrow dip).
  \draw[blue!70!black, line width=1.6pt]
    plot[domain=0:1, samples=350] (\x,{costAaron(\x)});

  \draw[green!50!black, line width=1.6pt]
    plot[domain=0:1, samples=350] (\x,{costCarlos(\x)});

  \draw[orange!80!black, line width=1.6pt]
    plot[domain=0:1, samples=350] (\x,{costEthan(\x)});

  % old LLM curve: lower envelope of the agent curves
  \draw[black, dotted, opacity=0.65, line width=3.2pt]
    plot[domain=0:1, samples=350] (\x,{oldllm(\x)});

  % RHS labels (x=1): keep only the envelope labels
  \pgfmathsetmacro{\yOldLLM}{oldllm(1)}


  \node[anchor=west] at (1.012,0.98) {human cost curves};

  %\draw[black!55, line width=0.6pt]           (1,{\yOldLLM})   -- (1.010,0.74);
  \node[anchor=west,align=left]                         at (1.012,0.8) {knowledge-sharing LLM\\(minimum across humans)};
\end{tikzpicture}
```

We can then illustrate a knowledge-creating LLM as pushing below the human frontier at some set of tasks:

```{tikz}
#| fig-align: center
\begin{tikzpicture}[x=10cm,y=6cm]
  \def\w{0.042}      % dip width
  \def\mmin{0.34}    % dip depth

  \def\bAaron{0.86}
  \def\bCarlos{0.90}
  \def\bEthan{0.94}
  \pgfmathsetmacro{\aAaron}{\bAaron-\mmin}
  \pgfmathsetmacro{\aCarlos}{\bCarlos-\mmin}
  \pgfmathsetmacro{\aEthan}{\bEthan-\mmin}

  % Helper functions
  \pgfmathdeclarefunction{costAaron}{1}{\pgfmathparse{\bAaron - \aAaron*exp(-((#1-0.10)^2)/\w)}}
  \pgfmathdeclarefunction{costCarlos}{1}{\pgfmathparse{\bCarlos - \aCarlos*exp(-((#1-0.42)^2)/\w)}}
  \pgfmathdeclarefunction{costEthan}{1}{\pgfmathparse{\bEthan - \aEthan*exp(-((#1-0.74)^2)/\w)}}
  \pgfmathdeclarefunction{costSuperEthan}{1}{\pgfmathparse{\bEthan - 0.8*exp(-((#1-0.74)^2)/\w)}}
  \pgfmathdeclarefunction{oldllm}{1}{\pgfmathparse{min(min(costAaron(#1),costCarlos(#1)),costEthan(#1))}}
  \pgfmathdeclarefunction{newllm}{1}{\pgfmathparse{min(min(costAaron(#1),costCarlos(#1)),costSuperEthan(#1))}}

  % Axes
  \draw[->, line width=0.8pt] (0,0) -- node[midway,below] {task type} (1.0,0);
  \draw[->, line width=0.8pt] (0,0) -- (0,1.18) node[midway,above,rotate=90] {cost (lower is better)};

  \draw[->, gray!60, line width=0.8pt] (1,0) -- (1,1.18);

  % Individual agent cost curves (mostly flat with a narrow dip).
  \draw[blue!70!black, line width=1.6pt]
    plot[domain=0:1, samples=350] (\x,{costAaron(\x)});

  \draw[green!50!black, line width=1.6pt]
    plot[domain=0:1, samples=350] (\x,{costCarlos(\x)});

  \draw[orange!80!black, line width=1.6pt]
    plot[domain=0:1, samples=350] (\x,{costEthan(\x)});

   % new LLM curve: old LLM curve shifted down
  \draw[black, dotted, opacity=0.65, line width=3.2pt]
    plot[domain=0:1, samples=350] (\x,{newllm(\x)});

  % RHS labels (x=1): keep only the envelope labels
  \pgfmathsetmacro{\yOldLLM}{oldllm(1)}
  \pgfmathsetmacro{\yNewLLM}{newllm(1)}

  \node[anchor=west] at (1.012,0.98) {human cost curves};

  %\draw[black!55, line width=0.6pt]           (1,{\yOldLLM})   -- (1.010,0.74);
  %\node[anchor=west]                         at (1.012,0.74) {old LLM\\(minimum across humans)};

  %\draw[black!55, line width=0.6pt]           (1,{\yNewLLM})   -- (1.010,0.66);
  \node[anchor=west,align=left]                         at (1.012,0.7) {knowledge-creating LLM\\(lower cost than best human)};
\end{tikzpicture}
```


<!-- |                                 | Knowledge-Sharing LLM          | Knowledge-Creating LLM        |
| ------------------------------- | ------------------------------ | ----------------------------- |
| Who uses it                     | Inexperienced                  | Experienced                   |
| Types of use                    | Outside your area of expertise | Inside your area of expertise |
| Effect on output                | Redistributes surplus          | Creates new surplus           |
| Effect on inequality            | Decreases inequality           | Increases inequality          |
| Value of exclusivity            | Low                            | High                          |
| Cost structure                  | Low marginal costs             | High marginal costs           |
| Effect on home production       | Increase                       | Decrease                      |
| Effect on returns to innovation | Decrease                       | Increase                      |
|                                 |                                |                               |
 -->


#           There are Only a Dozen Deep Problems (Galaxy Brain)

If you squint, a billion problems resolve into just a dozen common problems.
:  
    In many domains we can reduce the set of problems down to a much smaller set of equivalence-classes or canonical problems. We can then consider problem-solving as having two parts: (1) map to a canonical problem; (2) make progress on that canonical problem.
    
    Consider three types of problems which LLMs are often asked to solve:

(1) Constraint-satisfaction problems.
: 
    Optimization theory textbooks will often have two types of results (1) proofs on the optimality of certain algorithms; (2) proofs that one type of problem is logically equivalent to another type of problem (e.g. a very large class of problems are equivalent to  [3SAT][3SAT], or can be reduced to 3SAT in polynomial time). Some algorithms are known to be optimal but many others are being continually improved.

(2) Factual problems.
: 
    We can reduce a factual question into (1) find the documented facts that are relevant to this question; (2) infer the answer from those facts. Once you have collected the existing documented facts you hit a ceiling, which can only be advanced by collecting more facts.

(3) Statistical inference problems.
: 
    For many classes of supervised learning problems there exists an existing "best practice", e.g. a [recent article][nvidia] says *"Over hundreds of Kaggle competitions, we’ve refined a playbook that consistently lands us near the top of the leaderboard"*. Thus if you ask an LLM to do statistical inference, it can relatively easily find the existing best-practice, but then it is much harder to advance on that (and if it does, then the solution would be very generally applicable).

This is a difficulty for LLM benchmarking.
: 

    The mapping between idiosyncratic and canonical problems is a difficulty for LLM benchmarking. If each problem can be mapped to a canonical problem, and there exists a best-known-algorithm for each of those canonical problems, then it's difficult to test the model's intelligence. A reasonably smart LLM will know how to map a new problem into a canonical problem, and will know the textbook best-practice for that canonical problem (XGboost, ARIMA, gaussian process, branch-and-cut, PPO, etc.).

Labs will spend a lot on fixed inference, a little on variable inference.
: 
    If this perspective is accurate then it has deep implications for the economics of AI: the marginal cost of solving an idiosyncratic problem is small (you just need to map it to one of the canonical problems, and apply that solution), but there's very high value in making progress on the canonical problems. So we would expect AI labs to be spending huge amounts of compute on advancing the SoTA on the few deep problems of the world, and providing a service that solves idiosyncratic problems very cheaply.


There will be a land-grab in intellectual property.
: 
    If we maintain the same intellectual property law then this implies there will be a land-grab: firms will rush to be the first to discover new technologies which they can patent. But it seems plausible that the exclusivity will be inefficient, i.e. it wasn't necessary to motivate the research, the new technology would've been discovered anyway.


#           Appendix

Examples of knowledge-creating LLMs.
:  
   @novikov2025alphaevolve (Alpha-Evolve):

      > "AlphaEvolve orchestrates an autonomous pipeline of LLMs, whose task is to improve an algorithm by making direct changes to the code. ... When applied to optimizing critical components of large-scale computational stacks at Google, AlphaEvolve developed a more efficient scheduling algorithm for data centers, found a functionally equivalent simplification in the circuit design of hardware accelerators, and accelerated the training of the LLM underpinning AlphaEvolve itself. Furthermore, AlphaEvolve discovered novel, provably correct algorithms that surpass state-of-the-art solutions on a spectrum of problems in mathematics and computer science, significantly expanding the scope of prior automated discovery methods (Romera-Paredes et al., 2023)."

    @yuksekgonul2026learning (TTT-Discover):

      > "We report results for every problem we attempted, across mathematics, GPU kernel engineering, algorithm design, and biology. TTT-Discover sets the new state of the art in almost all of them: (i) Erdős’ minimum overlap problem and an autocorrelation inequality; (ii) a GPUMode kernel competition (up to 2×faster than prior art); (iii) past AtCoder algorithm competitions; and (iv) denoising problem in single-cell analysis. Our solutions are reviewed by experts or the organizers."

   

#           An Economic Model [UNFINISHED]

A basic model of knowledge and output.
: In a very simple model we have:

      1. Aggregate output is determined by the best knowledge.
      2. Aggregate profit is determined by the distance between the best and second-best knowledge.

      Suppose there are $L$ people, each has 1 unit of labor, and there is just one good. Each person knows some subset of recipes $R_i\subseteq R$, and each recipe yields some cost of producing the good from labor, $c(r)$. Then person $i$'s effective cost $c_i$ is the lowest cost among the recipes that they know. Each person can rent labor from others to produce the consumption good, and we assume labor is allocated via Bertrand wage competition among recipe-holders; workers are price-takers and work for the highest wage.

      We can order the costs from lowest to highest, $c_{(1)}\leq \cdots \leq c_{(L)}$. In equilibrium the lowest-cost agent will rent the labor of all others, produce the good at the lowest cost $c_{(1)}$, and then sell the good back at a price equal to the second-lowest cost ($1/c_{(2)}$), and keep the remainder as profit:
: $$\begin{aligned}
      \text{output} &= \frac{1}{c_{(1)}}L  && \text{(the best recipe)}\\
      \text{profit} &= \left(\frac{1}{c_{(1)}}-\frac{1}{c_{(2)}}\right)(L-1) 
         && \text{(diff bw 1st and 2nd-best recipe)}
   \end{aligned}
   $$


Knowledge-sharing spreads output.
:  Suppose we share the best recipe among the whole population, so now $c'_{(2)}=c'_{(1)}=c_{(1)}$. Now total output is unchanged, but profit is eliminated, and the output is spread equally among all actors.

Knowledge-creation increases output.
: Suppose we can improve the best recipe, $c'_{(1)}<c_{(1)}$. Total output will increase. The effect on profit will depend on (1) whether the identity of the lowest-cost producer changes; and (2) the degree of improvement.

<!-- 
The market for knowledge.
: We now should turn to how knowledge-sharing and knowledge-creation is used. The answers are somewhat sensitive to the specifics of the market. 
-->


<!-- notes on models: 2026-01-31-knowledge-creating-model.md -->

[3SAT]: https://en.wikipedia.org/wiki/Boolean_satisfiability_problem

[nvidia]: https://developer.nvidia.com/blog/the-kaggle-grandmasters-playbook-7-battle-tested-modeling-techniques-for-tabular-data/

[transformative]: https://tecunningham.github.io/posts/2025-09-19-transformative-AI-notes.html