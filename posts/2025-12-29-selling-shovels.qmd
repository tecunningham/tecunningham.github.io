---
title: Selling Shovels
draft: true
---

Claim: labs will switch from selling shovels to using the shovels themselves.
: As the models get stronger labs will stop selling access to the models, and instead use the models themselves to create or co-create artefacts (algorithms, videos, scientific discoveries), which they can directly sell, or take a revenue-share ffrom.

Examples:
:     - Create a movie
      - Predict stock prices & trade on them
      - Optimize a widely-used algorithm
      - Optimize a widely-used technology
      - Make a scientific discovery

Observations on modeling this:
:     1. _Probably we can ignore the inference costs._ -- seems like main implications are just from value side, & ignoring cost.
      1. _Distinction between local vs global value._ -- (not quite rivalness or excludability, but correlation in value).
      2. _Distinction between large problems and small problem._

Theory on residual rights.
: Suppose there are two factors, it's efficient to assign ownership (residual rights) to the factor which has less-observable inputs ("the party whose investment is most important and most difficult to specify in a contract").

Who could I get to coauthor?
: Erik B; Andrey; Philip Trammel; Basil; _Andy Haupt_.

      Hi Phil, Basil, Andy. Merry christmas! I've written up a one-page note on an issue I think is important, & I'm looking for a coauthor, in case I could tempt any of you. I'm personally persuaded this is going to be a big deal, & I feel I haven't seen public discussion of this issue, so keen to get this out somewhere. (& FWIW my expectation is partly informed by my industry experience.)

##       Models

Small problems vs big problems (demand curve).
:     - The old model can solve a lot of $1 problems, the new model can solve a few $1M problems.
      - Can think of this as steepening of the demand curve, so it becomes optimal to raise the price. But by itself this doesn't have implications for rent-vs-own or buy-vs-build.

Global value vs local value.
:     - Suppose old models solve *local* problems, & new models solve *global* problems (nonrival).
      - Suppose the total surplus generated in each case is the same.
      - Village example: (1) you dig a well and sell the water; (2) you build a library and sell access.
      - If you sell the inputs to build a nonrival good, then can't charge a premium for it.

Unobservable inputs.
:     - Suppose output depends on inputs from humans and from the AI, what's the efficient allocation of ownership of the outputs?
      - Oliver Hart says "ownership should be allocated to the party whose investment is most important and most difficult to specify in a contract."
      - For existing models it's difficult to specify the human inputs in a contract.
      - However as new models get better it's easier to specify them.

Human-level vs superhuman (M&M model).
:     - Each human has a knowledge set, allows them to produce certain goods.
      - Assume symmetric demand across goods (and σ>1), pins down sorting of people to goods.
      - Old AI gives people existing skills.
      - New AI gives people new skills. 

Vertical integration.
:  


(note: Dixit-Stiglitz love-of-variety CES has $\sigma>1$, i.e. gross substitutes, otherwise you get pathological cases)

##       ownership / residual rights

Alchian and Demsetz (1972):

: > "“The essential role of the firm is to economize on the costs of measuring marginal productivities. ... the monitor must be the residual claimant."

Fama and Jensen (1983):

: > "Efficient organization assigns residual claims to those with the greatest incentives to monitor and control.

Hart (1995):

: > **"Ownership should be allocated to the party whose investment is most important and most difficult to specify in a contract.** ... The owner of an asset has the right to decide on its use in all contingencies not specified in the contract, and hence ownership confers bargaining power when investments are non-verifiable."

Examples:

: > "If a fisherman rents a boat, then when unforeseen contingencies arise the owner of the boat has control. If instead the fisherman owns the boat, then he has control over its use in all circumstances not specified in the contract."

: > "When a worker’s actions are hard to specify, it may be optimal for the firm to hire the worker and own the output, rather than contract for a finished good."


##       post on METR slack

I feel that in 2026 we're going to get a blast of capabilities from a direction we're not expecting. Specifically using a lot of inference to optimize on a single task:

- Create a movie
- Predict stock prices
- Optimize algorithms
- Optimize technology
- Solve scientific problems

You want to spend a ton of tokens going deep on a single problem, and you can have a semi-custom architecture for this. Labs wouldn't want to *sell* this ability to customers, it makes more economic sense to *use* the technology internally and then sell the product you've create with it.

This makes me a bit more anxious about AI R&D ability not being publicly observable, because AI R&D is a type of optimization problem, & it seems likely that labs will postpone releasing this technology publicly.

##        shovels metaphor

Suppose you have a lot of shovels:

1. The valley is full of gold flakes everywhere, then you make money selling shovels to other people.
2. The valley has one large gold nugget burried deep, then you use the shovels yourself to dig it out yourself.

original quote, but not clear provenance:

> "When Everybody Is Digging for Gold, It’s Good To Be in the Pick and Shovel Business"



## 2025-12-24 |                      monopoly in general equilibrium

1. **TLDR: you can now choose the price vector.**

2. **In an Edgeworth box, the other guy's offer curve is now your budget constraint.**

3. **If e=1 (Cobb-Douglas), offer curves will be straight lines:**

   ![](images/2025-12-24-06-14-37.png)
   - I can get half his loaves, while giving away almost zero fishes.

4. **If gross complements you can get everything from the other guy.**

![](images/2025-12-24-06-20-29.png)

5. **If gross substitutes you can only get a little extra surplus.**

![](images/2025-12-28-06-38-42.png)

[ChatGPT diagrams](https://chatgpt.com/share/695141da-a83c-8013-8366-e1caa9c5e9c1)

--------------------------------------------

[Lones Smith notes on monopoly in general equilibrium](https://www.lonessmith.com/wp-content/uploads/2020/09/7-GE-in-Exchange-Economies-1.pdf)

   - Monopolist "seeks his highest indifference curve on Iris’s TOC [trade offer curve]"
   - Nice point that monopolist can do even better with a two-part tariff. 


#                       notes

[Naveen Rao, Databricks VP, Feb 2025](https://x.com/NaveenGRao/status/1886544584588619840)

   > "Prediction: all closed AI model providers will stop selling APIs in the next 2-3 years. Only open models will be available via APIs.

   > "Why? For an open model service, the value prop is clear...it's hard to build a scalable service to access the model and the model is commodity. The race-to-the bottom happened with the commodity already (model). Let AI app builders iterate on great UIs for apps upon scalable services with commodity capabilities

   > "Closed model providers are trying to build non-commodity capabilities and they need great UIs to deliver those. It's not just a model anymore, but an app with a UI for a purpose.

   > "If closed models are available via API, all it does is create competition for the app the closed provider is building. The secret sauce is capabilities + UI."

Alexander Doria ["The Model is the Product"](https://vintagedata.org/blog/posts/model-is-the-product)

   (says that models will do eveyrhting, you don't need a wrapper)
   (thanks to Elsa Jiang for the reference)

(story that OpenAI will share revenues with clients for developing new drugs)

[Sarah Friar comments Jan 2026](https://openai.com/index/a-business-that-scales-with-the-value-of-intelligence/): 

> "Licensing, IP-based agreements, and outcome-based pricing will share in the value created."

- https://sean.heelan.io/2026/01/18/on-the-coming-industrialisation-of-exploit-generation-with-llms/


- https://x.com/karansdalal/status/2014429596847112605
   - > "Test-time training is inevitable. We’re heading toward models that truly learn from experience: TTT for LLM memory (TTT-E2E), and now for open scientific problems."
- https://x.com/james_y_zou/status/2014404929566490848
   - > "Standard AI learns to imitate.  We introduce a new framework that trains AI to make new discoveries in science + engineering."
