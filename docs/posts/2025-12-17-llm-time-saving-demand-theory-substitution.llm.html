<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Tom Cunningham">
<meta name="dcterms.date" content="2026-01-25">
<meta name="description" content="Tom Cunningham blog">

<title>LLM Time-Saving, Demand Theory, and Task Activation | Tom Cunningham – Tom Cunningham</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

<script type="text/javascript">

(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-12027453-1', 'auto');

ga('send', {
  hitType: 'pageview',
  'anonymizeIp': true,
});
</script>
<script src="../site_libs/quarto-diagram/mermaid.min.js"></script>
<script src="../site_libs/quarto-diagram/mermaid-init.js"></script>
<link href="../site_libs/quarto-diagram/mermaid.css" rel="stylesheet">
<script>window.MathJax = {
   loader: { load: ["https://cdn.jsdelivr.net/gh/sonoisa/XyJax-v3@3.0.1/build/xypic.js"]},
   tex: {packages: {'[+]': ['xypic','bm']},
         macros: {  bm: ["\\boldsymbol{#1}", 1],
                    ut: ["\\underbrace{#1}_{\\text{#2}}", 2],
                    utt: ["\\underbrace{#1}_{\\substack{\\text{#2}\\\\\\text{#3}}}", 3] }
   }
};
</script>
<style>
   h1 {  border-bottom: 8px solid #557;}
   h2 {  border-bottom: 1px solid #ccc;}
   .greyproof {
      background-color: #f5f5f5;
      padding: 1em;
      margin: 1em 0;
      border-radius: 4px;
   }
</style>
<meta name="quarto:status" content="draft">

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../styles.css">
<meta name="twitter:title" content="LLM Time-Saving, Demand Theory, and Task Activation | Tom Cunningham">
<meta name="twitter:description" content="Tom Cunningham blog">
<meta name="twitter:card" content="summary">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner"><div id="quarto-draft-alert" class="alert alert-warning"><i class="bi bi-pencil-square"></i>Draft</div>
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Tom Cunningham</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href=".././about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/testingham"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/tom-cunningham-a9433/"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://tecunningham.github.io/index.xml"> <i class="bi bi-rss-fill" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://scholar.google.com/citations?user=MDB_DgkAAAAJ"> 
<span class="menu-text">scholar</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">LLM Time-Saving, Demand Theory, and Task Activation</h1>
                      </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Tom Cunningham (METR) </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">January 25, 2026</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#results-first-summary" id="toc-results-first-summary" class="nav-link active" data-scroll-target="#results-first-summary">Results-first summary</a></li>
  <li><a href="#setup-time-prices-and-speedups" id="toc-setup-time-prices-and-speedups" class="nav-link" data-scroll-target="#setup-time-prices-and-speedups">Setup: time prices and speedups</a></li>
  <li><a href="#estimation-cheat-sheet" id="toc-estimation-cheat-sheet" class="nav-link" data-scroll-target="#estimation-cheat-sheet">Estimation cheat sheet</a>
  <ul class="collapse">
  <li><a href="#two-good-reduction-ai-affected-bundle-vs-the-rest" id="toc-two-good-reduction-ai-affected-bundle-vs-the-rest" class="nav-link" data-scroll-target="#two-good-reduction-ai-affected-bundle-vs-the-rest">Two-good reduction (AI-affected bundle vs the rest)</a></li>
  <li><a href="#if-you-observe-pre-and-post-time-shares-you-can-infer-an-elasticity-in-ces" id="toc-if-you-observe-pre-and-post-time-shares-you-can-infer-an-elasticity-in-ces" class="nav-link" data-scroll-target="#if-you-observe-pre-and-post-time-shares-you-can-infer-an-elasticity-in-ces">If you observe pre and post time shares, you can infer an elasticity (in CES)</a></li>
  <li><a href="#estimation-flowchart-what-to-do-with-your-data" id="toc-estimation-flowchart-what-to-do-with-your-data" class="nav-link" data-scroll-target="#estimation-flowchart-what-to-do-with-your-data">Estimation flowchart (what to do with your data)</a></li>
  <li><a href="#what-you-can-estimate-with-what-data" id="toc-what-you-can-estimate-with-what-data" class="nav-link" data-scroll-target="#what-you-can-estimate-with-what-data">What you can estimate with what data</a></li>
  </ul></li>
  <li><a href="#continuous-intensive-margin-model" id="toc-continuous-intensive-margin-model" class="nav-link" data-scroll-target="#continuous-intensive-margin-model">Continuous (intensive-margin) model</a>
  <ul class="collapse">
  <li><a href="#primal-dual-and-the-time-price-index" id="toc-primal-dual-and-the-time-price-index" class="nav-link" data-scroll-target="#primal-dual-and-the-time-price-index">Primal, dual, and the time price index</a></li>
  <li><a href="#evcv-in-time-units" id="toc-evcv-in-time-units" class="nav-link" data-scroll-target="#evcv-in-time-units">EV/CV in time units</a></li>
  <li><a href="#small-changes-share-weighted" id="toc-small-changes-share-weighted" class="nav-link" data-scroll-target="#small-changes-share-weighted">Small changes (share-weighted)</a></li>
  <li><a href="#large-changes-area-under-compensated-demand" id="toc-large-changes-area-under-compensated-demand" class="nav-link" data-scroll-target="#large-changes-area-under-compensated-demand">Large changes (area under compensated demand)</a></li>
  <li><a href="#ces-specialization-closed-form" id="toc-ces-specialization-closed-form" class="nav-link" data-scroll-target="#ces-specialization-closed-form">CES specialization (closed-form)</a></li>
  </ul></li>
  <li><a href="#discrete-extensive-margin-model-task-activation" id="toc-discrete-extensive-margin-model-task-activation" class="nav-link" data-scroll-target="#discrete-extensive-margin-model-task-activation">Discrete (extensive-margin) model: task activation</a>
  <ul class="collapse">
  <li><a href="#unit-demand-formulation" id="toc-unit-demand-formulation" class="nav-link" data-scroll-target="#unit-demand-formulation">Unit-demand formulation</a></li>
  <li><a href="#setup-cost-variant-bridging-discrete-and-continuous" id="toc-setup-cost-variant-bridging-discrete-and-continuous" class="nav-link" data-scroll-target="#setup-cost-variant-bridging-discrete-and-continuous">Setup-cost variant (bridging discrete and continuous)</a></li>
  <li><a href="#worked-example-discrete-not-continuous" id="toc-worked-example-discrete-not-continuous" class="nav-link" data-scroll-target="#worked-example-discrete-not-continuous">Worked example (discrete, not continuous)</a></li>
  <li><a href="#newly-activated-tasks-cadillac-tasks" id="toc-newly-activated-tasks-cadillac-tasks" class="nav-link" data-scroll-target="#newly-activated-tasks-cadillac-tasks">Newly activated tasks (“Cadillac tasks”)</a></li>
  </ul></li>
  <li><a href="#applications" id="toc-applications" class="nav-link" data-scroll-target="#applications">Applications</a>
  <ul class="collapse">
  <li><a href="#application-1-from-query-level-time-savings-to-an-aggregate-lift-anthropic" id="toc-application-1-from-query-level-time-savings-to-an-aggregate-lift-anthropic" class="nav-link" data-scroll-target="#application-1-from-query-level-time-savings-to-an-aggregate-lift-anthropic">Application 1: from query-level time savings to an aggregate lift (Anthropic)</a></li>
  <li><a href="#application-2-interpreting-uplift-rcts-metr-open-source-dev" id="toc-application-2-interpreting-uplift-rcts-metr-open-source-dev" class="nav-link" data-scroll-target="#application-2-interpreting-uplift-rcts-metr-open-source-dev">Application 2: interpreting “uplift” RCTs (METR / open-source dev)</a></li>
  </ul></li>
  <li><a href="#experimental-design-estimating-substitution-and-selection" id="toc-experimental-design-estimating-substitution-and-selection" class="nav-link" data-scroll-target="#experimental-design-estimating-substitution-and-selection">Experimental design (estimating substitution and selection)</a></li>
  <li><a href="#diagrams" id="toc-diagrams" class="nav-link" data-scroll-target="#diagrams">Diagrams</a>
  <ul class="collapse">
  <li><a href="#threshold-diagram-discrete-activation" id="toc-threshold-diagram-discrete-activation" class="nav-link" data-scroll-target="#threshold-diagram-discrete-activation">Threshold diagram (discrete activation)</a></li>
  </ul></li>
  <li><a href="#checklist-for-the-desiderata" id="toc-checklist-for-the-desiderata" class="nav-link" data-scroll-target="#checklist-for-the-desiderata">Checklist for the desiderata</a></li>
  <li><a href="#related-literature-more-explicit" id="toc-related-literature-more-explicit" class="nav-link" data-scroll-target="#related-literature-more-explicit">Related literature (more explicit)</a>
  <ul class="collapse">
  <li><a href="#index-numbers-and-exact-welfare-from-price-changes-continuous-case" id="toc-index-numbers-and-exact-welfare-from-price-changes-continuous-case" class="nav-link" data-scroll-target="#index-numbers-and-exact-welfare-from-price-changes-continuous-case">Index numbers and exact welfare from price changes (continuous case)</a></li>
  <li><a href="#time-allocation-information-costs-and-overhead-time" id="toc-time-allocation-information-costs-and-overhead-time" class="nav-link" data-scroll-target="#time-allocation-information-costs-and-overhead-time">Time allocation, information costs, and “overhead” time</a></li>
  <li><a href="#discrete-activation-selection-and-welfare-with-lumpy-choices" id="toc-discrete-activation-selection-and-welfare-with-lumpy-choices" class="nav-link" data-scroll-target="#discrete-activation-selection-and-welfare-with-lumpy-choices">Discrete activation, selection, and welfare with lumpy choices</a></li>
  <li><a href="#task-based-technological-change-and-aggregation" id="toc-task-based-technological-change-and-aggregation" class="nav-link" data-scroll-target="#task-based-technological-change-and-aggregation">Task-based technological change and aggregation</a></li>
  <li><a href="#empirical-ai-productivity-and-usage-measurement" id="toc-empirical-ai-productivity-and-usage-measurement" class="nav-link" data-scroll-target="#empirical-ai-productivity-and-usage-measurement">Empirical AI productivity and usage measurement</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<div id="7c1f652a" class="cell" data-results="asis" data-execution_count="2">
<div class="cell-output cell-output-display cell-output-markdown">
<details class="validation-checklist">
<summary>
Validation Checks
</summary>
<ul>
<li>✅&nbsp;Programmatic: required sections present (8/8)</li>
<li>✅&nbsp;Programmatic: proof structure (collapsed)</li>
<li>✅&nbsp;Programmatic: estimation flowchart present</li>
<li>✅&nbsp;Programmatic: Mermaid syntax lint (offline)</li>
<li>⏳&nbsp;Programmatic: Mermaid renders via mermaid.ink (optional)</li>
<li>✅&nbsp;Programmatic: diagrams present</li>
<li>✅&nbsp;Programmatic: applications present</li>
<li>✅&nbsp;Programmatic: experimental design present</li>
<li>✅&nbsp;Programmatic: bibliography tests
<ul>
<li>✅&nbsp;Duplicate citekeys</li>
<li>✅&nbsp;One field per line + trailing comma</li>
<li>✅&nbsp;Source locator present (url/doi/eprint) (225/225)</li>
<li>✅&nbsp;Abstract length &lt;= 500 words (72/72)</li>
<li>✅&nbsp;abstract_source only when abstract is present (63/63)</li>
<li>✅&nbsp;arXiv eprints use arxiv.org/pdf/&lt;id&gt;.pdf URLs (24/24)</li>
<li>✅&nbsp;text_url has local text archive (16/16)</li>
<li>✅&nbsp;bibclean lint</li>
</ul></li>
<li>✅&nbsp;Programmatic: citekeys resolve in <code>posts/ai.bib</code></li>
<li>⏳&nbsp;LLM-assisted: quality + citation plausibility gate (optional)</li>
</ul>
</details>
</div>
</div>
<style>
   details.validation-checklist {
      background: #f5f5f5;
      border: 1px solid #777;
      border-radius: 6px;
      padding: 0.5em 0.75em;
      margin-bottom: 1em;
   }
   details.validation-checklist > summary {
      cursor: pointer;
   }
   .callout-header {
      cursor: pointer;
   }
   dl {display: grid;}
   dt {grid-column-start: 1; width: 10em;}
   dd {grid-column-start: 2; margin-left: 2em;}
</style>
<section id="results-first-summary" class="level2">
<h2 class="anchored" data-anchor-id="results-first-summary">Results-first summary</h2>
<p>We want a productivity lift from LLM time-saving that allows for substitution: after an LLM changes which tasks are cheap in time, you reallocate time across tasks (and possibly activate tasks you previously skipped). This is a classic demand-theory problem, with <em>time</em> as the budget and <em>tasks</em> as the goods.</p>
<ul>
<li><p><strong>Estimand.</strong> Let <span class="math inline">\(p_i\)</span> be time per unit of task-output <span class="math inline">\(i\)</span>, and let <span class="math inline">\(u(x)\)</span> be an output index (effective work accomplished). For a unit time endowment, <span class="math display">\[
v(p)\;=\;\max_{x\ge 0} u(x)\quad\text{s.t.}\quad \sum_i p_i x_i\le 1.
\]</span> If an LLM yields speedups <span class="math inline">\(\beta_i\)</span> so <span class="math inline">\(p_i' = p_i/\beta_i\)</span>, the productivity gain is <span class="math inline">\(v(p')/v(p)\)</span>.</p></li>
<li><p><strong>Continuous (intensive-margin) benchmark.</strong> Under standard regularity and (especially) homotheticity, <span class="math inline">\(v(p)=1/P(p)\)</span> where <span class="math inline">\(P(p)=e(p,1)\)</span> is the unit time-expenditure function (a time price index). Small changes obey a Divisia/Tornqvist approximation <span class="math inline">\(\Delta\ln v\approx \sum_i s_i\,\Delta\ln\beta_i\)</span>. Large changes require integrating <em>compensated</em> shares (“area under Hicksian demand”). <span class="citation" data-cites="caves1982indexnumbers">Caves, Christensen, and Diewert (<a href="#ref-caves1982indexnumbers" role="doc-biblioref">1982</a>)</span>; <span class="citation" data-cites="hausman1981exact">Hausman (<a href="#ref-hausman1981exact" role="doc-biblioref">1981</a>)</span>; <span class="citation" data-cites="willig1976consumerssurplus">Willig (<a href="#ref-willig1976consumerssurplus" role="doc-biblioref">1976</a>)</span></p></li>
<li><p><strong>Discrete (extensive-margin) reality.</strong> Many tasks have setup time, are lumpy, or are “unit-demand” (you either do them or not). A particularly important empirical condition is: <strong>LLMs reduce time costs more for tasks you previously avoided</strong> (high reading/search/writing overhead). Under that condition, “AI-affected time share” is endogenous, and ex-ante shares can badly misstate the productivity lift unless you model (or measure) the extensive margin.</p></li>
<li><p><strong>Practical upshot.</strong> With only a baseline share <span class="math inline">\(s_0\)</span> on an “AI bundle” and a speedup <span class="math inline">\(\beta\)</span>, the implied gain spans a wide range (complements lower bound to substitutes upper bound). To get a point estimate you need either (i) a demand system / elasticity that maps <span class="math inline">\(s_0,\beta\mapsto v(p')/v(p)\)</span>, or (ii) experimental variation that traces out how time allocation responds as the effective AI cost changes.</p></li>
</ul>
</section>
<section id="setup-time-prices-and-speedups" class="level2">
<h2 class="anchored" data-anchor-id="setup-time-prices-and-speedups">Setup: time prices and speedups</h2>
<p><strong>Objects.</strong> Tasks <span class="math inline">\(i=1,\dots,n\)</span>, outputs <span class="math inline">\(x_i\ge 0\)</span>, time endowment normalized to <span class="math inline">\(1\)</span>, time prices <span class="math inline">\(p_i&gt;0\)</span> (time per unit of task output), and LLM speedups <span class="math inline">\(\beta_i&gt;0\)</span> so <span class="math inline">\(p_i' = p_i/\beta_i\)</span>.</p>
<p>We interpret <span class="math inline">\(u(x)\)</span> as an <em>output index</em> or “effective work accomplished,” with time prices defining the budget: <span class="math display">\[
\sum_i p_i x_i \le 1.
\]</span></p>
<p>The important split is:</p>
<ol type="1">
<li><strong>Continuous intensive margin:</strong> choose continuous <span class="math inline">\(x_i\)</span> (smooth substitution).</li>
<li><strong>Discrete extensive margin:</strong> choose which tasks to activate (unit demand or setup costs).</li>
</ol>
<p>I treat these separately because the logic, formulas, and data requirements diverge.</p>
</section>
<section id="estimation-cheat-sheet" class="level2">
<h2 class="anchored" data-anchor-id="estimation-cheat-sheet">Estimation cheat sheet</h2>
<p>This section is a “lookup table” for turning <em>measured</em> speedups into a productivity lift <span class="math inline">\(v(p')/v(p)\)</span> under common assumptions.</p>
<section id="two-good-reduction-ai-affected-bundle-vs-the-rest" class="level3">
<h3 class="anchored" data-anchor-id="two-good-reduction-ai-affected-bundle-vs-the-rest">Two-good reduction (AI-affected bundle vs the rest)</h3>
<p>For many back-of-envelope calculations, you can collapse tasks into:</p>
<ul>
<li><strong>good 2:</strong> the set of tasks whose time cost drops by <span class="math inline">\(\beta\)</span> when AI is allowed,</li>
<li><strong>good 1:</strong> everything else (normalized).</li>
</ul>
<p>Let <span class="math inline">\(s_0\)</span> be the <strong>pre-AI time share</strong> on good 2 (i.e.&nbsp;<span class="math inline">\(s_0 \equiv p_2 x_2 / (p_1 x_1+p_2 x_2)\)</span> evaluated at baseline prices), and suppose only <span class="math inline">\(p_2\)</span> changes to <span class="math inline">\(p_2' = p_2/\beta\)</span>.</p>
<p>Then common benchmarks are:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th>Assumption about substitution</th>
<th>Implied output gain <span class="math inline">\(v(p')/v(p)\)</span></th>
<th>Notes</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Perfect complements (Amdahl-style)</td>
<td><span class="math inline">\(\dfrac{1}{(1-s_0)+s_0/\beta}\)</span></td>
<td>Fixed proportions; AI only relaxes the bottleneck</td>
</tr>
<tr class="even">
<td>Cobb-Douglas (<span class="math inline">\(\varepsilon=1\)</span>)</td>
<td><span class="math inline">\(\beta^{s_0}\)</span></td>
<td>Share is constant; log change is <span class="math inline">\(s_0\ln\beta\)</span></td>
</tr>
<tr class="odd">
<td>CES elasticity <span class="math inline">\(\varepsilon\)</span></td>
<td><span class="math inline">\(\left((1-s_0)+s_0\,\beta^{\varepsilon-1}\right)^{\frac{1}{\varepsilon-1}}\)</span></td>
<td>Requires <span class="math inline">\(\varepsilon\)</span> (or enough data to infer it)</td>
</tr>
<tr class="even">
<td>Perfect substitutes</td>
<td><span class="math inline">\(\beta\)</span></td>
<td>You can reallocate everything to the sped-up bundle</td>
</tr>
</tbody>
</table>
<p>In the multi-task case, a common log-index approximation is the Tornqvist/Divisia form <span class="math display">\[
\Delta\ln v \;\approx\; \sum_i \bar s_i\,\ln \beta_i,\qquad \bar s_i \equiv \tfrac12(s_i^0+s_i^1),
\]</span> which uses average (pre/post) time shares. <span class="citation" data-cites="caves1982indexnumbers">Caves, Christensen, and Diewert (<a href="#ref-caves1982indexnumbers" role="doc-biblioref">1982</a>)</span></p>
<p><strong>Anthropic-style numbers as a sanity check.</strong> If <span class="math inline">\(s_0=0.10\)</span> and <span class="math inline">\(\beta=5\)</span> (80% time reduction when AI is used), the implied gain ranges from:</p>
<ul>
<li>complements bound: <span class="math inline">\(1/(0.9+0.02)\approx 1.087\)</span> (8.7%),</li>
<li>Cobb-Douglas: <span class="math inline">\(5^{0.1}\approx 1.174\)</span> (17.4%),</li>
<li>CES with <span class="math inline">\(\varepsilon=2\)</span>: <span class="math inline">\(0.9+0.1\cdot 5 = 1.4\)</span> (40%),</li>
<li>substitutes bound: <span class="math inline">\(5\)</span> (400%).</li>
</ul>
<p>The spread here is the point: large conditional speedups do <em>not</em> translate to a unique aggregate lift without additional structure or data.</p>
</section>
<section id="if-you-observe-pre-and-post-time-shares-you-can-infer-an-elasticity-in-ces" class="level3">
<h3 class="anchored" data-anchor-id="if-you-observe-pre-and-post-time-shares-you-can-infer-an-elasticity-in-ces">If you observe pre and post time shares, you can infer an elasticity (in CES)</h3>
<p>In the same two-good CES setting, let <span class="math inline">\(s_1\)</span> be the <strong>post-AI</strong> time share on good 2. Then <span class="math display">\[
\operatorname{logit}(s_1)-\operatorname{logit}(s_0)=(\varepsilon-1)\ln \beta,
\]</span> so <span class="math display">\[
\varepsilon \;=\; 1 + \frac{\operatorname{logit}(s_1)-\operatorname{logit}(s_0)}{\ln\beta}.
\]</span></p>
<p>Here <span class="math inline">\(\operatorname{logit}(s)\equiv \ln\!\left(\frac{s}{1-s}\right)\)</span>.</p>
<p>This is often the cleanest way to use both pre and post shares: estimate <span class="math inline">\(\varepsilon\)</span>, then plug into the CES gain formula. (And if you do <em>not</em> believe CES globally, you should treat this as local-to-the-observed price change.)</p>
</section>
<section id="estimation-flowchart-what-to-do-with-your-data" class="level3">
<h3 class="anchored" data-anchor-id="estimation-flowchart-what-to-do-with-your-data">Estimation flowchart (what to do with your data)</h3>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">flowchart TD
  A["Goal: estimate productivity lift&lt;br/&gt;v(p_new)/v(p_old)&lt;br/&gt;for fixed time endowment"] --&gt; B{"Are tasks mostly divisible&lt;br/&gt;at the relevant margin?"}

  B --&gt;|Yes: continuous| C{"Are speedups small&lt;br/&gt;or broad-based?"}
  C --&gt;|Yes| D["Use share-weighted log changes:&lt;br/&gt;d ln v ~= sum_i s_i d ln beta_i&lt;br/&gt;(Tornqvist/Divisia)"]
  C --&gt;|No| E{"Do you have enough data to pin down substitution?&lt;br/&gt;e.g. CES elasticity, demand system"}
  E --&gt;|Yes| F["Compute an exact/parametric index:&lt;br/&gt;P(p)=e(p,1), v=1/P&lt;br/&gt;CES closed form when applicable"]
  E --&gt;|No| G["Trace a demand curve:&lt;br/&gt;vary effective AI cost/strength;&lt;br/&gt;estimate compensated shares; integrate"]

  B --&gt;|No: setup or unit-demand| H["Model extensive margin:&lt;br/&gt;which tasks get activated?"]
  H --&gt; I["Report both:&lt;br/&gt;(i) intensive effect on existing tasks,&lt;br/&gt;(ii) activation/selection effect"]
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</section>
<section id="what-you-can-estimate-with-what-data" class="level3">
<h3 class="anchored" data-anchor-id="what-you-can-estimate-with-what-data">What you can estimate with what data</h3>
<table class="caption-top table">
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th>What you can measure</th>
<th>Recommended move</th>
<th>What you can credibly report</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>One big conditional speedup <span class="math inline">\(\beta\)</span> + a baseline share <span class="math inline">\(s_0\)</span></td>
<td>Report complements/substitutes bounds; add CES sensitivity</td>
<td>A wide interval for <span class="math inline">\(v(p')/v(p)\)</span> unless you assume <span class="math inline">\(\varepsilon\)</span></td>
</tr>
<tr class="even">
<td>Pre and post shares <span class="math inline">\((s_0,s_1)\)</span> for an AI bundle + a speedup <span class="math inline">\(\beta\)</span></td>
<td>Use the logit formula to estimate <span class="math inline">\(\varepsilon\)</span>; plug into CES gain</td>
<td>A model-based point estimate (local to the observed change)</td>
</tr>
<tr class="odd">
<td>Multiple randomized “AI price/quality” arms + observed shares</td>
<td>Estimate share response vs <span class="math inline">\(\ln\beta\)</span>; integrate shares over the change</td>
<td>An “area under the (compensated) demand curve” estimate for large changes</td>
</tr>
<tr class="even">
<td>Choice/activation data (tasks attempted) under multiple AI prices</td>
<td>Model activation thresholds / setup costs explicitly</td>
<td>Decomposition into intensive and extensive margins</td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="continuous-intensive-margin-model" class="level2">
<h2 class="anchored" data-anchor-id="continuous-intensive-margin-model">Continuous (intensive-margin) model</h2>
<section id="primal-dual-and-the-time-price-index" class="level3">
<h3 class="anchored" data-anchor-id="primal-dual-and-the-time-price-index">Primal, dual, and the time price index</h3>
<p>The primal problem is <span class="math display">\[
v(p)\;=\;\max_{x\ge 0} u(x) \quad\text{s.t.}\quad \sum_i p_i x_i\le 1.
\]</span></p>
<p>Define the expenditure function <span class="math display">\[
e(p,\bar u)=\min_{x\ge 0} \Big\{\sum_i p_i x_i: u(x)\ge \bar u\Big\}.
\]</span></p>
<p>If <span class="math inline">\(u(\cdot)\)</span> is homothetic and degree-1 homogeneous, then <span class="math inline">\(e(p,\bar u)=\bar u\,e(p,1)\)</span>. Define the <strong>unit time price index</strong> <span class="math display">\[
P(p)\equiv e(p,1)\quad\Rightarrow\quad v(p)=\frac{1}{P(p)}.
\]</span></p>
<p>This is the classic index-number framing applied to time prices. <span class="citation" data-cites="caves1982indexnumbers">Caves, Christensen, and Diewert (<a href="#ref-caves1982indexnumbers" role="doc-biblioref">1982</a>)</span></p>
</section>
<section id="evcv-in-time-units" class="level3">
<h3 class="anchored" data-anchor-id="evcv-in-time-units">EV/CV in time units</h3>
<p>Let <span class="math inline">\(p^0\to p^1\)</span> and <span class="math inline">\(u^k=v(p^k)\)</span>. Equivalent and compensating variation (measured in <em>time</em>) are <span class="math display">\[
EV=e(p^0,u^1)-1,\qquad CV=e(p^1,u^0)-1.
\]</span></p>
<p>Under homotheticity, <span class="math display">\[
EV=\frac{P(p^0)}{P(p^1)}-1,\qquad CV=\frac{P(p^1)}{P(p^0)}-1.
\]</span></p>
<p>This is the cleanest way to translate LLM time savings into a welfare measure. <span class="citation" data-cites="hausman1981exact">Hausman (<a href="#ref-hausman1981exact" role="doc-biblioref">1981</a>)</span></p>
</section>
<section id="small-changes-share-weighted" class="level3">
<h3 class="anchored" data-anchor-id="small-changes-share-weighted">Small changes (share-weighted)</h3>
<p>Let <span class="math inline">\(t_i(p)\equiv p_i x_i^*(p)\)</span> be optimal time shares. For small changes in time prices, <span class="math display">\[
d\ln v\;=\;-d\ln P\;\approx\;\sum_i t_i\,d\ln \beta_i.
\]</span></p>
<p>This is the time-allocation analog of share-weighted Hulten-style approximations. <span class="citation" data-cites="hulten1978growth">Hulten (<a href="#ref-hulten1978growth" role="doc-biblioref">1978</a>)</span></p>
</section>
<section id="large-changes-area-under-compensated-demand" class="level3">
<h3 class="anchored" data-anchor-id="large-changes-area-under-compensated-demand">Large changes (area under compensated demand)</h3>
<p>When LLM gains are large, constant-elasticity approximations are dangerous. Using Hicksian (compensated) shares <span class="math inline">\(s_i^H(p)\)</span>, <span class="math display">\[
d\ln P(p)=\sum_i s_i^H(p)\,d\ln p_i.
\]</span></p>
<p>For a single changing price <span class="math inline">\(p_2\)</span>, <span class="math display">\[
\ln\frac{P(p^1)}{P(p^0)}=\int s_2^H(p_2)\,d\ln p_2,
\]</span></p>
<p>i.e., exact welfare is the <strong>area under the compensated demand curve</strong>. <span class="citation" data-cites="willig1976consumerssurplus">Willig (<a href="#ref-willig1976consumerssurplus" role="doc-biblioref">1976</a>)</span></p>
</section>
<section id="ces-specialization-closed-form" class="level3">
<h3 class="anchored" data-anchor-id="ces-specialization-closed-form">CES specialization (closed-form)</h3>
<p>For a CES aggregator <span class="math display">\[
u(x)=\left(\sum_i \alpha_i x_i^{\frac{\sigma-1}{\sigma}}\right)^{\frac{\sigma}{\sigma-1}},\quad\sigma&gt;0,
\]</span></p>
<p>the price index and time shares are <span class="math display">\[
P(p)=\left(\sum_i \alpha_i^{\sigma}p_i^{1-\sigma}\right)^{\frac{1}{1-\sigma}},\qquad
t_i(p)=\frac{\alpha_i^{\sigma}p_i^{1-\sigma}}{\sum_j \alpha_j^{\sigma}p_j^{1-\sigma}}.
\]</span></p>
<p>In the two-task case, if task 2 speeds up by <span class="math inline">\(\beta\)</span> and its ex-ante share is <span class="math inline">\(s_0\)</span>, then <span class="math display">\[
\frac{y'}{y}=\left((1-s_0)+s_0\,\beta^{\varepsilon-1}\right)^{\frac{1}{\varepsilon-1}},\qquad \varepsilon\equiv\sigma.
\]</span></p>
<p>This is the clean continuous benchmark. <span class="citation" data-cites="caves1982indexnumbers">Caves, Christensen, and Diewert (<a href="#ref-caves1982indexnumbers" role="doc-biblioref">1982</a>)</span></p>
<section id="proposition-two-good-ces-gain-and-share-shift" class="level4">
<h4 class="anchored" data-anchor-id="proposition-two-good-ces-gain-and-share-shift">Proposition: two-good CES gain and share shift</h4>
<p><strong>Claim.</strong> In a two-good CES benchmark where only good 2 speeds up by <span class="math inline">\(\beta\)</span> (so <span class="math inline">\(p_2'=p_2/\beta\)</span>), the output gain and share shift can be written in terms of the ex-ante share <span class="math inline">\(s_0\)</span>:</p>
<ol type="1">
<li><strong>Output gain</strong> <span class="math display">\[
\frac{v(p')}{v(p)}=\left((1-s_0)+s_0\,\beta^{\varepsilon-1}\right)^{\frac{1}{\varepsilon-1}}.
\]</span></li>
<li><strong>Post-AI share</strong> <span class="math display">\[
s_1=\frac{s_0\,\beta^{\varepsilon-1}}{(1-s_0)+s_0\,\beta^{\varepsilon-1}}
\quad\Leftrightarrow\quad
\operatorname{logit}(s_1)-\operatorname{logit}(s_0)=(\varepsilon-1)\ln\beta.
\]</span></li>
</ol>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Proof (structured)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="1">
<li><em>Given</em> CES unit-expenditure (time price) index <span class="math display">\[
P(p)=\left(\alpha_1^{\varepsilon}p_1^{1-\varepsilon}+\alpha_2^{\varepsilon}p_2^{1-\varepsilon}\right)^{\frac{1}{1-\varepsilon}},
\qquad v(p)=\frac{1}{P(p)}.
\]</span></li>
<li><em>Let</em> <span class="math inline">\(p_2' = p_2/\beta\)</span> with <span class="math inline">\(p_1\)</span> fixed. Then <span class="math display">\[
\frac{v(p')}{v(p)}=\frac{P(p)}{P(p')}=
\left(
  \frac{\alpha_1^{\varepsilon}p_1^{1-\varepsilon}+\alpha_2^{\varepsilon}p_2^{1-\varepsilon}}
       {\alpha_1^{\varepsilon}p_1^{1-\varepsilon}+\alpha_2^{\varepsilon}(p_2/\beta)^{1-\varepsilon}}
\right)^{\frac{1}{\varepsilon-1}}.
\]</span></li>
<li><em>Define</em> the ex-ante share <span class="math display">\[
s_0\equiv\frac{\alpha_2^{\varepsilon}p_2^{1-\varepsilon}}
               {\alpha_1^{\varepsilon}p_1^{1-\varepsilon}+\alpha_2^{\varepsilon}p_2^{1-\varepsilon}}.
\]</span> Substituting into Step 2 yields the claimed gain formula.</li>
<li><em>For shares,</em> note CES time shares satisfy <span class="math display">\[
\frac{s}{1-s}=\frac{\alpha_2^{\varepsilon}p_2^{1-\varepsilon}}{\alpha_1^{\varepsilon}p_1^{1-\varepsilon}}.
\]</span> Therefore, <span class="math display">\[
\frac{s_1/(1-s_1)}{s_0/(1-s_0)}
=
\frac{(p_2')^{1-\varepsilon}}{p_2^{1-\varepsilon}}
=
\left(\frac{p_2/\beta}{p_2}\right)^{1-\varepsilon}
=
\beta^{\varepsilon-1},
\]</span> which rearranges to the stated closed form for <span class="math inline">\(s_1\)</span> and the logit identity.</li>
<li><strong>QED.</strong></li>
</ol>
</div>
</div>
</div>
</section>
</section>
</section>
<section id="discrete-extensive-margin-model-task-activation" class="level2">
<h2 class="anchored" data-anchor-id="discrete-extensive-margin-model-task-activation">Discrete (extensive-margin) model: task activation</h2>
<p>The continuous model assumes you always do <em>some</em> of each task. That is wrong when tasks are lumpy, have setup costs, or are unit-demand. In those cases, LLMs can create <strong>newly affordable tasks</strong>, meaning the major effect is <em>selection</em>, not <em>intensive</em> time reallocation.</p>
<section id="unit-demand-formulation" class="level3">
<h3 class="anchored" data-anchor-id="unit-demand-formulation">Unit-demand formulation</h3>
<p>Let each task have payoff <span class="math inline">\(u_i\)</span> and required time <span class="math inline">\(w_i(p)\)</span>, with decision <span class="math inline">\(q_i\in\{0,1\}\)</span>. Then <span class="math display">\[
\max_{q\in\{0,1\}^n}\sum_i u_i q_i\quad\text{s.t.}\quad \sum_i w_i(p) q_i\le 1.
\]</span></p>
<p>Speedups change <span class="math inline">\(w_i\)</span> by <span class="math inline">\(\beta_i\)</span>, which can <strong>turn tasks on</strong> once a threshold is crossed. This is exactly the “Cadillac tasks” phenomenon: tasks that were too time-expensive become attractive after the LLM. The usual CES elasticity is not a good summary in this regime.</p>
<p>One useful empirical way to think about the “tasks you previously avoided” condition is to decompose time cost into a baseline component plus an “overhead” component (search, reading, drafting, refactoring). For example, write <span class="math display">\[
w_i=a_i+b_i,
\]</span> and suppose AI primarily reduces overhead, <span class="math inline">\(b_i' = b_i/\beta^{O}\)</span> while <span class="math inline">\(a_i\)</span> is unchanged. Then <span class="math display">\[
w_i' = a_i + \frac{b_i}{\beta^{O}},\qquad
\beta_i \equiv \frac{w_i}{w_i'} = \frac{a_i+b_i}{a_i+b_i/\beta^{O}},
\]</span> so <span class="math inline">\(\beta_i\)</span> is increasing in the overhead share <span class="math inline">\(b_i/(a_i+b_i)\)</span>. Tasks you previously avoided plausibly have high overhead shares, so they get larger effective speedups and are more likely to cross activation thresholds.</p>
</section>
<section id="setup-cost-variant-bridging-discrete-and-continuous" class="level3">
<h3 class="anchored" data-anchor-id="setup-cost-variant-bridging-discrete-and-continuous">Setup-cost variant (bridging discrete and continuous)</h3>
<p>Add a fixed setup time <span class="math inline">\(\phi_i\)</span> and a continuous intensity <span class="math inline">\(x_i\)</span>: <span class="math display">\[
\max_{q,x}\;u(x)\quad\text{s.t.}\quad \sum_i \phi_i q_i + \sum_i p_i x_i \le 1,\; x_i=0\;\text{if }q_i=0.
\]</span></p>
<p>If <span class="math inline">\(\phi_i=0\)</span>, we recover the continuous model. If <span class="math inline">\(\phi_i&gt;0\)</span>, large LLM speedups mostly expand the active set <span class="math inline">\(\{i:q_i=1\}\)</span>, not the intensive shares.</p>
</section>
<section id="worked-example-discrete-not-continuous" class="level3">
<h3 class="anchored" data-anchor-id="worked-example-discrete-not-continuous">Worked example (discrete, not continuous)</h3>
<p><strong>Example.</strong> Suppose you can pick <em>one</em> task (unit-demand). Task A yields value <span class="math inline">\(u_A=10\)</span> and takes 1 hour. Task B yields <span class="math inline">\(u_B=12\)</span> and takes 2 hours. Without LLMs you choose A. Now an LLM speeds up task B so it takes 1 hour. You switch to B.</p>
<ul>
<li><strong>Upper bound on time-equivalent gain:</strong> 1 hour (if the extra value <span class="math inline">\(u_B-u_A\)</span> is “worth” a full hour).</li>
<li><strong>Lower bound:</strong> 0 hours (if the extra value is just a small quality bump).</li>
</ul>
<p>So the <em>observed</em> reallocation does not identify a precise time-savings without modeling discrete choice. This is why constant-elasticity summaries can be weak in the activation regime.</p>
</section>
<section id="newly-activated-tasks-cadillac-tasks" class="level3">
<h3 class="anchored" data-anchor-id="newly-activated-tasks-cadillac-tasks">Newly activated tasks (“Cadillac tasks”)</h3>
<p>Call a task <em>newly activated</em> if you would not do it at baseline prices but you do once its time cost drops. (In earlier conversations I called these “Cadillac tasks.”)</p>
<ul>
<li>literature reviews you previously would not attempt,</li>
<li>custom data visualizations,</li>
<li>long-form proofreading or refactoring.</li>
</ul>
<p>In a unit-demand or setup-cost model, these tasks show up as <strong>newly activated <span class="math inline">\(q_i=1\)</span> choices</strong>, not as marginal increases in <span class="math inline">\(x_i\)</span>. That is why “AI share of time” can jump even if your underlying preferences are stable: the feasible set changed.</p>
</section>
</section>
<section id="applications" class="level2">
<h2 class="anchored" data-anchor-id="applications">Applications</h2>
<section id="application-1-from-query-level-time-savings-to-an-aggregate-lift-anthropic" class="level3">
<h3 class="anchored" data-anchor-id="application-1-from-query-level-time-savings-to-an-aggregate-lift-anthropic">Application 1: from query-level time savings to an aggregate lift (Anthropic)</h3>
<p><span class="citation" data-cites="anthropic2025estimatingproductivitygains">Anthropic (<a href="#ref-anthropic2025estimatingproductivitygains" role="doc-biblioref">2025</a>)</span> estimate time savings from Claude conversations by comparing time required with vs without AI for a sample of tasks drawn from usage logs.</p>
<p>Suppose the headline inputs (illustrative, in the spirit of the writeup) are:</p>
<ul>
<li>Claude is used for <span class="math inline">\(s_0=10\%\)</span> of baseline work (measured pre-AI / from logs),</li>
<li>conditional time reduction is 80%, i.e.&nbsp;speedup <span class="math inline">\(\beta=5\)</span> when AI is used.</li>
</ul>
<p>Then even in the <em>continuous two-good</em> approximation, the implied aggregate lift depends sharply on substitution:</p>
<ul>
<li>complements/Amdahl bound: <span class="math inline">\(+8.7\%\)</span>,</li>
<li>Cobb-Douglas: <span class="math inline">\(+17.4\%\)</span>,</li>
<li>CES with <span class="math inline">\(\varepsilon=2\)</span>: <span class="math inline">\(+40\%\)</span>.</li>
</ul>
<p>The key empirical question is therefore not only “how big is <span class="math inline">\(\beta\)</span> when AI is used?” but also “how does the <em>time share</em> respond as the relative time price changes?” (In CES that’s summarized by <span class="math inline">\(\varepsilon\)</span>; outside CES, you need the whole demand curve.)</p>
<p>Two concrete complications show up immediately in a log-based setting:</p>
<ol type="1">
<li><strong>Endogenous task mix (extensive margin).</strong> If AI reduces time costs more for tasks you previously avoided (high search/reading/writing overhead), then the pre-AI share <span class="math inline">\(s_0\)</span> understates the mass of tasks that become attractive post-AI.</li>
<li><strong>Quality-adjusted output.</strong> Some measured “time savings” are quality improvements (or vice versa). If your output index treats quality as part of output, you need a quality measure to map time changes into <span class="math inline">\(u(x)\)</span>.</li>
</ol>
</section>
<section id="application-2-interpreting-uplift-rcts-metr-open-source-dev" class="level3">
<h3 class="anchored" data-anchor-id="application-2-interpreting-uplift-rcts-metr-open-source-dev">Application 2: interpreting “uplift” RCTs (METR / open-source dev)</h3>
<p><span class="citation" data-cites="becker2025uplift">J. Becker et al. (<a href="#ref-becker2025uplift" role="doc-biblioref">2025</a>)</span> is an RCT where tasks are assigned to allow vs disallow AI tools, and the outcome is completion time (with additional self-reports and robustness checks). The striking headline in that paper is that AI access <em>increases</em> completion time on average in their setting.</p>
<p>From the demand-theory perspective:</p>
<ul>
<li>A simple back-of-envelope translation: if allowing AI increases completion time by 19%, then the implied “speedup” is <span class="math inline">\(\beta \approx 1/1.19 \approx 0.84\)</span> (a slowdown). Holding output constant, that’s about a 16% productivity hit on that task population.</li>
<li>With a <strong>fixed task set</strong> (as in many RCTs), the main object you learn is a task-level time-price change <span class="math inline">\(p_i\to p_i'\)</span> (a <span class="math inline">\(\beta_i\)</span> distribution), holding task composition fixed.</li>
<li>Translating that into an <strong>aggregate productivity index</strong> still requires an output/quality index: are we holding output constant (pure time saved), holding time constant (more output), or letting both adjust? In practice you often want “quality-adjusted output per unit time.”</li>
<li>If, in future settings, AI access changes <em>which</em> tasks are attempted, then the design has to either (i) fix tasks (to isolate intensive effects) or (ii) explicitly allow selection and measure it (to capture the extensive margin).</li>
</ul>
</section>
</section>
<section id="experimental-design-estimating-substitution-and-selection" class="level2">
<h2 class="anchored" data-anchor-id="experimental-design-estimating-substitution-and-selection">Experimental design (estimating substitution and selection)</h2>
<p>Designing studies that map <span class="math inline">\(\{\beta_i\}\)</span> into an aggregate lift <span class="math inline">\(v(p')/v(p)\)</span> is mostly about (a) measuring substitution, and (b) separating intensive vs extensive margins.</p>
<ol type="1">
<li><strong>Decide the estimand up front.</strong> “Same tasks, faster” (hold <span class="math inline">\(x\)</span> fixed) is different from “best use of a fixed time budget” (maximize <span class="math inline">\(u(x)\)</span>). The latter matches the substitution estimand in this note.</li>
<li><strong>Run two complementary protocols.</strong>
<ul>
<li><strong>Fixed-task protocol (intensive margin):</strong> randomize AI availability within a pre-specified task list; measure time and quality on each task.</li>
<li><strong>Time-budget protocol (substitution/selection):</strong> give participants a fixed time budget and a menu (or open-ended objective); randomize AI availability; measure the output index achieved under each condition.</li>
</ul></li>
<li><strong>Measure quality explicitly.</strong> Use blinded human evaluation, unit tests, or objective metrics; pre-register how quality enters <span class="math inline">\(u(x)\)</span> (e.g.&nbsp;threshold vs continuous scoring).</li>
<li><strong>Trace a demand curve by varying effective AI “price.”</strong> Randomize not only “AI allowed,” but the <em>effective cost</em> of using AI (token budgets, latency, model quality tiers, usage quotas). This gives variation to estimate how shares move with relative time prices (the object behind <span class="math inline">\(\varepsilon\)</span> or, more generally, Hicksian shares).</li>
<li><strong>Handle learning and spillovers.</strong> Use cross-over designs, washout periods, or between-subject randomization where appropriate; measure experience and allow for dynamic treatment effects.</li>
</ol>
</section>
<section id="diagrams" class="level2">
<h2 class="anchored" data-anchor-id="diagrams">Diagrams</h2>
<section id="threshold-diagram-discrete-activation" class="level3">
<h3 class="anchored" data-anchor-id="threshold-diagram-discrete-activation">Threshold diagram (discrete activation)</h3>
<div id="5d11cdbb" class="cell" data-execution_count="3">
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="2025-12-17-llm-time-saving-demand-theory-substitution.llm_files/figure-html/cell-3-output-1.png" width="471" height="336" class="figure-img"></p>
<figcaption>Discrete activation: speedups switch on tasks</figcaption>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="checklist-for-the-desiderata" class="level2">
<h2 class="anchored" data-anchor-id="checklist-for-the-desiderata">Checklist for the desiderata</h2>
<ul>
<li><strong>Bibliography validity:</strong> citations are included and checked against <code>ai.bib</code>. See the validation checklist at the top.</li>
<li><strong>Citation faithfulness:</strong> the optional LLM-assisted check flags suspicious claim-to-citation mismatches (also in the checklist).</li>
<li><strong>Proofs:</strong> proofs are structured, collapsed by default, and include numbered steps plus a QED marker.</li>
<li><strong>Cheat sheet:</strong> includes a two-good benchmark table and an estimation flowchart.</li>
<li><strong>Legible diagrams:</strong> Mermaid estimation flowchart + a discrete activation figure.</li>
<li><strong>Applications:</strong> explicit discussion of Anthropic time-savings and METR uplift-style RCTs.</li>
<li><strong>Experimental design:</strong> concrete protocol suggestions for estimating substitution and selection.</li>
</ul>
</section>
<section id="related-literature-more-explicit" class="level2">
<h2 class="anchored" data-anchor-id="related-literature-more-explicit">Related literature (more explicit)</h2>
<p>This note touches several literatures that are often cited separately. Here is a reading map that matches the objects used above (price indices, time allocation, discrete activation, and empirical measurement).</p>
<section id="index-numbers-and-exact-welfare-from-price-changes-continuous-case" class="level3">
<h3 class="anchored" data-anchor-id="index-numbers-and-exact-welfare-from-price-changes-continuous-case">Index numbers and exact welfare from price changes (continuous case)</h3>
<ul>
<li><strong>“True” cost-of-living index and the expenditure function.</strong> Konus defines the cost-of-living index as the ratio of minimum expenditures needed to reach a fixed utility level at two price vectors. This is exactly the object <span class="math inline">\(P(p)=e(p,1)\)</span> (with time prices instead of money prices) that makes <span class="math inline">\(v(p)=1/P(p)\)</span> under homotheticity. <span class="citation" data-cites="konus1939trueindex">Konus (<a href="#ref-konus1939trueindex" role="doc-biblioref">1939</a>)</span></li>
<li><strong>Exact/superlative indices and share-weighted approximations.</strong> Diewert formalizes when standard indices (including Tornqvist/Divisia-type log-share formulas) are “exact” for flexible demand/production forms, and motivates using share-weighted log changes as a local approximation. <span class="citation" data-cites="diewert1976exact">Diewert (<a href="#ref-diewert1976exact" role="doc-biblioref">1976</a>)</span></li>
<li><strong>Productivity measurement via index numbers.</strong> Caves-Christensen-Diewert is a central reference for exact index-number measurement of input, output, and productivity and for the duality-based framing used in the continuous model here. <span class="citation" data-cites="caves1982indexnumbers">Caves, Christensen, and Diewert (<a href="#ref-caves1982indexnumbers" role="doc-biblioref">1982</a>)</span></li>
<li><strong>Exact welfare for large changes.</strong> Willig and Hausman connect equivalent/compensating variation and consumer surplus to integrals of compensated demand, clarifying why large AI shocks call for “area under Hicksian demand” rather than constant-elasticity shortcuts. <span class="citation" data-cites="willig1976consumerssurplus">Willig (<a href="#ref-willig1976consumerssurplus" role="doc-biblioref">1976</a>)</span>; <span class="citation" data-cites="hausman1981exact">Hausman (<a href="#ref-hausman1981exact" role="doc-biblioref">1981</a>)</span></li>
<li><strong>Estimating demand systems.</strong> Deaton-Muellbauer’s AIDS is a workhorse integrable demand system used to estimate (Marshallian/Hicksian) demand and welfare effects of price changes in practice. <span class="citation" data-cites="deaton1980aids">Deaton and Muellbauer (<a href="#ref-deaton1980aids" role="doc-biblioref">1980</a>)</span></li>
</ul>
</section>
<section id="time-allocation-information-costs-and-overhead-time" class="level3">
<h3 class="anchored" data-anchor-id="time-allocation-information-costs-and-overhead-time">Time allocation, information costs, and “overhead” time</h3>
<ul>
<li><strong>Time as a scarce resource.</strong> Becker’s allocation-of-time framework treats time as a fundamental constraint; it is the natural ancestor of interpreting task durations as “prices” in a time budget. <span class="citation" data-cites="becker1965allocation">G. S. Becker (<a href="#ref-becker1965allocation" role="doc-biblioref">1965</a>)</span></li>
<li><strong>Time requirements as part of preferences/technology.</strong> DeSerpa emphasizes that goods require time to consume/produce and develops shadow-price implications; this is close to the time-price interpretation here. <span class="citation" data-cites="deserpa1971time">DeSerpa (<a href="#ref-deserpa1971time" role="doc-biblioref">1971</a>)</span></li>
<li><strong>Search and information as economic objects.</strong> Stigler’s economics-of-information treats costly search as central; empirically, many LLM speedups look like reductions in search/reading/writing overhead rather than reductions in “core” task time. <span class="citation" data-cites="stigler1961information">Stigler (<a href="#ref-stigler1961information" role="doc-biblioref">1961</a>)</span></li>
<li><strong>Goods as characteristics.</strong> Lancaster’s characteristics model is a useful alternative interpretation: tasks can be seen as bundles of characteristics (information, drafting, formatting, reasoning), and AI shifts the implicit “prices” of those characteristics. <span class="citation" data-cites="lancaster1966consumer">Lancaster (<a href="#ref-lancaster1966consumer" role="doc-biblioref">1966</a>)</span></li>
</ul>
</section>
<section id="discrete-activation-selection-and-welfare-with-lumpy-choices" class="level3">
<h3 class="anchored" data-anchor-id="discrete-activation-selection-and-welfare-with-lumpy-choices">Discrete activation, selection, and welfare with lumpy choices</h3>
<ul>
<li><strong>Welfare with discrete choice.</strong> Small-Rosen is a classic reference on how to do welfare analysis when choices are discrete; it is the natural toolkit for unit-demand tasks and activation thresholds. <span class="citation" data-cites="smallrosen1981welfare">Small and Rosen (<a href="#ref-smallrosen1981welfare" role="doc-biblioref">1981</a>)</span></li>
<li><strong>Estimation tools for discrete choice.</strong> Train is the standard applied reference for estimating random-utility/discrete-choice models (including simulation methods) when you want to quantify substitution and welfare. <span class="citation" data-cites="train2003discretechoice">Train (<a href="#ref-train2003discretechoice" role="doc-biblioref">2003</a>)</span></li>
</ul>
</section>
<section id="task-based-technological-change-and-aggregation" class="level3">
<h3 class="anchored" data-anchor-id="task-based-technological-change-and-aggregation">Task-based technological change and aggregation</h3>
<ul>
<li><strong>Tasks as the primitive.</strong> Autor-Levy-Murnane (and Acemoglu-Autor) popularize task-based views of technology’s effects, which is conceptually aligned with treating tasks as “goods” with relative prices in time. <span class="citation" data-cites="autor2003skill">Autor, Levy, and Murnane (<a href="#ref-autor2003skill" role="doc-biblioref">2003</a>)</span>; <span class="citation" data-cites="acemoglu2011handbook">Acemoglu and Autor (<a href="#ref-acemoglu2011handbook" role="doc-biblioref">2011</a>)</span></li>
<li><strong>Small-shock aggregation (Hulten logic).</strong> Hulten’s share-weighted result is the backbone of why <span class="math inline">\(\\Delta\\ln v\\approx \\sum_i s_i\\,\\Delta\\ln\\beta_i\)</span> can be reasonable for small or broad shocks. <span class="citation" data-cites="hulten1978growth">Hulten (<a href="#ref-hulten1978growth" role="doc-biblioref">1978</a>)</span></li>
<li><strong>When share-weighted formulas fail.</strong> Baqaee-Farhi is a canonical reference on nonlinearities and large shocks (“beyond Hulten”); it connects directly to why large AI shocks motivate demand-curve integration and careful treatment of selection. <span class="citation" data-cites="baqaee2019macro">Baqaee and Farhi (<a href="#ref-baqaee2019macro" role="doc-biblioref">2019</a>)</span></li>
<li><strong>Micro-to-macro technology measurement.</strong> Oberfield-Raval is a useful reference on linking micro evidence on technology to macro implications. <span class="citation" data-cites="oberfield2021micro">Oberfield and Raval (<a href="#ref-oberfield2021micro" role="doc-biblioref">2021</a>)</span></li>
<li><strong>CES as a workhorse.</strong> Dixit-Stiglitz is the canonical CES/variety reference that sits behind many closed-form substitution formulas (including the two-good CES benchmark used above). <span class="citation" data-cites="dixit1977monopolistic">Dixit and Stiglitz (<a href="#ref-dixit1977monopolistic" role="doc-biblioref">1977</a>)</span></li>
</ul>
</section>
<section id="empirical-ai-productivity-and-usage-measurement" class="level3">
<h3 class="anchored" data-anchor-id="empirical-ai-productivity-and-usage-measurement">Empirical AI productivity and usage measurement</h3>
<ul>
<li><strong>Task-level time savings from logs.</strong> Anthropic’s Claude-log approach illustrates the appeal (and limits) of measuring conditional time savings and baseline shares in observational usage data. <span class="citation" data-cites="anthropic2025estimatingproductivitygains">Anthropic (<a href="#ref-anthropic2025estimatingproductivitygains" role="doc-biblioref">2025</a>)</span></li>
<li><strong>RCT “uplift” estimates.</strong> Becker et al.&nbsp;(METR) is an example of randomized access to AI tools with completion time outcomes, highlighting the importance of quality measurement and task selection. <span class="citation" data-cites="becker2025uplift">J. Becker et al. (<a href="#ref-becker2025uplift" role="doc-biblioref">2025</a>)</span></li>
<li><strong>Other early gen-AI productivity evidence.</strong> Noy-Zhang and Brynjolfsson-Li-Raymond are widely cited early studies of gen-AI impacts (often with quality or heterogeneity considerations). <span class="citation" data-cites="noy2023generative">Noy and Zhang (<a href="#ref-noy2023generative" role="doc-biblioref">2023</a>)</span>; <span class="citation" data-cites="brynjolfsson2023generative">Brynjolfsson, Li, and Raymond (<a href="#ref-brynjolfsson2023generative" role="doc-biblioref">2023</a>)</span></li>
<li><strong>What people do with chatbots.</strong> Chatterji et al.&nbsp;document usage patterns and task composition for ChatGPT, which matters for mapping micro speedups to aggregate lifts when the task mix is endogenous. <span class="citation" data-cites="chatterji2025chatgpt">Chatterji et al. (<a href="#ref-chatterji2025chatgpt" role="doc-biblioref">2025</a>)</span></li>
<li><strong>Valuing time/information services.</strong> Varian and Collis-Brynjolfsson are representative of the broader literature on valuing digital services and time savings, complementary to the demand-theory framing here. <span class="citation" data-cites="varian2011economic">Varian (<a href="#ref-varian2011economic" role="doc-biblioref">2011</a>)</span>; <span class="citation" data-cites="collis2025welfare">Collis and Brynjolfsson (<a href="#ref-collis2025welfare" role="doc-biblioref">2025</a>)</span></li>
</ul>



</section>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-acemoglu2011handbook" class="csl-entry" role="listitem">
Acemoglu, Daron, and David Autor. 2011. <span>“Skills, Tasks and Technologies: Implications for Employment and Earnings.”</span> In, edited by David Card and Orley Ashenfelter, 4:1043–1171. Handbook of Labor Economics. Elsevier. https://doi.org/<a href="https://doi.org/10.1016/S0169-7218(11)02410-5">https://doi.org/10.1016/S0169-7218(11)02410-5</a>.
</div>
<div id="ref-anthropic2025estimatingproductivitygains" class="csl-entry" role="listitem">
Anthropic. 2025. <span>“Estimating AI Productivity Gains from Claude Conversations.”</span> 2025. <a href="https://www.anthropic.com/research/estimating-productivity-gains">https://www.anthropic.com/research/estimating-productivity-gains</a>.
</div>
<div id="ref-autor2003skill" class="csl-entry" role="listitem">
Autor, David, Frank Levy, and Richard J Murnane. 2003. <span>“The Skill Content of Recent Technological Change: An Empirical Exploration.”</span> <em>The Quarterly Journal of Economics</em> 118 (4): 1279–1333. <a href="https://doi.org/10.3386/w8337">https://doi.org/10.3386/w8337</a>.
</div>
<div id="ref-baqaee2019macro" class="csl-entry" role="listitem">
Baqaee, David Rezza, and Emmanuel Farhi. 2019. <span>“The Macroeconomic Impact of Microeconomic Shocks: Beyond Hulten’s Theorem.”</span> <em>Econometrica</em> 87 (4): 1155–1206. <a href="https://doi.org/10.3982/ecta15202">https://doi.org/10.3982/ecta15202</a>.
</div>
<div id="ref-becker1965allocation" class="csl-entry" role="listitem">
Becker, Gary S. 1965. <span>“A Theory of the Allocation of Time.”</span> <em>The Economic Journal</em> 75 (299): 493. <a href="https://doi.org/10.2307/2228949">https://doi.org/10.2307/2228949</a>.
</div>
<div id="ref-becker2025uplift" class="csl-entry" role="listitem">
Becker, Joel, Nate Rush, Elizabeth Barnes, and David Rein. 2025. <span>“Measuring the Impact of Early-2025 AI on Experienced Open-Source Developer Productivity.”</span> <a href="https://arxiv.org/pdf/2507.09089.pdf">https://arxiv.org/pdf/2507.09089.pdf</a>.
</div>
<div id="ref-brynjolfsson2023generative" class="csl-entry" role="listitem">
Brynjolfsson, Erik, Danielle Li, and Lindsey R Raymond. 2023. <span>“Generative AI at Work.”</span> <em>Available at SSRN 4573321</em>. <a href="https://doi.org/10.1093/qje/qjae044">https://doi.org/10.1093/qje/qjae044</a>.
</div>
<div id="ref-caves1982indexnumbers" class="csl-entry" role="listitem">
Caves, Douglas W., Laurits R. Christensen, and W. Erwin Diewert. 1982. <span>“The Economic Theory of Index Numbers and the Measurement of Input, Output, and Productivity.”</span> <em>Econometrica</em> 50 (6): 1393–1414. <a href="https://www.jstor.org/stable/1913382">https://www.jstor.org/stable/1913382</a>.
</div>
<div id="ref-chatterji2025chatgpt" class="csl-entry" role="listitem">
Chatterji, Aaron, Thomas Cunningham, David J. Deming, Zoe Hitzig, Christopher Ong, Carl Yan Shan, and Kevin Wadman. 2025. <span>“How People Use ChatGPT.”</span> Working Paper 34255. National Bureau of Economic Research. <a href="https://doi.org/10.3386/w34255">https://doi.org/10.3386/w34255</a>.
</div>
<div id="ref-collis2025welfare" class="csl-entry" role="listitem">
Collis, Avinash, and Erik Brynjolfsson. 2025. <span>“AI’s Overlooked $97 Billion Contribution to the Economy.”</span> <em>Wall Street Journal</em>, August. <a href="https://www.wsj.com/opinion/ais-overlooked-97-billion-contribution-to-the-economy-users-service-da6e8f55">https://www.wsj.com/opinion/ais-overlooked-97-billion-contribution-to-the-economy-users-service-da6e8f55</a>.
</div>
<div id="ref-deaton1980aids" class="csl-entry" role="listitem">
Deaton, Angus, and John Muellbauer. 1980. <span>“An Almost Ideal Demand System.”</span> <em>American Economic Review</em> 70 (3): 312–26. <a href="https://www.semanticscholar.org/search?q=An%20Almost%20Ideal%20Demand%20System">https://www.semanticscholar.org/search?q=An%20Almost%20Ideal%20Demand%20System</a>.
</div>
<div id="ref-deserpa1971time" class="csl-entry" role="listitem">
DeSerpa, Allan C. 1971. <span>“A Theory of the Economics of Time.”</span> <em>The Economic Journal</em> 81 (324): 828–46. <a href="https://doi.org/10.2307/2230320">https://doi.org/10.2307/2230320</a>.
</div>
<div id="ref-diewert1976exact" class="csl-entry" role="listitem">
Diewert, W. Erwin. 1976. <span>“Exact and Superlative Index Numbers.”</span> <em>Journal of Econometrics</em> 4 (2): 115–45. <a href="https://doi.org/10.1016/0304-4076(76)90009-9">https://doi.org/10.1016/0304-4076(76)90009-9</a>.
</div>
<div id="ref-dixit1977monopolistic" class="csl-entry" role="listitem">
Dixit, Avinash K, and Joseph E Stiglitz. 1977. <span>“Monopolistic Competition and Optimum Product Diversity.”</span> <em>The American Economic Review</em> 67 (3): 297–308. <a href="https://www.semanticscholar.org/search?q=Monopolistic%20competition%20and%20optimum%20product%20diversity">https://www.semanticscholar.org/search?q=Monopolistic%20competition%20and%20optimum%20product%20diversity</a>.
</div>
<div id="ref-hausman1981exact" class="csl-entry" role="listitem">
Hausman, Jerry A. 1981. <span>“Exact Consumer’s Surplus and Deadweight Loss.”</span> <em>American Economic Review</em> 71 (4): 662–76. <a href="https://www.semanticscholar.org/search?q=Exact%20Consumer%27s%20Surplus%20and%20Deadweight%20Loss">https://www.semanticscholar.org/search?q=Exact%20Consumer%27s%20Surplus%20and%20Deadweight%20Loss</a>.
</div>
<div id="ref-hulten1978growth" class="csl-entry" role="listitem">
Hulten, Charles R. 1978. <span>“Growth Accounting with Intermediate Inputs.”</span> <em>The Review of Economic Studies</em> 45 (3): 511–18. <a href="https://doi.org/10.2307/2297252">https://doi.org/10.2307/2297252</a>.
</div>
<div id="ref-konus1939trueindex" class="csl-entry" role="listitem">
Konus, A. A. 1939. <span>“The Problem of the True Index of the Cost of Living.”</span> <em>Econometrica</em> 7 (1): 10. <a href="https://doi.org/10.2307/1906997">https://doi.org/10.2307/1906997</a>.
</div>
<div id="ref-lancaster1966consumer" class="csl-entry" role="listitem">
Lancaster, Kelvin J. 1966. <span>“A New Approach to Consumer Theory.”</span> <em>Journal of Political Economy</em> 74 (2): 132–57. <a href="https://doi.org/10.1086/259131">https://doi.org/10.1086/259131</a>.
</div>
<div id="ref-noy2023generative" class="csl-entry" role="listitem">
Noy, Shakked, and Whitney Zhang. 2023. <span>“Experimental Evidence on the Productivity Effects of Generative AI.”</span> <em>arXiv Preprint arXiv:2304.02313</em>. <a href="https://arxiv.org/pdf/2304.02313.pdf">https://arxiv.org/pdf/2304.02313.pdf</a>.
</div>
<div id="ref-oberfield2021micro" class="csl-entry" role="listitem">
Oberfield, Ezra, and Devesh Raval. 2021. <span>“Micro Data and Macro Technology.”</span> <em>Econometrica</em> 89 (2): 703–32. <a href="https://doi.org/10.2139/ssrn.2188988">https://doi.org/10.2139/ssrn.2188988</a>.
</div>
<div id="ref-smallrosen1981welfare" class="csl-entry" role="listitem">
Small, Kenneth A., and Harvey S. Rosen. 1981. <span>“Applied Welfare Economics with Discrete Choice Models.”</span> <em>Econometrica</em> 49 (1): 105. <a href="https://doi.org/10.2307/1911129">https://doi.org/10.2307/1911129</a>.
</div>
<div id="ref-stigler1961information" class="csl-entry" role="listitem">
Stigler, George J. 1961. <span>“The Economics of Information.”</span> <em>Journal of Political Economy</em> 69 (3): 213–25. <a href="https://doi.org/10.1086/258464">https://doi.org/10.1086/258464</a>.
</div>
<div id="ref-train2003discretechoice" class="csl-entry" role="listitem">
Train, Kenneth E. 2003. <em>Discrete Choice Methods with Simulation</em>. Cambridge University Press. <a href="https://doi.org/10.1017/cbo9780511753930">https://doi.org/10.1017/cbo9780511753930</a>.
</div>
<div id="ref-varian2011economic" class="csl-entry" role="listitem">
Varian, Hal. 2011. <span>“Economic Value of Google.”</span> <a href="https://dl.icdst.org/pdfs/files1/f87de5ba3c43760ebcbc2a1d90950dbc.pdf">https://dl.icdst.org/pdfs/files1/f87de5ba3c43760ebcbc2a1d90950dbc.pdf</a>.
</div>
<div id="ref-willig1976consumerssurplus" class="csl-entry" role="listitem">
Willig, Robert D. 1976. <span>“Consumer’s Surplus Without Apology.”</span> <em>American Economic Review</em> 66 (4): 589–97. <a href="https://www.semanticscholar.org/paper/745fa39279d59c6f6b14dce4a38bcf098774c2ad">https://www.semanticscholar.org/paper/745fa39279d59c6f6b14dce4a38bcf098774c2ad</a>.
</div>
</div></section><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{cunningham_(metr)2026,
  author = {Cunningham (METR), Tom},
  title = {LLM {Time-Saving,} {Demand} {Theory,} and {Task}
    {Activation}},
  date = {2026-01-25},
  url = {tecunningham.github.io/posts/2025-12-17-llm-time-saving-demand-theory-substitution.llm.html},
  langid = {en}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-cunningham_(metr)2026" class="csl-entry quarto-appendix-citeas" role="listitem">
Cunningham (METR), Tom. 2026. <span>“LLM Time-Saving, Demand Theory, and
Task Activation.”</span> January 25, 2026. <a href="https://tecunningham.github.io/posts/2025-12-17-llm-time-saving-demand-theory-substitution.llm.html">tecunningham.github.io/posts/2025-12-17-llm-time-saving-demand-theory-substitution.llm.html</a>.
</div></div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("tecunningham\.github\.io");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>