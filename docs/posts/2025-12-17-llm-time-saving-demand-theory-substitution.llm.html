<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.25">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Tom Cunningham">
<meta name="dcterms.date" content="2026-01-26">
<meta name="description" content="Tom Cunningham blog">

<title>LLM Time-Saving, Demand Theory, and Task Activation | Tom Cunningham – Tom Cunningham</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-7b89279ff1a6dce999919e0e67d4d9ec.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-d5e7c60e6424aa6ccf163f01508596ce.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

<script type="text/javascript">

(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-12027453-1', 'auto');

ga('send', {
  hitType: 'pageview',
  'anonymizeIp': true,
});
</script>
<script src="../site_libs/quarto-diagram/mermaid.min.js"></script>
<script src="../site_libs/quarto-diagram/mermaid-init.js"></script>
<link href="../site_libs/quarto-diagram/mermaid.css" rel="stylesheet">
<script>window.MathJax = {
   loader: { load: ["https://cdn.jsdelivr.net/gh/sonoisa/XyJax-v3@3.0.1/build/xypic.js"]},
   tex: {packages: {'[+]': ['xypic','bm']},
         macros: {  bm: ["\\boldsymbol{#1}", 1],
                    ut: ["\\underbrace{#1}_{\\text{#2}}", 2],
                    utt: ["\\underbrace{#1}_{\\substack{\\text{#2}\\\\\\text{#3}}}", 3] }
   }
};
</script>
<style>
   h1 {  border-bottom: 8px solid #557;}
   h2 {  border-bottom: 1px solid #ccc;}
   .greyproof {
      background-color: #f5f5f5;
      padding: 1em;
      margin: 1em 0;
      border-radius: 4px;
   }
</style>
<meta name="quarto:status" content="draft">

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../styles.css">
<meta name="twitter:title" content="LLM Time-Saving, Demand Theory, and Task Activation | Tom Cunningham">
<meta name="twitter:card" content="summary">
</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner"><div id="quarto-draft-alert" class="alert alert-warning"><i class="bi bi-pencil-square"></i>Draft</div>
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../index.html" class="navbar-brand navbar-brand-logo">
    </a>
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Tom Cunningham</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href=".././about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/testingham"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/tom-cunningham-a9433/"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://tecunningham.github.io/index.xml"> <i class="bi bi-rss-fill" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://scholar.google.com/citations?user=MDB_DgkAAAAJ"> 
<span class="menu-text">scholar</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">LLM Time-Saving, Demand Theory, and Task Activation</h1>
                      </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Tom Cunningham (METR) </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">January 26, 2026</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#results-first-summary" id="toc-results-first-summary" class="nav-link active" data-scroll-target="#results-first-summary">Results-first summary</a></li>
  <li><a href="#setup-time-allocation-and-task-productivity" id="toc-setup-time-allocation-and-task-productivity" class="nav-link" data-scroll-target="#setup-time-allocation-and-task-productivity">Setup: time allocation and task productivity</a></li>
  <li><a href="#estimation-cheat-sheet" id="toc-estimation-cheat-sheet" class="nav-link" data-scroll-target="#estimation-cheat-sheet">Estimation cheat sheet</a>
  <ul class="collapse">
  <li><a href="#two-good-reduction-ai-affected-bundle-vs-the-rest" id="toc-two-good-reduction-ai-affected-bundle-vs-the-rest" class="nav-link" data-scroll-target="#two-good-reduction-ai-affected-bundle-vs-the-rest">Two-good reduction (AI-affected bundle vs the rest)</a></li>
  <li><a href="#if-you-observe-pre-and-post-time-shares-you-can-infer-an-elasticity-in-ces" id="toc-if-you-observe-pre-and-post-time-shares-you-can-infer-an-elasticity-in-ces" class="nav-link" data-scroll-target="#if-you-observe-pre-and-post-time-shares-you-can-infer-an-elasticity-in-ces">If you observe pre and post time shares, you can infer an elasticity (in CES)</a></li>
  <li><a href="#estimation-flowchart-what-to-do-with-your-data" id="toc-estimation-flowchart-what-to-do-with-your-data" class="nav-link" data-scroll-target="#estimation-flowchart-what-to-do-with-your-data">Estimation flowchart (what to do with your data)</a></li>
  <li><a href="#what-you-can-estimate-with-what-data" id="toc-what-you-can-estimate-with-what-data" class="nav-link" data-scroll-target="#what-you-can-estimate-with-what-data">What you can estimate with what data</a></li>
  </ul></li>
  <li><a href="#continuous-intensive-margin-model" id="toc-continuous-intensive-margin-model" class="nav-link" data-scroll-target="#continuous-intensive-margin-model">Continuous (intensive-margin) model</a></li>
  <li><a href="#discrete-extensive-margin-model" id="toc-discrete-extensive-margin-model" class="nav-link" data-scroll-target="#discrete-extensive-margin-model">Discrete (extensive-margin) model</a>
  <ul class="collapse">
  <li><a href="#unit-demand-formulation" id="toc-unit-demand-formulation" class="nav-link" data-scroll-target="#unit-demand-formulation">Unit-demand formulation</a></li>
  <li><a href="#setup-cost-variant-bridging-discrete-and-continuous" id="toc-setup-cost-variant-bridging-discrete-and-continuous" class="nav-link" data-scroll-target="#setup-cost-variant-bridging-discrete-and-continuous">Setup-cost variant (bridging discrete and continuous)</a></li>
  <li><a href="#worked-example-discrete-not-continuous" id="toc-worked-example-discrete-not-continuous" class="nav-link" data-scroll-target="#worked-example-discrete-not-continuous">Worked example (discrete, not continuous)</a></li>
  <li><a href="#newly-activated-tasks" id="toc-newly-activated-tasks" class="nav-link" data-scroll-target="#newly-activated-tasks">Newly activated tasks</a></li>
  </ul></li>
  <li><a href="#applications" id="toc-applications" class="nav-link" data-scroll-target="#applications">Applications</a>
  <ul class="collapse">
  <li><a href="#application-1-from-query-level-time-savings-to-an-aggregate-lift-anthropic" id="toc-application-1-from-query-level-time-savings-to-an-aggregate-lift-anthropic" class="nav-link" data-scroll-target="#application-1-from-query-level-time-savings-to-an-aggregate-lift-anthropic">Application 1: from query-level time savings to an aggregate lift (Anthropic)</a></li>
  <li><a href="#application-2-interpreting-uplift-rcts-metr-open-source-dev" id="toc-application-2-interpreting-uplift-rcts-metr-open-source-dev" class="nav-link" data-scroll-target="#application-2-interpreting-uplift-rcts-metr-open-source-dev">Application 2: interpreting “uplift” RCTs (METR / open-source dev)</a></li>
  </ul></li>
  <li><a href="#experimental-design" id="toc-experimental-design" class="nav-link" data-scroll-target="#experimental-design">Experimental design</a></li>
  <li><a href="#related-literature-more-explicit" id="toc-related-literature-more-explicit" class="nav-link" data-scroll-target="#related-literature-more-explicit">Related literature (more explicit)</a>
  <ul class="collapse">
  <li><a href="#index-numbers-and-exact-welfare-from-price-changes-continuous-case" id="toc-index-numbers-and-exact-welfare-from-price-changes-continuous-case" class="nav-link" data-scroll-target="#index-numbers-and-exact-welfare-from-price-changes-continuous-case">Index numbers and exact welfare from price changes (continuous case)</a></li>
  <li><a href="#time-allocation-information-costs-and-overhead-time" id="toc-time-allocation-information-costs-and-overhead-time" class="nav-link" data-scroll-target="#time-allocation-information-costs-and-overhead-time">Time allocation, information costs, and “overhead” time</a></li>
  <li><a href="#discrete-activation-selection-and-welfare-with-lumpy-choices" id="toc-discrete-activation-selection-and-welfare-with-lumpy-choices" class="nav-link" data-scroll-target="#discrete-activation-selection-and-welfare-with-lumpy-choices">Discrete activation, selection, and welfare with lumpy choices</a></li>
  <li><a href="#task-based-technological-change-and-aggregation" id="toc-task-based-technological-change-and-aggregation" class="nav-link" data-scroll-target="#task-based-technological-change-and-aggregation">Task-based technological change and aggregation</a></li>
  <li><a href="#empirical-ai-productivity-and-usage-measurement" id="toc-empirical-ai-productivity-and-usage-measurement" class="nav-link" data-scroll-target="#empirical-ai-productivity-and-usage-measurement">Empirical AI productivity and usage measurement</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<div id="ed7d9d47" class="cell" data-results="asis" data-execution_count="1">
<div class="cell-output cell-output-display cell-output-markdown">
<details class="validation-checklist">
<summary>
Validation Checks
</summary>
<pre class="text"><code>Validation Checks
✅ Programmatic: proof structure (collapsed)
✅ Programmatic: Mermaid syntax lint (offline)
✅ [7/7] Programmatic: bibliography tests
  ✅ Duplicate citekeys
  ✅ One field per line + trailing comma
  ✅ Source locator present (url/doi/eprint) (225/225)
  ✅ Abstract length &lt;= 500 words (72/72)
  ✅ abstract_source only when abstract is present (63/63)
  ✅ arXiv eprints use arxiv.org/pdf/&lt;id&gt;.pdf URLs (24/24)
  ✅ text_url has local text archive (16/16)
✅ Programmatic: citekeys resolve in posts/ai.bib
⏳ LLM-assisted: quality + citation plausibility gate (optional)</code></pre>
</details>
</div>
</div>
<style>
  dl {display: grid;}
  dt {grid-column-start: 1; width: 18em;}
  dd {grid-column-start: 2; margin-left: 1.25em;}
  details.validation-checklist {
    background: #f5f5f5;
    border: 1px solid #777;
    border-radius: 6px;
    padding: 0.5em 0.75em;
    margin-bottom: 1em;
  }
  details.validation-checklist > summary {
    cursor: pointer;
  }
</style>
<section id="results-first-summary" class="level2">
<h2 class="anchored" data-anchor-id="results-first-summary">Results-first summary</h2>
<dl>
<dt><strong>Speedups do not mechanically translate into aggregate productivity.</strong></dt>
<dd>
Once LLMs change the relative time costs of tasks, optimal time allocation changes, and the aggregate lift depends on substitution and (often) task activation.
</dd>
<dt><strong>Overall lift is not pinned down by a share and a conditional speedup alone.</strong></dt>
<dd>
If tasks that get sped up initially take share <span class="math inline">\(s\)</span> of time and get speedup factor <span class="math inline">\(A\)</span> when you do them, then an arithmetic share calculation gives <span class="math inline">\(1+s(A-1)\)</span>. That expression is correct only for a knife-edge estimand where you hold the task mix fixed. If you let the person reoptimize, <span class="math inline">\(s\)</span> is endogenous and the total lift depends on substitution.
</dd>
<dt><strong>Allowing reallocation makes the estimand a time-allocation object.</strong></dt>
<dd>
Let <span class="math inline">\(t=(t_1,\dots,t_n)\)</span> be time allocated across tasks with <span class="math inline">\(\sum_i t_i=1\)</span>. Let <span class="math inline">\(A=(A_1,\dots,A_n)\)</span> be task-specific productivity (effective output per unit time on each task). Let the output index be <span class="math display">\[
  y(A_1 t_1,\dots,A_n t_n),
  \]</span> where <span class="math inline">\(y(\cdot)\)</span> is increasing in each argument. The substitution-adjusted productivity level is <span class="math display">\[
  V(A)\equiv \max_{t\ge 0}\; y(A_1 t_1,\dots,A_n t_n)\quad\text{s.t.}\quad \sum_i t_i\le 1.
  \]</span> An LLM changes productivity from <span class="math inline">\(A^0\)</span> to <span class="math inline">\(A^1\)</span>, and the lift is <span class="math inline">\(V(A^1)/V(A^0)\)</span>.
</dd>
<dt><strong>Substitutability governs how much time share moves when a task becomes cheap.</strong></dt>
<dd>
In a continuous model, if tasks are close substitutes then time shifts strongly toward the sped-up tasks and the aggregate lift can be much larger than <span class="math inline">\(1+s(A-1)\)</span>. If tasks are strong complements, time shares are stable and the aggregate lift is closer to the share calculation. In parametric cases this is summarized by an elasticity; outside parametric cases it is a demand-curve object.
</dd>
<dt><strong>Observing post-LLM shares can identify the elasticity in a CES benchmark.</strong></dt>
<dd>
In a two-good CES setting, observing both pre and post time shares for an AI-affected bundle, together with the relevant speedup, identifies the substitution elasticity via a logit-share formula. This makes post-LLM shares especially informative when you want a point estimate.
</dd>
<dt><strong>With unit-demand task choice, you can bound the lift using pre and post task baskets.</strong></dt>
<dd>
If tasks are lumpy and you either do a task or not, and you observe the time required for each task pre and post AI, then you can bound the aggregate lift by evaluating the pre-AI chosen basket at post-AI time prices (a Laspeyres-style bound) and the post-AI chosen basket at post-AI time prices (a Paasche-style bound). The discrete section formalizes this.
</dd>
</dl>
</section>
<section id="setup-time-allocation-and-task-productivity" class="level2">
<h2 class="anchored" data-anchor-id="setup-time-allocation-and-task-productivity">Setup: time allocation and task productivity</h2>
<dl>
<dt><strong>The canonical setup is time allocation with task productivity.</strong></dt>
<dd>
You choose time shares <span class="math inline">\(t=(t_1,\dots,t_n)\)</span> with <span class="math inline">\(\sum_i t_i=1\)</span>, and productivity enters as the vector <span class="math inline">\(A=(A_1,\dots,A_n)\)</span> in the output index <span class="math inline">\(y(A_1 t_1,\dots,A_n t_n)\)</span>.
</dd>
<dt><strong>Index-number results can be imported by reinterpreting productivity as inverse prices.</strong></dt>
<dd>
If you define a time price <span class="math inline">\(p_i\equiv 1/A_i\)</span> for an efficiency unit of task <span class="math inline">\(i\)</span>, then changes in <span class="math inline">\(A\)</span> can be analyzed with standard expenditure-function and price-index tools. I use that equivalence in the continuous section because it is the cleanest way to import known results about exact indices, Tornqvist approximations, and compensated-demand integrals.
</dd>
<dt><strong>Two margins matter.</strong></dt>
<dd>
The continuous model treats tasks as divisible and focuses on intensive reallocation. The discrete model treats the task set as lumpy (setup time or unit demand) and focuses on which tasks get activated.
</dd>
<dt><strong>Continuous intensive margin means smooth substitution.</strong></dt>
<dd>
Choose time shares <span class="math inline">\(t_i\)</span> and allow interior reallocation.
</dd>
<dt><strong>Discrete extensive margin means task activation and selection.</strong></dt>
<dd>
Choose which tasks to do at all (unit demand or setup costs).
</dd>
<dt><strong>Separating the two margins keeps assumptions and data requirements explicit.</strong></dt>
<dd>
The logic, formulas, and data requirements diverge sharply between intensive reallocation and extensive-margin activation, so I treat them separately.
</dd>
</dl>
</section>
<section id="estimation-cheat-sheet" class="level2">
<h2 class="anchored" data-anchor-id="estimation-cheat-sheet">Estimation cheat sheet</h2>
<dl>
<dt><strong>This section maps measured productivity changes into a lift under common assumptions.</strong></dt>
<dd>
It is a lookup table for turning observed time changes or productivity multipliers into a substitution-adjusted lift <span class="math inline">\(V(A^1)/V(A^0)\)</span>.
</dd>
</dl>
<section id="two-good-reduction-ai-affected-bundle-vs-the-rest" class="level3">
<h3 class="anchored" data-anchor-id="two-good-reduction-ai-affected-bundle-vs-the-rest">Two-good reduction (AI-affected bundle vs the rest)</h3>
<dl>
<dt><strong>A two-good reduction collapses tasks into an AI-affected bundle and the rest.</strong></dt>
<dd>
For back-of-envelope calculations, define two bundles: good 2 is the set of tasks whose productivity rises by a factor <span class="math inline">\(A\)</span> when AI is allowed, and good 1 is everything else (normalized). Let <span class="math inline">\(s_0\)</span> be the pre-AI time share on good 2, and suppose only good 2 gets the productivity multiplier <span class="math inline">\(A&gt;1\)</span>. Common benchmarks are:
</dd>
</dl>
<table class="caption-top table">
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th>Assumption about substitution</th>
<th>Implied output gain <span class="math inline">\(V(A^1)/V(A^0)\)</span></th>
<th>Notes</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Perfect complements (Amdahl-style)</td>
<td><span class="math inline">\(\dfrac{1}{(1-s_0)+s_0/A}\)</span></td>
<td>Fixed proportions; AI only relaxes the bottleneck</td>
</tr>
<tr class="even">
<td>Cobb-Douglas (<span class="math inline">\(\varepsilon=1\)</span>)</td>
<td><span class="math inline">\(A^{s_0}\)</span></td>
<td>Share is constant; log change is <span class="math inline">\(s_0\ln A\)</span></td>
</tr>
<tr class="odd">
<td>CES elasticity <span class="math inline">\(\varepsilon\)</span></td>
<td><span class="math inline">\(\left((1-s_0)+s_0\,A^{\varepsilon-1}\right)^{\frac{1}{\varepsilon-1}}\)</span></td>
<td>Requires <span class="math inline">\(\varepsilon\)</span> (or enough data to infer it)</td>
</tr>
<tr class="even">
<td>Perfect substitutes</td>
<td><span class="math inline">\(A\)</span></td>
<td>You can reallocate everything to the sped-up bundle</td>
</tr>
</tbody>
</table>
<dl>
<dt><strong>In the multi-task case, a Tornqvist/Divisia log-index is a convenient approximation.</strong></dt>
<dd>
A common approximation is <span class="math display">\[
  \Delta\ln V \;\approx\; \sum_i \bar t_i\,\ln\left(\frac{A_i^1}{A_i^0}\right),\qquad \bar t_i \equiv \tfrac12(t_{i,0}+t_{i,1}),
  \]</span> which uses average (pre/post) time shares (see <span class="citation" data-cites="caves1982indexnumbers">Caves, Christensen, and Diewert (<a href="#ref-caves1982indexnumbers" role="doc-biblioref">1982</a>)</span>).
</dd>
<dt><strong>Anthropic-style numbers span a wide range under different substitution assumptions.</strong></dt>
<dd>
If <span class="math inline">\(s_0=0.10\)</span> and <span class="math inline">\(A=5\)</span> (a 5x multiplier when AI is used), the implied gain depends heavily on the benchmark.
</dd>
</dl>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Benchmark</th>
<th style="text-align: right;">Gain factor</th>
<th style="text-align: right;">Percent</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Complements bound</td>
<td style="text-align: right;"><span class="math inline">\(1/(0.9+0.02)\approx 1.087\)</span></td>
<td style="text-align: right;"><span class="math inline">\(+8.7\\%\)</span></td>
</tr>
<tr class="even">
<td>Cobb-Douglas</td>
<td style="text-align: right;"><span class="math inline">\(5^{0.1}\approx 1.174\)</span></td>
<td style="text-align: right;"><span class="math inline">\(+17.4\\%\)</span></td>
</tr>
<tr class="odd">
<td>CES, <span class="math inline">\(\varepsilon=2\)</span></td>
<td style="text-align: right;"><span class="math inline">\(0.9+0.1\\cdot 5 = 1.4\)</span></td>
<td style="text-align: right;"><span class="math inline">\(+40\\%\)</span></td>
</tr>
<tr class="even">
<td>Substitutes bound</td>
<td style="text-align: right;"><span class="math inline">\(5\)</span></td>
<td style="text-align: right;"><span class="math inline">\(+400\\%\)</span></td>
</tr>
</tbody>
</table>
<dl>
<dt><strong>The spread is the point.</strong></dt>
<dd>
Large conditional speedups do not translate to a unique aggregate lift without additional structure or data.
</dd>
</dl>
</section>
<section id="if-you-observe-pre-and-post-time-shares-you-can-infer-an-elasticity-in-ces" class="level3">
<h3 class="anchored" data-anchor-id="if-you-observe-pre-and-post-time-shares-you-can-infer-an-elasticity-in-ces">If you observe pre and post time shares, you can infer an elasticity (in CES)</h3>
<dl>
<dt><strong>In a two-good CES benchmark, post-AI shares identify the elasticity.</strong></dt>
<dd>
In the same two-good CES setting, let <span class="math inline">\(s_1\)</span> be the post-AI time share on good 2. Then <span class="math display">\[
  \operatorname{logit}(s_1)-\operatorname{logit}(s_0)=(\varepsilon-1)\ln A,
  \]</span> so <span class="math display">\[
  \varepsilon \;=\; 1 + \frac{\operatorname{logit}(s_1)-\operatorname{logit}(s_0)}{\ln A}.
  \]</span> Here <span class="math inline">\(\operatorname{logit}(s)\equiv \ln\!\left(\frac{s}{1-s}\right)\)</span>. This is often the cleanest way to use both pre and post shares: estimate <span class="math inline">\(\varepsilon\)</span>, then plug into the CES gain formula. If you do not believe CES globally, treat this as local to the observed price change.
</dd>
</dl>
</section>
<section id="estimation-flowchart-what-to-do-with-your-data" class="level3">
<h3 class="anchored" data-anchor-id="estimation-flowchart-what-to-do-with-your-data">Estimation flowchart (what to do with your data)</h3>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">flowchart TD
  A["Goal: estimate productivity lift&lt;br/&gt;V(A_new)/V(A_old)&lt;br/&gt;for fixed time endowment"] --&gt; B{"Are tasks mostly divisible&lt;br/&gt;at the relevant margin?"}

  B --&gt;|Yes: continuous| C{"Are speedups small&lt;br/&gt;or broad-based?"}
  C --&gt;|Yes| D["Use share-weighted log changes:&lt;br/&gt;d ln V ~= sum_i t_i d ln A_i&lt;br/&gt;(Tornqvist/Divisia)"]
  C --&gt;|No| E{"Do you have enough data to pin down substitution?&lt;br/&gt;e.g. CES elasticity, demand system"}
  E --&gt;|Yes| F["Compute an exact/parametric index:&lt;br/&gt;map p_i=1/A_i; use e(p,1)&lt;br/&gt;CES closed form when applicable"]
  E --&gt;|No| G["Trace a demand curve:&lt;br/&gt;vary effective AI cost/strength;&lt;br/&gt;estimate compensated shares; integrate"]

  B --&gt;|No: setup or unit-demand| H["Model extensive margin:&lt;br/&gt;which tasks get activated?"]
  H --&gt; I["Unit-demand tasks: bound the lift&lt;br/&gt;Laspeyres lower bound: pre-AI basket at post-AI time prices&lt;br/&gt;Paasche upper bound: post-AI basket at post-AI time prices"]
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</section>
<section id="what-you-can-estimate-with-what-data" class="level3">
<h3 class="anchored" data-anchor-id="what-you-can-estimate-with-what-data">What you can estimate with what data</h3>
<table class="caption-top table">
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th>What you can measure</th>
<th>Recommended move</th>
<th>What you can credibly report</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>One big conditional multiplier <span class="math inline">\(A\)</span> + a baseline share <span class="math inline">\(s_0\)</span></td>
<td>Report complements/substitutes bounds; add CES sensitivity</td>
<td>A wide interval for <span class="math inline">\(V(A^1)/V(A^0)\)</span> unless you assume <span class="math inline">\(\varepsilon\)</span></td>
</tr>
<tr class="even">
<td>Pre and post shares <span class="math inline">\((s_0,s_1)\)</span> for an AI bundle + a multiplier <span class="math inline">\(A\)</span></td>
<td>Use the logit formula to estimate <span class="math inline">\(\varepsilon\)</span>; plug into CES gain</td>
<td>A model-based point estimate (local to the observed change)</td>
</tr>
<tr class="odd">
<td>Multiple randomized “AI price/quality” arms + observed shares</td>
<td>Estimate share response vs <span class="math inline">\(\ln A\)</span>; integrate shares over the change</td>
<td>An “area under the (compensated) demand curve” estimate for large changes</td>
</tr>
<tr class="even">
<td>Choice/activation data (tasks attempted) under multiple AI prices</td>
<td>Model activation thresholds / setup costs explicitly</td>
<td>Decomposition into intensive and extensive margins</td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="continuous-intensive-margin-model" class="level2">
<h2 class="anchored" data-anchor-id="continuous-intensive-margin-model">Continuous (intensive-margin) model</h2>
<dl>
<dt><strong>Homotheticity lets you treat productivity changes as inverse price changes.</strong></dt>
<dd>
Write effective task output as <span class="math inline">\(z_i\equiv A_i t_i\)</span>. Then <span class="math display">\[
  V(A)=\max_{z\ge 0}\; y(z)\quad\text{s.t.}\quad \sum_i \frac{z_i}{A_i}\le 1.
  \]</span> Define time prices <span class="math inline">\(p_i\equiv 1/A_i\)</span>. This turns the constraint into <span class="math inline">\(\sum_i p_i z_i\le 1\)</span>, so standard expenditure-function and index-number results apply. In particular, define the unit-expenditure function <span class="math inline">\(P(p)\equiv e(p,1)\)</span>. Under homotheticity, the productivity level is <span class="math display">\[
  V(A)=\frac{1}{P(1/A)}.
  \]</span> This is the classic index-number framing applied to time prices (see <span class="citation" data-cites="caves1982indexnumbers">Caves, Christensen, and Diewert (<a href="#ref-caves1982indexnumbers" role="doc-biblioref">1982</a>)</span>).
</dd>
<dt><strong>EV and CV translate productivity changes into welfare changes in time units.</strong></dt>
<dd>
Let <span class="math inline">\(A^0\to A^1\)</span> and define <span class="math inline">\(p^k\equiv 1/A^k\)</span>. Equivalent and compensating variation (measured in time) are <span class="math display">\[
  EV=e(p^0, V(A^1))-1,\qquad CV=e(p^1, V(A^0))-1.
  \]</span> Under homotheticity, <span class="math display">\[
  EV=\frac{P(p^0)}{P(p^1)}-1,\qquad CV=\frac{P(p^1)}{P(p^0)}-1,
  \]</span> which is a clean way to translate time-saving into a welfare measure (see <span class="citation" data-cites="hausman1981exact">Hausman (<a href="#ref-hausman1981exact" role="doc-biblioref">1981</a>)</span>).
</dd>
<dt><strong>Small changes admit a share-weighted approximation.</strong></dt>
<dd>
Let <span class="math inline">\(t_i(A)\)</span> denote optimal time shares. For small changes, <span class="math display">\[
  d\ln V \;\approx\;\sum_i t_i(A)\,d\ln A_i.
  \]</span> This is the time-allocation analog of share-weighted Hulten-style logic (see <span class="citation" data-cites="hulten1978growth">Hulten (<a href="#ref-hulten1978growth" role="doc-biblioref">1978</a>)</span>).
</dd>
<dt><strong>Large changes require integrating compensated shares.</strong></dt>
<dd>
When gains are large, constant-elasticity shortcuts are dangerous. Using Hicksian (compensated) shares <span class="math inline">\(s_i^H(p)\)</span>, <span class="math display">\[
  d\ln P(p)=\sum_i s_i^H(p)\,d\ln p_i.
  \]</span> For a single changing price (equivalently, a single changing productivity component), <span class="math display">\[
  \ln\frac{P(p^1)}{P(p^0)}=\int s_2^H(p_2)\,d\ln p_2,
  \]</span> i.e., exact welfare is an area-under-the-compensated-demand-curve object (see <span class="citation" data-cites="willig1976consumerssurplus">Willig (<a href="#ref-willig1976consumerssurplus" role="doc-biblioref">1976</a>)</span>).
</dd>
<dt><strong>CES yields closed-form formulas useful for back-of-envelope work.</strong></dt>
<dd>
For a CES aggregator in <span class="math inline">\(z\)</span>, <span class="math display">\[
  y(z)=\left(\sum_i \alpha_i z_i^{\frac{\sigma-1}{\sigma}}\right)^{\frac{\sigma}{\sigma-1}},\quad\sigma&gt;0,
  \]</span> the associated price index and (compensated) shares have closed form. In a two-good reduction where only good 2 gets a productivity multiplier <span class="math inline">\(A\)</span> and its ex-ante time share is <span class="math inline">\(s_0\)</span>, <span class="math display">\[
  \frac{V(A^1)}{V(A^0)}=\left((1-s_0)+s_0\,A^{\varepsilon-1}\right)^{\frac{1}{\varepsilon-1}},\qquad \varepsilon\equiv\sigma.
  \]</span> This is the clean continuous benchmark (see <span class="citation" data-cites="caves1982indexnumbers">Caves, Christensen, and Diewert (<a href="#ref-caves1982indexnumbers" role="doc-biblioref">1982</a>)</span>).
</dd>
</dl>
<section id="two-good-ces-yields-closed-form-gain-and-share-shift" class="level4">
<h4 class="anchored" data-anchor-id="two-good-ces-yields-closed-form-gain-and-share-shift">Two-good CES yields closed-form gain and share shift</h4>
<dl>
<dt><strong>The output gain has a closed form in terms of <span class="math inline">\(s_0,A,\varepsilon\)</span>.</strong></dt>
<dd>
In a two-good CES benchmark where only good 2 gets a multiplier <span class="math inline">\(A\)</span> (so <span class="math inline">\(p_2'=p_2/A\)</span>), <span class="math display">\[
  \frac{V(A^1)}{V(A^0)}=\left((1-s_0)+s_0\,A^{\varepsilon-1}\right)^{\frac{1}{\varepsilon-1}}.
  \]</span>
</dd>
<dt><strong>The post-AI share shift pins down <span class="math inline">\(\varepsilon\)</span> when <span class="math inline">\(s_1\)</span> is observed.</strong></dt>
<dd>
The post-AI time share is <span class="math display">\[
  s_1=\frac{s_0\,A^{\varepsilon-1}}{(1-s_0)+s_0\,A^{\varepsilon-1}}
  \quad\Leftrightarrow\quad
  \operatorname{logit}(s_1)-\operatorname{logit}(s_0)=(\varepsilon-1)\ln A.
  \]</span>
</dd>
</dl>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Proof (structured)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="1">
<li><em>Given</em> CES unit-expenditure (time price) index <span class="math display">\[
P(p)=\left(\alpha_1^{\varepsilon}p_1^{1-\varepsilon}+\alpha_2^{\varepsilon}p_2^{1-\varepsilon}\right)^{\frac{1}{1-\varepsilon}},
\qquad V(A)=\frac{1}{P(1/A)}.
\]</span></li>
<li><em>Let</em> <span class="math inline">\(p_2' = p_2/A\)</span> with <span class="math inline">\(p_1\)</span> fixed. Then <span class="math display">\[
\frac{V(A^1)}{V(A^0)}=\frac{P(p)}{P(p')}=
\left(
  \frac{\alpha_1^{\varepsilon}p_1^{1-\varepsilon}+\alpha_2^{\varepsilon}p_2^{1-\varepsilon}}
       {\alpha_1^{\varepsilon}p_1^{1-\varepsilon}+\alpha_2^{\varepsilon}(p_2/A)^{1-\varepsilon}}
\right)^{\frac{1}{\varepsilon-1}}.
\]</span></li>
<li><em>Define</em> the ex-ante share <span class="math display">\[
s_0\equiv\frac{\alpha_2^{\varepsilon}p_2^{1-\varepsilon}}
               {\alpha_1^{\varepsilon}p_1^{1-\varepsilon}+\alpha_2^{\varepsilon}p_2^{1-\varepsilon}}.
\]</span> Substituting into Step 2 yields the claimed gain formula.</li>
<li><em>For shares,</em> note CES time shares satisfy <span class="math display">\[
\frac{s}{1-s}=\frac{\alpha_2^{\varepsilon}p_2^{1-\varepsilon}}{\alpha_1^{\varepsilon}p_1^{1-\varepsilon}}.
\]</span> Therefore, <span class="math display">\[
\frac{s_1/(1-s_1)}{s_0/(1-s_0)}
=
\frac{(p_2')^{1-\varepsilon}}{p_2^{1-\varepsilon}}
=
\left(\frac{p_2/A}{p_2}\right)^{1-\varepsilon}
=
A^{\varepsilon-1},
\]</span> which rearranges to the stated closed form for <span class="math inline">\(s_1\)</span> and the logit identity.</li>
<li>QED.</li>
</ol>
</div>
</div>
</div>
</section>
</section>
<section id="discrete-extensive-margin-model" class="level2">
<h2 class="anchored" data-anchor-id="discrete-extensive-margin-model">Discrete (extensive-margin) model</h2>
<dl>
<dt><strong>Task activation makes selection central.</strong></dt>
<dd>
The continuous model assumes you always do some of each task. That is wrong when tasks are lumpy, have setup costs, or are unit-demand. In those cases, LLMs can create newly affordable tasks, meaning the major effect is selection (which tasks get done at all), not intensive reallocation.
</dd>
</dl>
<section id="unit-demand-formulation" class="level3">
<h3 class="anchored" data-anchor-id="unit-demand-formulation">Unit-demand formulation</h3>
<dl>
<dt><strong>A unit-demand formulation treats tasks as lumpy goods.</strong></dt>
<dd>
Let each task have payoff <span class="math inline">\(u_i\)</span> and required time <span class="math inline">\(w_i\)</span>, with decision <span class="math inline">\(q_i\in\{0,1\}\)</span>. Then <span class="math display">\[
  \max_{q\in\{0,1\}^n}\sum_i u_i q_i\quad\text{s.t.}\quad \sum_i w_i q_i\le 1.
  \]</span>
</dd>
<dt><strong>Productivity multipliers can turn tasks on at extensive-margin thresholds.</strong></dt>
<dd>
If AI multiplies productivity for task <span class="math inline">\(i\)</span> by <span class="math inline">\(A_i\)</span>, and time required is inversely proportional to productivity, then <span class="math inline">\(w_i\)</span> falls to <span class="math inline">\(w_i/A_i\)</span>. That change can turn tasks on once a threshold is crossed. This is the basic lumpy-choice phenomenon: tasks that were too time-expensive become attractive after AI. A CES elasticity is not a good summary statistic in this regime.
</dd>
<dt><strong>Pre and post task baskets give Laspeyres and Paasche bounds on the lift.</strong></dt>
<dd>
Suppose you observe (i) the pre-AI chosen task vector <span class="math inline">\(q^0\)</span> and the post-AI chosen task vector <span class="math inline">\(q^1\)</span>, and (ii) the per-task time requirements before and after AI, denoted <span class="math inline">\(w_i^0\)</span> and <span class="math inline">\(w_i^1\)</span>. Define the time cost of a basket as <span class="math inline">\(T^k(q)\equiv \sum_i w_i^k q_i\)</span>. Consider the fixed-basket lifts <span class="math display">\[
  G_L \equiv \frac{T^0(q^0)}{T^1(q^0)} \qquad\text{and}\qquad
  G_P \equiv \frac{T^0(q^1)}{T^1(q^1)}.
  \]</span> Under standard revealed-preference logic for a cost-of-living index (with time as the numeraire), the true time-price index lies between Paasche and Laspeyres, so the productivity lift lies between their inverses: <span class="math display">\[
  G_L \;\le\; \frac{V(A^1)}{V(A^0)} \;\le\; G_P.
  \]</span> Intuitively, <span class="math inline">\(G_L\)</span> is a conservative hold-the-old-basket-fixed estimate (lower bound), while <span class="math inline">\(G_P\)</span> allows both the basket and effective prices to shift (upper bound).
</dd>
<dt><strong>Tasks with high “overhead shares” get larger effective multipliers.</strong></dt>
<dd>
A useful way to think about the tasks-you-previously-avoided condition is to decompose time cost into a baseline component plus an overhead component (search, reading, drafting, refactoring). For example, write <span class="math display">\[
  w_i=a_i+b_i,
  \]</span> and suppose AI primarily reduces overhead, <span class="math inline">\(b_i' = b_i/A^{O}\)</span> while <span class="math inline">\(a_i\)</span> is unchanged. Then <span class="math display">\[
  w_i' = a_i + \frac{b_i}{A^{O}},\qquad
  A_i \equiv \frac{w_i}{w_i'} = \frac{a_i+b_i}{a_i+b_i/A^{O}},
  \]</span> so <span class="math inline">\(A_i\)</span> is increasing in the overhead share <span class="math inline">\(b_i/(a_i+b_i)\)</span>. Tasks you previously avoided plausibly have high overhead shares, so they get larger effective multipliers and are more likely to cross activation thresholds.
</dd>
</dl>
</section>
<section id="setup-cost-variant-bridging-discrete-and-continuous" class="level3">
<h3 class="anchored" data-anchor-id="setup-cost-variant-bridging-discrete-and-continuous">Setup-cost variant (bridging discrete and continuous)</h3>
<dl>
<dt><strong>Setup costs create lumpy activation even when within-task intensity is divisible.</strong></dt>
<dd>
Add a fixed setup time <span class="math inline">\(\phi_i\)</span> and allow continuous within-task time allocations: <span class="math display">\[
\max_{q,t}\; y(A_1 t_1,\dots,A_n t_n)\quad\text{s.t.}\quad \sum_i \phi_i q_i + \sum_i t_i \le 1,\; t_i=0\;\text{if }q_i=0.
\]</span>
</dd>
<dt><strong>With setup costs, large shocks mostly expand the active set.</strong></dt>
<dd>
If <span class="math inline">\(\phi_i=0\)</span>, we recover the continuous model. If <span class="math inline">\(\phi_i&gt;0\)</span>, large productivity changes mostly expand the active set <span class="math inline">\(\{i:q_i=1\}\)</span>, not the intensive shares.
</dd>
</dl>
</section>
<section id="worked-example-discrete-not-continuous" class="level3">
<h3 class="anchored" data-anchor-id="worked-example-discrete-not-continuous">Worked example (discrete, not continuous)</h3>
<dl>
<dt><strong>Discrete choice does not identify a single time-savings without more structure.</strong></dt>
<dd>
Suppose you can pick one task (unit demand). Task A yields value <span class="math inline">\(u_A=10\)</span> and takes 1 hour. Task B yields <span class="math inline">\(u_B=12\)</span> and takes 2 hours. Without LLMs you choose A. Now an LLM speeds up task B so it takes 1 hour, and you switch to B. The observed switch is consistent with a wide range of time-equivalent gains:
</dd>
</dl>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Bound interpretation</th>
<th style="text-align: right;">Time-equivalent gain</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Upper bound (extra value worth a full hour)</td>
<td style="text-align: right;">1 hour</td>
</tr>
<tr class="even">
<td>Lower bound (extra value is only a small quality bump)</td>
<td style="text-align: right;">0 hours</td>
</tr>
</tbody>
</table>
<dl>
<dt><strong>Selection effects require a model or bounds, not just observed switching.</strong></dt>
<dd>
The observed reallocation does not identify a precise time-savings without modeling discrete choice. This is why constant-elasticity summaries can be weak in the activation regime.
</dd>
</dl>
</section>
<section id="newly-activated-tasks" class="level3">
<h3 class="anchored" data-anchor-id="newly-activated-tasks">Newly activated tasks</h3>
<dl>
<dt><strong>Definition of newly activated tasks.</strong></dt>
<dd>
Call a task newly activated if you would not do it at baseline time prices but you do once its time cost drops. Examples include literature reviews you previously would not attempt, custom data visualizations, and long-form proofreading or refactoring.
</dd>
<dt><strong>These show up as extensive-margin choices, not smooth intensities.</strong></dt>
<dd>
In a unit-demand or setup-cost model, these tasks show up as newly activated <span class="math inline">\(q_i=1\)</span> choices, not as marginal changes in time allocations. This is why AI share of time can jump even if underlying preferences are stable: the feasible set changed.
</dd>
</dl>
</section>
</section>
<section id="applications" class="level2">
<h2 class="anchored" data-anchor-id="applications">Applications</h2>
<section id="application-1-from-query-level-time-savings-to-an-aggregate-lift-anthropic" class="level3">
<h3 class="anchored" data-anchor-id="application-1-from-query-level-time-savings-to-an-aggregate-lift-anthropic">Application 1: from query-level time savings to an aggregate lift (Anthropic)</h3>
<dl>
<dt><strong>Anthropic-style log studies estimate conditional time savings on observed AI conversations.</strong></dt>
<dd>
<span class="citation" data-cites="anthropic2025estimatingproductivitygains">Anthropic (<a href="#ref-anthropic2025estimatingproductivitygains" role="doc-biblioref">2025</a>)</span> estimates time savings from Claude conversations by comparing time required with vs without AI for a sample of tasks drawn from usage logs.
</dd>
<dt><strong>Back-of-envelope inputs can be summarized as a baseline share and a productivity multiplier.</strong></dt>
<dd>
Illustratively, the inputs are:
</dd>
</dl>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Quantity</th>
<th style="text-align: right;">Symbol</th>
<th style="text-align: right;">Value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Baseline time share on the AI-affected bundle</td>
<td style="text-align: right;"><span class="math inline">\(s_0\)</span></td>
<td style="text-align: right;"><span class="math inline">\(10\\%\)</span></td>
</tr>
<tr class="even">
<td>Productivity multiplier when AI is used</td>
<td style="text-align: right;"><span class="math inline">\(A\)</span></td>
<td style="text-align: right;"><span class="math inline">\(5\)</span></td>
</tr>
</tbody>
</table>
<dl>
<dt><strong>Even in a two-good continuous approximation, the implied lift depends sharply on substitution.</strong></dt>
<dd>
The table below shows how different assumptions about substitutability map the same inputs into very different lifts.
</dd>
</dl>
<table class="caption-top table">
<colgroup>
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th>Assumption about substitution</th>
<th>What it means in this note</th>
<th>Assumption on <span class="math inline">\(\varepsilon\)</span></th>
<th>Implied lift when <span class="math inline">\(s_0=10\%\)</span> and <span class="math inline">\(A=5\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Strong complements (Amdahl/Leontief-style)</td>
<td>Time shares do not move much when a subset of tasks speeds up</td>
<td>effectively <span class="math inline">\(\varepsilon\to 0\)</span></td>
<td>about <span class="math inline">\(+8.7\%\)</span></td>
</tr>
<tr class="even">
<td>Cobb-Douglas benchmark</td>
<td>Unit elasticity, moderate reallocation</td>
<td><span class="math inline">\(\varepsilon=1\)</span></td>
<td>about <span class="math inline">\(+17.4\%\)</span></td>
</tr>
<tr class="odd">
<td>CES example with stronger substitution</td>
<td>Time shifts strongly toward the sped-up bundle</td>
<td><span class="math inline">\(\varepsilon=2\)</span></td>
<td>about <span class="math inline">\(+40\%\)</span></td>
</tr>
</tbody>
</table>
<dl>
<dt><strong>The key empirical object is the share response to an effective price change.</strong></dt>
<dd>
The identification problem is not only how big <span class="math inline">\(A\)</span> is when AI is used, but how time shares respond when relative time prices change. In the CES benchmark that response is summarized by <span class="math inline">\(\varepsilon\)</span>; outside CES, it is a demand-curve object.
</dd>
<dt><strong>Endogenous task mix can make pre-AI shares a poor guide.</strong></dt>
<dd>
If AI reduces time costs more for tasks you previously avoided (high search/reading/writing overhead), then the pre-AI share <span class="math inline">\(s_0\)</span> understates the mass of tasks that become attractive post-AI.
</dd>
<dt><strong>Quality adjustment matters whenever “time saved” is partly quality.</strong></dt>
<dd>
Some measured time savings are quality improvements (or vice versa). If your output index treats quality as part of output, you need a quality measure to map time changes into the output index <span class="math inline">\(y(\cdot)\)</span>.
</dd>
</dl>
</section>
<section id="application-2-interpreting-uplift-rcts-metr-open-source-dev" class="level3">
<h3 class="anchored" data-anchor-id="application-2-interpreting-uplift-rcts-metr-open-source-dev">Application 2: interpreting “uplift” RCTs (METR / open-source dev)</h3>
<dl>
<dt><strong>Uplift RCTs often identify intensive effects on a fixed task set.</strong></dt>
<dd>
<span class="citation" data-cites="becker2025uplift">J. Becker et al. (<a href="#ref-becker2025uplift" role="doc-biblioref">2025</a>)</span> is an RCT where tasks are assigned to allow vs disallow AI tools, and the outcome is completion time (with additional self-reports and robustness checks). The headline is that AI access increases completion time on average in their setting.
</dd>
<dt><strong>A simple back-of-envelope converts time changes into a productivity multiplier.</strong></dt>
<dd>
If allowing AI increases completion time by 19%, then the implied productivity multiplier is <span class="math inline">\(A \approx 1/1.19 \approx 0.84\)</span> (a slowdown). Holding output constant, that is about a 16% productivity hit on that task population.
</dd>
<dt><strong>Fixed-task designs identify an <span class="math inline">\(A_i\)</span> distribution but not substitution.</strong></dt>
<dd>
With a fixed task set (as in many RCTs), the main object you learn is a task-level time change (an <span class="math inline">\(A_i\)</span> distribution if you convert time changes into productivity multipliers), holding task composition fixed. Mapping that into <span class="math inline">\(V(A^1)/V(A^0)\)</span> requires additional assumptions or variation that moves the task mix.
</dd>
<dt><strong>Aggregate interpretations require an explicit output and quality index.</strong></dt>
<dd>
Translating time changes into an aggregate productivity index still requires an output/quality index: are we holding output constant (pure time saved), holding time constant (more output), or letting both adjust? In practice you often want quality-adjusted output per unit time.
</dd>
<dt><strong>If AI changes which tasks are attempted, the design must measure selection.</strong></dt>
<dd>
If AI access changes which tasks are attempted, then the design has to either fix tasks (to isolate intensive effects) or explicitly allow selection and measure it (to capture the extensive margin).
</dd>
</dl>
</section>
</section>
<section id="experimental-design" class="level2">
<h2 class="anchored" data-anchor-id="experimental-design">Experimental design</h2>
<dl>
<dt><strong>Design choices mostly trade off identification of substitution against control of selection.</strong></dt>
<dd>
Designing studies that map <span class="math inline">\(\{A_i\}\)</span> into an aggregate lift <span class="math inline">\(V(A^1)/V(A^0)\)</span> is mostly about measuring substitution and separating intensive vs extensive margins.
</dd>
<dt><strong>Decide the estimand before collecting data.</strong></dt>
<dd>
Same tasks, faster (hold task outputs fixed) is different from best use of a fixed time budget (maximize <span class="math inline">\(y(A_1 t_1,\dots,A_n t_n)\)</span>). The latter matches the substitution estimand in this note.
</dd>
<dt><strong>Use complementary protocols to separate intensive and extensive margins.</strong></dt>
<dd>
A simple way to separate margins is to run both a fixed-task and a time-budget protocol:
</dd>
</dl>
<table class="caption-top table">
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th>Protocol</th>
<th>What is held fixed</th>
<th>What it identifies</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Fixed-task protocol</td>
<td>A pre-specified task list</td>
<td>Task-level time/quality changes (intensive margin)</td>
</tr>
<tr class="even">
<td>Time-budget protocol</td>
<td>A fixed time endowment and objective</td>
<td>Substitution and selection (task mix + output index)</td>
</tr>
</tbody>
</table>
<dl>
<dt><strong>Measure quality explicitly and specify how it enters the output index.</strong></dt>
<dd>
Use blinded human evaluation, unit tests, or objective metrics; pre-register how quality enters <span class="math inline">\(y(\cdot)\)</span> (e.g.&nbsp;threshold vs continuous scoring).
</dd>
<dt><strong>Trace a demand curve by randomizing effective AI price/quality.</strong></dt>
<dd>
Randomize not only AI allowed, but the effective cost or strength of AI (token budgets, latency, model quality tiers, usage quotas). This gives variation to estimate how shares move with relative time prices (the object behind <span class="math inline">\(\varepsilon\)</span> or, more generally, Hicksian shares).
</dd>
<dt><strong>Handle learning, spillovers, and dynamics.</strong></dt>
<dd>
Use cross-over designs, washout periods, or between-subject randomization where appropriate; measure experience and allow for dynamic treatment effects.
</dd>
</dl>
</section>
<section id="related-literature-more-explicit" class="level2">
<h2 class="anchored" data-anchor-id="related-literature-more-explicit">Related literature (more explicit)</h2>
<dl>
<dt><strong>This section is a reading map keyed to the objects used in the note.</strong></dt>
<dd>
The goal is to point to canonical references for price indices, time allocation, discrete activation, and empirical measurement, without mixing too much bibliographic detail into the thesis lines.
</dd>
</dl>
<section id="index-numbers-and-exact-welfare-from-price-changes-continuous-case" class="level3">
<h3 class="anchored" data-anchor-id="index-numbers-and-exact-welfare-from-price-changes-continuous-case">Index numbers and exact welfare from price changes (continuous case)</h3>
<dl>
<dt><strong>Expenditure-function cost-of-living indices.</strong></dt>
<dd>
<span class="citation" data-cites="konus1939trueindex">Konus (<a href="#ref-konus1939trueindex" role="doc-biblioref">1939</a>)</span> defines a cost-of-living index as the ratio of minimum expenditures needed to reach a fixed utility level at two price vectors. This is exactly the object <span class="math inline">\(P(p)=e(p,1)\)</span> (with time prices instead of money prices) that corresponds here to <span class="math inline">\(V(A)=1/P(1/A)\)</span> under homotheticity.
</dd>
<dt><strong>Exact/superlative indices and share-weighted approximations.</strong></dt>
<dd>
<span class="citation" data-cites="diewert1976exact">Diewert (<a href="#ref-diewert1976exact" role="doc-biblioref">1976</a>)</span> formalizes when index numbers (including Tornqvist/Divisia-type log-share formulas) are exact for flexible functional forms and motivates using share-weighted log changes as a local approximation.
</dd>
<dt><strong>Duality and productivity measurement via index numbers.</strong></dt>
<dd>
<span class="citation" data-cites="caves1982indexnumbers">Caves, Christensen, and Diewert (<a href="#ref-caves1982indexnumbers" role="doc-biblioref">1982</a>)</span> is a central reference for exact index-number measurement of input, output, and productivity, and for the duality framing used in the continuous model here.
</dd>
<dt><strong>Large changes and compensated-demand integrals.</strong></dt>
<dd>
<span class="citation" data-cites="willig1976consumerssurplus">Willig (<a href="#ref-willig1976consumerssurplus" role="doc-biblioref">1976</a>)</span> and <span class="citation" data-cites="hausman1981exact">Hausman (<a href="#ref-hausman1981exact" role="doc-biblioref">1981</a>)</span> connect equivalent/compensating variation and consumer surplus to integrals of compensated demand, clarifying why large AI shocks call for area under Hicksian demand rather than constant-elasticity shortcuts.
</dd>
<dt><strong>Demand systems for practical welfare calculations.</strong></dt>
<dd>
<span class="citation" data-cites="deaton1980aids">Deaton and Muellbauer (<a href="#ref-deaton1980aids" role="doc-biblioref">1980</a>)</span> introduces AIDS, a workhorse integrable demand system used to estimate demand and welfare effects of price changes in practice.
</dd>
</dl>
</section>
<section id="time-allocation-information-costs-and-overhead-time" class="level3">
<h3 class="anchored" data-anchor-id="time-allocation-information-costs-and-overhead-time">Time allocation, information costs, and “overhead” time</h3>
<dl>
<dt><strong>Time allocation as a core economic problem.</strong></dt>
<dd>
<span class="citation" data-cites="becker1965allocation">G. S. Becker (<a href="#ref-becker1965allocation" role="doc-biblioref">1965</a>)</span> frames time allocation as a core economic problem, and is a natural ancestor of treating task durations as time prices.
</dd>
<dt><strong>Time requirements and shadow prices.</strong></dt>
<dd>
<span class="citation" data-cites="deserpa1971time">DeSerpa (<a href="#ref-deserpa1971time" role="doc-biblioref">1971</a>)</span> emphasizes that goods require time to consume/produce and develops shadow-price implications close to the time-price interpretation here.
</dd>
<dt><strong>Information/search costs as a mechanism for time savings.</strong></dt>
<dd>
<span class="citation" data-cites="stigler1961information">Stigler (<a href="#ref-stigler1961information" role="doc-biblioref">1961</a>)</span> treats costly search as central; empirically, many LLM speedups look like reductions in search/reading/writing overhead rather than reductions in core task time.
</dd>
<dt><strong>Characteristics and implicit prices.</strong></dt>
<dd>
<span class="citation" data-cites="lancaster1966consumer">Lancaster (<a href="#ref-lancaster1966consumer" role="doc-biblioref">1966</a>)</span> gives an alternative lens: tasks bundle characteristics (information, drafting, formatting, reasoning), and AI shifts the implicit prices of those characteristics.
</dd>
</dl>
</section>
<section id="discrete-activation-selection-and-welfare-with-lumpy-choices" class="level3">
<h3 class="anchored" data-anchor-id="discrete-activation-selection-and-welfare-with-lumpy-choices">Discrete activation, selection, and welfare with lumpy choices</h3>
<dl>
<dt><strong>Welfare tools for discrete choice.</strong></dt>
<dd>
<span class="citation" data-cites="smallrosen1981welfare">Small and Rosen (<a href="#ref-smallrosen1981welfare" role="doc-biblioref">1981</a>)</span> is a classic reference for welfare analysis with discrete choice, directly relevant for unit-demand tasks and activation thresholds.
</dd>
<dt><strong>Applied discrete-choice estimation.</strong></dt>
<dd>
<span class="citation" data-cites="train2003discretechoice">Train (<a href="#ref-train2003discretechoice" role="doc-biblioref">2003</a>)</span> is a standard applied reference for estimating random-utility/discrete-choice models when you want to quantify substitution and welfare.
</dd>
</dl>
</section>
<section id="task-based-technological-change-and-aggregation" class="level3">
<h3 class="anchored" data-anchor-id="task-based-technological-change-and-aggregation">Task-based technological change and aggregation</h3>
<dl>
<dt><strong>Task-based technological change.</strong></dt>
<dd>
<span class="citation" data-cites="autor2003skill">Autor, Levy, and Murnane (<a href="#ref-autor2003skill" role="doc-biblioref">2003</a>)</span> and <span class="citation" data-cites="acemoglu2011handbook">Acemoglu and Autor (<a href="#ref-acemoglu2011handbook" role="doc-biblioref">2011</a>)</span> popularize task-based views of technology, conceptually aligned with treating tasks as goods with relative time prices.
</dd>
<dt><strong>Small-shock share-weighted logic (Hulten-style).</strong></dt>
<dd>
<span class="citation" data-cites="hulten1978growth">Hulten (<a href="#ref-hulten1978growth" role="doc-biblioref">1978</a>)</span> is the backbone for why <span class="math inline">\(\Delta\ln V\approx \sum_i t_i\,\Delta\ln A_i\)</span> can be reasonable for small or broad shocks.
</dd>
<dt><strong>Beyond small shocks: nonlinearities and large changes.</strong></dt>
<dd>
<span class="citation" data-cites="baqaee2019macro">Baqaee and Farhi (<a href="#ref-baqaee2019macro" role="doc-biblioref">2019</a>)</span> is a canonical reference on nonlinearities and large shocks and connects directly to why large AI shocks motivate demand-curve integration and careful treatment of selection.
</dd>
<dt><strong>Micro-to-macro aggregation from technology evidence.</strong></dt>
<dd>
<span class="citation" data-cites="oberfield2021micro">Oberfield and Raval (<a href="#ref-oberfield2021micro" role="doc-biblioref">2021</a>)</span> is a useful reference on linking micro evidence on technology to macro implications.
</dd>
<dt><strong>CES as a workhorse benchmark.</strong></dt>
<dd>
<span class="citation" data-cites="dixit1977monopolistic">Dixit and Stiglitz (<a href="#ref-dixit1977monopolistic" role="doc-biblioref">1977</a>)</span> sits behind many closed-form substitution formulas, including the two-good CES benchmark used above.
</dd>
</dl>
</section>
<section id="empirical-ai-productivity-and-usage-measurement" class="level3">
<h3 class="anchored" data-anchor-id="empirical-ai-productivity-and-usage-measurement">Empirical AI productivity and usage measurement</h3>
<dl>
<dt><strong>Log-based time-savings evidence.</strong></dt>
<dd>
<span class="citation" data-cites="anthropic2025estimatingproductivitygains">Anthropic (<a href="#ref-anthropic2025estimatingproductivitygains" role="doc-biblioref">2025</a>)</span> illustrates the appeal (and limits) of measuring conditional time savings and baseline shares in observational usage data.
</dd>
<dt><strong>Fixed-task RCT evidence.</strong></dt>
<dd>
<span class="citation" data-cites="becker2025uplift">J. Becker et al. (<a href="#ref-becker2025uplift" role="doc-biblioref">2025</a>)</span> exemplifies randomized access to AI tools with completion-time outcomes, highlighting the importance of quality measurement and task selection.
</dd>
<dt><strong>Early gen-AI productivity evidence across settings.</strong></dt>
<dd>
<span class="citation" data-cites="noy2023generative">Noy and Zhang (<a href="#ref-noy2023generative" role="doc-biblioref">2023</a>)</span> and <span class="citation" data-cites="brynjolfsson2023generative">Brynjolfsson, Li, and Raymond (<a href="#ref-brynjolfsson2023generative" role="doc-biblioref">2023</a>)</span> are widely cited early studies with evidence on productivity and heterogeneity.
</dd>
<dt><strong>Usage composition and task mix.</strong></dt>
<dd>
<span class="citation" data-cites="chatterji2025chatgpt">Chatterji et al. (<a href="#ref-chatterji2025chatgpt" role="doc-biblioref">2025</a>)</span> documents usage patterns and task composition for ChatGPT, relevant when the task mix is endogenous.
</dd>
<dt><strong>Valuing time savings and digital services.</strong></dt>
<dd>
<span class="citation" data-cites="varian2011economic">Varian (<a href="#ref-varian2011economic" role="doc-biblioref">2011</a>)</span> and <span class="citation" data-cites="collis2025welfare">Collis and Brynjolfsson (<a href="#ref-collis2025welfare" role="doc-biblioref">2025</a>)</span> are representative of work valuing digital services and time savings, complementary to the demand-theory framing here.
</dd>
</dl>



</section>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-acemoglu2011handbook" class="csl-entry" role="listitem">
Acemoglu, Daron, and David Autor. 2011. <span>“Skills, Tasks and Technologies: Implications for Employment and Earnings.”</span> In, edited by David Card and Orley Ashenfelter, 4:1043–1171. Handbook of Labor Economics. Elsevier. https://doi.org/<a href="https://doi.org/10.1016/S0169-7218(11)02410-5">https://doi.org/10.1016/S0169-7218(11)02410-5</a>.
</div>
<div id="ref-anthropic2025estimatingproductivitygains" class="csl-entry" role="listitem">
Anthropic. 2025. <span>“Estimating AI Productivity Gains from Claude Conversations.”</span> 2025. <a href="https://www.anthropic.com/research/estimating-productivity-gains">https://www.anthropic.com/research/estimating-productivity-gains</a>.
</div>
<div id="ref-autor2003skill" class="csl-entry" role="listitem">
Autor, David, Frank Levy, and Richard J Murnane. 2003. <span>“The Skill Content of Recent Technological Change: An Empirical Exploration.”</span> <em>The Quarterly Journal of Economics</em> 118 (4): 1279–1333. <a href="https://doi.org/10.3386/w8337">https://doi.org/10.3386/w8337</a>.
</div>
<div id="ref-baqaee2019macro" class="csl-entry" role="listitem">
Baqaee, David Rezza, and Emmanuel Farhi. 2019. <span>“The Macroeconomic Impact of Microeconomic Shocks: Beyond Hulten’s Theorem.”</span> <em>Econometrica</em> 87 (4): 1155–1206. <a href="https://doi.org/10.3982/ecta15202">https://doi.org/10.3982/ecta15202</a>.
</div>
<div id="ref-becker1965allocation" class="csl-entry" role="listitem">
Becker, Gary S. 1965. <span>“A Theory of the Allocation of Time.”</span> <em>The Economic Journal</em> 75 (299): 493. <a href="https://doi.org/10.2307/2228949">https://doi.org/10.2307/2228949</a>.
</div>
<div id="ref-becker2025uplift" class="csl-entry" role="listitem">
Becker, Joel, Nate Rush, Elizabeth Barnes, and David Rein. 2025. <span>“Measuring the Impact of Early-2025 AI on Experienced Open-Source Developer Productivity.”</span> <a href="https://arxiv.org/pdf/2507.09089.pdf">https://arxiv.org/pdf/2507.09089.pdf</a>.
</div>
<div id="ref-brynjolfsson2023generative" class="csl-entry" role="listitem">
Brynjolfsson, Erik, Danielle Li, and Lindsey R Raymond. 2023. <span>“Generative AI at Work.”</span> <em>Available at SSRN 4573321</em>. <a href="https://doi.org/10.1093/qje/qjae044">https://doi.org/10.1093/qje/qjae044</a>.
</div>
<div id="ref-caves1982indexnumbers" class="csl-entry" role="listitem">
Caves, Douglas W., Laurits R. Christensen, and W. Erwin Diewert. 1982. <span>“The Economic Theory of Index Numbers and the Measurement of Input, Output, and Productivity.”</span> <em>Econometrica</em> 50 (6): 1393–1414. <a href="https://www.jstor.org/stable/1913382">https://www.jstor.org/stable/1913382</a>.
</div>
<div id="ref-chatterji2025chatgpt" class="csl-entry" role="listitem">
Chatterji, Aaron, Thomas Cunningham, David J. Deming, Zoe Hitzig, Christopher Ong, Carl Yan Shan, and Kevin Wadman. 2025. <span>“How People Use ChatGPT.”</span> Working Paper 34255. National Bureau of Economic Research. <a href="https://doi.org/10.3386/w34255">https://doi.org/10.3386/w34255</a>.
</div>
<div id="ref-collis2025welfare" class="csl-entry" role="listitem">
Collis, Avinash, and Erik Brynjolfsson. 2025. <span>“AI’s Overlooked $97 Billion Contribution to the Economy.”</span> <em>Wall Street Journal</em>, August. <a href="https://www.wsj.com/opinion/ais-overlooked-97-billion-contribution-to-the-economy-users-service-da6e8f55">https://www.wsj.com/opinion/ais-overlooked-97-billion-contribution-to-the-economy-users-service-da6e8f55</a>.
</div>
<div id="ref-deaton1980aids" class="csl-entry" role="listitem">
Deaton, Angus, and John Muellbauer. 1980. <span>“An Almost Ideal Demand System.”</span> <em>American Economic Review</em> 70 (3): 312–26. <a href="https://www.semanticscholar.org/search?q=An%20Almost%20Ideal%20Demand%20System">https://www.semanticscholar.org/search?q=An%20Almost%20Ideal%20Demand%20System</a>.
</div>
<div id="ref-deserpa1971time" class="csl-entry" role="listitem">
DeSerpa, Allan C. 1971. <span>“A Theory of the Economics of Time.”</span> <em>The Economic Journal</em> 81 (324): 828–46. <a href="https://doi.org/10.2307/2230320">https://doi.org/10.2307/2230320</a>.
</div>
<div id="ref-diewert1976exact" class="csl-entry" role="listitem">
Diewert, W. Erwin. 1976. <span>“Exact and Superlative Index Numbers.”</span> <em>Journal of Econometrics</em> 4 (2): 115–45. <a href="https://doi.org/10.1016/0304-4076(76)90009-9">https://doi.org/10.1016/0304-4076(76)90009-9</a>.
</div>
<div id="ref-dixit1977monopolistic" class="csl-entry" role="listitem">
Dixit, Avinash K, and Joseph E Stiglitz. 1977. <span>“Monopolistic Competition and Optimum Product Diversity.”</span> <em>The American Economic Review</em> 67 (3): 297–308. <a href="https://www.semanticscholar.org/search?q=Monopolistic%20competition%20and%20optimum%20product%20diversity">https://www.semanticscholar.org/search?q=Monopolistic%20competition%20and%20optimum%20product%20diversity</a>.
</div>
<div id="ref-hausman1981exact" class="csl-entry" role="listitem">
Hausman, Jerry A. 1981. <span>“Exact Consumer’s Surplus and Deadweight Loss.”</span> <em>American Economic Review</em> 71 (4): 662–76. <a href="https://www.semanticscholar.org/search?q=Exact%20Consumer%27s%20Surplus%20and%20Deadweight%20Loss">https://www.semanticscholar.org/search?q=Exact%20Consumer%27s%20Surplus%20and%20Deadweight%20Loss</a>.
</div>
<div id="ref-hulten1978growth" class="csl-entry" role="listitem">
Hulten, Charles R. 1978. <span>“Growth Accounting with Intermediate Inputs.”</span> <em>The Review of Economic Studies</em> 45 (3): 511–18. <a href="https://doi.org/10.2307/2297252">https://doi.org/10.2307/2297252</a>.
</div>
<div id="ref-konus1939trueindex" class="csl-entry" role="listitem">
Konus, A. A. 1939. <span>“The Problem of the True Index of the Cost of Living.”</span> <em>Econometrica</em> 7 (1): 10. <a href="https://doi.org/10.2307/1906997">https://doi.org/10.2307/1906997</a>.
</div>
<div id="ref-lancaster1966consumer" class="csl-entry" role="listitem">
Lancaster, Kelvin J. 1966. <span>“A New Approach to Consumer Theory.”</span> <em>Journal of Political Economy</em> 74 (2): 132–57. <a href="https://doi.org/10.1086/259131">https://doi.org/10.1086/259131</a>.
</div>
<div id="ref-noy2023generative" class="csl-entry" role="listitem">
Noy, Shakked, and Whitney Zhang. 2023. <span>“Experimental Evidence on the Productivity Effects of Generative AI.”</span> <em>arXiv Preprint arXiv:2304.02313</em>. <a href="https://arxiv.org/pdf/2304.02313.pdf">https://arxiv.org/pdf/2304.02313.pdf</a>.
</div>
<div id="ref-oberfield2021micro" class="csl-entry" role="listitem">
Oberfield, Ezra, and Devesh Raval. 2021. <span>“Micro Data and Macro Technology.”</span> <em>Econometrica</em> 89 (2): 703–32. <a href="https://doi.org/10.2139/ssrn.2188988">https://doi.org/10.2139/ssrn.2188988</a>.
</div>
<div id="ref-smallrosen1981welfare" class="csl-entry" role="listitem">
Small, Kenneth A., and Harvey S. Rosen. 1981. <span>“Applied Welfare Economics with Discrete Choice Models.”</span> <em>Econometrica</em> 49 (1): 105. <a href="https://doi.org/10.2307/1911129">https://doi.org/10.2307/1911129</a>.
</div>
<div id="ref-stigler1961information" class="csl-entry" role="listitem">
Stigler, George J. 1961. <span>“The Economics of Information.”</span> <em>Journal of Political Economy</em> 69 (3): 213–25. <a href="https://doi.org/10.1086/258464">https://doi.org/10.1086/258464</a>.
</div>
<div id="ref-train2003discretechoice" class="csl-entry" role="listitem">
Train, Kenneth E. 2003. <em>Discrete Choice Methods with Simulation</em>. Cambridge University Press. <a href="https://doi.org/10.1017/cbo9780511753930">https://doi.org/10.1017/cbo9780511753930</a>.
</div>
<div id="ref-varian2011economic" class="csl-entry" role="listitem">
Varian, Hal. 2011. <span>“Economic Value of Google.”</span> <a href="https://dl.icdst.org/pdfs/files1/f87de5ba3c43760ebcbc2a1d90950dbc.pdf">https://dl.icdst.org/pdfs/files1/f87de5ba3c43760ebcbc2a1d90950dbc.pdf</a>.
</div>
<div id="ref-willig1976consumerssurplus" class="csl-entry" role="listitem">
Willig, Robert D. 1976. <span>“Consumer’s Surplus Without Apology.”</span> <em>American Economic Review</em> 66 (4): 589–97. <a href="https://www.semanticscholar.org/paper/745fa39279d59c6f6b14dce4a38bcf098774c2ad">https://www.semanticscholar.org/paper/745fa39279d59c6f6b14dce4a38bcf098774c2ad</a>.
</div>
</div></section><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{cunningham_(metr)2026,
  author = {Cunningham (METR), Tom},
  title = {LLM {Time-Saving,} {Demand} {Theory,} and {Task}
    {Activation}},
  date = {2026-01-26},
  url = {tecunningham.github.io/posts/2025-12-17-llm-time-saving-demand-theory-substitution.llm.html},
  langid = {en}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-cunningham_(metr)2026" class="csl-entry quarto-appendix-citeas" role="listitem">
Cunningham (METR), Tom. 2026. <span>“LLM Time-Saving, Demand Theory, and
Task Activation.”</span> January 26, 2026. <a href="https://tecunningham.github.io/posts/2025-12-17-llm-time-saving-demand-theory-substitution.llm.html">tecunningham.github.io/posts/2025-12-17-llm-time-saving-demand-theory-substitution.llm.html</a>.
</div></div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("tecunningham\.github\.io");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>