<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.357">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Tom Cunningham">
<meta name="description" content="Tom Cunningham blog">

<title>High Dimensional World | Tom Cunningham</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

<script type="text/javascript">

(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-12027453-1', 'auto');

ga('send', {
  hitType: 'pageview',
  'anonymizeIp': true,
});
</script>
<style>
   h1 {  border-bottom: 4px solid black;}
   h2 {  border-bottom: 1px solid #ccc;}
</style>
<script>window.MathJax = {
   loader: { load: ["https://cdn.jsdelivr.net/gh/sonoisa/XyJax-v3@3.0.1/build/xypic.js"]},
   tex: {packages: {'[+]': ['xypic','bm']},
         macros: {  bm: ["\\boldsymbol{#1}", 1],
                    ut: ["\\underbrace{#1}_{\\text{#2}}", 2],
                    utt: ["\\underbrace{#1}_{\\substack{\\text{#2}\\\\\\text{#3}}}", 3],
                    rsucc: ["\\rotatebox[origin=c]{#1}{$\succ$}",1],
                    bmatrix: ["\\begin{bmatrix}#1\\end{bmatrix}", 1]
                    }
   }
};
</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../styles.css">
<meta name="twitter:title" content="High Dimensional World | Tom Cunningham">
<meta name="twitter:description" content="AKA the Manifold Hypothesis &amp; Social Science">
<meta name="twitter:image" content="tecunningham.github.io/posts/images/2023-11-02-10-44-49.png">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="floating nav-fixed slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Tom Cunningham</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href=".././about.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/testingham" rel="" target=""><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/tom-cunningham-a9433/" rel="" target=""><i class="bi bi-linkedin" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://tecunningham.github.io/index.xml" rel="" target=""><i class="bi bi-rss-fill" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://scholar.google.com/citations?user=MDB_DgkAAAAJ" rel="" target="">
 <span class="menu-text">scholar</span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">High Dimensional World</h1>
            <p class="subtitle lead">AKA the Manifold Hypothesis &amp; Social Science</p>
                      </div>
  </div>
    
  
  <div class="quarto-title-meta">

      
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul class="collapse">
  <li><a href="#formal-setup" id="toc-formal-setup" class="nav-link active" data-scroll-target="#formal-setup">Formal Setup</a></li>
  <li><a href="#implications-of-high-dimensional-signals" id="toc-implications-of-high-dimensional-signals" class="nav-link" data-scroll-target="#implications-of-high-dimensional-signals">Implications of High-Dimensional Signals</a></li>
  <li><a href="#model-with-high-dimensional-signal" id="toc-model-with-high-dimensional-signal" class="nav-link" data-scroll-target="#model-with-high-dimensional-signal">Model with High-Dimensional Signal</a></li>
  <li><a href="#application-to-perception" id="toc-application-to-perception" class="nav-link" data-scroll-target="#application-to-perception">Application to Perception</a></li>
  <li><a href="#application-to-recommendation" id="toc-application-to-recommendation" class="nav-link" data-scroll-target="#application-to-recommendation">Application to Recommendation</a></li>
  <li><a href="#models-typically-assume-low-dimensional-signal" id="toc-models-typically-assume-low-dimensional-signal" class="nav-link" data-scroll-target="#models-typically-assume-low-dimensional-signal">Models Typically Assume Low-Dimensional Signal</a></li>
  <li><a href="#short-version" id="toc-short-version" class="nav-link" data-scroll-target="#short-version">Short Version</a></li>
  <li><a href="#misc" id="toc-misc" class="nav-link" data-scroll-target="#misc">Misc</a></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
    </div>
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full" id="quarto-document-content">




<style>
   h1 {  border-bottom: 4px solid black; }
   h2 {  border-bottom: 1px solid gray; padding-bottom: 0px; color: black; }
</style>
<p><strong>TLDR: in most cases people aren’t limited by the <em>quantity</em> of information available, but by the <em>interpretation</em> of that information.</strong></p>
<p>Most signals we deal with are high-dimensional (sensory stimuli, images, text, audio), but they can be represented as coming from a low-dimensional space. People have imperfect knowledge of the mapping, i.e.&nbsp;how to recover the low-dimensional structure from the high-dimensional. (the “Manifold hypothesis” – <span class="citation" data-cites="bengio2013representation">Bengio, Courville, and Vincent (<a href="#ref-bengio2013representation" role="doc-biblioref">2013</a>)</span> ).</p>
<p><strong>Observations about high dimensionality of the world.</strong></p>
<ol type="1">
<li><em>Most signals are redundant.</em> If you remove a word, or a few pixels, or a snippet of audio, then comprehension is hardly affected, and the missing data can be reconstructed with high confidence. (<a href="https://en.wikipedia.org/wiki/Markov_blanket">Markov blanket</a>)</li>
<li><em>It’s been hard to teach computers high-dimensional problems.</em> Computers could beat humans at linear regression since the 1960s, but it took them another 50 years to perform well with high-dimensional signals (text, audio, images).</li>
<li><em>Unsupervised learning is valuable.</em> Unsupervised learning helps us do dimensionality reduction, &amp; so generalizes to other areas. Likewise cross-training is valuable: learning to predict cats makes us better at predicting dogs.</li>
<li><em>Perception is dimensionality reduction.</em> Processing of sensory data recovers <span class="math inline">\(\hat{v}_1,\hat{v}_2\)</span> from <span class="math inline">\(x_1,\ldots,x_M\)</span>.</li>
</ol>
<p><strong>Implications.</strong></p>
<ol type="1">
<li><em>Implication: experience is more valuable than bandwidth.</em> Growth in <span class="math inline">\(n\)</span> is more valuable than growth in <span class="math inline">\(p\)</span>.</li>
</ol>

<div class="no-row-height column-margin column-container"><div class="">
<p><span class="math display">\[
   \xymatrix@R=1em@C=.5em{
      \txt{low-\\dimensional\\state} &amp; \txt{high-\\dimensional\\signals} &amp; \txt{low-\\dimensional\\representation} \\
               &amp; \boxed{x_{1}}\ar[dddr]\ar[dr] \\
      v_1\ar@{-}[ur]\ar\ar@{-}[r]\ar\ar@{-}[dddr]\ar\ar@{-}[ddr]
               &amp; \boxed{x_{2}}\ar[ddr]\ar[r]
                           &amp; \hat{v}_1\\
      {\tiny\vdots} &amp; {\tiny\vdots} &amp; {\tiny\vdots} \\
      v_q\ar@{-}[uuur]\ar@{-}[uur]\ar@{-}[r]\ar@{-}[dr]
               &amp; \boxed{x_{p-1}}\ar[r]\ar[uur]
                           &amp; \hat{v}_q\\
               &amp; \boxed{x_{p}}\ar[ur]\ar[uuur]}
\]</span> Note that the connections between <span class="math inline">\(\bm{v}\)</span> and <span class="math inline">\(\bm{x}\)</span> are not directional (they don’t have arrowheads), the latent state doesn’t necessarily cause the signal, they are jointly determined. However the signals do cause the representation (<span class="math inline">\(\hat{\bm{v}}\)</span>).</p>
</div></div><section id="formal-setup" class="level1">
<h1>Formal Setup</h1>
<p><span class="math display">\[x = A v + e\]</span></p>
<p><span class="math display">\[\begin{aligned}
   x &amp;\in \mathbb{R}^p &amp;&amp;  \text{observation (image, text, sound)}\\
   v &amp;\in \mathbb{R}^q &amp;&amp; \text{state (objects, meaning, words)}\\
   p &amp;\gg q
      &amp;&amp; \text{(observations higher dimensionality than state)}\\
   A &amp;\in \mathbb{R}^{p\times q} &amp;&amp; \text{mapping} \\
   e &amp;\in \mathbb{R}^q &amp;&amp; \text{noise}
\end{aligned}
\]</span></p>
</section>
<section id="implications-of-high-dimensional-signals" class="level1">
<h1>Implications of High-Dimensional Signals</h1>
<ol type="1">
<li><strong>Redundancy.</strong> If one part of a signal is removed then it’s possible to reconstruct it from the rest of the signal.</li>
</ol>
</section>
<section id="model-with-high-dimensional-signal" class="level1 page-columns page-full">
<h1>Model with High-Dimensional Signal</h1>
<p><span class="math display">\[x = Av\]</span></p>
<div class="page-columns page-full"><p>You want to know <span class="math inline">\(E[v_1|x]\)</span>, but you don’t know <span class="math inline">\(A\)</span>. <a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p><div class="no-row-height column-margin column-container"><li id="fn1"><p><sup>1</sup>&nbsp;Related: solving a least-squares model when over-determined or under-determined - <a href="https://twitter.com/gabrielpeyre/status/1779736411366924549/photo/1">tweet</a>, <a href="https://en.wikipedia.org/wiki/Least_squares">Wikipedia</a></p></li></div></div>
<p>The model from imitation. There are a set of <span class="math inline">\(n\)</span> questions, each is a vector of <span class="math inline">\(p\)</span> attributes, this is not stochastic. Each question has a scalar answer <span class="math inline">\(a^i\)</span>, and you infer weights given <span class="math inline">\(\bm{a}=Q\bm{w}\)</span>.</p>
<p><span class="math display">\[\begin{aligned}
   \bm{a} &amp;=Q\bm{w} \\
   \ut{\bmatrix{a^1 \\ \vdots \\ a^n}}{answers}
      &amp;= \ut{\bmatrix{q_1^1 w_1 + \ldots q_p^1w_p \\ \vdots \\ q_1^n w_1 + \ldots q_p^nw_p}}{questions} \\
   \hat{\bm{w}} &amp;= Q'(QQ')^{-1}\bm{a}
\end{aligned}
\]</span></p>
</section>
<section id="application-to-perception" class="level1">
<h1>Application to Perception</h1>
<p><strong>Perception wrongly treated as compression.</strong> It’s clear in many cases of perception that the signal is high-dimensional, yet there are some weird anomalies. A common model is that the signal is <em>compressed</em> and then reconstructed. E.g. Sim, Woodford, compressed sensing, etc.</p>
<p>The <em>compression</em> problem has some subtle differences from the <em>inference</em> problem.</p>
</section>
<section id="application-to-recommendation" class="level1">
<h1>Application to Recommendation</h1>
<p><strong>In short.</strong></p>
<ol type="1">
<li><p><strong>We want to predict a person’s response to an item.</strong> The item could be a post, a song, a video, an advertisement, a product. The person’s response could be clicking, purchasing, upvoting, or labelling as toxic.</p></li>
<li><p><strong>Model: low-dimensional semantics.</strong> I will state a simple model of human judgment and then try to describe some of the facts we observe about recommendation. Assume that the content of each item (pixels, characters, etc.) can be represented in a low-dimensional space, the “semantics.” Each person’s response is fully determined by the semantics, though different people have different weights.</p></li>
<li><p><strong>World without computers.</strong> There are many practical decisions people make about others’ judgments: will people like this concerto? how many copies is this book likely to sell? is this painting obscene? Then we can use a mixture of our own judgments and simple statistics about others judgments – e.g.&nbsp;what are the best-selling books, what are the most-beloved paintings.</p></li>
<li><p><strong>Very small computers.</strong> Suppose our computers can digitize data about preference but not the full content of the items themselves. Then we can do collaborative filtering to predict preference, irrespective of the content.</p></li>
<li><p><strong>Small computers.</strong> Suppose we now have access to the full digital representation of each piece of content. Somewhat surprisingly this information is not very useful. In most cases it is very difficult to extract .</p></li>
<li><p><strong>Large computers.</strong> Now suppose we have computers that are <em>large</em> such that they can extract the semantics of each item with high accuracy.</p>
<ul>
<li><em>Prediction:</em> the content discovery problem (AKA cold start) is solved.</li>
<li><em>Prediction:</em> we will start synthesizing content. (However a classifier that has high accuracy on its training set could perform badly off-distribution, and thus do badly in synthesizing content).</li>
</ul></li>
</ol>
<hr>
<p>Suppose our raw data looks like this: <span class="math display">\[\begin{aligned}
      \bm{x}^j    &amp;  &amp;&amp; \text{high dimensional input}\\
      i^j  &amp;\in \mathbb{N}
         &amp;&amp; \text{identity of rater}\\
      R^j  &amp;\in \mathbb{R}
         &amp;&amp; \text{rating}
   \end{aligned}
   \]</span></p>
<hr>
<p><strong>Application to search:</strong> History of search engines:</p>
<ol type="1">
<li>Text match between query and document.</li>
<li></li>
</ol>
</section>
<section id="models-typically-assume-low-dimensional-signal" class="level1">
<h1>Models Typically Assume Low-Dimensional Signal</h1>
<p><strong>Three dimensions of interest, n, p, &amp; q.</strong></p>
<p><span class="math display">\[\begin{aligned}
   n  &amp;= \text{sample size}\\
   p  &amp;= \text{dimensionality of signal}\\
   q  &amp;= \text{dimensionality of state}
\end{aligned}
\]</span></p>
<p><strong>Typically we model problems as <span class="math inline">\(n&gt;p\)</span> and <span class="math inline">\(q&gt;p\)</span>.</strong></p>
<ul>
<li><strong>Statistics: <span class="math inline">\(n&gt;p\)</span></strong></li>
<li><strong>Economics: <span class="math inline">\(n=\infty\)</span>, <span class="math inline">\(q&gt;p\)</span>.</strong></li>
<li><strong>Signal extraction: <span class="math inline">\(n=\infty\)</span>, <span class="math inline">\(q&gt;p\)</span>.</strong></li>
<li><strong>Perception: (…).</strong></li>
</ul>
<p><span class="math display">\[\xymatrix@R=1em@C=.5em{
   \txt{high-\\dimensional\\state} &amp; \txt{low-\\dimensional\\signal} &amp; \txt{high-\\dimensional\\representation} \\
   v_1\ar[dr] &amp; &amp; \hat{v}_1 \\
         &amp; \boxed{x_1}\ar[ur]\ar[dr] &amp; \\
   v_2\ar[ur] &amp; &amp; \hat{v}_2}
\]</span></p>
<p><strong>Applied to statistics.</strong> The canonical statistical inference problem is where the number of observations is larger than the number of features (<span class="math inline">\(n&gt;p\)</span>), e.g.&nbsp;linear regression is only well-defined when <span class="math inline">\(n&gt;p\)</span>.</p>
<p><strong>Applied to economics.</strong> Most models of inference in economics have the agent receives a signal that is not fully revealing of the state because it has lower cardinality than the state (e.g.&nbsp;a binary signal), or because there is noise (then you can think of the noise as part of the state, and so the state is higher-dimensional than the signal). E.g.:</p>
<ul>
<li>Estimating the productivity of an employee from their education.</li>
<li>Estimating demand conditions from sales.</li>
<li>Estimate the quality of a product from a coarse signal.</li>
</ul>
<p>Yet in practical situations information sets often <em>do not</em> seem to be discrete or univariate, instead they’re enormously rich: we have the newspaper, we have millions of datapoints about employees, we have the internet.</p>
<p><strong>Related literature in economics.</strong></p>
<ul>
<li><em>Rational inattention.</em> (sims/caplin/woodford) is just about compressing a high-dimensional signal to fit it through a pipeline, not about ignorance of the distribution, or making inferences from it.</li>
<li><em>Learning in games.</em> Various people have written about Bayesian agents slowly learning the state of the world, e.g.&nbsp;Fudenberg and Levine on learning in games, though I think those models are typically low-dimensional.</li>
<li><em>Misspecified models.</em> (Alwyn Young, Matt Rabin) – but this is assuming it’s low-dimensional model. Maybe people have well-specified but imperfectly calibrated models.</li>
<li><em>Aumann, Agreeing to disagree.</em> Presumably the speed of convergence is proportional to complexity of the world models. If so then high-dimensional models could rationalize the substantial equilibrium variance in beliefs. Might be able to formalize this in Gaussian model.</li>
<li><em>Rugged landscape.</em> Steven Callender has some papers, e.g.&nbsp;“Innovation and Competition on a Rugged Technological Landscape”, e.g.&nbsp;see this graph: <img src="images/2023-11-02-10-44-49.png" class="img-fluid"> <img src="images/2024-04-13-06-23-19.png" class="img-fluid"></li>
<li><em>Savage: <em>small world</em> problem.</em></li>
</ul>
</section>
<section id="short-version" class="level1">
<h1>Short Version</h1>
<p>Here’s a big-picture take on econ modeling.</p>
<p>In short: we usually model agents making inferences given a low-dimensional signal (n&gt;p), but maybe the more common decision problem is high dimensional (n&lt;p).</p>
<p>Motivated by this observation: computers have been able to beat humans at statistical inference since the 1960s for low-dimensional problems, e.g.&nbsp;linear regression (n&gt;p). But it took another 50 years for computers to learn how to do high-dimensional problems (n&lt;p), e.g.&nbsp;to interpret text, images, sound. An implication is that humans must have some incredibly powerful modules for interpreting high-dimensional data (AKA finding latent structures), &amp; perhaps modeling that process is important for understanding communication.</p>
<p>An additional observation: when we model decision-making under uncertainty we usually assume the problem is low-dimensional (n&gt;p). We assume people already know the joint distribution of everything (rational expectations), and their signal is coarse relative to the state of the world, i.e.&nbsp;they are constrained on p.&nbsp;But in reality signals don’t seem so coarse: people read the newspaper, they observe rich details about each others’ behaviour, they have the ability to examine products carefully. Maybe instead the problem is that they have rich signals but they don’t know how to interpret them, i.e.&nbsp;maybe the more common economic inference problem is high-dimensional (p&lt;n).</p>
<p>Some implications:</p>
<ul>
<li><p>In this world you can’t reduce economic decision-making to a few variables: consumers make judgments using a <em>gestalt</em> from rich data, so predicting behavior just using price and quality will have limited explanatory power (similarly, businesses don’t just use interest rate &amp; unemployment to form expectations).</p></li>
<li><p>The value of more experience (doubling <span class="math inline">\(n\)</span>) is higher than the value of a richer signal (doubling <span class="math inline">\(p\)</span>).</p></li>
<li><p>Unsupervised learning is valuable, it helps you learn the latent structure of the world, thus agents with experience in one problem will be better at unrelated problems, e.g.&nbsp;judging quality or forecasting economic conditions, because they have a stronger grasp of the latent structure of the world.</p></li>
</ul>
<p>I know of a couple of things that are superficially similar but I think don’t quite capture this: rational inattention (sims/caplin/woodford) is just about compressing a high-dimensional signal, not about ignorance of the distribution; various people have written about Bayesian agents slowly learning the state of the world (e.g.&nbsp;Fudenberg and Levine on learning in games) but I think those models are low-dimensional.</p>
</section>
<section id="misc" class="level1">
<h1>Misc</h1>
<p><strong>Rob Donelly comments:</strong></p>
<blockquote class="blockquote">
<p>“I agree with your claim that most of economic modeling has generally focused on restricting the agents uncertainty to a low dimensional set of signals, but I wonder how much of that is limitation of what is tractable in a theory model (and similar constraints for an empirical model).</p>
</blockquote>
<blockquote class="blockquote">
<p>“For example Frank Knight had his paper about unknown/unquantifiable risks back in 1921, but I don’t think there has been much progress on good approaches for modeling this. It’s reasonably challenging to have a model of uncertainty even with a single dimensional uncertainty (e.g.&nbsp;2001 Nobel prize for Akerlof, Spence, Stiglitz).</p>
</blockquote>
<blockquote class="blockquote">
<p>“In empirical models it’s especially difficult to try to learn what someone’s beliefs/expectations are, since we almost never have ground truth data on beliefs, so instead we have to try to infer those beliefs based on decisions. Usually that is only possible under very strong modeling assumptions about what people know and what they are uncertain about. At least in the consumer search models that I am most familiar with, that usually ends up with a model where consumers have accurate expectations/beliefs about nearly everything except for a very small number of things they are learning/updating about.</p>
</blockquote>
<blockquote class="blockquote">
<p>“It seems like the other extreme is a purely behavioral model e.g.&nbsp;that takes the entire lifetime history of everything a person has seen and done, and predicts what’ll they’ll do/choose next.</p>
</blockquote>
<blockquote class="blockquote">
<p>“A slightly different context, Athey has the paper that tries to predict for timber auctions what will happen when they move from a open bid to sealed bid auction. There she showed you can predict how the buyers will respond to the new auction format by assuming their prior behavior was generated under rational expectations + a single dimensional type</p>
</blockquote>
<blockquote class="blockquote">
<p>“It’s unclear to me under what circumstances you would trust a purely behaviorally grounded model to be able to extrapolate to new circumstances that are very different than the data you trained on</p>
</blockquote>
<p><strong>Sean Taylor:</strong></p>
<blockquote class="blockquote">
<p>“One concept I like for this is a”world model” which the intelligent agent uses to make predictions and choose actions. We are choosing models and parameters which are analytically convenient or which make it possible to identify the world model from data, but it’s a much more general concept … I believe it is reinforcement learning terminology.</p>
</blockquote>
<p><strong>Chemistry predicting properties of substances from atomic structure.</strong> It’s better to predict behaviour from behaviour of other macrophenomon, than to predict from microstructure.</p>
<p><strong>Application: forecasting.</strong> Given the same information (the same p) people have different experience (different n), and so substantially different ability to forecast. In addition, in many cases people are more constrained on having more history (base rates) than on knowing more about this particular situation.</p>
<p>Also note that good forecasters can way outperform low-dimensional statistical models, because the good forecasters have latent model of the world.</p>
<p><strong>The mind and the computer are just reflections of the world.</strong> We can study the world, the mind, and the computer. But we will find the same patterns reflected in all three.</p>
<p><strong>High-dimensional problems are the ones that used to be uniquely the domain of humans.</strong></p>
<p><em>Application to perception:</em></p>
<ul>
<li>Woodford will talk about how there’s too much information, but then sets it up as a problem of <em>compressing</em> the information to fit through a pipeline, rather than a problem of interpreting the information.</li>
</ul>
<ol type="1">
<li><p><strong>Humans have an uncanny ability to interpret high-dimensional data (n&lt;&lt;p).</strong> Computers have been able to beat humans at low-dimensional prediction problems for 50 years. But only in the last 10 years have computers figured out how to interpret images, text, sound.</p></li>
<li><p><strong>Typical econ approach: you know distribution, form expectation E[v|x].</strong> But</p></li>
</ol>
<p><em>A model of high-dimensional inference.</em></p>
<ul>
<li>You get signal x=Av, where A is unknown.</li>
<li>You have x_1,…,x_{p-1} and want to predict x_p.</li>
<li>You have n prior experiences of x.</li>
</ul>
<p><em>Applied to consumer choice:</em> purchase decision is <em>gestalt</em>, not just price and unidimensional quality.</p>
<p><strong>Data generating process for high dimensional</strong></p>
<p>We want a generate model such that:</p>
<ol type="1">
<li>Low dimensional state generates high-dimensional signal.</li>
<li>The state <em>cannot</em> be recovered with a simple algorithm (linear, nearest neighbor). You need something hierarchical like a neural net.</li>
</ol>
<p>Examples:</p>
<ul>
<li><em>2D view of 3D scene.</em> this has both (i) big interactions, e.g.&nbsp;green object looks cyan when the light is blue; (ii) complex environmental statistics – you need to gradually learn priors.</li>
</ul>



</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" role="list">
<div id="ref-bengio2013representation" class="csl-entry" role="listitem">
Bengio, Yoshua, Aaron Courville, and Pascal Vincent. 2013. <span>“Representation Learning: A Review and New Perspectives.”</span> <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em> 35 (8): 1798–828.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>