<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.25">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Tom Cunningham">
<meta name="description" content="Tom Cunningham blog">

<title>&lt;strong&gt;?meta:title&lt;/strong&gt; | Tom Cunningham – Tom Cunningham</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-7b89279ff1a6dce999919e0e67d4d9ec.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-d5e7c60e6424aa6ccf163f01508596ce.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

<script type="text/javascript">

(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-12027453-1', 'auto');

ga('send', {
  hitType: 'pageview',
  'anonymizeIp': true,
});
</script>
<script>window.MathJax = {
   loader: { load: ["https://cdn.jsdelivr.net/gh/sonoisa/XyJax-v3@3.0.1/build/xypic.js"]},
   tex: {packages: {'[+]': ['xypic','bm']},
         macros: {  bm: ["\\boldsymbol{#1}", 1],
                    ut: ["\\underbrace{#1}_{\\text{#2}}", 2],
                    utt: ["\\underbrace{#1}_{\\substack{\\text{#2}\\\\\\text{#3}}}", 3] }
   }
};
</script>
<style>
   h1 {  border-bottom: 8px solid #557;}
   h2 {  border-bottom: 1px solid #ccc;}
   .greyproof {
      background-color: #f5f5f5;
      padding: 1em;
      margin: 1em 0;
      border-radius: 4px;
   }
</style>
<meta name="twitter:title" content="?meta:title | Tom Cunningham">
<meta name="twitter:image" content="tecunningham.github.io/posts/images/2024-11-11-14-45-57.png">
<meta name="twitter:image-height" content="564">
<meta name="twitter:image-width" content="758">
<meta name="twitter:card" content="summary_large_image">
</head><body class="nav-fixed quarto-light">\newenvironment{figure*}{\begin{figure}}{\end{figure}}
\newenvironment{table*}{\begin{table}}{\end{table}}
\usepackage[english]{babel}
\usepackage{morewrites}
\newwrite\stuff
\usepackage{enumitem}
\setlist[description]{style=multiline,leftmargin=3cm,itemsep=20pt}
\usetheme{boxes}
\useoutertheme{metropolis}
\useinnertheme{circles}
\usecolortheme{dove}
\usefonttheme{serif}
\AtBeginDocument{\fontsize{8}{8}\selectfont}
\setbeamerfont{footnote}{size=\tiny}
\setbeamercolor{block title example}{bg=orange,fg=white}
\setbeamercolor{block body example}{bg=orange!20,fg=black}
\definecolor{fbblue}{RGB}{70,111,170}
\definecolor{fblightblue}{RGB}{230,234,240}
\setbeamercolor{frametitle}{bg=black,fg=white}
\setbeamercolor{framesubtitle}{bg=black,fg=white}
\setbeamercolor{section in head/foot}{bg=black,fg=white}
\setbeamercolor{subsection in head/foot}{bg=black,fg=white}
\makeatletter\newcommand{\@minipagerestore}{\setlength{\parskip}{1em}}\makeatother
<meta name="quarto:status" content="draft">


<link rel="stylesheet" href="../styles.css">




<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner"><div id="quarto-draft-alert" class="alert alert-warning"><i class="bi bi-pencil-square"></i>Draft</div>
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../index.html" class="navbar-brand navbar-brand-logo">
    </a>
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Tom Cunningham</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href=".././about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/testingham"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/tom-cunningham-a9433/"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://tecunningham.github.io/index.xml"> <i class="bi bi-rss-fill" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://scholar.google.com/citations?user=MDB_DgkAAAAJ"> 
<span class="menu-text">scholar</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block"></header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        
    <div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="2024-11-11-meta-slides-effect-of-ai-on-communication.pdf"><i class="bi bi-file-pdf"></i>Beamer</a></li></ul></div></div>
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full" id="quarto-document-content">




<section id="section" class="level1">
<h1></h1>
<p><img src="images/2024-11-11-14-45-57.png" class="img-fluid"></p>
<dl>
<dt>Hi.</dt>
<dd>
It’s lovely to be back around Facebook people :).
</dd>
</dl>
</section>
<section id="advertisements" class="level1">
<h1>Advertisements</h1>
<dl>
<dt>Paper</dt>
<dd>
<p>“<a href="https://arxiv.org/abs/2402.06831">What We Know About Using Non-Engagement Signals in Content Ranking</a>”</p>
</dd>
</dl>
<p><br></p>
<dl>
<dt>Blog post</dt>
<dd>
<p>“<a href="https://tecunningham.github.io/posts/2023-01-31-social-media-suspensions-data.html">Social Media Suspensions of Prominent Accounts</a>”</p>
</dd>
<dd>
<img src="images/2024-11-11-14-54-12.png" class="img-fluid" style="width:5cm">
</dd>
</dl>
<p><br></p>
<dl>
<dt>Blog post</dt>
<dd>
“<a href="https://tecunningham.github.io/posts/2023-07-27-meta-2020-elections-experiments.html">How Much has Social Media affected Polarization?</a>”
</dd>
<dd>
<img src="images/2024-11-11-14-57-56.png" class="img-fluid" style="width:5cm">
</dd>
<dt>OpenAI work</dt>
<dd>
The economic impact of AI.
</dd>
</dl>
</section>
<section id="today" class="level1">
<h1>Today</h1>
<dl>
<dt>What effect will AI have on content moderation and communication?</dt>
<dd>
<p>I will talk about a dozen different aspects.</p>
</dd>
</dl>
<dl>
<dt>I will talk through some predictions.</dt>
<dd>
<p>I add as much evidence and argument as I can, but often I will say “it seems reasonable to expect that…”</p>
</dd>
<dd>
Not sure how persuasive but I feel it’s worth making concrete predictions.
</dd>
</dl>
</section>
<section id="background-on-ai" class="level1">
<h1>Background on AI</h1>
<dl>
<dt>AI is growing fast.</dt>
<dd>
<img src="images/2023-09-19-09-55-57.png" class="img-fluid" width="300">
</dd>
<dt>AI can classify, but it can also synthesize.</dt>
<dd>
AI classification can approach human levels. But AI can also synthesize new content, beyond the capabilities of any human.
</dd>
</dl>
</section>
<section id="an-arms-race" class="level1">
<h1>An Arms Race</h1>
<dl>
<dt>We will be discussing adversarial equilibrium problems.</dt>
<dd>
<p>Content moderation, spam filtering, misinformation. New models are available to both sides, &amp; we want to know the equilibrium impact.</p>
</dd>
<dt>An “internal” property of a message is a function solely of the content.</dt>
<dd>
<p>E.g. whether an image contains nudity, whether text contains hate speech, whether a joke is funny. These properties hold independent of any outside facts. AI classifiers are rapidly approaching human-level accuracy for these properties and this means that platforms (and governments) will be able to near-perfectly filter by internal properties even if content-producers have access to the same technology.</p>
</dd>
<dt>An “external” property of a message depends on some fact outside the message’s content.</dt>
<dd>
<p>E.g. whether an image was computer-generated, whether a claim is true, whether a message came from a specific person. Platforms will get better at predicting external properties but they will be outpaced by motivated actors who can manipulate fakes until they become indistinguishable from genuine articles, and able to manipulate lies so they’re indistinguishable from the truth.</p>
</dd>
</dl>
</section>
<section id="working-on-formalizing-these-arguments" class="level1">
<h1>Working on Formalizing these Arguments</h1>
<dl>
<dt>Working on formalizing these arguments.</dt>
<dd>
Have been working with Ines Moreno de Barreda and Dan Quigley to try to make these more formal. I feel it’s an under-studied area.
</dd>
</dl>
<p><img src="images/2024-11-12-09-39-14.png" class="img-fluid" width="300"></p>
</section>
<section id="the-prevalence-of-policy-violating-content-will-decline" class="level1">
<h1>The Prevalence of Policy-Violating Content Will Decline</h1>
<dl>
<dt>All large internet platforms use automated systems to detect policy-violating content.</dt>
<dd>
<p>All major platforms ban or suppress various types of content, e.g.&nbsp;hate speech, incitement to violence, nudity, graphic content. It has not been practical to have a human review each message because the platforms have a high volume of messages being sent with low latency. However automated systems have always been used: early systems simply checked for the appearance of prohibited words or matched against media databases, later systems used classifiers trained on human labels. See a brief history of automated content moderation <a href="https://tecunningham.github.io/posts/2023-11-18-history-automated-text-moderation.html">here</a>.</p>
</dd>
<dt>Simple classifiers have high offline accuracy.</dt>
<dd>
<p>Simple classifiers which just look for the appearance of specific words are often useful, e.g.&nbsp;certain words and phrases are highly predictive of whether text would be labelled as “toxic” or “hate speech.” However this method has many false positives (<span class="citation" data-cites="chen2022profanity">Chen (<a href="#ref-chen2022profanity" role="doc-biblioref">2022</a>)</span>) and false negatives (<span class="citation" data-cites="heiner2022toxic">Heiner (<a href="#ref-heiner2022toxic" role="doc-biblioref">2022</a>)</span>).</p>
</dd>
</dl>
</section>
<section id="section-1" class="level1">
<h1></h1>
<dl>
<dt>Simple classifiers are easily evaded.</dt>
<dd>
<p>It is typically easy to alter a violating message such that humans still think it is violating but the classifier does not. As a consequence the accuracy of these classifiers looks much higher offline than online, as users take steps to evade them.</p>
<ul>
<li><span class="citation" data-cites="grondahl2018need">Gröndahl et al. (<a href="#ref-grondahl2018need" role="doc-biblioref">2018</a>)</span> note that hate speech detectors can easily be fooled if you “insert typos, change word boundaries or add innocuous words.”</li>
<li><span class="citation" data-cites="han2020fortifying">Han and Tsvetkov (<a href="#ref-han2020fortifying" role="doc-biblioref">2020</a>)</span> note that simple models are poor at detecting “veiled toxicity” which they define as including “codewords, novel forms of offense, and subtle and often unintentional manifestations of social bias such as microaggressions and condescension.”</li>
<li><span class="citation" data-cites="lees2021capturing">A. Lees et al. (<a href="#ref-lees2021capturing" role="doc-biblioref">2021</a>)</span> note that simple models are poor at detecting “covert toxicity” which includes “types of toxicity that may not be immediately obvious. Covertly toxic comments may use obfuscation, code words, suggestive emojis, dark humor, or sarcasm …[and] [m]icroaggressions.” These papers evaluate models trained to identify <em>context-independent</em> toxicity, i.e.&nbsp;where the ground truth is human rating of the text alone without additional information on context or audience.</li>
</ul>
</dd>
<dt>LLM-based classifiers are approaching human levels of performance.</dt>
<dd>
<p>In August 2023 OpenAI described using GPT-4 as a content labeler (<span class="citation" data-cites="weng2023gpt4moderation">Weng, Goel, and Vallone (<a href="#ref-weng2023gpt4moderation" role="doc-biblioref">2023</a>)</span>) and said “[l]abeling quality by GPT-4 is similar to human moderators with light training … [h]owever, both are still overperformed by experienced, well-trained human moderators.”</p>
</dd>
</dl>
</section>
<section id="section-2" class="level1 page-columns page-full">
<h1></h1>
<dl class="page-columns page-full">
<dt>LLM-based classifiers handle adversarial cases well.</dt>
<dd class="page-columns page-full">
<p>Google’s 2022 generation of text moderation models, which use transformer-based LLMs, are able to correctly classify many types of adversarial messages which are designed to evade simpler classifiers. <span class="citation" data-cites="whitlocklees2022perspective">A. W. Lees et al. (<a href="#ref-whitlocklees2022perspective" role="doc-biblioref">2022</a>)</span> say their classifier performs well against “code-switching, covert toxicity, emoji-based hate, human-readable obfuscation, [and] distribution shift.” Google’s 2023 generation spam classifier uses an embedding that is “robust against typos and character-level adversarial attacks” (<span class="citation" data-cites="bursztein2023retvec">Bursztein et al. (<a href="#ref-bursztein2023retvec" role="doc-biblioref">2023</a>)</span>).<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;Arnaud Norman <a href="https://bulkninja.notion.site/Email-Obfuscation-Rendered-almost-Ineffective-Against-ChatGPT-728fba1b948d42c6b8dfa73cb64984e4">writes about</a> how algorithms to scrape email addresses are often easy to evade, by adding special characters or other obfuscations, but that ChatGPT can straight-forwardly decode most such obfuscations.</p></div></div></dd>
<dt>Better classifiers will lower prevalence even if they are available to adversaries.</dt>
<dd>
<p>Suppose an adversarial content-producer had access to the same classifier that was used by the platform. The produced could keep testing different variants of a violating post until they found a variant that was truly violating, but not identified as violating by the classifier, i.e.&nbsp;a false negative. However as the platform’s model becomes more accurate there will be fewer possible false positives, and so the task becomes relatively more time-consuming for the adversary, and thus we should expect prevalence to decline.</p>
</dd>
</dl>
</section>
<section id="section-3" class="level1 page-columns page-full">
<h1></h1>
<dl class="page-columns page-full">
<dt>The prevalence of policy-violating content has declined dramatically.</dt>
<dd class="page-columns page-full">
<p>Meta reports that the prevalence of nudity, bullying, hate speech, and graphic content each declined by a factor of between 2 and 5 between 2017 and 2022, and that the share of identified-violating content that was first identified by an ML model (“proactive rate”) is approaching 100% for most categories. I think much of this decline can be attributed to improvements in the quality of classifiers.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> Mark Zuckerberg has been making predictions for a long time that human raters could be substituted with AI. Although he was over-optimistic about the pace, I think he has been largely correct, e.g.&nbsp;in late 2018 he said “through the end of 2019, we expect to have trained our systems to proactively detect the vast majority of problematic content.”<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></p>
<div class="no-row-height column-margin column-container"><div id="fn2"><p><sup>2</sup>&nbsp;It is important to remember that the “proactive rate” is the share of <em>detected</em> content that is detected by AI, the share of <em>violating</em> content that is detected by AI will certainly be significantly lower but is not generally reported. See Meta’s <a href="https://transparency.fb.com/data/community-standards-enforcement/">Community Standards report</a> and <a href="http://tecunningham.github.io/2023-01-31-social-media-suspensions-data.html#meta-facebook-instagram">my visualization of this data</a>.</p></div><div id="fn3"><p><sup>3</sup>&nbsp;Zuckerberg, <a href="https://www.facebook.com/notes/751449002072082/">“A Blueprint for Content Governance and Enforcement”</a></p></div></div></dd>
</dl>
<p><img src="./2023-01-31-social-media-suspensions-data_files/figure-html/unnamed-chunk-28-1.png" class="img-fluid"></p>
</section>
<section id="section-4" class="level1">
<h1></h1>
<dl>
<dt>Employment of human moderators will likely decline.</dt>
<dd>
<p>As computer accuracy improves fewer messages will need to be escalated for human review, additionally fewer humans will be needed to label training data.</p>
</dd>
<dt>This prediction also applies to government monitoring and censorship.</dt>
<dd>
<p>Many governments use some kind of automated scanning tools to intercept or censor messages based on their content, e.g.&nbsp;the US’s NSA and Cybserspace Administration of China. Better AI will allow these agencies to classify every post with reliability as high as if they had a human read each one, thus we should expect obfuscation will become a much less-effective workaround for censorship.</p>
</dd>
</dl>
</section>
<section id="section-5" class="level1 page-columns page-full">
<h1></h1>
<dl class="page-columns page-full">
<dt>This prediction would fail if there were hard limits on the performance of AI.</dt>
<dd>
<p>It’s conceivable that there are ways of obfuscating content that will remain difficult for an AI to identify for a long time. However even if LLMs cannot identify violating content in real-time it seems likely they could catch up quickly. Suppose humans invent new types of obfuscation, e.g.&nbsp;misspelling words in a particular way. An LLM which is continually trained on human-labeled samples could likely learn the pattern and thus force humans to continually adopt new patterns.</p>
</dd>
<dt>Prevalence will never decline to exactly zero because it’s inherently noisy.</dt>
<dd class="page-columns page-full">
<p>An AI model can never perfectly predict human-rater evaluation because humans are themselves noisy: there is both between-rater variation and within-rater variation in labelling for any given piece of content. Thus if the ground truth is human judgment then even an infallible classifier could not be used to drive prevalence all the way to zero.<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a></p>
<div class="no-row-height column-margin column-container"><div id="fn4"><p><sup>4</sup>&nbsp;Strictly speaking: this will be true if no content has a probability of being labelled as positive by a human of exactly zero.</p></div></div></dd>
</dl>
</section>
<section id="the-prevalence-of-context-specific-violations-will-increase" class="level1">
<h1>The Prevalence of <em>Context-Specific</em> Violations Will Increase</h1>
<dl>
<dt>Some messages have a violating significance only to their intended audience.</dt>
<dd>
<p>We can define a message as violating in one of two ways: (1) has a violating significance to the average person (average citizen or average user), or (2) has a violating significance to the intended audience of that message.</p>
</dd>
<dd>
<p>I will define a “contextual violation” as a message that is violating to its intended audience but not to the average person. This is stronger than just having a double meaning where both meanings are clear to all audiences. I am specifically talking about messages which are interpreted in distinct ways by different audiences. Of course contextual violations are often unstable, over time the average person will often learn the contextual meaning.</p>
</dd>
</dl>
</section>
<section id="section-6" class="level1 page-columns page-full">
<h1></h1>
<dl class="page-columns page-full">
<dt>Many messages on social media use contextual violations.</dt>
<dd class="page-columns page-full">
<ul>
<li>Saying “globalist” when your audience understands it to mean “jewish”<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a></li>
</ul>
<div class="no-row-height column-margin column-container"><div id="fn5"><p><sup>5</sup>&nbsp;A related phenomena is people using selective truths to give an impression that is false.</p></div></div></dd>
<dd>
<ul>
<li>Saying the opposite of what is meant, e.g.&nbsp;a bigot saying excessively positive things about an ethnic group, or a pro-anorexia poster making anti-anorexic statements sarcastically.</li>
</ul>
</dd>
<dd>
<ul>
<li>Using euphemisms for illegal substances or illegal acts.</li>
</ul>
</dd>
<dd>
<ul>
<li>Using emojis of eggplants and peaches with sexual connotations.</li>
</ul>
</dd>
<dd>
<ul>
<li>Using photos without explicit nudity but which can be read as pornographic.</li>
</ul>
</dd>
<dt>Improved detection will cause substitution towards contextual violations.</dt>
<dd>
<p>As AI improves the ability to detect violations it seems likely that there will be at least some substitution towards context-specific violations, however as long as there is some cost to using a contextual-violation then we would expect a less than one-for-one substitution.</p>
</dd>
</dl>
</section>
<section id="section-7" class="level1 page-columns page-full">
<h1></h1>
<dl class="page-columns page-full">
<dt>Platforms could detect contextual violations if they wanted to.</dt>
<dd class="page-columns page-full">
<p>When doing human evaluation then platforms could either (1) provide human raters with detail about the message’s context and audience, or (2) assign human raters to messages based on their experience with that community.<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a> Likewise AI models could be trained to include rich representation of the context. An additional advantage of adding context is that it can identify and exempt posts that violate the letter but not the spirit of the policy.</p>
<div class="no-row-height column-margin column-container"><div id="fn6"><p><sup>6</sup>&nbsp;Platforms already have some policies that include context, e.g.&nbsp;Facebook’s <a href="https://transparency.fb.com/policies/community-standards/bullying-harassment/">“Bullying and Harassment policy”</a> bans “repeatedly contacting someone in a manner that is unwanted or sexually harassing.”</p></div></div></dd>
<dt>Platforms may not want to remove contextual violations.</dt>
<dd>
<p>There are reasons why platforms may be reluctant to use context in determining violations: it is more complex, and can lead to awkward PR where the platform is shown to be censoring words and images have a harmless interpretation.</p>
</dd>
<dd>
Additionally platforms care both about being seen to restrict harmful content, as well as about the actual harm prevented.
</dd>
</dl>
</section>
<section id="section-8" class="level1 page-columns page-full">
<h1></h1>
<dl class="page-columns page-full">
<dt>Contextual violations have long existed in broadcast media.</dt>
<dd class="page-columns page-full">
<p>There have been many cases where contextual violations have been tolerated: e.g.&nbsp;newspapers would allow classified advertisments for prostitutes if described as masseuses, vibrators if described as massage wands, contraception if described as marital aids, and abortion if described as <a href="https://slate.com/human-interest/2014/08/history-of-contraception-19th-century-classified-ads-for-abortifacients-and-contraceptives.html">“removal of obstructions”</a>. Thus it seems plausible that platforms will tolerate a substantial amount of contextually-violating content to remain.<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a></p>
<div class="no-row-height column-margin column-container"><div id="fn7"><p><sup>7</sup>&nbsp;In Facebook’s Marketplace it is prohibited to list guns for sale. As a consequence people began to list gun <em>cases</em>, with the understanding that a case was standing in for a gun. Facebook then updated their policy to prohibit selling gun cases. In turn people began to list gun stickers as stand-ins for guns. See WSJ reports from <a href="https://www.wsj.com/articles/gun-sellers-are-sneaking-onto-facebooks-booming-secondhand-marketplace-11566315198">2020</a> and <a href="https://www.wsj.com/articles/gun-sellers-use-new-tactic-to-deal-on-facebook-marketplace-11598270872">2021</a>.</p></div></div></dd>
<dt>Government censorship is unlikely to be constrained by context-specific violations.</dt>
<dd>
Once a censor discovers that a term has an anti-government significance in a certain context then they are likely to start censoring that term. E.g. China has suppressed online mentions of <a href="https://www.bbc.com/news/blogs-china-blog-40627855">Winnie the Pooh</a> because it is associated with criticism of Xi Jinping, and in 2022 Hong Kong police arrested protestors for holding blank pieces of paper.<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a>
</dd>
<div class="no-row-height column-margin column-container"><div id="fn8"><p><sup>8</sup>&nbsp;https://www.axios.com/2022/11/28/china-protests-blank-paper-covid</p></div></div></dl>
</section>
<section id="the-prevalence-of-variants-of-known-violating-content-will-decline" class="level1">
<h1>The Prevalence of Variants of Known-Violating Content Will Decline</h1>
<dl>
<dt>Most platforms check content against databases of known-violating content.</dt>
<dd>
<p>The databases are often shared across platforms, known as “signal sharing”, e.g.&nbsp;databases of illegal sexual media (PhotoDNA), IP-protected content (Content ID), or terrorist recruitment content (GIFCT).</p>
</dd>
<dt>Existing equilibrium is cat-and-mouse obfuscation.</dt>
<dd>
<p>Sophisticated uploaders obfuscate their content, e.g.&nbsp;by adding noise, and platforms expand their matching algorithms using fuzzy matching.</p>
</dd>
<dt>Detecting variants of known content is subtly different from detecting violating content.</dt>
<dd>
<p>The difference between “does this picture show a handsome face?” and “does this picture show Tom’s face?”</p>
</dd>
<dd>
The latter question becomes complicated: if a picture <em>coincidentally</em> looks like Tom, does it represent Tom? Much 20th century philosophy has been written about these types of issues.
</dd>
</dl>
</section>
<section id="section-9" class="level1">
<h1></h1>
<dl>
<dt>It seems likely <em>gratuitous</em> will violations to go to zero.</dt>
<dd>
<p>Suppose someone wants to violate the policy just for the sake of violating that policy, e.g.&nbsp;they want to show a shocking image. Call this “gratuitous” violations.</p>
</dd>
<dd>
Currently the easiest way to do this is to first find a violating piece of content, then obfuscate it.
</dd>
<dd>
If attackers can use AI synthesis they no longer need to find existing violating content, they can synthesize new ones. The defensive technique of checking against known-violating content becomes much worse.
</dd>
<dd>
However if defenders have AI recognition, then by the same argument as above prevalence will go to zero.
</dd>
</dl>
<p></p>
</section>
<section id="platforms-will-not-be-able-to-identify-bots-from-their-behavior" class="level1">
<h1>Platforms Will Not Be Able to Identify Bots from Their Behavior</h1>
<dl>
<dt>Most online platforms struggle with automated users (bots) who are disruptive in a variety of ways.</dt>
<dd>
<p>One way of protecting against bots is with behavioral tests, e.g.&nbsp;a CAPTCHA test asking users an image-recognition task, or by using on-platform behavior to detect whether a user is human. However improvements in AI mean that computers have human-level performance on image-recognition tasks, and can learn to imitate human-style behavior patterns, thus it seems likely these behavioral tests will become ineffective against sophisticated actors. <span class="citation" data-cites="searles2023empirical">Searles et al. (<a href="#ref-searles2023empirical" role="doc-biblioref">2023</a>)</span> finds that most contemporary CAPTCHAs can be solved by computers with higher-than-human accuracy.</p>
</dd>
<dt>This does not imply that the prevalence of bots will increase.</dt>
<dd>
<p>All platforms need some defense against bots so they will have to rely relatively more on other forms of authentication, such as monetary payment, offline identity credentials (government ID, credit card number), hard-to-fake metadata (unique IP address, device ID), or 3rd-party identity provider (Sign in with Google, OpenID, Worldcoin). Thus the barriers to signing up for a service, and especially posting on it, will become higher, but the effect on equilibrium prevalence of bots is ambiguous.</p>
</dd>
<dd>
See <em>Proof of Personhood</em> by OpenAI colleagues (Zoe Hitzig et al.).
</dd>
</dl>
</section>
<section id="platforms-will-find-it-hard-to-discriminate-between-real-and-fake-media" class="level1">
<h1>Platforms Will Find It Hard to Discriminate between Real and Fake Media</h1>
<dl>
<dt>In some cases the ground truth depends on properties outside the content.</dt>
<dd>
<p>I will refer to these properties as “external” in contrast to “internal” properties which depend only on the content such as whether a picture depicts nudity. Some examples of external properties:</p>
<ul>
<li>Whether a piece of media was generated in the traditional way (photographing a scene, recording a sound), or has been manipulated or synthesized.</li>
<li>Whether text was written by a human.</li>
<li>Whether text was written by a specific person, e.g.&nbsp;by Shakespeare.</li>
</ul>
</dd>
<dt>Advances in AI help both forgery-detection and forgery-creation.</dt>
<dd>
<p>It is clear that a better statistical model of genuine artefacts will help detect forgeries but it will also help create convincing forgeries.</p>
</dd>
</dl>
</section>
<section id="section-10" class="level1">
<h1></h1>
<dl>
<dt>Determined forgers will be able to fool humans.</dt>
<dd>
<p>It seems likely that the latter effect will dominate: it will gradually become possible to camouflage computer-generated content such that neither a computer nor a human could tell them apart. If the content-producer has access to the platforms’ model then they can keep perturbing their fake media until it is labelled as non-fake.</p>
</dd>
<dt>We cannot reliably discriminate between real and AI-generated media.</dt>
<dd>
<p>As of late 2023, programs to detect synthetically generated media have relatively poor accuracy: OpenAI announced a model to detect LLM-created text in January 2023 but then <a href="https://decrypt.co/149826/openai-quietly-shutters-its-ai-detection-tool">shut it down</a> in July because of poor performance. In June 2023 the NY Times compared a variety of tools to detect computer-generated images and found that with minimal effort they could all be <a href="https://www.nytimes.com/interactive/2023/06/28/technology/ai-detection-midjourney-stable-diffusion-dalle.html">reliably fooled</a>.</p>
</dd>
</dl>
</section>
<section id="section-11" class="level1 page-columns page-full">
<h1></h1>
<dl class="page-columns page-full">
<dt>The prevalence of synthetic media will increase on unmoderated platforms.</dt>
<dd class="page-columns page-full">
<p>The major platforms have incentives to limit the prevalence of fake media,<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a> and can control the prevalence even without reliable classifiers. E.g. Meta and YouTube dramatically decreased the prevalence of misinformation over 2016-2020 not primarily through real-time detection of whether a given claim is false, but by (1) adjusting ranking to penalize publishers who tend to circulate false claims; (2) punishing publishers who circulate proven-false claims. Thus I do not expect overall prevalence of fake factual media to substantially increase on the major platforms.</p>
<div class="no-row-height column-margin column-container"><div id="fn9"><p><sup>9</sup>&nbsp;The goals of platforms in content moderation are discussed in my note on ranking, <span class="citation" data-cites="cunningham2023ranking">Cunningham (<a href="#ref-cunningham2023ranking" role="doc-biblioref">2023</a>)</span>.</p></div></div></dd>
</dl>
</section>
<section id="fake-media-deepfakes-will-not-have-a-substantial-influence-on-politics" class="level1">
<h1>Fake Media (Deepfakes) Will Not Have a Substantial Influence on Politics</h1>
<dl>
<dt>As synthetic media becomes common people will rely more on provenance.</dt>
<dd>
<p>As it becomes cheaper to manipulate and synthesize media then people are likely to become more skeptical and rely relatively more on the <em>provenance</em> of information. Thus although synthetic media will likely circulate I do not think it will have a substantial influence on beliefs in equilibrium.</p>
</dd>
<dt>It has always been easy to create misleading documents.</dt>
<dd>
<p>It is not difficult to forge or alter documents, or edit video in a misleading way. As a consequence mainstream media organizations typically do not publish leaked materials unless they have either a chain or provenance for the leaks or independent confirmation of their content.</p>
</dd>
</dl>
</section>
<section id="section-12" class="level1">
<h1></h1>
<dl>
<dt>Influential forgeries of documents have been historically rare.</dt>
<dd>
<p>In an Appendix below I compile a simple dataset of politically influential document leaks in the US over the past 25 years and estimate around 10% of them were based on forged materials.</p>
</dd>
<dt>The quantity of false claims circulating on the internet is not primarily constrained by the quality of their content.</dt>
<dd>
<p>A great deal of false claims already circulate on the internet, especially in loosely moderated parts: e.g.&nbsp;by email, on Telegram, 4chan, Truth Social, WhatsApp, Twitter. It’s not clear that the quality of the faked media is an important constraint on the volume that circulates.</p>
</dd>
<dd>
It’s not uncommon to find a clip of an interview with a politician edited to make it appear that they are admitting to a crime or secret agenda. If people already take what they see at face value then adding deepfakes seems unlikely to change their opinions substantially. Alternatively if people are skeptical and look for corroborating sources then, again, deepfakes would be unpersuasive. It seems that deepfakes would only be influential if there are a significant population who are exposed to many lies but are not haded because the documentary evidence is not sufficiently strong.
</dd>
</dl>
<p></p>
<p></p>
<p></p>
</section>
<section id="communication-will-migrate-towards-large-closed-platforms" class="level1">
<h1>Communication Will Migrate Towards Large Closed Platforms</h1>
<dl>
<dt>Small platforms will be overrun with AI-created content.</dt>
<dd>
<p>In particular, AI-created bots, spam, obfuscated violating content, and fake media. This would imply that consumers will tend to migrate to larger closed platforms with more effective defences, and which have more restriction on participation. This continues a general movement over the last 20 years of communication moving from small open platforms (independent email, small forums, mailing lists, independent websites) to large closed platforms (large email providers, large social media platforms).</p>
</dd>
<dt>People will rely more on established sources of truth.</dt>
<dd>
<p>E.g. they will rely relatively more on Wikipedia, Community Notes, and mainstream recognized media sources. The ordinary content-based signs of trustworthiness will become less reliable: having a professional website, well-edited text, well-argued reasoning, and documentary evidence.</p>
</dd>
</dl>
</section>
<section id="section-13" class="level1">
<h1></h1>
<dl>
<dt>People will rely more on cryptographic signing to verify authenticity.</dt>
<dd>
<p>I am not sure how strong this effect will be: it is generally more efficient for an intermediary to verify authenticity of senders than for users to do it themselves. I think we’ve seen that in other domains: (1) PGP signing of email has been less important than email providers filtering spam and phishing; (2) SSL certificates in browsers have been less important than browsers giving warnings for suspected phishing sites (e.g.&nbsp;Google’s <a href="https://safebrowsing.google.com">safe browsing</a> database of sites with phishing or malware is used to give warnings in Chrome and Safari).</p>
</dd>
<dt>Pedigree will become more important in publication.</dt>
<dd>
As an editor accepting submissions (e.g.&nbsp;an academic journal, a literary magazine, a newspaper letters page) the quality of the work submitted is typically correlated with more superficial features such as the grammaticallity and the length. As it becomes easy to synthesize text then those superficial features will become less informative about quality and editors are likely to rely relatively more on hard-to-fake signals like the pedigree of authors: what have they published before, and which college the author went to.
</dd>
</dl>
</section>
<section id="entertainment-will-become-largely-synthetic" class="level1">
<h1>Entertainment will Become Largely Synthetic</h1>
<dl>
<dt>A computer that can detect if a photo is pretty can also create a pretty photo.</dt>
<dd>
<p>A classifier that can detect whether a joke is funny should also be able to generate funny jokes.[^jokes] On average people spend around 3 hours per day watching entertainment (TV, YouTube, TikTok, Instagram). It seems likely that trained models will be able to synthesize content that is highly engaging though it’s hard to anticipate what it will look like.</p>
</dd>
</dl>
</section>
<section id="things-will-get-weird" class="level1">
<h1>Things Will Get Weird</h1>
<dl>
<dt>People will synthesize completely new violating images/videos.</dt>
<dd>
<p><span class="citation" data-cites="thiel2023generative">Thiel, Stroebel, and Portnoff (<a href="#ref-thiel2023generative" role="doc-biblioref">2023</a>)</span> say that, as of early 2023, less than 1% of child sexual abuse media (CSAM) appears to be synthetically generated. However the ability to synthesize has been advancing rapidly, “to the point that some images are only distinguishable from reality if the viewer is very familiar with photography, lighting and the characteristics of diffusion model outputs … it is likely that in under a year it will become significantly easier to generate adult images that are indistinguishable from actual images.”</p>
</dd>
<dt>Producers will synthesize content to sit on the <em>edge</em> of a category.</dt>
<dd>
<p>If platforms take action whenever content passes some threshold then adversarial actors will generate or perturb content such that it sits right below the threshold. If a platform removes a photo whenever more than 50% of raters would say it depicts nudity then producers would upload photos which 49% of raters would say depicts nudity. People would upload movies which <em>almost</em> look like an existing IP-protected movie, and students might submit essays that are close to existing sources but don’t quite trigger the plagiarism detector.</p>
</dd>
</dl>
</section>
<section id="influential-leaks-of-us-political-documents-since-1997" class="level1">
<h1>Influential leaks of US political documents since 1997:</h1>
<table class="caption-top table">
<colgroup>
<col style="width: 41%">
<col style="width: 4%">
<col style="width: 17%">
<col style="width: 36%">
</colgroup>
<tbody>
<tr class="odd">
<td>Tripp Tapes</td>
<td>1997</td>
<td>audio</td>
<td>Tripp to Starr</td>
</tr>
<tr class="even">
<td><del>Iraq letters to Niger (“yellowcake”)</del></td>
<td>2002</td>
<td>documents</td>
<td>Unknown to Italians to CIA</td>
</tr>
<tr class="odd">
<td><del>Bush military transcripts (“Killian”)</del></td>
<td>2004</td>
<td>fax of 1970s memo</td>
<td>Unknown to ret colonel to CBS</td>
</tr>
<tr class="even">
<td>Abu Ghraib photos</td>
<td>2004</td>
<td>photos</td>
<td>Unknown to CBS</td>
</tr>
<tr class="odd">
<td>Baghdad Airstrike</td>
<td>2007</td>
<td>video</td>
<td>Chelsea Manning to Wikileaks</td>
</tr>
<tr class="even">
<td>US Iraq war logs</td>
<td>2010</td>
<td>digital docs</td>
<td>Chelsea Manning to Wikileaks</td>
</tr>
<tr class="odd">
<td>US Diplomatic cables</td>
<td>2010</td>
<td>digital docs</td>
<td>Chelsea Manning to Wikileaks</td>
</tr>
<tr class="even">
<td>Romney Tape (“47%”)</td>
<td>2012</td>
<td>audio</td>
<td>Bartender to Mother Jones</td>
</tr>
<tr class="odd">
<td>NSA Surveillance Leaks</td>
<td>2013</td>
<td>digital docs</td>
<td>Edward Snowden to the Guardian, WaPo</td>
</tr>
<tr class="even">
<td>DNC emails</td>
<td>2016</td>
<td>emails</td>
<td>Unknown to Wikileaks</td>
</tr>
<tr class="odd">
<td>Podesta emails</td>
<td>2016</td>
<td>emails</td>
<td>Unknown to Wikileaks</td>
</tr>
<tr class="even">
<td>Colin Powell emails</td>
<td>2016</td>
<td>emails</td>
<td>Unknown to DCLeaks</td>
</tr>
<tr class="odd">
<td>Panama papers</td>
<td>2016</td>
<td>documents</td>
<td>Unknown to Süddeutsche Zeitung</td>
</tr>
<tr class="even">
<td>Donald Trump Access Hollywood Tape</td>
<td>2016</td>
<td>video</td>
<td>Unknown to Washington Post</td>
</tr>
<tr class="odd">
<td>China Cables</td>
<td>2019</td>
<td>digital docs</td>
<td>Unknown to the ICIJ</td>
</tr>
<tr class="even">
<td>Hunter Biden laptop</td>
<td>2020</td>
<td>docs, audio, video</td>
<td>computer shop to Giuliani to NY Post</td>
</tr>
<tr class="odd">
<td>Los Angeles Council call (“changuito”)</td>
<td>2022</td>
<td>audio</td>
<td>Unknown to Reddit to LA Times</td>
</tr>
</tbody>
</table>



</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-bursztein2023retvec" class="csl-entry" role="listitem">
Bursztein, Elie, Marina Zhang, Owen Vallis, Xinyu Jia, and Alexey Kurakin. 2023. <span>“RETVec: Resilient and Efficient Text Vectorizer.”</span> <a href="https://arxiv.org/pdf/2302.09207.pdf">https://arxiv.org/pdf/2302.09207.pdf</a>.
</div>
<div id="ref-chen2022profanity" class="csl-entry" role="listitem">
Chen, Edwin. 2022. <a href="https://www.surgehq.ai/blog/are-popular-toxicity-models-simply-profanity-detectors">https://www.surgehq.ai/blog/are-popular-toxicity-models-simply-profanity-detectors</a>.
</div>
<div id="ref-cunningham2023ranking" class="csl-entry" role="listitem">
Cunningham, Tom. 2023. <span>“Ranking by Engagement.”</span> <a href="http://tecunningham.github.io/2023-04-28-ranking-by-engagement.html">http://tecunningham.github.io/2023-04-28-ranking-by-engagement.html</a>.
</div>
<div id="ref-grondahl2018need" class="csl-entry" role="listitem">
Gröndahl, Tommi, Luca Pajola, Mika Juuti, Mauro Conti, and N. Asokan. 2018. <span>“All You Need Is "Love": Evading Hate-Speech Detection.”</span> <a href="https://arxiv.org/pdf/1808.09115.pdf">https://arxiv.org/pdf/1808.09115.pdf</a>.
</div>
<div id="ref-han2020fortifying" class="csl-entry" role="listitem">
Han, Xiaochuang, and Yulia Tsvetkov. 2020. <span>“Fortifying Toxic Speech Detectors Against Veiled Toxicity.”</span> In <em>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>, 7732–39. Online: Association for Computational Linguistics. <a href="https://doi.org/10.18653/v1/2020.emnlp-main.622">https://doi.org/10.18653/v1/2020.emnlp-main.622</a>.
</div>
<div id="ref-heiner2022toxic" class="csl-entry" role="listitem">
Heiner, Scott. 2022. <span>“Real-World ML Failures: The Violence, Racism, and Sexism Uncaught by Twitter’s Content Moderation Systems.”</span> <a href="https://www.surgehq.ai/blog/25-examples-of-twitters-content-moderation-failures">https://www.surgehq.ai/blog/25-examples-of-twitters-content-moderation-failures</a>.
</div>
<div id="ref-whitlocklees2022perspective" class="csl-entry" role="listitem">
Lees, Alyssa Whitlock, Vinh Q. Tran, Yi Tay, Jeffrey Scott Sorensen, Jai Gupta, Donald Metzler, and Lucy Vasserman. 2022. <span>“A New Generation of Perspective API: Efficient Multilingual Character-Level Transformers.”</span> In. <a href="https://dl.acm.org/doi/10.1145/3534678.3539147">https://dl.acm.org/doi/10.1145/3534678.3539147</a>.
</div>
<div id="ref-lees2021capturing" class="csl-entry" role="listitem">
Lees, Alyssa, Daniel Borkan, Ian Kivlichan, Jorge Nario, and Tesh Goyal. 2021. <span>“Capturing Covertly Toxic Speech via Crowdsourcing.”</span> In <em>Proceedings of the First Workshop on Bridging Human<span>–</span>Computer Interaction and Natural Language Processing</em>, 14–20. Online: Association for Computational Linguistics. <a href="https://aclanthology.org/2021.hcinlp-1.3">https://aclanthology.org/2021.hcinlp-1.3</a>.
</div>
<div id="ref-searles2023empirical" class="csl-entry" role="listitem">
Searles, Andrew, Yoshimichi Nakatsuka, Ercan Ozturk, Andrew Paverd, Gene Tsudik, and Ai Enkoji. 2023. <span>“An Empirical Study &amp; Evaluation of Modern CAPTCHAs.”</span> <a href="https://arxiv.org/pdf/2307.12108.pdf">https://arxiv.org/pdf/2307.12108.pdf</a>.
</div>
<div id="ref-thiel2023generative" class="csl-entry" role="listitem">
Thiel, David, Melissa Stroebel, and Rebecca Portnoff. 2023. <span>“Generative ML and CSAM: Implications and Mitigations.”</span> <a href="https://www.semanticscholar.org/paper/bbcbaedfe893f9cd5d6390adf616cecdabfc651d">https://www.semanticscholar.org/paper/bbcbaedfe893f9cd5d6390adf616cecdabfc651d</a>.
</div>
<div id="ref-weng2023gpt4moderation" class="csl-entry" role="listitem">
Weng, Lilian, Vik Goel, and Andrea Vallone. 2023. <span>“Using GPT-4 for Content Moderation.”</span> <a href="https://openai.com/blog/using-gpt-4-for-content-moderation">https://openai.com/blog/using-gpt-4-for-content-moderation</a>.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("tecunningham\.github\.io");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>