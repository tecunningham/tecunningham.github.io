<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Tom Cunningham">
<meta name="description" content="Tom Cunningham blog">

<title>Hallucinations and Alignment | Tom Cunningham – Tom Cunningham</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

<script type="text/javascript">

(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-12027453-1', 'auto');

ga('send', {
  hitType: 'pageview',
  'anonymizeIp': true,
});
</script>
<script>window.MathJax = {
   loader: { load: ["https://cdn.jsdelivr.net/gh/sonoisa/XyJax-v3@3.0.1/build/xypic.js"]},
   tex: {packages: {'[+]': ['xypic','bm']},
         macros: {  bm: ["\\boldsymbol{#1}", 1],
                    ut: ["\\underbrace{#1}_{\\text{#2}}", 2],
                    utt: ["\\underbrace{#1}_{\\substack{\\text{#2}\\\\\\text{#3}}}", 3] }
   }
};
</script>
<style>
   h1 {  border-bottom: 8px solid #557;}
   h2 {  border-bottom: 1px solid #ccc;}
   .greyproof {
      background-color: #f5f5f5;
      padding: 1em;
      margin: 1em 0;
      border-radius: 4px;
   }
</style>
<meta name="quarto:status" content="draft">

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../styles.css">
<meta name="twitter:title" content="Hallucinations and Alignment | Tom Cunningham">
<meta name="twitter:description" content="Tom Cunningham blog">
<meta name="twitter:card" content="summary">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner"><div id="quarto-draft-alert" class="alert alert-warning"><i class="bi bi-pencil-square"></i>Draft</div>
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Tom Cunningham</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href=".././about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/testingham"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/tom-cunningham-a9433/"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://tecunningham.github.io/index.xml"> <i class="bi bi-rss-fill" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://scholar.google.com/citations?user=MDB_DgkAAAAJ"> 
<span class="menu-text">scholar</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Hallucinations and Alignment</h1>
                      </div>
  </div>
    
  
  <div class="quarto-title-meta">

      
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<div class="callout callout-style-default callout-note callout-titled" title="Project spec (human)">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Project spec (human)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ul>
<li><p>Overall goal: a blog post about why language models hallucinate, that it’s a badly-specified payoff function.</p></li>
<li><p><strong>If there are important ambiguities or inconsistencies in the spec you should ask me.</strong></p></li>
<li><p>Basic model:</p>
<ul>
<li>Canonical problem: the user has to choose between a few options (multi-choice), the LLM has probabilities on each answer.</li>
<li>Distinguish LLM outputs: binary (recommend one option), ternary (can abstain), and continuous (report probabilities over options).</li>
<li>The user has some outside option from not choosing, which is above choosing the wrong option. Can also extend such that they can pay a cost to get the right answer themselves.</li>
</ul></li>
<li><p>Claims:</p>
<ul>
<li>Continuous output is best.</li>
<li>The usefulness of a binary-output LLM to a user is convex in its avg accuracy.</li>
<li>The threshold for making a claim is p^*=(_a-_f)/(_s-_f).</li>
<li>Illustrate different user preferences over succeed/fail/abstain on a simplex</li>
<li>Training with a reward only for accuracy encourages guessing over abstention.</li>
</ul></li>
<li><p>Additional notes</p>
<ul>
<li>Related literature: cite and discuss Chow (1970) and Kalai et al.&nbsp;(2025); for each, list their claims precisely.</li>
<li>The diagrams should be super clear. Make sure you <em>look</em> at the diagrams to see that they are readable.</li>
<li>Plot data from different studies on simplex diagrams. Also give comments on the diagrams, on what the takewaay is about tradeoffs here, &amp; see that’s consistent with what the original papers say.</li>
</ul></li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="Project plan (LLM)">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Project plan (LLM)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ul>
<li><p>Deliverable: a blog post explaining hallucinations as payoff-misalignment (user utility vs training/eval rewards), using a simple decision-theory model.</p></li>
<li><p>Structure:</p>
<ul>
<li>Setup: multi-choice question with <span class="math inline">\(k\)</span> options; model has posterior <span class="math inline">\(p(y\mid x)\)</span>; user chooses (i) pick an option, (ii) abstain, or (iii) pay a cost to verify (optional extension).</li>
<li>Outputs: compare binary (one option), ternary (option or abstain), continuous (probabilities over options).</li>
<li>Core threshold: derive <span class="math inline">\(p^*=(\pi_a-\pi_f)/(\pi_s-\pi_f)\)</span> and interpret.</li>
<li>Key claims to support:
<ul>
<li>Continuous output is (weakly) best for the user (information-loss argument).</li>
<li>Binary usefulness is convex in average accuracy (kink at the abstain/use threshold).</li>
<li>Accuracy-only rewards + binary grading encourage guessing over abstention; connect to Kalai et al.&nbsp;(2025) and Chow (1970).</li>
</ul></li>
<li>Geometry: use a Marschak-Machina simplex to visualize (a) user preferences (indifference lines) and (b) training/eval objectives.</li>
</ul></li>
<li><p>Figures:</p>
<ul>
<li>1D payoff-vs-confidence threshold plot (clean, consistent sign conventions).</li>
<li>Optional verification extension plot (attempt vs verify threshold).</li>
<li>Simplex with indifference grids for a few payoff ratios/objectives.</li>
<li>Simplex points from multiple studies/benchmarks + short takeaways, with explicit comparability caveats.</li>
</ul></li>
<li><p>Editing rules while executing:</p>
<ul>
<li>Do not edit <code>PROJECT-SPEC-HUMAN</code>.</li>
<li>Keep notation consistent across text + figures (<span class="math inline">\(\pi_s,\pi_f,\pi_a\)</span>; typically normalize <span class="math inline">\(\pi_a=0\)</span>).</li>
</ul></li>
</ul>
</div>
</div>
</div>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>Hallucinations are usually described as the model “making things up”. But in many applications, hallucinations are the predictable outcome of a mis-specified payoff function: the user cares about the tradeoff between <strong>being right</strong>, <strong>being wrong</strong>, and <strong>not answering</strong> (or escalating to verification), while most training and evaluation pipelines implicitly reward “answer something” much more than “know when to stop”.</p>
<p>This post treats question answering as a small decision problem with payoffs <span class="math inline">\((\pi_s,\pi_f,\pi_a)\)</span> for succeed / fail / abstain. That framing connects directly to Chow’s classic reject-option rule in pattern recognition <span class="citation" data-cites="chow1970optimum">(<a href="#ref-chow1970optimum" role="doc-biblioref">Chow 1970</a>)</span>, to the Marschak-Machina probability simplex, and to recent results arguing that binary evaluation systematically pressures models to guess <span class="citation" data-cites="kalai2025why">(<a href="#ref-kalai2025why" role="doc-biblioref">Kalai et al. 2025</a>)</span>.</p>
</section>
<section id="basic-model" class="level2">
<h2 class="anchored" data-anchor-id="basic-model">Basic model</h2>
<p>Consider a multiple-choice question with <span class="math inline">\(k\)</span> options and a hidden correct answer <span class="math inline">\(y^\star\)</span>. The model observes an input <span class="math inline">\(x\)</span> and has a posterior distribution <span class="math inline">\(p(y\mid x)\)</span> over options.</p>
<p>The user can take one of three actions:</p>
<ol type="1">
<li><strong>Answer:</strong> pick an option <span class="math inline">\(\hat y\)</span>.</li>
<li><strong>Abstain:</strong> do not answer (or defer to a safer outside option).</li>
<li><strong>Verify (optional extension):</strong> pay a cost <span class="math inline">\(c\)</span> to obtain the correct answer by some other means.</li>
</ol>
<p>For now, summarize payoffs as constants:</p>
<ul>
<li>Succeed (pick <span class="math inline">\(\hat y=y^\star\)</span>): payoff <span class="math inline">\(\pi_s\)</span>.</li>
<li>Fail (pick <span class="math inline">\(\hat y\neq y^\star\)</span>): payoff <span class="math inline">\(\pi_f\)</span>.</li>
<li>Abstain (outside option): payoff <span class="math inline">\(\pi_a\)</span>.</li>
</ul>
<p>Assume <span class="math inline">\(\pi_s&gt;\pi_a&gt;\pi_f\)</span>: being right is best; abstaining is better than being wrong.</p>
<section id="outputs-binary-ternary-continuous" class="level3">
<h3 class="anchored" data-anchor-id="outputs-binary-ternary-continuous">Outputs: binary, ternary, continuous</h3>
<p>We can distinguish LLM “answer formats” by how much information they expose about <span class="math inline">\(p(y\mid x)\)</span>:</p>
<ul>
<li><strong>Binary:</strong> the model returns a single recommended option <span class="math inline">\(\hat y\)</span>.</li>
<li><strong>Ternary:</strong> the model either returns <span class="math inline">\(\hat y\)</span> or abstains.</li>
<li><strong>Continuous:</strong> the model returns (an approximation to) the full distribution <span class="math inline">\(p(y\mid x)\)</span> over options.</li>
</ul>
</section>
</section>
<section id="claims" class="level2">
<h2 class="anchored" data-anchor-id="claims">Claims</h2>
<ol type="1">
<li><p><strong>A single threshold organizes abstention.</strong> If an “attempt” succeeds with probability <span class="math inline">\(p\)</span> and fails with probability <span class="math inline">\(1-p\)</span>, then attempting has expected payoff <span class="math display">\[
\mathrm{E}[\pi\mid \text{attempt}] = p\,\pi_s + (1-p)\,\pi_f.
\]</span> Attempting is optimal iff <span class="math inline">\(\mathrm{E}[\pi\mid \text{attempt}] \ge \pi_a\)</span>, i.e. <span class="math display">\[
p \ge p^* \equiv \frac{\pi_a-\pi_f}{\pi_s-\pi_f}.
\]</span></p></li>
<li><p><strong>Binary usefulness is convex in average accuracy.</strong> A user with an outside option chooses to rely on a binary-output model only when <span class="math inline">\(p\ge p^*\)</span>. So the user’s value is the max of an outside option and a linear function of <span class="math inline">\(p\)</span>, which is convex.</p></li>
<li><p><strong>Continuous output is (weakly) best.</strong> If the model provides <span class="math inline">\(p(y\mid x)\)</span>, the user can compute the expected payoff of each action (answer/abstain/verify) and implement the optimal policy. Any coarser output (binary or ternary) throws away information, and cannot improve expected utility.</p></li>
<li><p><strong>The simplex makes preferences and objectives visible.</strong> In the Marschak-Machina simplex over <span class="math inline">\((p_s,p_f,p_a)\)</span>, user preferences correspond to indifference lines whose slope is determined by payoff ratios; training/evaluation objectives correspond to different directions in the same triangle.</p></li>
<li><p><strong>Hallucinations are a consequence of the objective.</strong> Accuracy-only training rewards and binary grading make abstention suboptimal and encourage guessing. Chow (1970) derives the optimal reject rule in this exact payoff model <span class="citation" data-cites="chow1970optimum">(<a href="#ref-chow1970optimum" role="doc-biblioref">Chow 1970</a>)</span>; Kalai et al.&nbsp;(2025) argue modern LLM pipelines effectively ignore this reject option and therefore pressure models to hallucinate <span class="citation" data-cites="kalai2025why">(<a href="#ref-kalai2025why" role="doc-biblioref">Kalai et al. 2025</a>)</span>.</p></li>
</ol>
</section>
<section id="from-probabilities-to-actions" class="level2">
<h2 class="anchored" data-anchor-id="from-probabilities-to-actions">From probabilities to actions</h2>
<p>For a multiple-choice question, suppose the user answers by choosing the MAP option <span class="math inline">\(\hat y(x)=\arg\max_y p(y\mid x)\)</span>. Under the symmetric payoff model above (only “correct vs incorrect” matters), the probability of success from attempting is <span class="math display">\[
p_{\max}(x)\equiv \max_y p(y\mid x).
\]</span></p>
<p>So the attempt-vs-abstain decision is driven by a single number: answer iff <span class="math inline">\(p_{\max}(x)\ge p^*\)</span>.</p>
<p>If verification is available at cost <span class="math inline">\(c\)</span>, one simple version is: verifying yields certain success with payoff <span class="math inline">\(\pi_s-c\)</span>. Then for each question the user compares three quantities:</p>
<ul>
<li>Attempt: <span class="math inline">\(p_{\max}(x)\,\pi_s + (1-p_{\max}(x))\,\pi_f\)</span>.</li>
<li>Abstain: <span class="math inline">\(\pi_a\)</span>.</li>
<li>Verify: <span class="math inline">\(\pi_s-c\)</span>.</li>
</ul>
<p>This makes the “payoff mis-specification” point concrete: evaluation regimes that treat abstention as failure implicitly set <span class="math inline">\(\pi_a\approx \pi_f\)</span>, eliminating the region where “don’t answer” is optimal.</p>
<section id="convex-value-of-a-binary-output-model" class="level3">
<h3 class="anchored" data-anchor-id="convex-value-of-a-binary-output-model">Convex value of a binary-output model</h3>
<p>In the most constrained interface, a binary-output model only returns <span class="math inline">\(\hat y\)</span> and the user cannot condition on per-question confidence (they only know the model’s average accuracy <span class="math inline">\(p\)</span> on the relevant distribution). Then the user’s best policy is either to follow the model or to abstain, and the resulting value is <span class="math display">\[
V_{\text{binary}}(p)=\max\Bigl\{\pi_a,\; p\,\pi_s + (1-p)\,\pi_f\Bigr\}.
\]</span></p>
<p>This is the maximum of two affine functions of <span class="math inline">\(p\)</span>, so it is convex. It has a kink at the threshold <span class="math inline">\(p=p^*\)</span>: below the threshold the user abstains and additional accuracy has (locally) zero value; above the threshold, value increases linearly with accuracy. This is one reason “small accuracy gains” can feel useless until a system crosses a reliability threshold.</p>
</section>
<section id="why-continuous-output-is-weakly-best" class="level3">
<h3 class="anchored" data-anchor-id="why-continuous-output-is-weakly-best">Why continuous output is (weakly) best</h3>
<p>Continuous output (the distribution <span class="math inline">\(p(y\mid x)\)</span>, or any sufficiently rich summary like <span class="math inline">\((\hat y,p_{\max})\)</span>) lets the user implement the payoff-optimal policy question-by-question: answer only when it clears their <span class="math inline">\(p^*\)</span>, abstain otherwise, and (if available) trigger verification in the middle region.</p>
<p>Binary and ternary outputs are strict coarsenings of the posterior: they discard information about confidence. By a standard “more information cannot hurt” argument (Blackwell ordering), a user who observes a more informative signal can always simulate a less informative one by ignoring information, but not vice versa <span class="citation" data-cites="blackwell1953equivalent">(<a href="#ref-blackwell1953equivalent" role="doc-biblioref">Blackwell 1953</a>)</span>. So a continuous interface is weakly better than any binary/ternary interface for any fixed payoff function.</p>
</section>
</section>
<section id="probability-payoff-diagram" class="level2">
<h2 class="anchored" data-anchor-id="probability-payoff-diagram">Probability-Payoff Diagram</h2>
<p>This figure visualizes the threshold rule: as confidence <span class="math inline">\(p\)</span> rises, the expected payoff of attempting rises linearly from <span class="math inline">\(\pi_f\)</span> (when <span class="math inline">\(p=0\)</span>) to <span class="math inline">\(\pi_s\)</span> (when <span class="math inline">\(p=1\)</span>). Abstaining yields the flat payoff <span class="math inline">\(\pi_a\)</span>. The optimal policy is to attempt when the blue line crosses the abstain line.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="2026-02-26-hallucinations-and-alignment_files/figure-html/unnamed-chunk-1-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<section id="optional-extension-verification" class="level3">
<h3 class="anchored" data-anchor-id="optional-extension-verification">Optional extension: verification</h3>
<p>Suppose the user has a way to pay a cost <span class="math inline">\(c\)</span> to obtain the correct answer (e.g.&nbsp;look it up, run an expensive check, ask a human). In the simplest model, verification yields certain success with payoff <span class="math inline">\(\pi_s-c\)</span>.</p>
<p>Since abstaining and verifying are both “outside options” (their payoff does not depend on the model’s confidence), the only relevant outside-option payoff is <span class="math display">\[
\pi_{\text{outside}}=\max\{\pi_a,\;\pi_s-c\}.
\]</span></p>
<p>The attempt rule is the same threshold logic as before: attempt iff <span class="math display">\[
p \ge \frac{\pi_{\text{outside}}-\pi_f}{\pi_s-\pi_f}.
\]</span></p>
<p>The diagram below shows an example where verification dominates abstention (<span class="math inline">\(\pi_s-c&gt;\pi_a\)</span>): at low confidence the user verifies; only above a higher threshold does it become worth attempting directly.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="2026-02-26-hallucinations-and-alignment_files/figure-html/unnamed-chunk-2-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="simplex-representation" class="level2">
<h2 class="anchored" data-anchor-id="simplex-representation">Simplex Representation</h2>
<p>The probability simplex has three vertices corresponding to the three pure outcomes: certain success (<span class="math inline">\(p_s=1\)</span>), certain failure (<span class="math inline">\(p_f=1\)</span>), and certain abstention (<span class="math inline">\(p_a=1\)</span>). Any lottery over outcomes is a point in this triangle.</p>
<p>Different training/evaluation objectives induce different indifference-curve sets over <span class="math inline">\((p_s,p_f,p_a)\)</span>. The figure below contrasts three illustrative objectives.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="2026-02-26-hallucinations-and-alignment_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Each point in the simplex is a lottery over outcomes: a model might succeed with probability <span class="math inline">\(p_s\)</span>, fail with probability <span class="math inline">\(p_f\)</span>, and abstain with probability <span class="math inline">\(p_a\)</span>. The panels show three different objective families:</p>
<ul>
<li><strong>Reward accuracy</strong> (<span class="math inline">\(U=p_s\)</span>): success is rewarded, but failure and abstention are treated the same. This creates pressure to guess rather than abstain.</li>
<li><strong>Punish failure</strong> (linear expected utility): failure is explicitly penalized relative to abstention, expanding the region where abstaining is optimal.</li>
<li><strong>F1</strong> (a non-linear metric): indifference curves bend, reflecting that the metric itself builds in a particular tradeoff between attempting and being correct.</li>
</ul>
<section id="indifference-curve-slope-derivation" class="level3">
<h3 class="anchored" data-anchor-id="indifference-curve-slope-derivation">Indifference-curve slope derivation</h3>
<p>Let <span class="math inline">\(p_s, p_f, p_a = 1-p_s-p_f\)</span> denote the probabilities of succeed, fail, and abstain. Expected utility is</p>
<p><span class="math display">\[
U = \pi_s\, p_s + \pi_f\, p_f + \pi_a\, p_a.
\]</span></p>
<ol type="1">
<li><p>Substitute <span class="math inline">\(p_a = 1 - p_s - p_f\)</span>: <span class="math display">\[
\begin{aligned}
U
&amp;= \pi_a \\
&amp;\quad+ (\pi_s-\pi_a)\,p_s \\
&amp;\quad+ (\pi_f-\pi_a)\,p_f.
\end{aligned}
\]</span></p></li>
<li><p>Hold <span class="math inline">\(U = \bar U\)</span> and solve for <span class="math inline">\(p_f\)</span>: <span class="math display">\[
\begin{aligned}
p_f
&amp;= \frac{\bar U - \pi_a}{\pi_f-\pi_a}
- \frac{\pi_s-\pi_a}{\pi_f-\pi_a}\,p_s.
\end{aligned}
\]</span></p></li>
<li><p>The slope of the indifference curve in the <span class="math inline">\((p_s, p_f)\)</span> plane is therefore: <span class="math display">\[
\frac{dp_f}{dp_s}\bigg|_{U=\bar U}
= -\frac{\pi_s-\pi_a}{\pi_f-\pi_a}.
\]</span></p></li>
<li><p>Normalizing <span class="math inline">\(\pi_a=0\)</span>, this simplifies to: <span class="math display">\[
\frac{dp_f}{dp_s}\bigg|_{U=\bar U}
= -\frac{\pi_s}{\pi_f},
\qquad
p_f = \frac{\bar U}{\pi_f} - \frac{\pi_s}{\pi_f}\,p_s.
\]</span></p></li>
</ol>
<p>The slope depends only on payoff differences relative to abstain. When failure is very costly (<span class="math inline">\(|\pi_f|\)</span> large after normalizing <span class="math inline">\(\pi_a=0\)</span>), the curves are flatter: the decision-maker tolerates little additional failure probability in exchange for more success probability.</p>
</section>
</section>
<section id="related-literature" class="level2">
<h2 class="anchored" data-anchor-id="related-literature">Related Literature</h2>
<section id="brisk-summary" class="level3">
<h3 class="anchored" data-anchor-id="brisk-summary">Brisk summary</h3>
<ul>
<li><strong>Reject option / selective prediction.</strong> The classical Bayes-optimal abstention rule is Chow’s reject option <span class="citation" data-cites="chow1970optimum">(<a href="#ref-chow1970optimum" role="doc-biblioref">Chow 1970</a>)</span>. Modern ML re-derives and extends it as “selective classification” and the risk-coverage tradeoff <span class="citation" data-cites="herbei2006reject bartlett2008reject elyaniv2010selective geifman2019selectivenet">(<a href="#ref-herbei2006reject" role="doc-biblioref">Herbei and Wegkamp 2006</a>; <a href="#ref-bartlett2008reject" role="doc-biblioref">Bartlett and Wegkamp 2008</a>; <a href="#ref-elyaniv2010selective" role="doc-biblioref">El-Yaniv and Wiener 2010</a>; <a href="#ref-geifman2019selectivenet" role="doc-biblioref">Geifman and El-Yaniv 2019</a>)</span>.</li>
<li><strong>Output format and information.</strong> The “continuous output is weakly best” argument is an instance of the general fact that more informative signals cannot reduce expected utility (Blackwell order) <span class="citation" data-cites="blackwell1953equivalent">(<a href="#ref-blackwell1953equivalent" role="doc-biblioref">Blackwell 1953</a>)</span>.</li>
<li><strong>Probability forecasts and incentives.</strong> Proper scoring rules provide a principled way to reward honest probability reports and encourage calibrated uncertainty estimates <span class="citation" data-cites="gneiting2007scoring">(<a href="#ref-gneiting2007scoring" role="doc-biblioref">Gneiting and Raftery 2007</a>)</span>.</li>
<li><strong>LLM self-evaluation.</strong> Some work finds that language models can estimate the probability their own answers are correct (e.g.&nbsp;by producing a calibrated <span class="math inline">\(P(\text{True})\)</span>), which is exactly the quantity needed to implement threshold rules <span class="citation" data-cites="kadavath2022mostly">(<a href="#ref-kadavath2022mostly" role="doc-biblioref">Kadavath et al. 2022</a>)</span>.</li>
<li><strong>Distribution-free prediction sets.</strong> Conformal prediction is a complementary route: it outputs sets (or abstains) with finite-sample coverage guarantees and can be layered on top of any base model <span class="citation" data-cites="shafer2008conformal angelopoulos2021gentle">(<a href="#ref-shafer2008conformal" role="doc-biblioref">Shafer and Vovk 2008</a>; <a href="#ref-angelopoulos2021gentle" role="doc-biblioref">Angelopoulos and Bates 2021</a>)</span>.</li>
</ul>
</section>
<section id="chow-1970-optimal-reject-rules" class="level3">
<h3 class="anchored" data-anchor-id="chow-1970-optimal-reject-rules">Chow (1970): Optimal reject rules</h3>
<p><span class="citation" data-cites="chow1970optimum">Chow (<a href="#ref-chow1970optimum" role="doc-biblioref">1970</a>)</span> introduces the <strong>reject option</strong> (which he calls the “Indecision class” <span class="math inline">\(I\)</span>) into pattern recognition and derives the optimal error-reject tradeoff. Chow’s terminology maps directly onto ours:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Chow’s term</th>
<th>Our term</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>correct recognition</td>
<td>succeed</td>
</tr>
<tr class="even">
<td>error (misclassification)</td>
<td>fail</td>
</tr>
<tr class="odd">
<td>rejection / indecision</td>
<td>abstain</td>
</tr>
</tbody>
</table>
<p>Chow’s setup adds a third action (reject) to ordinary classification. In one common normalization, the costs are <span class="math inline">\(0\)</span> for a correct classification, <span class="math inline">\(1\)</span> for an error, and <span class="math inline">\(t\)</span> for a rejection.</p>
<p>The key result (“Chow’s rule”) is a posterior-threshold rule: accept and classify when confident enough, otherwise reject: <span class="math display">\[
\max_i P(G_i \mid x) \ge 1-t
\quad\Rightarrow\quad \text{accept;}
\qquad
\max_i P(G_i \mid x) &lt; 1-t
\quad\Rightarrow\quad \text{reject.}
\]</span></p>
<p>It is optimal in the sense that, for a given rejection threshold (equivalently, a given reject rate), no other rule achieves a lower error rate.</p>
<p>The threshold <span class="math inline">\(t\)</span> is related to the costs of the three outcomes as <span class="math inline">\(t = (C_r - C_c)/(C_e - C_c)\)</span>, where <span class="math inline">\(C_e, C_r, C_c\)</span> are the costs of error, rejection, and correct recognition. In our payoff notation <span class="math inline">\((\pi_s,\pi_f,\pi_a)\)</span>, Chow’s rule becomes: predict iff</p>
<p><span class="math display">\[
\max_y P(y \mid x) \ge \frac{\pi_a - \pi_f}{\pi_s - \pi_f}.
\]</span></p>
<p>In the Marschak-Machina triangle, this threshold corresponds to one of the indifference lines: the boundary between the region where prediction is preferred and the region where abstention is preferred.</p>
</section>
<section id="kalai-nachum-vempala-and-zhang-2025-why-language-models-hallucinate" class="level3">
<h3 class="anchored" data-anchor-id="kalai-nachum-vempala-and-zhang-2025-why-language-models-hallucinate">Kalai, Nachum, Vempala, and Zhang (2025): Why language models hallucinate</h3>
<p><span class="citation" data-cites="kalai2025why">Kalai et al. (<a href="#ref-kalai2025why" role="doc-biblioref">2025</a>)</span> argue that hallucinations are not a mysterious glitch but a predictable consequence of how models are trained and evaluated. Their central thesis is that the three-outcome structure (succeed, fail, abstain) is systematically distorted by binary evaluation:</p>
<p>The paper makes two distinct arguments:</p>
<p><strong>1. Pretraining origin.</strong> Even with error-free training data, the statistical objective of pretraining produces hallucinations. The authors reduce the problem to binary classification (“Is-It-Valid”), showing that</p>
<p><span class="math display">\[
\text{generative error rate} \gtrsim 2 \cdot \text{IIV misclassification rate}.
\]</span></p>
<p>For arbitrary facts (like someone’s birthday) where there is no learnable pattern, the hallucination rate after pretraining is at least the fraction of facts appearing exactly once in the training data.</p>
<p><strong>2. Post-training persistence.</strong> Even after RLHF and other interventions, hallucinations persist because nearly all evaluation benchmarks use binary grading that penalizes abstention:</p>
<p>The fix they propose is exactly the payoff structure from our Marschak-Machina framework: penalize errors more than abstentions, with an explicit confidence threshold <span class="math inline">\(t\)</span> stated in the prompt. Their proposed scoring rule awards <span class="math inline">\(+1\)</span> for a correct answer, <span class="math inline">\(-t/(1-t)\)</span> for an incorrect answer, and <span class="math inline">\(0\)</span> for abstaining—so that answering is optimal iff confidence exceeds <span class="math inline">\(t\)</span>. This is Chow’s reject-option rule rediscovered in the LLM evaluation context.</p>
</section>
<section id="selective-classification-risk-coverage-tradeoffs" class="level3">
<h3 class="anchored" data-anchor-id="selective-classification-risk-coverage-tradeoffs">Selective classification (risk-coverage tradeoffs)</h3>
<p>In modern ML, the reject option is often framed as <strong>selective classification</strong>: a predictor chooses a subset of examples to label (“coverage”) and aims to minimize error on that subset (“risk”). This is the same three-outcome structure in different words: success/failure live inside the covered set, and abstention is the complement.</p>
<ul>
<li><span class="citation" data-cites="elyaniv2010selective">El-Yaniv and Wiener (<a href="#ref-elyaniv2010selective" role="doc-biblioref">2010</a>)</span> develops foundations for selective classification and emphasizes the risk-coverage tradeoff.</li>
<li><span class="citation" data-cites="herbei2006reject">Herbei and Wegkamp (<a href="#ref-herbei2006reject" role="doc-biblioref">2006</a>)</span> and <span class="citation" data-cites="bartlett2008reject">Bartlett and Wegkamp (<a href="#ref-bartlett2008reject" role="doc-biblioref">2008</a>)</span> study classification with a reject option and how to learn it via loss minimization.</li>
<li><span class="citation" data-cites="geifman2019selectivenet">Geifman and El-Yaniv (<a href="#ref-geifman2019selectivenet" role="doc-biblioref">2019</a>)</span> shows one way to build the reject option directly into deep networks by jointly learning a predictor and a selection function.</li>
</ul>
<p>The important connection to this post is: once you make abstention explicit, the “right” threshold is not a moral property of the model; it is the decision boundary induced by payoffs.</p>
</section>
<section id="calibration-and-scoring-rules" class="level3">
<h3 class="anchored" data-anchor-id="calibration-and-scoring-rules">Calibration and scoring rules</h3>
<p>If you want a continuous interface (probabilities) to be useful, you need those probabilities to mean something. Proper scoring rules give a principled way to reward honest probability forecasts and thereby encourage calibration <span class="citation" data-cites="gneiting2007scoring">(<a href="#ref-gneiting2007scoring" role="doc-biblioref">Gneiting and Raftery 2007</a>)</span>. Empirically, some work finds that language models can often estimate the probability their own answers are correct, which is exactly the signal a user needs to implement a threshold rule <span class="citation" data-cites="kadavath2022mostly">(<a href="#ref-kadavath2022mostly" role="doc-biblioref">Kadavath et al. 2022</a>)</span>.</p>
</section>
<section id="conformal-prediction-prediction-sets" class="level3">
<h3 class="anchored" data-anchor-id="conformal-prediction-prediction-sets">Conformal prediction (prediction sets)</h3>
<p>Conformal prediction is a complementary approach: instead of outputting a single label, it outputs a <strong>set</strong> of plausible labels with finite-sample coverage guarantees. Large sets correspond to “I don’t know” behavior; singletons correspond to confident predictions. This provides a distribution-free way to control error rates of the attempted answers, given a calibration set <span class="citation" data-cites="shafer2008conformal angelopoulos2021gentle">(<a href="#ref-shafer2008conformal" role="doc-biblioref">Shafer and Vovk 2008</a>; <a href="#ref-angelopoulos2021gentle" role="doc-biblioref">Angelopoulos and Bates 2021</a>)</span>.</p>
</section>
</section>
<section id="implications-for-alignment" class="level2">
<h2 class="anchored" data-anchor-id="implications-for-alignment">Implications for “alignment”</h2>
<p>If you view hallucinations through this lens, “alignment” is not a mysterious property of model internals. It is the much more mundane question: does the model’s training and evaluation objective implement the user’s payoff function?</p>
<p>Practical implications:</p>
<ul>
<li><strong>Expose confidence.</strong> If the user cannot observe confidence, they cannot implement the threshold rule; binary outputs force guessing.</li>
<li><strong>Score abstention explicitly.</strong> Benchmarks that collapse abstain into “wrong” implicitly set <span class="math inline">\(\pi_a=\pi_f\)</span> and will select for guessing.</li>
<li><strong>Prefer calibrated probabilities or verification hooks.</strong> Either give users a usable <span class="math inline">\(p_{\max}\)</span>, or route medium-confidence cases to a verification workflow.</li>
</ul>
</section>
<section id="appendix-cross-benchmark-outcome-table" class="level2">
<h2 class="anchored" data-anchor-id="appendix-cross-benchmark-outcome-table">Appendix: Cross-Benchmark Outcome Table</h2>
<p>To make cross-model plotting easier, the table below standardizes outputs from multiple benchmarks into a common schema.</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>benchmark</th>
<th>model</th>
<th style="text-align: right;">p_s_pct</th>
<th style="text-align: right;">p_f_pct</th>
<th style="text-align: right;">p_a_pct</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>SimpleQA</td>
<td>Claude-3-haiku (2024-03-07)</td>
<td style="text-align: right;">5.1</td>
<td style="text-align: right;">19.6</td>
<td style="text-align: right;">75.3</td>
</tr>
<tr class="even">
<td>SimpleQA</td>
<td>Claude-3-sonnet (2024-02-29)</td>
<td style="text-align: right;">5.7</td>
<td style="text-align: right;">19.3</td>
<td style="text-align: right;">75.0</td>
</tr>
<tr class="odd">
<td>SimpleQA</td>
<td>Claude-3-opus (2024-02-29)</td>
<td style="text-align: right;">23.5</td>
<td style="text-align: right;">36.9</td>
<td style="text-align: right;">39.6</td>
</tr>
<tr class="even">
<td>SimpleQA</td>
<td>Claude-3.5-sonnet (2024-06-20)</td>
<td style="text-align: right;">28.9</td>
<td style="text-align: right;">36.1</td>
<td style="text-align: right;">35.0</td>
</tr>
<tr class="odd">
<td>SimpleQA</td>
<td>GPT-4o-mini</td>
<td style="text-align: right;">8.6</td>
<td style="text-align: right;">90.5</td>
<td style="text-align: right;">0.9</td>
</tr>
<tr class="even">
<td>SimpleQA</td>
<td>GPT-4o</td>
<td style="text-align: right;">38.2</td>
<td style="text-align: right;">60.8</td>
<td style="text-align: right;">1.0</td>
</tr>
<tr class="odd">
<td>SimpleQA</td>
<td>OpenAI o1-mini</td>
<td style="text-align: right;">8.1</td>
<td style="text-align: right;">63.4</td>
<td style="text-align: right;">28.5</td>
</tr>
<tr class="even">
<td>SimpleQA</td>
<td>OpenAI o1-preview</td>
<td style="text-align: right;">42.7</td>
<td style="text-align: right;">48.1</td>
<td style="text-align: right;">9.2</td>
</tr>
<tr class="odd">
<td>AbstentionBench</td>
<td>DeepSeek R1 Distill Llama 70B</td>
<td style="text-align: right;">43.7</td>
<td style="text-align: right;">10.3</td>
<td style="text-align: right;">46.0</td>
</tr>
<tr class="even">
<td>AbstentionBench</td>
<td>o1</td>
<td style="text-align: right;">27.2</td>
<td style="text-align: right;">6.8</td>
<td style="text-align: right;">66.0</td>
</tr>
<tr class="odd">
<td>AbstentionBench</td>
<td>S1.1 32B</td>
<td style="text-align: right;">45.6</td>
<td style="text-align: right;">11.4</td>
<td style="text-align: right;">43.0</td>
</tr>
<tr class="even">
<td>AbstentionBench</td>
<td>Llama 3.1 70B Tulu 3 DPO</td>
<td style="text-align: right;">26.1</td>
<td style="text-align: right;">6.9</td>
<td style="text-align: right;">67.0</td>
</tr>
<tr class="odd">
<td>AbstentionBench</td>
<td>Llama 3.1 70B Tulu 3 PPO RLVF</td>
<td style="text-align: right;">26.9</td>
<td style="text-align: right;">7.1</td>
<td style="text-align: right;">66.0</td>
</tr>
<tr class="even">
<td>AbstentionBench</td>
<td>Llama 3.3 70B Instruct</td>
<td style="text-align: right;">26.5</td>
<td style="text-align: right;">7.5</td>
<td style="text-align: right;">66.0</td>
</tr>
<tr class="odd">
<td>AbstentionBench</td>
<td>Gemini 1.5 Pro</td>
<td style="text-align: right;">25.4</td>
<td style="text-align: right;">7.6</td>
<td style="text-align: right;">67.0</td>
</tr>
<tr class="even">
<td>AbstentionBench</td>
<td>GPT-4o</td>
<td style="text-align: right;">23.3</td>
<td style="text-align: right;">7.8</td>
<td style="text-align: right;">69.0</td>
</tr>
<tr class="odd">
<td>AbstentionBench</td>
<td>Qwen2.5 32B</td>
<td style="text-align: right;">21.8</td>
<td style="text-align: right;">7.3</td>
<td style="text-align: right;">71.0</td>
</tr>
<tr class="even">
<td>AbstentionBench</td>
<td>Llama 3.1 8B Tulu 3 PPO RLVF</td>
<td style="text-align: right;">36.8</td>
<td style="text-align: right;">12.3</td>
<td style="text-align: right;">51.0</td>
</tr>
<tr class="odd">
<td>AbstentionBench</td>
<td>Llama 3.1 405B Instruct</td>
<td style="text-align: right;">23.7</td>
<td style="text-align: right;">8.3</td>
<td style="text-align: right;">68.0</td>
</tr>
<tr class="even">
<td>AbstentionBench</td>
<td>Llama 3.1 8B Tulu 3 DPO</td>
<td style="text-align: right;">34.8</td>
<td style="text-align: right;">12.2</td>
<td style="text-align: right;">53.0</td>
</tr>
<tr class="odd">
<td>AbstentionBench</td>
<td>Llama 3.1 70B Instruct</td>
<td style="text-align: right;">26.6</td>
<td style="text-align: right;">9.4</td>
<td style="text-align: right;">64.0</td>
</tr>
<tr class="even">
<td>AbstentionBench</td>
<td>Llama 3.1 70B Tulu 3 SFT</td>
<td style="text-align: right;">30.1</td>
<td style="text-align: right;">12.9</td>
<td style="text-align: right;">57.0</td>
</tr>
<tr class="odd">
<td>AbstentionBench</td>
<td>Llama 3.1 8B Instruct</td>
<td style="text-align: right;">23.8</td>
<td style="text-align: right;">10.2</td>
<td style="text-align: right;">66.0</td>
</tr>
<tr class="even">
<td>AbstentionBench</td>
<td>Mistral 7B v0.3</td>
<td style="text-align: right;">25.5</td>
<td style="text-align: right;">11.5</td>
<td style="text-align: right;">63.0</td>
</tr>
<tr class="odd">
<td>AbstentionBench</td>
<td>Llama 3.1 8B Tulu 3 SFT</td>
<td style="text-align: right;">37.1</td>
<td style="text-align: right;">20.0</td>
<td style="text-align: right;">43.0</td>
</tr>
<tr class="even">
<td>AbstentionBench</td>
<td>OLMo 7B</td>
<td style="text-align: right;">25.8</td>
<td style="text-align: right;">20.2</td>
<td style="text-align: right;">54.0</td>
</tr>
<tr class="odd">
<td>AbstentionBench</td>
<td>Llama 3.1 70B Base</td>
<td style="text-align: right;">25.5</td>
<td style="text-align: right;">25.5</td>
<td style="text-align: right;">49.0</td>
</tr>
<tr class="even">
<td>AbstentionBench</td>
<td>Llama 3.1 8B Base</td>
<td style="text-align: right;">23.5</td>
<td style="text-align: right;">32.5</td>
<td style="text-align: right;">44.0</td>
</tr>
<tr class="odd">
<td>Abstain-QA</td>
<td>GPT-4 Turbo</td>
<td style="text-align: right;">66.1</td>
<td style="text-align: right;">19.7</td>
<td style="text-align: right;">14.2</td>
</tr>
<tr class="even">
<td>Abstain-QA</td>
<td>GPT-4 32K</td>
<td style="text-align: right;">72.0</td>
<td style="text-align: right;">19.1</td>
<td style="text-align: right;">8.9</td>
</tr>
<tr class="odd">
<td>Abstain-QA</td>
<td>GPT-3.5 Turbo</td>
<td style="text-align: right;">61.1</td>
<td style="text-align: right;">37.4</td>
<td style="text-align: right;">1.5</td>
</tr>
<tr class="even">
<td>Abstain-QA</td>
<td>Mixtral 8x7b</td>
<td style="text-align: right;">54.1</td>
<td style="text-align: right;">37.0</td>
<td style="text-align: right;">8.9</td>
</tr>
<tr class="odd">
<td>Abstain-QA</td>
<td>Mixtral 8x22b</td>
<td style="text-align: right;">59.0</td>
<td style="text-align: right;">29.1</td>
<td style="text-align: right;">11.9</td>
</tr>
</tbody>
</table>
<p>Notes: - Table columns are constructed to look like probabilities in the <span class="math inline">\((p_s,p_f,p_a)\)</span> simplex: <span class="math inline">\(p_s=\text{p\_s\_pct}/100\)</span>, <span class="math inline">\(p_f=\text{p\_f\_pct}/100\)</span>, <span class="math inline">\(p_a=\text{p\_a\_pct}/100\)</span>. - For SimpleQA, these correspond directly to {Correct, Incorrect, Not attempted} shares. - For the other benchmarks, these are <em>constructed</em> from the paper’s summary metrics to enable geometric comparisons; interpret them as a mapping into a common coordinate system, not as identical underlying evaluation protocols.</p>
<section id="data-extraction-details-by-source" class="level3">
<h3 class="anchored" data-anchor-id="data-extraction-details-by-source">Data extraction details by source</h3>
<p><strong>SimpleQA (Wei et al., 2024).</strong> The table uses all model rows shown in the main SimpleQA model-comparison table (8 models). Here, <code>p_s_pct</code> is <strong>Correct</strong>, <code>p_a_pct</code> is <strong>Not attempted</strong>, and <code>p_f_pct</code> is computed as <span class="math inline">\(100-\text{Correct}-\text{Not attempted}\)</span>. I chose this slice because it is the paper’s canonical cross-model summary and directly exposes explicit non-attempt behavior.</p>
<p><strong>AbstentionBench (Kirichenko et al., 2025).</strong> The table uses all model rows from Appendix D Table 4 (20 models). The paper reports <strong>Average Accuracy</strong> and <strong>Average Abstention Recall</strong>. I set <span class="math inline">\(p_{a,\%} = \text{Average Abstention Recall}\)</span>, interpret <span class="math inline">\(100-p_a\)</span> as an attempt-like rate, and construct <span class="math display">\[
p_s \approx \text{AvgAcc}\cdot(1-p_a),\qquad
p_f \approx (1-\text{AvgAcc})\cdot(1-p_a),
\]</span> all expressed in percent. This is not a literal per-question abstain rate; it’s a mapping for geometric intuition using the only aggregate abstention signal reported in the table.</p>
<p><strong>Abstain-QA (Madhusudhan et al., 2024).</strong> This is a deliberate subset, not all values in the paper: I take the <strong>MMLU / Standard clause / Base</strong> rows (5 models) from the main result table. The paper reports <strong>AAC</strong> (answerable accuracy) and <strong>AR</strong> (abstention rate). I set <span class="math inline">\(p_{a,\%}=\text{AR}\)</span> and construct <span class="math inline">\(p_{s,\%}\)</span> and <span class="math inline">\(p_{f,\%}\)</span> by treating AAC as attempt-conditional accuracy: <span class="math display">\[
p_s = \text{AAC}\cdot(1-p_a),\qquad
p_f = (1-\text{AAC})\cdot(1-p_a),
\]</span> all expressed in percent.</p>
<p><strong>Important comparability caveats.</strong> Even after mapping all results into <span class="math inline">\((p_s,p_f,p_a)\)</span> coordinates, the underlying tasks and abstention metrics differ: SimpleQA is short-form factual QA with optional non-attempts, AbstentionBench is an abstention-focused multi-scenario benchmark with recall-style abstention metrics, and Abstain-QA is multiple-choice QA with an explicit IDK/NOTA option. So the combined table is useful for geometric intuition and directional comparisons, but not for strict leaderboard ranking across benchmarks.</p>
<p>Sources: ¹ <a href="https://arxiv.org/pdf/2411.04368">SimpleQA: Measuring short-form factuality in large language models</a><br>
² <a href="https://arxiv.org/html/2506.09038v1">AbstentionBench: Reasoning LLMs Fail on Unanswerable Questions</a><br>
³ <a href="https://arxiv.org/html/2407.16221">Do LLMs Know When to NOT Answer? Investigating Abstention Abilities of Large Language Models</a></p>
</section>
</section>
<section id="appendix-benchmark-points-in-the-simplex" class="level2">
<h2 class="anchored" data-anchor-id="appendix-benchmark-points-in-the-simplex">Appendix: Benchmark Points in the Simplex</h2>
<p>The next three figures plot benchmark observations as points on a Marschak-Machina simplex using a common transformation from the table columns:</p>
<p><span class="math display">\[
p_s = \text{p\_s\_pct}/100,\qquad
p_f = \text{p\_f\_pct}/100,\qquad
p_a = \text{p\_a\_pct}/100.
\]</span></p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="2026-02-26-hallucinations-and-alignment_files/figure-html/unnamed-chunk-4-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<section id="reading-the-simplex-plots" class="level3">
<h3 class="anchored" data-anchor-id="reading-the-simplex-plots">Reading the simplex plots</h3>
<ol type="1">
<li><p>The horizontal axis is <span class="math inline">\(p_s\)</span> (succeed share) and the vertical axis is <span class="math inline">\(p_f\)</span> (fail share). The remaining probability is <span class="math inline">\(p_a=1-p_s-p_f\)</span> (abstain share), so points closer to the diagonal edge have lower abstention.</p></li>
<li><p>Moving down (lower <span class="math inline">\(p_f\)</span>) corresponds to reducing failures; whether that is best depends on how much worse failure is than abstention (<span class="math inline">\(\pi_f\)</span> vs <span class="math inline">\(\pi_a\)</span>).</p></li>
<li><p>The labeled points illustrate that a model can look good under an “answer-everything” regime by pushing <span class="math inline">\(p_a\)</span> toward zero, but that is exactly the regime that a payoff function with a harsh <span class="math inline">\(\pi_f\)</span> would discourage.</p></li>
<li><p>Don’t over-interpret cross-benchmark comparisons: each source defines abstention differently, so these plots are best read as a geometric visualization of tradeoffs, not as a single unified leaderboard.</p></li>
</ol>



</section>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-angelopoulos2021gentle" class="csl-entry" role="listitem">
Angelopoulos, Anastasios N., and Stephen Bates. 2021. <span>“A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification.”</span> <em>arXiv Preprint</em>. <a href="https://doi.org/10.48550/arXiv.2107.07511">https://doi.org/10.48550/arXiv.2107.07511</a>.
</div>
<div id="ref-bartlett2008reject" class="csl-entry" role="listitem">
Bartlett, Peter L., and Marten H. Wegkamp. 2008. <span>“Classification with a Reject Option Using a Hinge Loss.”</span> <em>Journal of Machine Learning Research</em> 9 (59): 1823–40. <a href="https://www.jmlr.org/papers/v9/bartlett08a.html">https://www.jmlr.org/papers/v9/bartlett08a.html</a>.
</div>
<div id="ref-blackwell1953equivalent" class="csl-entry" role="listitem">
Blackwell, David. 1953. <span>“Equivalent Comparisons of Experiments.”</span> <em>The Annals of Mathematical Statistics</em> 24 (2): 265–72. <a href="https://doi.org/10.1214/aoms/1177729032">https://doi.org/10.1214/aoms/1177729032</a>.
</div>
<div id="ref-chow1970optimum" class="csl-entry" role="listitem">
Chow, C. K. 1970. <span>“On Optimum Recognition Error and Reject Tradeoff.”</span> <em>IEEE Transactions on Information Theory</em>. <a href="https://doi.org/10.1109/TIT.1970.1054406">https://doi.org/10.1109/TIT.1970.1054406</a>.
</div>
<div id="ref-elyaniv2010selective" class="csl-entry" role="listitem">
El-Yaniv, Ran, and Yair Wiener. 2010. <span>“On the Foundations of Noise-Free Selective Classification.”</span> <em>Journal of Machine Learning Research</em> 11 (53): 1605–41. <a href="https://www.jmlr.org/papers/v11/el-yaniv10a.html">https://www.jmlr.org/papers/v11/el-yaniv10a.html</a>.
</div>
<div id="ref-geifman2019selectivenet" class="csl-entry" role="listitem">
Geifman, Yonatan, and Ran El-Yaniv. 2019. <span>“SelectiveNet: A Deep Neural Network with an Integrated Reject Option.”</span> In <em>Proceedings of the 36th International Conference on Machine Learning</em>, 97:2151–59. Proceedings of Machine Learning Research. <a href="https://proceedings.mlr.press/v97/geifman19a.html">https://proceedings.mlr.press/v97/geifman19a.html</a>.
</div>
<div id="ref-gneiting2007scoring" class="csl-entry" role="listitem">
Gneiting, Tilmann, and Adrian E. Raftery. 2007. <span>“Strictly Proper Scoring Rules, Prediction, and Estimation.”</span> <em>Journal of the American Statistical Association</em> 102 (477): 359–78. <a href="https://doi.org/10.1198/016214506000001437">https://doi.org/10.1198/016214506000001437</a>.
</div>
<div id="ref-herbei2006reject" class="csl-entry" role="listitem">
Herbei, Radu, and Marten H. Wegkamp. 2006. <span>“Classification with Reject Option.”</span> <em>The Canadian Journal of Statistics</em> 34 (4): 709–21. <a href="https://doi.org/10.1002/cjs.5550340410">https://doi.org/10.1002/cjs.5550340410</a>.
</div>
<div id="ref-kadavath2022mostly" class="csl-entry" role="listitem">
Kadavath, Saurav, Tom Conerly, Amanda Askell, Tom Henighan, Dawn Drain, Ethan Perez, Nicholas Schiefer, et al. 2022. <span>“Language Models (Mostly) Know What They Know.”</span> <em>arXiv Preprint</em>. <a href="https://doi.org/10.48550/arXiv.2207.05221">https://doi.org/10.48550/arXiv.2207.05221</a>.
</div>
<div id="ref-kalai2025why" class="csl-entry" role="listitem">
Kalai, Adam Tauman, Ofir Nachum, Santosh S. Vempala, and Edwin Zhang. 2025. <span>“Why Language Models Hallucinate.”</span> <em>arXiv Preprint</em> arXiv:2509.04664 (September). <a href="https://doi.org/10.48550/arXiv.2509.04664">https://doi.org/10.48550/arXiv.2509.04664</a>.
</div>
<div id="ref-shafer2008conformal" class="csl-entry" role="listitem">
Shafer, Glenn, and Vladimir Vovk. 2008. <span>“A Tutorial on Conformal Prediction.”</span> <em>Journal of Machine Learning Research</em> 9 (12): 371–421. <a href="https://www.jmlr.org/papers/v9/shafer08a.html">https://www.jmlr.org/papers/v9/shafer08a.html</a>.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("tecunningham\.github\.io");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>