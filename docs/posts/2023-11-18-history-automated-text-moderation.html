<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.357">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Tom Cunningham">
<meta name="dcterms.date" content="2023-11-18">
<meta name="description" content="Tom Cunningham blog">

<title>The History of Automated Text Moderation | Tom Cunningham</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

<script type="text/javascript">

(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-12027453-1', 'auto');

ga('send', {
  hitType: 'pageview',
  'anonymizeIp': true,
});
</script>


<link rel="stylesheet" href="../styles.css">
<meta name="twitter:title" content="The History of Automated Text Moderation | Tom Cunningham">
<meta name="twitter:description" content="">
<meta name="twitter:card" content="summary">
</head>

<body class="floating nav-fixed slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Tom Cunningham</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href=".././about.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/testingham" rel="" target=""><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/tom-cunningham-a9433/" rel="" target=""><i class="bi bi-linkedin" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://tecunningham.github.io/index.xml" rel="" target=""><i class="bi bi-rss-fill" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://scholar.google.com/citations?user=MDB_DgkAAAAJ" rel="" target="">
 <span class="menu-text">scholar</span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">The History of Automated Text Moderation</h1>
                      </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p><a href="https://integrityinstitute.org/">Integrity Institute</a> collaborators: <a href="https://www.linkedin.com/in/alexrosenblatt/">Alex Rosenblatt</a>, <a href="https://www.linkedin.com/in/jeff-allen-scientist/">Jeff Allen</a>, <a href="https://www.linkedin.com/in/ejona-varangu/">Ejona Varangu</a>, <a href="https://www.linkedin.com/in/davesullivan41/">Dave Sullivan</a>, Tom Cunningham </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">November 18, 2023</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul class="collapse">
  <li><a href="#keywords" id="toc-keywords" class="nav-link active" data-scroll-target="#keywords">(1) Keywords</a></li>
  <li><a href="#simple-classifier-bag-of-words" id="toc-simple-classifier-bag-of-words" class="nav-link" data-scroll-target="#simple-classifier-bag-of-words">(2) Simple classifier (“Bag of words”)</a></li>
  <li><a href="#embedding-based-classifier-2013-2018" id="toc-embedding-based-classifier-2013-2018" class="nav-link" data-scroll-target="#embedding-based-classifier-2013-2018">(3) Embedding-based classifier (2013-2018)</a></li>
  <li><a href="#llm-based-classifiers-2018-2023" id="toc-llm-based-classifiers-2018-2023" class="nav-link" data-scroll-target="#llm-based-classifiers-2018-2023">(4) LLM-based classifiers (2018-2023)</a></li>
  <li><a href="#zero-shot-llms-2023-" id="toc-zero-shot-llms-2023-" class="nav-link" data-scroll-target="#zero-shot-llms-2023-">(5) Zero-shot LLMs (2023-)</a></li>
  <li><a href="#discussion" id="toc-discussion" class="nav-link" data-scroll-target="#discussion">Discussion</a></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
    </div>
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full" id="quarto-document-content">




<style>
    h1 {  border-bottom: 4px solid black;  }
    h2 {  border-bottom: 1px solid #ccc;}
</style>
<p><span style="background:yellow;">==Still a draft: not ready for general circulation.==</span> </p>
<p><strong>This document describes five technologies for automated text moderation,</strong> each roughly correspond to an historical phase.</p>
<p><strong>As a working example we will use the detection of “toxic” comments.</strong> In practice many different definitions of “toxic” have been used in the industry, and there are a variety of related concepts, e.g.&nbsp;“hate speech” and “offensive”.</p>
<section id="keywords" class="level1">
<h1>(1) Keywords</h1>
<p>The simplest technology is to hard-code a list of words which are considered “toxic”, e.g.&nbsp;a list of curse words. This can be implemented with regular expression. This has obvious limits on the accuracy and cannot be easily maintained, however many platforms still maintain a keyword block list for some sensitive terms.</p>
</section>
<section id="simple-classifier-bag-of-words" class="level1">
<h1>(2) Simple classifier (“Bag of words”)</h1>
<p>We can collect a large set of human-labeled data on whether individual messages are toxic, and then predict toxicity from the appearance of individual words e.g.&nbsp;using logistic regression or naive Bayes. These classifiers will find that certain words are highly predictive of toxicity. Simple classifiers often have reasonable accuracy but will have many important false positives and false negatives, and they are easy to evade by rewording or misspelling text.</p>
<ul>
<li>1961: Maron (1961) proposes the Naive Bayes classifier</li>
</ul>
</section>
<section id="embedding-based-classifier-2013-2018" class="level1 page-columns page-full">
<h1>(3) Embedding-based classifier (2013-2018)</h1>
<p>These models have two stages:</p>
<ol type="1">
<li>Pretrain: for each word calculate an embedding (a vector of numbers) which predicts its likelihood of co-occurring with other words. Pairs of words which are nearby in embedding-space typically have similar meanings.</li>
<li>Train: train a model to predict toxicity of a comment using the embedding of the words in a message (e.g.&nbsp;the average embedding).</li>
</ol>
<p>An advantage over simple classifiers is that these models require much less labeled data for an equal performance, because the pre-training stage has already learned (crudely) the meanings of different words. Thus these models can identify words that are diagnostic of toxicity even if they never appeared in the toxicity training set.</p>
<p>However embedding-based classifiers are still bad at edge cases, e.g.&nbsp;when a word is used inside a negation (“is an idiot” vs “is not an idiot”), or if a word is mis-spelt, or if harmless words are used to express an meaning that is toxic (“your brain is a bowl of jello”).</p>
<ul>
<li>2013: Word2Vec: a word embedding using a 2-layer neural network, (<span class="citation" data-cites="mikolov2013efficient">Mikolov et al. (<a href="#ref-mikolov2013efficient" role="doc-biblioref">2013</a>)</span>)</li>
<li>2014: GloVe: Global Vectors for Word Representation. They say “training is performed on aggregated global word-word co-occurrence statistics from a corpus” (<span class="citation" data-cites="pennington2014glove">Pennington, Socher, and Manning (<a href="#ref-pennington2014glove" role="doc-biblioref">2014</a>)</span>).</li>
<li>2015: fastText: word embedding from FAIR. They released pre-trained models for 294 languages (<span class="citation" data-cites="joulin2016bag">Joulin et al. (<a href="#ref-joulin2016bag" role="doc-biblioref">2016</a>)</span>)</li>
<li>2017: Jigsaw Perspective Toxicity API v1 from Google.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></li>
</ul>
<div class="no-row-height column-margin column-container"><li id="fn1"><p><sup>1</sup>&nbsp;I couldn’t find any authoritative documentation on the architecture of this classifier: I found one reference to it using the GloVe embeddings.</p></li></div></section>
<section id="llm-based-classifiers-2018-2023" class="level1">
<h1>(4) LLM-based classifiers (2018-2023)</h1>
<p>These models have three stages:</p>
<ol type="1">
<li>Embedding: Compute embedding of each token (a token is roughly equal to a word).</li>
<li>Pretrain: Train a deep neural net to predict a token from surrounding tokens (or prior tokens), using attention (i.e.&nbsp;don’t weight all words equally) on an enormous training set of text from books and the internet.</li>
<li>Train: Train a model to predict toxicity from labeled data using the top-level neurons in the net as features.</li>
</ol>
<p>Conceptually these are similar to embeddings but (1) they can represent the meaning of entire sentences instead of just words, (2) have more layers so tend to have more sophisticated representations of meaning.</p>
<ul>
<li>2017: Transformer architecture (<span class="citation" data-cites="vaswani2017attention">Vaswani et al. (<a href="#ref-vaswani2017attention" role="doc-biblioref">2017</a>)</span>)</li>
<li>2018: BERT transformer LLM, this model has been widely used as base model for a variety of natural language tasks, including content moderation (<span class="citation" data-cites="devlin2018bert">Devlin et al. (<a href="#ref-devlin2018bert" role="doc-biblioref">2018</a>)</span>)</li>
</ul>
</section>
<section id="zero-shot-llms-2023-" class="level1">
<h1>(5) Zero-shot LLMs (2023-)</h1>
<p>These models have three stages:</p>
<ol type="1">
<li>Embedding: Compute the embedding of each token.</li>
<li>Pretrain: Train a deep net to predict the next token from previous tokens, as above.</li>
<li>Directly ask the model whether a given message violates a given policy, e.g.&nbsp;“is the following sentence toxic? ___”</li>
</ol>
<p>Notably this method does not use any human-labeled data, it only needs to be told what type of text it is looking for. This is referred to as “zero shot”, meaning it needs zero training data. These models can also use “few shot” learning, where a small number of examples are given instead of the thousands of examples that had ordinarily been used.</p>
<p>This has big benefits: it allows you to very quickly refine policy, and the LLM can generate explanations for why it made a decision.</p>
<ul>
<li>2020: GPT-3: reasonable zero-shot performance (<span class="citation" data-cites="brown2020language">Brown et al. (<a href="#ref-brown2020language" role="doc-biblioref">2020</a>)</span>)</li>
<li>2022: ChatGPT published: very good zero-shot performance on many tasks.</li>
<li>2023: OpenAI provides GPT-4-based content moderation tools (<span class="citation" data-cites="weng2023gpt4moderation">Weng, Goel, and Vallone (<a href="#ref-weng2023gpt4moderation" role="doc-biblioref">2023</a>)</span>)</li>
<li>2023: <a href="https://www.safetykit.com">SafetyKit</a>, <a href="https://www.checkstep.com/blog/">CheckStep</a> provide LLM-based content-moderation.</li>
<li>2023: Stanford CoPE:an open-source LLM for moderation.</li>
</ul>
</section>
<section id="discussion" class="level1">
<h1>Discussion</h1>
<p><strong>Q: now that we can use LLMs for arbitrary labeling, will we change policies?</strong></p>
<ul>
<li>Proposals are coming out of Michael Bernstein’s lab, e.g. <span class="citation" data-cites="jia2023embedding">Jia et al. (<a href="#ref-jia2023embedding" role="doc-biblioref">2023</a>)</span>.</li>
<li>Dave Wilner has argued that because LLMs offer much greater flexibility then platforms will find it easier to write more complex policies and update them more frequently.</li>
</ul>
<p><strong>Q: what do we know about degree of accuracy across languages?</strong></p>
<ul>
<li>AI typically has a strong anglophone bias. Performance in non-English languages tends to be proportional to the distance from English, e.g.&nbsp;European languages tend to be worse.</li>
<li>Many noted that there is also a large bias in human systems.</li>
<li>An open question: how to define appropriate moderation standards across languages.</li>
<li>Some literature shows that LLMs have good performance in languages with relatively little training data, e.g. <span class="citation" data-cites="armengolestape2021multilingual">Armengol-Estapé, Gibert Bonet, and Melero (<a href="#ref-armengolestape2021multilingual" role="doc-biblioref">2021</a>)</span>. </li>
</ul>
<p><strong>Q: will censorship change when using LLMs instead of humans?</strong></p>
<ul>
<li>Jeff: an advantage of human censors over machine censors is that humans might exercise their judgment to refuse to censor, while machines will not.</li>
</ul>



</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" role="list">
<div id="ref-armengolestape2021multilingual" class="csl-entry" role="listitem">
Armengol-Estapé, Jordi, Ona de Gibert Bonet, and Maite Melero. 2021. <span>“On the Multilingual Capabilities of Very Large-Scale English Language Models.”</span> <a href="https://arxiv.org/abs/2108.13349">https://arxiv.org/abs/2108.13349</a>.
</div>
<div id="ref-brown2020language" class="csl-entry" role="listitem">
Brown, Tom B., Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, et al. 2020. <span>“Language Models Are Few-Shot Learners.”</span> <a href="https://arxiv.org/abs/2005.14165">https://arxiv.org/abs/2005.14165</a>.
</div>
<div id="ref-devlin2018bert" class="csl-entry" role="listitem">
Devlin, Jacob, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. <span>“Bert: Pre-Training of Deep Bidirectional Transformers for Language Understanding.”</span> <em>arXiv Preprint arXiv:1810.04805</em>.
</div>
<div id="ref-jia2023embedding" class="csl-entry" role="listitem">
Jia, Chenyan, Michelle S Lam, Minh Chau Mai, Jeff Hancock, and Michael S Bernstein. 2023. <span>“Embedding Democratic Values into Social Media AIs via Societal Objective Functions.”</span> <em>arXiv Preprint arXiv:2307.13912</em>.
</div>
<div id="ref-joulin2016bag" class="csl-entry" role="listitem">
Joulin, Armand, Edouard Grave, Piotr Bojanowski, and Tomas Mikolov. 2016. <span>“Bag of Tricks for Efficient Text Classification.”</span> <a href="https://arxiv.org/abs/1607.01759">https://arxiv.org/abs/1607.01759</a>.
</div>
<div id="ref-mikolov2013efficient" class="csl-entry" role="listitem">
Mikolov, Tomas, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. <span>“Efficient Estimation of Word Representations in Vector Space.”</span> <a href="https://arxiv.org/abs/1301.3781">https://arxiv.org/abs/1301.3781</a>.
</div>
<div id="ref-pennington2014glove" class="csl-entry" role="listitem">
Pennington, Jeffrey, Richard Socher, and Christopher D. Manning. 2014. <span>“GloVe: Global Vectors for Word Representation.”</span> In <em>Empirical Methods in Natural Language Processing (EMNLP)</em>, 1532–43. <a href="http://www.aclweb.org/anthology/D14-1162">http://www.aclweb.org/anthology/D14-1162</a>.
</div>
<div id="ref-vaswani2017attention" class="csl-entry" role="listitem">
Vaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. <span>“Attention Is All You Need.”</span> <em>Advances in Neural Information Processing Systems</em> 30.
</div>
<div id="ref-weng2023gpt4moderation" class="csl-entry" role="listitem">
Weng, Lilian, Vik Goel, and Andrea Vallone. 2023. <span>“Using GPT-4 for Content Moderation.”</span> <a href="https://openai.com/blog/using-gpt-4-for-content-moderation">https://openai.com/blog/using-gpt-4-for-content-moderation</a>.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>