<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.357">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Tom Cunningham">
<meta name="dcterms.date" content="2023-08-25">
<meta name="description" content="Tom Cunningham blog">

<title>Will LLMs Write Super-Persuasive Propaganda? | Tom Cunningham</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

<script type="text/javascript">

(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-12027453-1', 'auto');

ga('send', {
  hitType: 'pageview',
  'anonymizeIp': true,
});
</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../styles.css">
<meta name="twitter:title" content="Will LLMs Write Super-Persuasive Propaganda? | Tom Cunningham">
<meta name="twitter:description" content="">
<meta name="twitter:image" content="tecunningham.github.io/posts/2023-08-22-ceiling-on-ai-performance-persuasion_files/figure-html/unnamed-chunk-1-1.png">
<meta name="twitter:image-height" content="477">
<meta name="twitter:image-width" content="477">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="floating nav-fixed slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Tom Cunningham</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href=".././about.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/testingham" rel="" target=""><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/tom-cunningham-a9433/" rel="" target=""><i class="bi bi-linkedin" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://scholar.google.com/citations?user=MDB_DgkAAAAJ" rel="" target="">
 <span class="menu-text">scholar</span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Will LLMs Write Super-Persuasive Propaganda?</h1>
                      </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Tom Cunningham </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">August 25, 2023</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul class="collapse">
  <li><a href="#summary" id="toc-summary" class="nav-link active" data-scroll-target="#summary">Summary</a></li>
  <li><a href="#setup" id="toc-setup" class="nav-link" data-scroll-target="#setup">Setup</a></li>
  <li><a href="#plain-llms-will-not-exhibit-superhuman-performance" id="toc-plain-llms-will-not-exhibit-superhuman-performance" class="nav-link" data-scroll-target="#plain-llms-will-not-exhibit-superhuman-performance">Plain LLMs Will Not Exhibit Superhuman Performance</a></li>
  <li><a href="#paths-to-superhuman-performance" id="toc-paths-to-superhuman-performance" class="nav-link" data-scroll-target="#paths-to-superhuman-performance">Paths to Superhuman Performance</a>
  <ul class="collapse">
  <li><a href="#iterative-testing" id="toc-iterative-testing" class="nav-link" data-scroll-target="#iterative-testing">Iterative Testing</a></li>
  <li><a href="#self-play" id="toc-self-play" class="nav-link" data-scroll-target="#self-play">Self-Play</a></li>
  <li><a href="#supervised-learning" id="toc-supervised-learning" class="nav-link" data-scroll-target="#supervised-learning">Supervised Learning</a></li>
  </ul></li>
  <li><a href="#empirical-studies-on-persuasive-content" id="toc-empirical-studies-on-persuasive-content" class="nav-link" data-scroll-target="#empirical-studies-on-persuasive-content">Empirical Studies on Persuasive Content</a></li>
  <li><a href="#other-applications" id="toc-other-applications" class="nav-link" data-scroll-target="#other-applications">Other Applications</a></li>
  <li><a href="#additional-material" id="toc-additional-material" class="nav-link" data-scroll-target="#additional-material">Additional Material</a></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
    </div>
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full" id="quarto-document-content">




<style>
    h1 {  border-bottom: 4px solid black; }
    h2 {  border-bottom: 1px solid gray; padding-bottom: 0px; color: black; }
    /* font-size: 14px;  */
</style>
<p><span style="background:yellow;">==<em>Still a draft, don’t circulate!</em>==</span></p>
<section id="summary" class="level1">
<h1>Summary</h1>
<p><strong>Are LLMs likely to create superhumanly persuasive text?</strong> Will LLMs be able to write messages more persuasive than those written by professional copywriters, e.g.&nbsp;messages persuading you to click on a link, buy a product, or vote for a candidate.</p>
<p><strong>The same question applies to many other areas.</strong> Should we expect AI models to overtake us and write super-evocative prose, super-accurate diagnoses, super-creative proofs, super-groovy music, super-beautiful paintings?</p>
<p><strong>The current architecture of LLMs is unlikely to create super-persuasive text.</strong> Speaking loosely LLMs respond to a prompt by imitating how a human would respond to that prompt. Thus if you ask an LLM to write persuasive text it will write <em>averagely</em> persuasive text: even if it could write super-persuasive text it would not want to because that is not what a human would write.</p>
<p><strong>However changes to architecture could conceivably lead to super-persuasive text.</strong> Specifically:</p>
<ol type="1">
<li><strong>Iteration.</strong> Generating multiple variants and iteratively testing them for persuasiveness could help isolate the most persuasive variants. I am skeptical this would be a substantial improvement at least for text.</li>
<li><strong>Self-play.</strong> Using the LLM weights in a variety of indirect ways might help discover which texts are most persuasive. It is hard to judge how effective this will be.</li>
<li><strong>Supervised learning.</strong> Using datasets of real-world persuasiveness of text to train a model directly. With this approach it seems plausible that we would uncover pockets of persuasiveness not yet explored by humans.</li>
</ol>
<p><strong>It is unclear whether super-persuasive messages exist.</strong> We know that some messages are more persuasive than others but it is hard to know how much higher we can go. It’s possible that the most persuasive writers today are already close to the ceiling.</p>
</section>
<section id="setup" class="level1 page-columns page-full">
<h1>Setup</h1>
<p><strong>We are interested in the persuasive effect of a single short piece of text,</strong> e.g.:</p>
<ul>
<li>Effectiveness of an email in making people open an attached file.</li>
<li>Effectiveness of a tweet in making people buy a crypto coin.</li>
<li>Effectiveness of a blog post in making people vote for Ron DeSantis.</li>
</ul>
<div class="page-columns page-full"><p><strong>The persuasiveness of text is relative to some audience and some provenance.</strong> The same message will have a effect on your decisions depending on whether you think it comes from your sister or an old acquaintance. For concreteness assume the audience is the average American adult and they receive the message unsolicited from a stranger.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p><div class="no-row-height column-margin column-container"><li id="fn1"><p><sup>1</sup>&nbsp;To reach the audience the message has to survive a series of spam filters and ranking algorithms.</p></li></div></div>
<div class="page-columns page-full"><p><strong>Formal definition.</strong> We can think of a function <span class="math inline">\(p(t)\)</span>, where <span class="math inline">\(t\)</span> represents a piece of text, and <span class="math inline">\(p(.)\)</span> is the persuasive power: precisely, the average person’s probability of performing some action after seeing that text. The function <span class="math inline">\(p(t)\)</span> will be basically flat for almost all values of <span class="math inline">\(t\)</span> because in the space of all possible sentences more are meaningless or irrelevant and so likely to have infinitesimal effects on persuasion.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></p><div class="no-row-height column-margin column-container"><li id="fn2"><p><sup>2</sup>&nbsp;The space </p></li></div></div>
<p><strong>I’m setting aside many related questions.</strong> I will not consider (1) AI maintaining a conversation (chatbots, catfishing, pig butchering); (2) AI sending customized messages based on the respondent’s demographics; (3) AI choosing who to send messages to, based on predicted persuadability; (4) AI sending messages repeatedly to increase persuasion.For each of these cases it seems unlikely that AIs could be super-humanly persuasive without also being super-humanly persuasive in the base case of creating a single message. However I don’t think this applies to AI synthesizing recorded media (photo, audio, video): computers have already far superpassed human ability in synthesizing or altering recorded media to fit a given criteria, and so the situation is qualitatively different. Discussion of the persuasiveness of synthetic media involves the role of a recording as evidence that some event happened: we should expect the evidence-value to decline as artificially synthesized media becomes more prevalent.</p>
<p><strong>We want to compare persuasiveness of text created by different types of authors.</strong></p>
<ul>
<li><p>Human: subject in psychology experiment (e.g.&nbsp;undergraduate, mechanical turk)</p></li>
<li><p>Human: employee of influence operation (e.g.&nbsp;Internet Research Agency, pig butcher)</p></li>
<li><p>Human: professional copywriter (e.g.&nbsp;marketing professional)</p></li>
<li><p>Computer: LLM in 2023 (e.g.&nbsp;GPT-4)</p></li>
<li><p>Computer: LLM in 2025</p></li>
</ul>
<div class="page-columns page-full"><p><strong>There is substantial variation in human ability to write persuasive copy.</strong> Copywriters are hired for their ability to come up with text that makes people perform an action, i.e.&nbsp;they are hired for their knowledge of the function <span class="math inline">\(p(.)\)</span>, and it seems there must be substantial variation in individual ability: some people are better than others at writing persuasive slogans.<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></p><div class="no-row-height column-margin column-container"><li id="fn3"><p><sup>3</sup>&nbsp;From the <a href="https://www.awai.com/about/celebrating-clayton-makepeace/">obituary of a famous direct-marketing copywriter</a>: “When you read some of the greatest and most iconic headlines in copywriting history — such as, “7 HORSEMEN of the Coming STOCK MARKET APOCALYPSE” … “Shameless Two-Faced S.O.B.s!” … and, “Health Breakthrough News — Cholesterol’s EVIL TWIN”— smile and think to yourself, ‘Clayton Makepeace wrote that.’”</p></li></div></div>
<p> </p>
<p><strong>Social scientists have warned about hyper-persuasion many times in the last century.</strong> In the past 100 years there have been a dozen apparent discoveries of hyper-effective means of persuasion. In retrospect I think it’s fair to say they were mostly or all exaggerated: whether based on subconscious associations (Bernays), conditioning (Skinner), subliminal messages (Packard), brainwashing (Sargant), the power of conformity (Adorno, Asch, Zimbardo), priming and nudges (Bargh, Thaler), or statistical profiling (Cambridge Analytica).</p>
</section>
<section id="plain-llms-will-not-exhibit-superhuman-performance" class="level1 page-columns page-full">
<h1>Plain LLMs Will Not Exhibit Superhuman Performance</h1>
<div class="page-columns page-full"><p><strong>In short: LLMs don’t perform tasks, they imitate humans performing tasks.</strong> Loosely speaking LLMs are trained to predict the next word based on a corpus of text: they are imitating the natural structure of human text. If we ask an LLM to create a persuasive message it will try to imitate a human, thus if it is doing a good job it would only ever create a super-humanly persuasive message by accident.<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a></p><div class="no-row-height column-margin column-container"><li id="fn4"><p><sup>4</sup>&nbsp;Reminiscent of Lichtenberg on writers: <em>“The critics instruct us to stay close to nature, and authors read this advice; but they always think it safer to stay close to authors who have stayed close to nature.”</em></p></li></div></div>
<div class="page-columns page-full"><p><strong>Consider an LLM trained solely to predict the next word on a text corpus.</strong> For now assume no other tuning.<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a></p><div class="no-row-height column-margin column-container"><li id="fn5"><p><sup>5</sup>&nbsp;This was the basic model used by OpenAI’s GPT series of models until chat-GPT.</p></li></div></div>
<div class="cell page-columns page-full" data-hash="2023-08-22-ceiling-on-ai-performance-persuasion_cache/html/unnamed-chunk-1_9919dd3799e3bc7591b2104dc465ce48">

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<p><img src="2023-08-22-ceiling-on-ai-performance-persuasion_files/figure-html/unnamed-chunk-1-1.png" class="img-fluid" width="672"></p>
</div></div></div>
<p><strong>Consider the set of all possible questions.</strong> We can draw a Venn diagram (at right) showing the relationship between the questions that the LLM can answer accurately, and the sets that individual humans can answer. I will talk about “questions” but we can equally talk about “tasks”. For simplicity I will just consider two humans, Tom and Dick.</p>
<p><strong>The LLM will not be a subset of any individual human.</strong> We know that LLMs can answer questions with an encylopedic range and across different languages, i.e.&nbsp;beyond the range of any single person.</p>
<p><strong>For factual questions the LLM will be inside the union of the humans.</strong> Suppose we consider a set of factual questions, where the answer to each question is independent of the others, e.g.&nbsp;the number of chromosones a specific animal has, or the number of moons belonging to a given planet. An LLM can only answer the questions which it has read.</p>
<div class="cell page-columns page-full" data-hash="2023-08-22-ceiling-on-ai-performance-persuasion_cache/html/unnamed-chunk-2_5d0f98d923528ac3865a73e6c85dcaf8">

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<p><img src="2023-08-22-ceiling-on-ai-performance-persuasion_files/figure-html/unnamed-chunk-2-1.png" class="img-fluid" width="672"></p>
</div></div></div>
<p><strong>There are some questions which an LLM can answer that no human can answer.</strong> Some examples:</p>
<ul>
<li>An LLM can translate between any pair of languages. Presumably there are many pairs of languages for which there is no human who speaks both, and so nobody could translate from one to the other.</li>
<li>An LLM can combine distinct pieces of information.</li>
</ul>
<p><strong>For well-defined logical questions computers encompass humans.</strong></p>
</section>
<section id="paths-to-superhuman-performance" class="level1 page-columns page-full">
<h1>Paths to Superhuman Performance</h1>
<section id="iterative-testing" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="iterative-testing">Iterative Testing</h2>
<p><strong>In practice people are likely to generate multiple candidates, test each in the field, and choose the highest-performing variant.</strong> However this would only change our conclusion about super-human persuasiveness if the distribution of persuasiveness is different between human-generated and computer-generated text.</p>
<p>Suppose we can generate arbitrarily many passages of text <span class="math inline">\(t_1,\ldots,t_n\)</span>, and the persuasiveness of each text is represented by <span class="math inline">\(p_1,\ldots,p_n\)</span>. It’s safe to assume that there will be diminishing returns in persuasiveness (<span class="math inline">\(E[p_{n+1}]&lt;E[p_n]\)</span>), both for human-generated and computer-generated text, however as long as there is some variance in persuasiveness then iterative testing will be worthwhile. Suppose that the first or most-promising generation of both a human and a computer are equally persuasive on average (<span class="math inline">\(E[p_1^H]=E[p_1^C]\)</span>).</p>
<div class="cell page-columns page-full" data-hash="2023-08-22-ceiling-on-ai-performance-persuasion_cache/html/unnamed-chunk-3_b0662a3221d8c32e0944bbee10cce7c9">

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="2023-08-22-ceiling-on-ai-performance-persuasion_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">caption</figcaption>
</figure>
</div>
</div></div></div>
<p><strong>The persuasiveness of computer-generated copy could be higher after the iterative process for one of two reasons.</strong> Both of these questions are open to testing, unfortunately I’m not aware of any empirical literature on either of these questions.</p>
<p><strong>(1) If computer-generated text has higher variance.</strong> <span class="math inline">\(V[p_n^H]&lt;V[p_n^C]\)</span>. The returns to exploration will increase in the variance of the outputs (holding fixed the mean), and likewise the expected persuasiveness of the ultimately selected alternative will be higher.</p>
<p>I am skeptical that computer-generated text will have higher variance of persuasiveness than human-generated text. A common observation about LLMs is that they are less creative than humans at the same task. Variance can be increased by adjusting parameters of the model, e.g.&nbsp;generating lower-probability tokens by setting a higher temperature, but this will very likely decrease the average persuasiveness.</p>
<p>A more subtle point is the covariance of persuasiveness between each element in the sequence. If an LLM generated minor variations on the same basic pattern then we would expect high covariance between texts and consequently relatively lower returns to iterative selection.</p>
<p><strong>(2) If computer-generated text has flatter returns.</strong> <span class="math inline">\(\frac{E[p_{n+1}^H]}{E[p_{n}^H]}&lt;\frac{E[p_{n+1}^C]}{E[p_{n}^C]}\)</span>.</p>
<p>An LLM can generate hundreds of candidate texts at almost no time or costlessly, while a human .</p>
</section>
<section id="self-play" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="self-play">Self-Play</h2>
<div class="page-columns page-full"><p>Suppose that LLMs can create only averagely competent persuasive material: still there’s the possibility of improving it by iterative improvement: e.g.&nbsp;find a cluster of questions along the lines of “is this persuasive?”<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a></p><div class="no-row-height column-margin column-container"><li id="fn6"><p><sup>6</sup>&nbsp;Thanks to Grady Ward for this suggestion.</p></li></div></div>
<p>Precedents from self-play in chess and Go. Analogy: palindrome, or playing a rubik’s cube. There is good reason to expect that LLMs will expand the frontier of mathematical reasoning through this ability. (Chain of thought, tree of thought, graph of thought).</p>
<p>It’s very difficult to create in one-shot, but could imagine an iterative solution.</p>
</section>
<section id="supervised-learning" class="level2">
<h2 class="anchored" data-anchor-id="supervised-learning">Supervised Learning</h2>
<p>In some cases we have large datasets with the ground truth of how persuasive a message is. E.g. Facebook databases have records of every ad impression and whether the user clicked (around 1 trillion/month). This is of sufficient scale that we could directly synthesize ads which the user is highly likely to click and there’s no reason for there to be a ceiling.</p>
</section>
</section>
<section id="empirical-studies-on-persuasive-content" class="level1">
<h1>Empirical Studies on Persuasive Content</h1>
<p><strong>Experiments evaluating the persuasiveness of AI-generated text.</strong> Since 2022 there has been a small literature comparing the persuasiveness of human-generated and computer-generated text, where persuasion is measured by a human survey response before and after reading an article. The studies have all found that LLMs can generate somewhat-persuasive content.</p>
<ul>
<li><span class="citation" data-cites="bai2023persuade">Bai et al. (<a href="#ref-bai2023persuade" role="doc-biblioref">2023</a>)</span></li>
<li><span class="citation" data-cites="goldstein2023persuasive">Goldstein et al. (<a href="#ref-goldstein2023persuasive" role="doc-biblioref">2023</a>)</span></li>
<li><span class="citation" data-cites="hackenburg2023persuasive">Hackenburg and Margetts (<a href="#ref-hackenburg2023persuasive" role="doc-biblioref">2023</a>)</span></li>
<li><span class="citation" data-cites="matz2023personalized">Matz et al. (<a href="#ref-matz2023personalized" role="doc-biblioref">2023</a>)</span></li>
<li><span class="citation" data-cites="palmer2023large">Palmer and Spirling (<a href="#ref-palmer2023large" role="doc-biblioref">2023</a>)</span></li>
<li><span class="citation" data-cites="qin2023large">Qin et al. (<a href="#ref-qin2023large" role="doc-biblioref">2023</a>)</span></li>
</ul>
</section>
<section id="other-applications" class="level1">
<h1>Other Applications</h1>
</section>
<section id="additional-material" class="level1 page-columns page-full">
<h1>Additional Material</h1>
<p>Some have worried that computer-generated content will be more persuasive than even the best human-generated content, for example:</p>
<ul>
<li>Advertisements for Coke might become hypnotically effective, giving you an irresistible desire to drink Coke.</li>
<li>Content generated by influence operations to influence elections might become highly influential.</li>
</ul>
<div class="page-columns page-full"><p><strong>We can make this measurable by predicting the total amount spent on advertising.</strong> If computer-generated ads are more persuasive than human-generated ads then firms should be willing to spend more on each ad, and so the equilibrium price of advertising will rise.<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a>.</p><div class="no-row-height column-margin column-container"><li id="fn7"><p><sup>7</sup>&nbsp;Although the price of ads should increase it is unclear whether the quantity of ads shown would increase or decrease. In a simple model of ad-supported media the equilibrium quantity of advs is determined by (1) the curvature of demand from advertisers, (2) the curvature of disutility from consumers. An increase in the persuasive power of advertising will shift demand up but there’s no clear reason for curvature to change.</p></li></div></div>
<p>In fact ad expenditure has been around 1% of GDP since 1930: https://www.ben-evans.com/presentations <img src="images/2023-07-12-05-36-29.png" class="img-fluid"></p>
<p>We can make some very loose generalizations about human persuadability:</p>
<ol type="1">
<li><p><em>Human attitudes are highly sensitive to influences.</em> A person’s adult attitudes, beliefs, and preferences, are highly sensitive to their upbringing and context: if your parents are Catholic then you are highly likely to grow up Catholic. The same is true for eating fish, enjoying country music, being a Democrat, taking your shoes off inside, and your attitude to sex before marriage. The correlations can only be partly explained by direct genetic or economic effects, implying that attitudes are highly sensitive to experience.</p></li>
<li><p><em>Considerable resources are devoted to persuasion.</em><a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a></p></li>
<li><p><em>The effective means of persuasion are only crudely known.</em> In the past 100 years there have been a dozen apparent discoveries of hyper-effective means of persuasion. In retrospect they were mostly or all exaggerated. Whether using subconscious associations (Bernays), using conditioning (Skinner), using subliminal messages (Packard), using brainwashing (Sargant), using the power of conformity (Adorno, Asch, Zimbardo), using priming and nudges (Bargh, Thaler), or using statistical profiling (Cambridge Analytica).</p></li>
<li><p><em>Carefully measured evidence of persuasive effects tend to be low.</em></p></li>
<li><p>Nevertheless 1/3 of the economy is devoted to persuasion, and attitudes and preferences vary between populations primarily due to social context implying there must be <em>some</em> extra-rational means by which people form their attitudes.</p></li>
</ol>
<div class="no-row-height column-margin column-container"><li id="fn8"><p><sup>8</sup>&nbsp;McCloskey and Klamer have a 1995 paper titled “One Quarter of GDP is Persuasion”.</p></li></div><p>A recent <a href="https://carnegieendowment.org/2021/06/28/measuring-effects-of-influence-operations-key-findings-and-gaps-from-empirical-research-pub-84824">review of the effectiveness of influence operations</a> finds that influence through traditional broadcast media (e.g.&nbsp;Russia Today) probably have a bigger impact than covert campaigns through social media.</p>
<ul>
<li>Expenditure on advertising in the US is around 1% of GDP, and expenditure on political advertising is 0.04% (using $250B on advertising, $10B on political advertising, and $23T GDP).
<ul>
<li><a href="https://martech.org/worldwide-spend-on-marketing-to-hit-4-7-trillion-by-2025/">Estimate US marketing spend of $1.4T/year</a>, 8% of revenue.</li>
<li>Estimate US advertising spend of $250B/year</li>
</ul></li>
</ul>
<p><strong>Progress.</strong> AI models have surpassed humans in many areas (numerical calculation, chess, Go), and are comparable in other areas (recognition of images, writing, speech).</p>



</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" role="list">
<div id="ref-bai2023persuade" class="csl-entry" role="listitem">
Bai, Hui, Jan G Voelkel, johannes C Eichstaedt, and Robb Willer. 2023. <span>“Artificial Intelligence Can Persuade Humans on Political Issues.”</span> OSF Preprints. <a href="https://doi.org/10.31219/osf.io/stakv">https://doi.org/10.31219/osf.io/stakv</a>.
</div>
<div id="ref-goldstein2023persuasive" class="csl-entry" role="listitem">
Goldstein, Josh A, Jason Chao, Shelby Grossman, Alex Stamos, and Michael Tomz. 2023. <span>“Can AI Write Persuasive Propaganda?”</span> SocArXiv. <a href="https://doi.org/10.31235/osf.io/fp87b">https://doi.org/10.31235/osf.io/fp87b</a>.
</div>
<div id="ref-hackenburg2023persuasive" class="csl-entry" role="listitem">
Hackenburg, Kobi, and Helen Margetts. 2023. <span>“Evaluating the Persuasive Influence of Political Microtargeting with Large Language Models.”</span> OSF Preprints. <a href="https://doi.org/10.31219/osf.io/wnt8b">https://doi.org/10.31219/osf.io/wnt8b</a>.
</div>
<div id="ref-matz2023personalized" class="csl-entry" role="listitem">
Matz, Sandra, Jake Teeny, Sumer S Vaid, Gabriella M Harari, and Moran Cerf. 2023. <span>“The Potential of Generative AI for Personalized Persuasion at Scale.”</span> PsyArXiv. <a href="https://doi.org/10.31234/osf.io/rn97c">https://doi.org/10.31234/osf.io/rn97c</a>.
</div>
<div id="ref-palmer2023large" class="csl-entry" role="listitem">
Palmer, Alexis, and Arthur Spirling. 2023. <span>“Large Language Models Can Argue in Convincing and Novel Ways about Politics: Evidence from Experiments and Human Judgement.”</span> Working paper), Technical report.
</div>
<div id="ref-qin2023large" class="csl-entry" role="listitem">
Qin, Zhen, Rolf Jagerman, Kai Hui, Honglei Zhuang, Junru Wu, Jiaming Shen, Tianqi Liu, et al. 2023. <span>“Large Language Models Are Effective Text Rankers with Pairwise Ranking Prompting.”</span> <a href="https://arxiv.org/abs/2306.17563">https://arxiv.org/abs/2306.17563</a>.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>