<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.357">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Tom Cunningham">
<meta name="dcterms.date" content="2017-02-25">
<meta name="description" content="Tom Cunningham blog">

<title>Weber’s Law Doesn’t Imply Concave Representations or Concave Judgments | Tom Cunningham</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

<script type="text/javascript">

(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-12027453-1', 'auto');

ga('send', {
  hitType: 'pageview',
  'anonymizeIp': true,
});
</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../styles.css">
<meta name="twitter:title" content="Weber’s Law Doesn’t Imply Concave Representations or Concave Judgments | Tom Cunningham">
<meta name="twitter:description" content="">
<meta name="twitter:image" content="https://www.dropbox.com/s/24cumup0i7uiksn/runningman.jpg?raw=1">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Tom Cunningham</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href=".././about.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/testingham" rel="" target=""><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/tom-cunningham-a9433/" rel="" target=""><i class="bi bi-linkedin" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://scholar.google.com/citations?user=MDB_DgkAAAAJ" rel="" target="">
 <span class="menu-text">scholar</span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Weber’s Law Doesn’t Imply Concave Representations or Concave Judgments</h1>
                      </div>
  </div>
    
  
  <div class="quarto-title-meta">

      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">February 25, 2017</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://www.dropbox.com/s/24cumup0i7uiksn/runningman.jpg?raw=1" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">runningman</figcaption>
</figure>
</div>
<p><strong>Nutshell.</strong></p>
<ol type="1">
<li>If you spend any time reading about behavioural economics you’ll come across “diminishing sensitivity” pretty soon, applied to all sorts of things in decision-making (probability weighting, value-function weighting, relative thinking), and often you’ll find a reference to “Weber’s law” from psychology.</li>
<li>Weber’s law says that if you can tell the difference between a 1-pound and a 1.2-pound weight 90% of the time, then you will also be able to tell the difference between a 10-pound and 12-pound weight about 90% of the time (and generally, the ability to discriminate between two sensations is a function of the ratio of the magnitudes).</li>
<li>This finding is often interpreted as implying that we have, in some sense, <em>concave</em> representations of value. And indeed this behaviour <em>would</em> be implied by a model in which we receive a signal which is a concave function of the underlying value, plus additive noise.</li>
<li>However Weber’s law would also be seen if we have a linear representation of value with multiplicative noise. And there are good reasons to think that perceptual noise is generally closer to multiplicative than additive (but I leave that for another time).</li>
<li>Also of interest is, given our assumptions about value and noise, how a person’s posteriors look. I.e., what is the average best-guess of the weight of an object, given it’s true weight. I also derive those below (you have to make assumptions about a person’s priors), and show that, under multiplicative noise &amp; lognormal priors, expected weight is concave function of true weight, while under additive noise &amp; uniform priors, expected weight is a linear function of true weight.</li>
<li>In general I think that Weber’s law is <em>not</em> relevant most of the anomalies we see in decision-making. This note doesn’t really tie the knot on that argument, but I think these are useful results going in that direction. (I’m sure these mathematical points must have been made elsewhere but I’ve never been able to find them.)</li>
</ol>
<section id="history." class="level1">
<h1>History.</h1>
<p>Ernst Weber (1795-1878) tested subjects’ ability to discriminate between the strength of sensations - for example two sounds, two shades of light, two intensities of touch - and found that the Just Noticeable Difference (JND) between two sensations tended to be proportional to the average magnitude of the two sensations: e.g., if you can determine which of two lights is brighter with 80% accuracy, then Weber predicts that you will also have 80% accuracy when the brightness of both lights is doubled. Gustav Fechner (1801-1887) showed that, under the assumption that each JND has an equal subjective difference, this implies a logarithmic relationship between objective and subjective magnitude. Later S. S. Stevens (1906-1973) directly asked subjects for cardinal reports of subjective intensity and found a power law relationship (i.e., the logarithmic relation is a special case of this).</p>
</section>
<section id="in-decision-making" class="level1">
<h1>In Decision-Making</h1>
<p>In the 19th century a number of economists made a connection between the Weber-Fechner law and the diminishing marginal utility of consumption. However Max Weber – a different Weber – Weber the sociologist, wrote an essay in 1908 to explain that they are fundamentally distinct phenomena (“Marginal Utility Theory and the Fundamental Law of Psychophysics”). Stigler later wrote about Max Weber’s essay and agreed that there is little meaningful connection.</p>
<p>More recently the Weber-Fechner law has been cited by a number of economists to explain diminishing sensitivity in other domains (not just in absolute consumption): Thaler (1980), Tversky &amp; Kahneman (1992), Thaler (1999), Gonzalez &amp; Wu (1999) all argue that the curvature of a gain/loss function, and of probability-weighting function, are somehow connected with the Weber-Fechner law in perception.</p>
<p>However, I show below that the Weber behaviour (the proportional JND being invariant to scale) does not imply either (A) a concave internal representation of magnitude; or (B) a concave bias in judgment of magnitudes.</p>
<p>(It’s also worth noting that a <em>literal</em> application of Weber’s law to decision-making would be the following: that subjects are equally likely to choose \$7 over \$8, as they are to choose \$70 over \$80. I’m not sure if this has ever been tested, it doesn’t seem like an especially interesting fact for economic decision-making.)</p>
</section>
<section id="webers-law-linear-vs-concave-representations-of-value" class="level1">
<h1>Weber’s Law &amp; Linear vs Concave Representations of Value</h1>
<p>First I show that Weber’s law does not imply that we must have, in some sense, a concave representation of value. I show that the law can be derived from two different setups: one in which we have a linear representation and multiplicative noise; one with a concave representation and additive noise.</p>
<p>Suppose that we can observe subjects’ judgments about which of two values (<span class="math inline">\(v_{1}\)</span> and <span class="math inline">\(v_{2}\)</span>) is greater. Then we can define a just noticeable difference, <span class="math inline">\(JND(v,p)\)</span>, as the difference in values, such that subjects correctly discriminate <span class="math inline">\(v\)</span> and <span class="math inline">\(v+JND(v,p)\)</span> in a proportion <span class="math inline">\(p\)</span> of trials.</p>
<section id="linear-representation-multiplicative-noise" class="level2">
<h2 class="anchored" data-anchor-id="linear-representation-multiplicative-noise">Linear Representation &amp; Multiplicative Noise</h2>
<p>Assume people get signals about underlying value with multiplicative noise, <span class="math inline">\(s=v\cdot e\)</span>, with <span class="math inline">\(e\)</span> lognormal. For conciseness let <span class="math inline">\(\delta=JND(v_{1},p)\)</span>, then <span class="math inline">\(\delta\)</span> can be implicitly defined as:</p>
<p><span class="math display">\[
\begin{aligned}
p   =&amp;  P(E[v_{1}+\delta|s_{2}]&gt;E[v_{1}|s_{1}]) \\
    =&amp;  P((v_{1}+\delta)e_{2}&gt;v_{1}e_{1}) \\
    =&amp;  P(\ln(v_{1}+\delta)+\ln e_{2}&gt;\ln v_{1}+\ln e_{1}) \\
    =&amp;  \Phi\left(\frac{\ln(v_{1}+\delta)-\ln v_{1}}{\sigma_{e}^{2}+\sigma_{e}^{2}}\right)
\end{aligned}
\]</span></p>
<p>where <span class="math inline">\(\Phi\)</span> is the CDF of a standard normal distribution. Then,</p>
<p><span class="math display">\[
\begin{aligned}
\ln(v_{1}+\delta)-\ln v_{1} =&amp;   2\sigma_{e}^{2}\Phi^{-1}(p) \\
\frac{v_{1}+\delta}{v_{1}}  =&amp;   \exp(2\sigma_{e}^{2}\Phi^{-1}(p))\\
JND(v_{1},p)=\delta         =&amp;   v_{1}\left[\exp(2\sigma_{e}^{2}\Phi^{-1}(p))-1\right]
\end{aligned}
\]</span></p>
<p>In other words, the just noticeable difference is proportional to the value, <span class="math inline">\(v_{1}\)</span>, as found by Weber.</p>
</section>
<section id="a-concave-representation-additive-noise" class="level2">
<h2 class="anchored" data-anchor-id="a-concave-representation-additive-noise">A Concave Representation &amp; Additive Noise</h2>
<p>Suppose that the decision-maker receives a concave signal of value with additive noise, i.e.&nbsp;<span class="math inline">\(s=\ln v+e\)</span>, with Gaussian <span class="math inline">\(e\)</span>. Then the derivation is very similar:</p>
<p><span class="math display">\[
\begin{aligned}
  p =&amp; P(E[v_{1}|s_{2}]&gt;E[v_{1}|s_{1}]) \\
    =&amp; P(\ln(v_{1}+\delta)+e_{2}&gt;\ln v_{1}+e_{1}).
\end{aligned}
\]</span></p>
<p>The rest of the derivation is the same: i.e., the JND in the neighborhood of <span class="math inline">\(v_{1}\)</span> will be proportional to <span class="math inline">\(v_{1}\)</span>.</p>
</section>
</section>
<section id="webers-law-bias-in-judgment" class="level1">
<h1>Weber’s Law &amp; Bias in Judgment</h1>
<p>Weber’s law implies that perception is noisy. We can then ask what is the appropriate Bayesian posterior given noise. In particular, what will the relationship be between a value <span class="math inline">\(v\)</span>, and the subjective best-estimate of that value given the signal <span class="math inline">\(s(v)\)</span>, i.e.&nbsp;<span class="math inline">\(E[E[v\|s]\|v]\)</span>.</p>
<p>It has often been assumed that Weber’s law will imply or justify a concave bias in estimates of value. However I show that this is not necessarily so.</p>
<p><strong>Note on expectations:</strong> In a continuous setup, like the below, you can’t just write the conditional expectation as an integral without further notes. The conditional expectation is undefined without specifying which <em>limit</em> you’re taking (<a href="https://en.wikipedia.org/wiki/Borel%E2%80%93Kolmogorov_paradox">AKA Borel-Kolmogorov paradox</a>). Below I <em>believe</em> that the integrals follow from taking limits with respect to the noise. Intuitively, this is like assuming that you observe only that the signal is in some range <span class="math inline">\((s-\varepsilon,s+\varepsilon)\)</span>, and taking limits as <span class="math inline">\(\varepsilon\rightarrow0\)</span>.</p>
<section id="multiplicative-noise-posteriors-are-concave-in-v" class="level2">
<h2 class="anchored" data-anchor-id="multiplicative-noise-posteriors-are-concave-in-v">Multiplicative Noise =&gt; Posteriors are Concave in <span class="math inline">\(v\)</span></h2>
<p>Suppose we have lognormal priors for both <span class="math inline">\(v\)</span> and <span class="math inline">\(e\)</span>:</p>
<p><span class="math display">\[
\begin{eqnarray*}
\ln v &amp; \sim &amp; N(\mu_{v},\sigma_{v}^{2})\\
\ln e &amp; \sim &amp; N(\mu_{e},\sigma_{e}^{2}),
\end{eqnarray*}
\]</span></p>
<p>and <span class="math inline">\(s=v\cdot e\)</span>, then we will have posteriors like:</p>
<p><span class="math display">\[
\begin{eqnarray*}
f(\ln v|s) &amp; \sim &amp; N(\frac{\sigma_{v}^{2}}{\sigma_{e}^{2}+\sigma_{v}^{2}}\ln s,\left(\sigma_{v}^{-2}+\sigma_{e}^{-2}\right)^{-1})\\
E[v|s] &amp; = &amp; \exp\left(\frac{\sigma_{v}^{2}}{\sigma_{e}^{2}+\sigma_{v}^{2}}\ln s+\frac{1}{2}\left(\sigma_{v}^{-2}+\sigma_{e}^{-2}\right)^{-1}\right)\\
&amp; = &amp; s^{\frac{\sigma_{v}^{2}}{\sigma_{e}^{2}+\sigma_{v}^{2}}}e^{\frac{1}{2}(\sigma_{v}^{-2}+\sigma_{e}^{-2})^{-1}}
\end{eqnarray*}
\]</span></p>
<p>This means that the expected <span class="math inline">\(v\)</span> is concave in the signal <span class="math inline">\(s\)</span> (because the exponent is less than one). Intuitively: a doubling of the value, which causes a doubling of the stimulus, will cause a <em>less</em> than doubling of the expected value conditional on that stimulus, because it will cause us to revise upwards our beliefs about both <span class="math inline">\(v\)</span> and <span class="math inline">\(e\)</span>.</p>
<p>Finally, we are also interested in the <em>average</em> posterior for a given <span class="math inline">\(v\)</span>. This will also be concave (abbreviating <span class="math inline">\(\alpha=\frac{\sigma_{v}^{2}}{\sigma_{e}^{2}+\sigma_{v}^{2}}\)</span>, and dropping the constant coefficient in <span class="math inline">\(E[v|s]\)</span>):</p>
<p><span class="math display">\[
\begin{eqnarray*}
E[E[v|s]|v] &amp; = &amp; \int(v\cdot e)^{\alpha}f(e)de\\
&amp; = &amp; v^{\alpha}\int e^{\alpha}f(e)de.
\end{eqnarray*}
\]</span></p>
</section>
<section id="additive-noise-posteriors-are-linear-in-v" class="level2">
<h2 class="anchored" data-anchor-id="additive-noise-posteriors-are-linear-in-v">Additive Noise =&gt; Posteriors are Linear in <span class="math inline">\(v\)</span></h2>
<p>Suppose again that the decision-maker receives a logarithmic signal with additive noise: <span class="math inline">\(s=\ln v+u\)</span>, and let <span class="math inline">\(u\)</span> be Gaussian. (I changed notation from <span class="math inline">\(e\)</span> to <span class="math inline">\(u\)</span> because I use a lot of exponential functions in the derivation.) Now assume that, in addition, <span class="math inline">\(v\)</span> is drawn from an improper uniform <span class="math inline">\((0,\infty)\)</span>. Consider the expected value of <span class="math inline">\(v\)</span> given the signal <span class="math inline">\(s\)</span> (I drop the constant term from the Gaussian distribution for conciseness):</p>
<p><span class="math display">\[
\begin{eqnarray*}
E[v|s] &amp; = &amp; \frac{\int_{0}^{\infty}ve^{-\left(s-\ln v\right)^{2}}dv}{\int_{0}^{\infty}e^{-\left(s-\ln v\right)^{2}}dv}.
\end{eqnarray*}
\]</span></p>
<p>Now exchange variables, so that <span class="math inline">\(v=e^{z}\)</span>:</p>
<p><span class="math display">\[
\begin{eqnarray*}
E[v|s] &amp; = &amp; \frac{\int_{-\infty}^{\infty}e^{z}e^{-(s-z)^{2}}e^{z}dz}{\int_{-\infty}^{\infty}e^{-(s-z)^{2}}e^{z}dz}\\
&amp; = &amp; \frac{\int_{-\infty}^{\infty}e^{-s^{2}+2(1+s)z-z^{2}}dz}{\int_{-\infty}^{\infty}e^{z-(s-z)^{2}}dz}\\
&amp; = &amp; \frac{\int_{-\infty}^{\infty}e^{-(z-1-s)^{2}}e^{1+2s}dz}{\int_{-\infty}^{\infty}e^{s+\frac{1}{4}}e^{-((s+\frac{1}{2})-z)^{2}}dz}\\
&amp; = &amp; e^{s}e^{3/4}\frac{\int_{-\infty}^{\infty}e^{-(z-1-s)^{2}}dz}{\int_{-\infty}^{\infty}e^{-((s+\frac{1}{2})-z)^{2}}dz}
\end{eqnarray*}
\]</span></p>
<p>Note that both of the integrals are independent of <span class="math inline">\(s\)</span> (because the integration is between <span class="math inline">\(-\infty\)</span> and <span class="math inline">\(\infty\)</span>), so there exists some <span class="math inline">\(\kappa\)</span> such that:</p>
<p><span class="math display">\[
E[x|s]=\text{e}^{s}\kappa.
\]</span></p>
<p>Finally we are interested in the average posterior for a given <span class="math inline">\(v\)</span> (here I’m again ignoring all constant terms):</p>
<p><span class="math display">\[
\begin{eqnarray*}
E[E[v|s]|v] &amp; = &amp; \int_{-\infty}^{\infty}E[v|s=\ln v+u]\text{e}^{-u^{2}}du\\
&amp; = &amp; \int_{-\infty}^{\infty}\text{e}^{(\ln v+u)}\kappa\text{e}^{-u^{2}}du\\
&amp; = &amp; v\int_{-\infty}^{\infty}\kappa\text{e}^{u-u^{2}}du.
\end{eqnarray*}
\]</span></p>
<p>I.e., despite the logarithmic internal representation, the average posterior is linear in the value.</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>