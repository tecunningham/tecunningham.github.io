<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.25">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Tom Cunningham">
<meta name="dcterms.date" content="2025-10-02">
<meta name="description" content="Tom Cunningham blog">

<title>Economics and Transformative AI | Tom Cunningham – Tom Cunningham</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-7b89279ff1a6dce999919e0e67d4d9ec.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-d5e7c60e6424aa6ccf163f01508596ce.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script src="../site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="../site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="../site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

<script type="text/javascript">

(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-12027453-1', 'auto');

ga('send', {
  hitType: 'pageview',
  'anonymizeIp': true,
});
</script>
<script>window.MathJax = {
   loader: { load: ["https://cdn.jsdelivr.net/gh/sonoisa/XyJax-v3@3.0.1/build/xypic.js"]},
   tex: {packages: {'[+]': ['xypic','bm']},
         macros: {  bm: ["\\boldsymbol{#1}", 1],
                    ut: ["\\underbrace{#1}_{\\text{#2}}", 2],
                    utt: ["\\underbrace{#1}_{\\substack{\\text{#2}\\\\\\text{#3}}}", 3] }
   }
};
</script>
<style>
   h1 {  border-bottom: 8px solid #557;}
   h2 {  border-bottom: 1px solid #ccc;}
   .greyproof {
      background-color: #f5f5f5;
      padding: 1em;
      margin: 1em 0;
      border-radius: 4px;
   }
</style>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../styles.css">
<meta name="twitter:title" content="Economics and Transformative AI | Tom Cunningham">
<meta name="twitter:image" content="tecunningham.github.io/posts/images/2025-09-25-05-16-22.png">
<meta name="twitter:image:alt" content="Windfall Trust Workshop">
<meta name="twitter:image-height" content="1080">
<meta name="twitter:image-width" content="2160">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../index.html" class="navbar-brand navbar-brand-logo">
    </a>
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Tom Cunningham</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href=".././about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/testingham"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/tom-cunningham-a9433/"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://tecunningham.github.io/index.xml"> <i class="bi bi-rss-fill" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://scholar.google.com/citations?user=MDB_DgkAAAAJ"> 
<span class="menu-text">scholar</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Economics and Transformative AI</h1>
                      </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Tom Cunningham </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">October 2, 2025</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#the-workshops" id="toc-the-workshops" class="nav-link active" data-scroll-target="#the-workshops">The Workshops</a></li>
  <li><a href="#general-observations" id="toc-general-observations" class="nav-link" data-scroll-target="#general-observations">General Observations</a></li>
  <li><a href="#we-dont-have-a-standard-model-of-ai" id="toc-we-dont-have-a-standard-model-of-ai" class="nav-link" data-scroll-target="#we-dont-have-a-standard-model-of-ai">We don’t have a standard model of AI</a></li>
  <li><a href="#a-conjecture-about-deep-models" id="toc-a-conjecture-about-deep-models" class="nav-link" data-scroll-target="#a-conjecture-about-deep-models">A Conjecture About Deep Models</a></li>
  <li><a href="#if-ai-can-do-everything-then-wages-will-fall." id="toc-if-ai-can-do-everything-then-wages-will-fall." class="nav-link" data-scroll-target="#if-ai-can-do-everything-then-wages-will-fall.">If AI can do everything then wages will fall.</a></li>
  <li><a href="#ai-scientists-will-be-unlike-human-scientists" id="toc-ai-scientists-will-be-unlike-human-scientists" class="nav-link" data-scroll-target="#ai-scientists-will-be-unlike-human-scientists">AI scientists will be unlike human scientists</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full" id="quarto-document-content">





<style>
   dl {display: grid;}
   dt {grid-column-start: 1; width: 10em;}
   @media (min-width: 768px) { dt { width: 15em; } }
   dd {grid-column-start: 2; margin-left: 2em;}
</style>

<div class="no-row-height column-margin column-container"><div class="">
<p>Thanks to comments from Daniel Björkegren, Andreas Haupt, Philip Trammel, Brent Cohn, Nick Otis, Andrey Fradkin, Jon de Quidt, Joel Becker.</p>
</div></div><dl>
<dt>&nbsp;</dt>
<dd>
This is a long collection of notes about economics &amp; AI, prompted by two excellent workshops I attended in mid-September: the Windfall Trust’s <a href="https://windfalltrust.org/">“Economic Scenarios for Transformative AI”</a> and the NBER’s <a href="https://www.nber.org/conferences/economics-transformative-ai-workshop-fall-2025">“Workshop on the Economics of Transformative AI”</a>. I had just left OpenAI’s Economic Research team, after releasing our paper, <a href="https://www.nber.org/papers/w34255">How People Use ChatGPT</a>.
</dd>
<dd>
<p>I’ll also try to explain a little why I’m excited about joining METR (I’ll explain why I left OpenAI another time).</p>
</dd>
<dt>Observations.</dt>
<dd>
<ol type="1">
<li><strong>There is no standard definition of machine intelligence.</strong> There have been many attempts to give a definition or a metric of machine intelligence but most have been unsatisfactory. The lack of a common language makes work in this field difficult, but it’s also a big opportunity.</li>
<li><strong>There is no standard model of AI’s economic impact.</strong> Economists have been using a wide range of assumptions to model AI’s impact, there is no standard framework. There seems to me an opportunity for ambitious economists to propose deep models of AI’s impact. A promising line would concentrate on AI’s ability to find low-dimensional representations of the world.</li>
<li><strong>GDP will be a poor proxy for AI’s impact.</strong> AI’s benefits are likely to elude GDP for two reasons: (1) it will reduce the necessity for exchange (and GDP measures exchange); (2) it will lower the labor required for services, and the value-added from services are typically imputed from the wage-bill.</li>
<li><strong>Transformative AI will raise the relative value of resources, and possibly lower the value of labor.</strong> If computers can do all human work then there will still be scarcity in natural resources (land, energy, minerals). Because humans require resources to do work (energy, land), demand for human labor will fall, creating a gap between land-rich and land-poor.</li>
<li><strong>AI will likely have a discontinuous impact on science and technology.</strong> Many existing models treat computers as substitutes for humans in the R&amp;D process, but there is reason to expect AI to have a qualitatively different effect on scientific progress.</li>
</ol>
</dd>
<dd>
<p>A common thread is this that I feel economics is slightly under-fulfilling its potential. I feel there are a thousand important ways in which AI will change society, but not many attempts at grand unifying theories.</p>
</dd>
</dl>
<section id="the-workshops" class="level1 page-columns page-full">
<h1>The Workshops</h1>
<dl>
<dt>The Windfall Trust workshop.</dt>
<dd>
<p>This workshop asked participants to discuss four possible future scenarios. Each scenario had a page-long description of what might happen, but they can be summarized as follows:</p>
<ol type="1">
<li>Low capability growth (“the incremental path”)</li>
<li>High capability growth without regulation (“the runaway economy”).</li>
<li>High capability growth with labor-market regulation to protect jobs (“the great pushback”)</li>
<li>High capability growth with redistribution (“the post-work society”)</li>
</ol>
</dd>
</dl>

<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/2025-09-25-05-16-22.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Windfall Trust Workshop"><img src="images/2025-09-25-05-16-22.png" class="img-fluid figure-img" alt="Windfall Trust Workshop"></a></p>
<figcaption>Windfall Trust Workshop</figcaption>
</figure>
</div></div><dl>
<dt>The NBER workshop.</dt>
<dd>
The NBER workshop was a set of chapters written for a volume on the impact of Transformative AI on a dozen different areas: R&amp;D, media, labor, competition, etc. Attendees were presenting the chapters they had written. The workshop was organized by Ajay Agrawal, Anton Korinek, and Erik Brynjolfsson.
</dd>
</dl>

<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/2025-09-29-09-44-20.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="NBER workshop"><img src="images/2025-09-29-09-44-20.png" class="img-fluid figure-img" alt="NBER workshop"></a></p>
<figcaption>NBER workshop</figcaption>
</figure>
</div></div></section>
<section id="general-observations" class="level1 page-columns page-full">
<h1>General Observations</h1>
<dl>
<dt>My view: we are driving in fog.</dt>
<dd>
<p>My personal view is that it’s reasonable to have high uncertainty about both AI progress and the effects of that progress: (1) it’s possible that AI will get very good very soon; (2) it’s difficult to anticipate what will happen if it does.</p>
<p>We are driving in fog: it’s possible we have miles of open road, it’s possible we’re about to hit a tree. It seems sensible to be prepared for either outcome.</p>
</dd>
<dt>Background: a tension between AI researchers and economists.</dt>
<dd>
<p>Here is a very simplified characterization of AI researchers’ beliefs about economic impacts:</p>
<ol type="1">
<li>AI will soon be able to replicate most human labor.</li>
<li>This will cause mass unemployment.</li>
<li>We should fund a universal benefit from AI company profits.</li>
</ol>
<p>Academic economists have often bristled at these arguments:</p>
<ol type="1">
<li>Economists have often been skeptics about AI capabilities and future AI progress (see below).</li>
<li>Economists argue (i) there are many frictions which prevent rapid changes; (ii) even if computers were better at everything than humans, there’s still comparative advantage; (iii) new technology will create new tasks for humans.</li>
<li>It’s not clear that AI companies will earn very high profits – most of the surplus from AI may go directly to the consumers of AI products.</li>
</ol>
<p>Having spent a lot of time with both AI researchers and economists, I feel both have substantial blindspots, &amp; could learn a lot from each other. AI people underestimate the frictions and sluggishness of economic processes; economists often fail to appreciate the speed of AI improvement &amp; avoid having hypothetical discussions about future trajectories.</p>
</dd>
<dt>Many economists avoided talking about transformative AI.</dt>
<dd>
<p>Both workshops were intended explicitly for discussion of a hypothetical: what would happen <em>if</em> AI capabilities approached human-level performance on most work?</p>
<p>Despite this, it seems to me that most of the economists resisted the hypothetical. Looking at the NBER papers I think about half were effectively discussing the effects of AI with <em>existing</em> capabilities, not the effects of transformative AI.</p>
<p>This resistance was a common topic of discussion. People gave a few different reasons for concentrating on contemporary AI instead of future AI: (1) they were doubtful that AI would improve very quickly; (2) they thought it’s more important to work on the economics of actually existing AI; (3) they thought the economics of superhuman AI was formally less interesting; (4) they thought superhuman AI was possible and important, but were nervous about being perceived as credulous by their colleagues.</p>
<p>Chad Jones presented <a href="https://conference.nber.org/conf_papers/f227502.pdf">a paper</a> which took seriously the existential dangers of AI, and argued that we should be spending hundreds of billions to prevent it. After his presentation the audience gave various comments but nobody (as I recall) gave a serious counter-argument. Nobody tried to dispute the substance of the argument – that an enormous asteroid is on a path to swipe our planet. Some people said this type of preventative work wouldn’t be politically feasible – but nobody seemed to express a sense of urgency you would expect if it was only political feasibility that was holding us back. The conference discussion mostly just drifted on to the next topic.</p>
</dd>
<dt>Defining AI capabilities is a hard problem.</dt>
<dd>
<p>It would be very useful to have a standard terminology for levels of AI capabilities. It would allow us to split our arguments into two parts: (1) when will AGI arrive? (2) what will happen when it gets here? We suffer from not being able to make this distinction. It is very often difficult to tell how much our disagreements are due to disagreement about capabilities progress, vs disagreement about the impact of that progress.</p>
<p>Conceptually the solution is simple but practically it’s hard. Many people have tried to define a set of capability levels but none have been widely adopted: most capability definitions are either too ambiguous or too narrow.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<p>I think this is just a fundamentally difficult problem. It feels like something you should be able to figure out in an afternoon (and I spent many afternoons on it), but it has resisted many great minds.</p>
<p>Here are some examples of definitions that are too ambiguous: (1) it can pass a Turing test; (2) it can do “most economically valuable labor”; (3) it can exhibit PhD-level intelligence; (4) it can do the job of a customer service worker. Each of these covers a very broad a range of interpretations, including some such that 2024-level models could already do this.</p>
<p>Here are some examples of definitions that are too precise: (1) it can solve ARC-AGI, (2) it can write a paper that passes peer review at NeurIPS, (3) it can earn $1M. These are relatively unambiguous but it’s also easy to imagine cases where a model passes these tests while it still has limited economic value.</p>
</dd>
</dl>
<p></p>
<dl>
<dt>We are making some progress in characterizing AI ability.</dt>
<dd>
<p>In 2023 and 2024 AI ability was often described in terms of its grades on standardized tests (SAT, GRE, LSAT), or by the human-equivalent years of education, e.g.&nbsp;Leopold Aschenbrenner and OpenAI talked about “college-level intelligence” and “PhD-level intelligence.” This was a reasonable way of trying to make comparisons but clearly had limits: LLMs were PhD-level at some tasks, but also they were clearly kindergarten level at others.</p>
<p>In 2025 METR (<span class="citation" data-cites="kwa2025longtasks">Kwa et al. (<a href="#ref-kwa2025longtasks" role="doc-biblioref">2025</a>)</span>) made a good argument that a more robust metric of AI ability is the human-time-length of tasks that a model can do (see image). It’s an imperfect metric but I think it’s the best we have now.</p>
<p>It seems to me that having a better characterization of AI abilities, and the difference between AI and human abilities, remains a huge open question, and almost all questions about the impact of AI depend on this. This is what I’m personally most interested in working on, and the reason why I’m joining METR.</p>
</dd>
</dl>

<div class="no-row-height column-margin column-container"><div class="">
<p><img src="images/2025-10-01-13-52-35.png" class="img-fluid"> A graph of model capabilities across domains, indexed by the human-time-length of tasks, <a href="https://metr.org/blog/2025-07-14-how-does-time-horizon-vary-across-domains/">from METR</a>.</p>
</div></div><dl>
<dt>I don’t think people appreciate the speed of AI improvement.</dt>
<dd>
<p>Speakers at the NBER workshop gave various examples of things the models still couldn’t do: (1) <a href="https://arcprize.org/arc-agi">solve ARC-AGI puzzles</a>; (2) <a href="https://arxiv.org/abs/2507.06952">extrapolate world models</a>; (3) <a href="https://www.anthropic.com/research/project-vend-1">operate vending machines</a>. These are all reasonable examples of limitations as of September 2025, but we should at the same time mention the rate of change. It seems very likely that the primary examples of tasks that AI <em>cannot</em> do in 2025 will turn into tasks that AI can do in 2026 (the same was true in 2024 and 2023).</p>
<p>Some general observations about the rate of progress:</p>
<ol type="1">
<li><em>ARC-AGI is falling quickly.</em> LLM scores on ARC-AGI-1 went from around 10% to 80% over a year, and scores on ARC-AGI-2 went from around 3% to 30% over a few months. It’s true that a large part of the performance improvement was due to adding wrappers around LLMs, but the models can write their own wrappers, so it seems likely they’ll be able to solve the class of problems which can be addressed by an LLM plus wrapper.</li>
<li><em>Benchmarks are falling rapidly.</em> It typically takes around 18 months for a newly introduced benchmark performance to go from 25% to 75%. We are frantically making up new tests to map out the limits of machine intelligence.</li>
<li><em>Consumer utility is growing dramatically.</em> Use of chatbots has been more than doubling each year, both on the intensive and extensive margins. People far prefer answers from newer chatbots to older chatbots. The Elo score of models on chatbot arena is growing at around 150 points/year. This implies about a 70% win-rate, and equivalent to the difference in skill between the top-rated chess player in the world and the player ranked 100.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></li>
</ol>
</dd>
</dl>

<div class="no-row-height column-margin column-container"><div class="">
<p><img src="images/2025-09-27-06-12-58.png" class="img-fluid" alt="ChatbotArena Elo scores over time"> From <a href="https://observablehq.com/@llms/lmsys-chatbot-arena-leader-over-time">ObservableHQ</a>.</p>
</div></div><dl>
<dt>The AI pessimism has mostly evaporated.</dt>
<dd>
<p>Over summer 2024 many economists predicted that AI would have small economic impacts:</p>
<ul>
<li>Daron Acemoglu predicted AI would add 0.06% to annual productivity growth over the next 10 years.</li>
<li>Josh Gans said <a href="https://x.com/joshgans/status/1812492809326276786">“I don’t think it will boost growth appreciably”</a> over the next 10 years.</li>
<li>Robert Gordon <a href="https://www.newyorkfed.org/medialibrary/media/research/conference/2024/AMEC%20US%20Productivity/Sessiontrue3_Gordon_LGAtrueNYFedtrueFuturetrueoftrueLP_240216">predicted small effects</a>.</li>
<li>Paul Romer <a href="https://finance.yahoo.com/news/nobel-laureate-paul-romer-sees-093000071.html">predicted small effects</a>.</li>
</ul>
<p>I have heard much less of this kind of talk in 2025.</p>
</dd>
</dl>
<dl>
<dt>GDP forecasts have been modeling diffusion, but ignoring capability growth.</dt>
<dd>
<p>Two quantitative forecasts of AI’s GDP impact are <span class="citation" data-cites="acemoglu2024simple">Acemoglu (<a href="#ref-acemoglu2024simple" role="doc-biblioref">2024</a>)</span> (0.06%/year) and <span class="citation" data-cites="aghion2024ai">Aghion and Bunel (<a href="#ref-aghion2024ai" role="doc-biblioref">2024</a>)</span> (1%/year). Both of those papers model AI’s future economic impact as primarily a <em>diffusion</em> process: they treat the arrival of AI as a one-time shock like electricity or the steam engine which is gradually adopted and adapted, but asymptotes.</p>
<p>I think this a bad assumption because AI’s capabilities have been getting dramatically better over time (discussed more above), and we don’t know where the ceiling is.</p>
<p>Conceptually, we can decompose the growth in LLM adoption over a given period into (i) quality growth; (ii) diffusion. It’s very difficult to separate these, but I think a reasonable guess is that growth over the last 12 months (Sept 2024 to Sept 2025) is about 1/2 diffusion of existing capabilities, and 1/2 the causal effect of new capabilities (precisely: growth would’ve been half as large if models had been frozen in Sept 2024). If this is true then a forecast which was just based on the diffusion of existing capabilities would have dramatically under-estimated the impact of AI, and the gap would become larger as the horizon got longer.</p>
<p>Forecasts of diffusion are, by construction, forecasts which assume that AI progress will stop. But neither of these papers gives an argument why we should expect that.</p>
</dd>
<dt>GDP will miss a lot.</dt>
<dd>
<p>There are two reasons why focussing just on GDP will miss important effects:</p>
<ol type="1">
<li><p><strong>AI will change relative prices.</strong> It seems likely that AI will lower the price of services (especially digital services) much more than the price of goods. If we just talk about the effect of AI on output overall, without distinguishing across domains, I think we will miss a lot. (I talk more about resource prices below).</p></li>
<li><p><strong>AI services won’t show up in GDP.</strong> AI is already providing a great deal of value (there are 700M ChatGPT users), but the value mostly won’t show up in GDP by our normal accounting methods.<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>. In fact it’s plausible that AI reduces GDP because it reduces demand for expertise: I no longer call my garage-door-repair guy, because ChatGPT tells me how to fix the door. Services are generally accounted for in GDP just by the wages paid to service-providers. If people substitute from human service-providers towards AI then measured GDP will fall even though true output has increased. If service-providing firms pass through their cost-savings to customers then their measured contribution to GDP will fall. The same argument applies to much older technologies – the printing press, the encylopedia, YouTube.<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a></p></li>
</ol>
</dd>
</dl>
<p></p>
<p></p>
<p></p>
<aside id="footnotes" class="footnotes footnotes-end-of-section" role="doc-footnote">
<hr>
<ol>
<li id="fn1"><p>In 2024 Bloomberg <a href="https://www.axios.com/2024/07/15/openai-chatgpt-reasoning-ai-levels">reported on</a> an OpenAI project to define five levels of AI capabilities (I worked a little on this). Also in 2024 Google Deep Mind released a <a href="https://arxiv.org/pdf/2311.02462">5-level framework</a>, based on the percentile of human ability (level 2 means 50th percentile of skilled human).<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>It likely be impossible to approach a 100% win-rate, because (1) a fraction of people give noisy answers; (2) some easy queries have a unique correct answer; (3) some queries are ambiguous, meaning different people who ask the same query will have different preferences, and so no answer could ever get 100% of the responses.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p><span class="citation" data-cites="collis2025welfare">Collis and Brynjolfsson (<a href="#ref-collis2025welfare" role="doc-biblioref">2025</a>)</span> estimate that generative AI is worth around $100/month to users in the US (i.e., they say they would require $100/month to give up these apps). This is far higher than the avg revenue or cost to provide these services.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p><span class="citation" data-cites="varian2011economic">Varian (<a href="#ref-varian2011economic" role="doc-biblioref">2011</a>)</span> discusses various ways of estimating the value of google, e.g.&nbsp;a finding in <span class="citation" data-cites="chen2014day">Chen, Jeon, and Kim (<a href="#ref-chen2014day" role="doc-biblioref">2014</a>)</span> that people can answer questions twice as fast with a search engine as with a library. These issues were also discussed in <span class="citation" data-cites="coyle2025measurement">Coyle and Poquiz (<a href="#ref-coyle2025measurement" role="doc-biblioref">2025</a>)</span> at the NBER workshop.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</aside>
</section>
<section id="we-dont-have-a-standard-model-of-ai" class="level1 page-columns page-full">
<h1>We don’t have a standard model of AI</h1>
<dl>
<dt>AI will change everything, but we don’t know how.</dt>
<dd>
<p>We want to predict the effect of AI on dozens of different areas of life – on medicine, on law, on entertainment, on news, on competition and markups, on scientific discovery, on personal relationships.</p>
<p>I will complain a little about the state of theorizing about the economic effects of AI. I feel that there’s not enough ambitious work which tries to model the effects of AI on human society in a deep structural way, which would allow us to make predictions across many domains.</p>
<p>If I’m missing some attempts please tell me.</p>
</dd>
<dt>Each paper used a different assumption about AI.</dt>
<dd>
<p>Each of the papers in the NBER workshop used some assumption about how AI changes the production function, but there were many different assumptions. Some of the ways that AI is modelled:</p>
<ul>
<li>AI allows capital to perform a wider set of tasks (tasks that previously only labor could do).</li>
<li>AI allows humans to do certain tasks more quickly.</li>
<li>AI allows humans to do a wider range of tasks.</li>
</ul>
<p>In many papers there’s no specific assumption on the types of task, just a parameter that reflects the share of tasks affected or the size of the effect. In some papers there are more structural assumptions on how tasks are affected, but there are a wide variety of assumptions, e.g.&nbsp;whether AI gives better predictions, or AI shares information. In some papers there are empirical assumptions, e.g.&nbsp;using an index of “AI exposure”.</p>
<p><span class="citation" data-cites="brynjolfsson2025agenda">Brynjolfsson, Korinek, and Agrawal (<a href="#ref-brynjolfsson2025agenda" role="doc-biblioref">2025</a>)</span> is a “research agenda for the economics of transformative AI”: it seems to me that the paper lists many good questions but cites relatively few papers, and the papers it does cite are generally treated only as exploratory conjectures.</p>
</dd>
<dt>Structural models of AI.</dt>
<dd>
<p>Here are two classes of somewhat more structural models.</p>
<ol type="1">
<li><p><span class="citation" data-cites="agrawal2019predictionjudgmentcomplexity">Agrawal, Gans, and Goldfarb (<a href="#ref-agrawal2019predictionjudgmentcomplexity" role="doc-biblioref">2019</a>)</span> – here AI improves the ability to predict some outcome, &amp; the authors argue these predictions are typically a complement to human judgments. A couple of notable features: (1) in this model AI and human intelligence are qualitatively different, they assume that only humans can exercise judgment, which I find hard to interpret; (2) the model doesn’t seem to naturally predict the knowledge-sharing feature that I would regard as the primary economic effect of LLMs (see below).</p></li>
<li><p><span class="citation" data-cites="ide2024artificialintelligenceknowledgeeconomy">Ide and Talamas (<a href="#ref-ide2024artificialintelligenceknowledgeeconomy" role="doc-biblioref">2024</a>)</span> – here each human has a certain level of knowledge (on a single dimension), and AI is able to substitute for that knowledge. This is an application of <span class="citation" data-cites="garicano2006organization">Garicano and Rossi-Hansberg (<a href="#ref-garicano2006organization" role="doc-biblioref">2006</a>)</span>’s model of the effect of information technology on organizational structure.</p></li>
</ol>
</dd>
<dt>A pocket model: LLMs share knowledge.</dt>
<dd>
<p>Here is a simple mental model that I often use: <em>LLMs share knowledge</em>. The model is unsatisfactory in many respects but has the virtues of being very simple and very general. Consider an LLM as just a database of answers to questions, containing the set of answers that already exist in the public domain (i.e., in the LLM’s training set).<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a> LLMs therefore lower the cost of access to existing knowledge, and people will consult an LLM when they encounter a problem for which (i) they do not know the answer, but (ii) they expect that someone else does know the answer (and the answer was included in the training set).</p>
<p>This is a very crude model of an LLM but I think it gives a reasonable characterization of their adoption and effect so far. Around 1/3 of adults in rich countries are regularly using chatbots, and I think it’s fair to say the majority of the use is solving problems outside the domain of the user’s own expertise, but inside someone else’s expertise (see our <a href="https://www.nber.org/papers/w34255">ChatGPT paper</a>). This knowledge-sharing model predicts that LLMs will flatten comparative advantage, so we should see more home production (people solve their own problems), less trade, and lower returns to experience.</p>
<p>The model has a number of imperfections as a general model of AI: (1) LLMs are often used to do tasks that don’t require knowledge outside the user’s domain, e.g.&nbsp;solving a problem that requires time and patience but not knowledge such as certain types of computer programming, writing, or creating images; (2) the model treats LLMs as strictly bound by the limits of human knowledge, this was a good approximation for early LLMs but it’s clear that AI is progressively expanding the boundary of human knowledge in a variety of ways.</p>
<p>This model is related to the Garicano-Ide-Talamas models in which an AI shares existing knowledge.</p>
</dd>
</dl>

<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/2025-09-22-05-32-49.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3" title="Distribution of queries from “How People Use ChatGPT”"><img src="images/2025-09-22-05-32-49.png" class="img-fluid figure-img" alt="Distribution of queries from “How People Use ChatGPT”"></a></p>
<figcaption>Distribution of queries from “How People Use ChatGPT”</figcaption>
</figure>
</div></div><dl>
<dt>Can we use existing models of human cognition?</dt>
<dd>
<p>There has been a lot of work by economists on the limits of human cognition over the last 50 years (AKA behavioral economics). This would seem like a natural quarry where we can get material for a theory of AI’s economic impact, however I’m not optimistic that there is much we can use.</p>
<p>Ideally we could start with a model of human decision-making and change the parameters to fit a model of computer decision-making. However there are not many clear candidates, theories in behavioral or psychological economics tend to emphasize biases: prospect theory, hyperbolic discounting, ambiguity aversion, heuristics, social preferences, rational inattention, two systems.</p>
<p>These are primarily theories of the <em>weaknesses</em> of human judgment, as such they do not seem to offer much explanation of the extraordinary strengths of human judgment – illustrated by the decades that it’s taken for computers to catch up with humans. These models don’t help explain why it has been so difficult to build a computer to do very basic human judgment and decision-making.<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a></p>
</dd>
</dl>
<aside id="footnotes-2" class="footnotes footnotes-end-of-section" role="doc-footnote">
<hr>
<ol start="5">
<li id="fn5"><p>A simple formalization of a question-answering model is in a <a href="https://tecunningham.github.io/posts/2023-09-05-model-of-ai-imitation.html">2023 blog post of mine</a>.<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>I used to work in behavioral economics, and my feeling about the field were already drifting in that direction: a <a href="https://tecunningham.github.io/posts/2016-04-30-relative-thinking.html">critique</a>, and a <a href="https://tecunningham.github.io/posts/2023-10-24-manifesto-perception-judgment-decision-making.html">suggestion</a>).<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</aside>
</section>
<section id="a-conjecture-about-deep-models" class="level1">
<h1>A Conjecture About Deep Models</h1>
<p></p>
<dl>
<dt>AI’s effect on a domain will depend on that domain’s statistical structure.</dt>
<dd>
<p>This will be a somewhat vague statement: my guess is that the most satisfying explanations of AI’s impact across different domains of human life (entertainment, news, hiring, shopping, etc.) will refer to the statistical properties of those domains, such as the latent dimensionality of that domain, or the strength of correlations in that domain.</p>
<p>Put another way: are there aspects of the statistical structure of the domain which a human brain can comprehend, but a computer brain cannot? are there aspects which a computer brain can appreciate but a human brain cannot? We already have well-established statistical theory on which types of estimator perform better on which types of data-generating process, the conjecture is that this type of theory will help organize a lot of observations about the impact of LLMs on social processes.</p>
<p>This line of thinking is inspired by some standard theory underlying the success of deep learning: that neural nets are able to learn low-dimensional structures in high-dimensional data (the “manifold hypothesis”, <span class="citation" data-cites="bengio2013representation">Bengio, Courville, and Vincent (<a href="#ref-bengio2013representation" role="doc-biblioref">2013</a>)</span>).</p>
</dd>
</dl>
<dl>
<dt>Examples of economic implications from statistical structure.</dt>
<dd>
<p>Here are a few brief cases in which the equilibrium economic effect of AI is determined by the underlying statistical structure of the domain. My conjecture is that these types of observations could be formalized in a common framework.</p>
<ol type="1">
<li><strong>The concentration of the market for AI depends on the dimensionality of the world.</strong> If the world is intrinsically high-dimensional then the returns to model scale will be steadily increasing, and so we should expect high concentration and high markups. If instead the world is intrinsically low-dimensional then the returns to scale will flatten, and there should be low concentration (high competition) and low markups.</li>
<li><strong>The effect of AI on scientific progress depends on the structure of the world.</strong> I give this argument below: if the world has a simple latent structure then progress will be bottlenecked more by intelligence than by data, and so advances in AI will dramatically accelerate scientific progress, without being bottlenecked on more data collection.</li>
<li><strong>The wages paid to an occupation depends on the work’s latent dimensionality.</strong> If the work consists of tasks with high latent dimensionality then the returns to experience and ability will be high, and so wages will be high. As AI changes the incremental effect of human experience and intelligence we should expect it to change the structure of wages.</li>
<li><strong>The demand for compute will depend on the self-similarity of the world.</strong> If 7 billion people all have very different problems then there are few efficiencies we can make in inference (through caching and distillation) and the share of GDP paid to compute will be high. If instead they have similar problems then the returns to additional compute will fall rapidly (demand will be inelastic) and the share of income paid to compute will be small.</li>
<li><strong>The value of a matching algorithm depends on the dimensionality of preferences.</strong> Suppose we are predicting the quality of a match between a person and an item (e.g.&nbsp;a viewer and a movie, or a person and a job). If the latent structure of match-qualities is very simple then classic collaborative filtering algorithms will be very efficient, and neural nets will have small additional value (e.g.&nbsp;suppose preferences over movies can be largely expressed on a single latent dimension). But if preferences are highly idiosyncratic then more advanced AI, and wider data sources, will have big effects on equilibrium outcomes.</li>
</ol>
</dd>
</dl>
</section>
<section id="if-ai-can-do-everything-then-wages-will-fall." class="level1">
<h1>If AI can do everything then wages will fall.</h1>
<dl>
<dt>What will happen when computers can do everything?</dt>
<dd>
<p>A lot of the discussion at both workshops was about the hypothetical world where computers can do everything that humans can do. Suppose there will be zero <em>intrinsic</em> demand for human-provision, i.e.&nbsp;people would not pay a higher price or accept a lower quality if a service was provided by a human instead of a machine. What would happen to human employment and wages.</p>
<p>Many papers argue that in this case human wages will increase: Pascual Restrepo made this argument at the NBER workshop (<span class="citation" data-cites="restrepo2025missed">Restrepo (<a href="#ref-restrepo2025missed" role="doc-biblioref">2025</a>)</span>), see also <span class="citation" data-cites="caselli2019robot">Caselli and Manning (<a href="#ref-caselli2019robot" role="doc-biblioref">2019</a>)</span>, <span class="citation" data-cites="smith2024">Smith (<a href="#ref-smith2024" role="doc-biblioref">2024</a>)</span>, <span class="citation" data-cites="trammell2025economic">(<a href="#ref-trammell2025economic" role="doc-biblioref"><strong>trammell2025economic?</strong></a>)</span> and <span class="citation" data-cites="korinek2024scenarios">Korinek and Suh (<a href="#ref-korinek2024scenarios" role="doc-biblioref">2024</a>)</span>.<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a></p>
<p>The argument follows the standard trade argument: if a farmer moves in next-door who can grow every vegetable more efficiently than you then it’s good news: you can just specailize in the vegetables you are <em>relatively</em> better at and trade with the neighbor at an advantage. (If capital is a complement to labor then robots might cause wages to decline in the short-run but they would recover in the long-run, see <span class="citation" data-cites="caselli2019robot">Caselli and Manning (<a href="#ref-caselli2019robot" role="doc-biblioref">2019</a>)</span>).</p>
</dd>
<dt>If resources are scarce, wages will drop.</dt>
<dd>
<p>This reassuring conclusion depends on there being no other scarce inputs which humans and computers compete for. All of the papers above mention this qualification, they say that the conclusions might change if there are fixed factors, but they do not put emphasis on this point. However it seems to me that if we take seriously the hypothetical (that computers can do all work that humans can) then the resource constraints will very quickly bind.<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a></p>
<p>Humans have resource inputs - say 100 square feet and 2000 calories/day. If a computer can do every task at a lower resource cost than a human, and there are plentiful computers, then there would be no humans employed in equilibrium.<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a> Concretely, humans who do not own land would starve: the price of their labor, denominated in energy and land, would fall below subsistence level.</p>
<p>Among people who are still alive (because they own land, or from charity), would they work? Only if the incremental resource cost of working was below the resource cost of using a computer for that job.</p>
<p>An analogy: suppose we have a stock of A100 chips, then we start introducing more powerful H100 chips. Assume the H100 can do more tasks/hour across all tasks. As we acquire H100s we will keep using A100s for the jobs they are comparatively better for. But once we have sufficiently many H100s we will start to unplug the A100s to make room.</p>
</dd>
</dl>
<dl>
<dt>A feudal world.</dt>
<dd>
<p>Here is a sketch of a world with transformative AI. Probably I’m missing important things but I find it helpful to be concrete. Make these assumptions:</p>
<ol type="1">
<li>Every service and every good can be produced by a robot, with 1hr of robot labor exactly equivalent to 1hr of human labor.</li>
<li>A human requires 100 square feet to live, but a robot requires 1 square foot. I will treat land as the only fixed resource, you can imagine this as also representing energy and scarce minerals.</li>
<li>Suppose robots are sufficiently plentiful that they are rented at their resource cost, i.e.&nbsp;1 square foot of land.</li>
<li>Suppose half of all humans own land while the other half do not. I.e. for half of all humans their only asset is their labor.</li>
<li>Suppose there is no <em>intrinsic</em> demand for human labor, people only care about the quality of the output, not who made it.</li>
</ol>
<p>For people who own property you now have as many workers as square feet of land. You can effectively order anything you want from Amazon, or get any arbitrarily high-quality service (medical, massage, education, entertainment). Your primary constraints are space and time, not quality or quantity of goods and services.</p>
<p>However suppose you do not own land, and pay rent every month. In order to provide a service cheaper than your landlord’s robot your wage needs to be equivalent to 1 square foot of land, i.e.&nbsp;less than subsistence.</p>
<p>Taken literally this implies that people without assets will become dependent on charity. It seems plausible that the landowners would provide land to the land-poor, but still there would be no employment in this scenario.</p>
<p></p>
</dd>
<dt>A model with labor and land.</dt>
<dd>
<p>For completeness, here’s a simple model. Let land and labor be gross complements, and let AI be a perfect substitute for labor, and suppose we have an arbitrarily large quantity of AI. Then the marginal product of labor falls to zero and the entirety of the output will be held by the land-owner. Human labor no longer has any value and workers must live off the charity of the land-owners.</p>
<p>Formally:</p>
<p><span class="math display">\[Y=(\ut{N}{land}^\rho+{(\ut{L}{labor}+\ut{C}{computers})}^{\rho})^{1/\rho}\]</span></p>
<p>as <span class="math inline">\(C\rightarrow\infty\)</span> then the marginal product of labor goes to zero, and all income goes to land.</p>
<p>Notes:</p>
<ul>
<li>I assumed labor and land are gross complements (<span class="math inline">\(\varepsilon=\frac{1}{1-\rho}&lt;1\)</span>). If production was Cobb-Douglas then making labor free implies we would get infinite output from a finite amount of land. As long as there is some limit on total output then land and labor must be gross complements beyond some point.</li>
<li>I assumed AI labor is free. We could instead assume AI has some resource cost. In that case the price of labor will be driven down to the input cost of AI labor. The input cost of AI labor could be defined in a few ways but they all appear to me low compared to exiting human wages: the land cost of a GPU is a few square inches, the energy cost is 400 watts.</li>
<li>We could distinguish between two sectors: a sector that requires land (goods) and a sector that requires only labor (services). If we introduce AI as free labor then human wages will retain the same purchasing power for services but their purchasing power for goods will collapse. Concretely: if you try to exchange your labor for goods you will have nothing to offer because the land-holder already has unlimited labor. The model predicts that workers will be not benefit from AI-produced-goods because AI requires land inputs.</li>
</ul>
</dd>
</dl>
<aside id="footnotes-3" class="footnotes footnotes-end-of-section" role="doc-footnote">
<hr>
<ol start="7">
<li id="fn7"><p><span class="citation" data-cites="korinek2024scenarios">Korinek and Suh (<a href="#ref-korinek2024scenarios" role="doc-biblioref">2024</a>)</span> argue that as AI progresses it will causes wages to increase then decrease, but this is a consequence of a specific assumption: that AI will has identical relative productivity across tasks to humans, among the tasks it can do, and so as AI becomes able to do more tasks then the equilibrium price vector first moves away from, then returns towards, the vector of human productivities.<a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8"><p>Restrepo gives examples of work that humans might do: <em>“For many socially intensive tasks—such as care work, hospitality, or therapy—the compute required to emulate human warmth or social intuition may be enormous. Even if such work is technically automatable, it may remain economically impractical to do so. As a result, these domains could continue to offer meaningful work for people.”</em> However it’s not clear to me why “emulating human warmth or social intuition” would have an “enormous compute requirement”, more than, say, driving a car, or filing records.<a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9"><p>Assuming computers are in sufficiently plentiful supply that we can ignore every other cost apart from their resource cost. If manufacturing computers requires resources then we could include their amortized manufacturing cost. If we have a scarce supply of computers for other reasons then of course this will keep human wages high.<a href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</aside>
</section>
<section id="ai-scientists-will-be-unlike-human-scientists" class="level1 page-columns page-full">
<h1>AI scientists will be unlike human scientists</h1>
<dl>
<dt>Will efficiency curves start dropping faster?</dt>
<dd>
<p>A good way of making the AI R&amp;D question very concrete is to look at historical input-efficiency curves across a lot of different areas, and try to predict where they will go in the future. Should we expect them to start dropping faster? Which ones?</p>
</dd>
<dd>
<p>In fact I think these efficiency curves are a very good subject for making forecasts about: both as an output (expressing the practical impact of AI), and as an input (a way of expressing the capability of AI, to then make conditional forecasts with).</p>
</dd>
</dl>

<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/2025-09-19-16-49-40.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4" title="Our World in Data: Technology Costs over Time."><img src="images/2025-09-19-16-49-40.png" class="img-fluid figure-img" alt="Our World in Data: Technology Costs over Time."></a></p>
<figcaption>Our World in Data: Technology Costs over Time.</figcaption>
</figure>
</div></div><dl>
<dt>Most models of AI R&amp;D are based on human R&amp;D.</dt>
<dd>
Models of AI’s impact on technological discovery are typically modelled on human R&amp;D, e.g.&nbsp;(1) AI increases the effective supply of human scientists; or (2) AI automates one component of the R&amp;D process. However both are modelled on a production function fitted on data with human researchers, and it seems to me likely that AI will qualitatively change that production function.
</dd>
<dt>There’s another way to model this.</dt>
<dd>
<p>My instinct is that there’s a different way of modeling this that is more structural. Suppose we have an unobserved landscape, and it can be explored either by a human brain or a computer brain. Human brains have been exploring the landscape, finding successively lower local minima, and also finding general patterns in the landscape (e.g.&nbsp;physical laws). We wish to understand how much computers will speed up exploration of the landscape.</p>
</dd>
</dl>
<div class="cell page-columns page-full">

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="2025-09-19-transformative-AI-notes_files/figure-html/unnamed-chunk-1-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5" title="Random landscape. Here there’s no structure: every x is an independent random draw."><img src="2025-09-19-transformative-AI-notes_files/figure-html/unnamed-chunk-1-1.png" class="img-fluid figure-img" width="672" alt="Random landscape. Here there’s no structure: every x is an independent random draw."></a></p>
<figcaption><strong>Random landscape.</strong> Here there’s no structure: every <span class="math inline">\(x\)</span> is an independent random draw.</figcaption>
</figure>
</div>
</div></div></div>
<div class="cell page-columns page-full">

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="2025-09-19-transformative-AI-notes_files/figure-html/unnamed-chunk-2-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6" title="Rugged landscape. This shows a Wiener process (random walk). Here there’s local correlation but no long-distance dependence."><img src="2025-09-19-transformative-AI-notes_files/figure-html/unnamed-chunk-2-1.png" class="img-fluid figure-img" width="672" alt="Rugged landscape. This shows a Wiener process (random walk). Here there’s local correlation but no long-distance dependence."></a></p>
<figcaption><strong>Rugged landscape.</strong> This shows a Wiener process (random walk). Here there’s local correlation but no long-distance dependence.</figcaption>
</figure>
</div>
</div></div></div>
<div class="cell page-columns page-full">

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="2025-09-19-transformative-AI-notes_files/figure-html/unnamed-chunk-3-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-7" title="Regular landscape. Here there’s some latent structure, implying that you can make long-distance predictions from local observations."><img src="2025-09-19-transformative-AI-notes_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid figure-img" width="672" alt="Regular landscape. Here there’s some latent structure, implying that you can make long-distance predictions from local observations."></a></p>
<figcaption><strong>Regular landscape.</strong> Here there’s some latent structure, implying that you can make long-distance predictions from local observations.</figcaption>
</figure>
</div>
</div></div></div>
<dl>
<dt>The effect of AI depends on the type of landscape.</dt>
<dd>
<p>Represent the landscape with a function <span class="math inline">\(y(x)\)</span>, and each period we choose an <span class="math inline">\(x\)</span> to minimize <span class="math inline">\(y(x)\)</span>. This is a well-defined explore-exploit problem, and we can characterize the expected progression of efficiency over time (the decline in <span class="math inline">\(y(.)\)</span> over time) as a function of the statistical structure of the landscape:</p>
<ol type="1">
<li><strong>Random landscape:</strong> If each <span class="math inline">\(y(x)\)</span> is completely independent there’s no intelligence needed in choosing <span class="math inline">\(x\)</span> (beyond keeping track of which locations you’ve already tried). This is just drawing balls from an urn. The growth in efficiency as a function of <span class="math inline">\(N\)</span> draws depends on the distribution of values of <span class="math inline">\(y\)</span> (<span class="citation" data-cites="muth1986search">Muth (<a href="#ref-muth1986search" role="doc-biblioref">1986</a>)</span>, <span class="citation" data-cites="kortum1997research">Kortum (<a href="#ref-kortum1997research" role="doc-biblioref">1997</a>)</span>).</li>
<li><strong>Rugged landscape:</strong> If <span class="math inline">\(y(x)\)</span> is correlated across <span class="math inline">\(x\)</span> but the correlation is local (e.g.&nbsp;if <span class="math inline">\(y(x)\)</span> is a Weiner process) then the best-estimate of <span class="math inline">\(y(x)\)</span> for a new <span class="math inline">\(x\)</span> will depend only on the neighboring values of <span class="math inline">\(x\)</span>. <span class="citation" data-cites="Callander2011">Callander (<a href="#ref-Callander2011" role="doc-biblioref">2011</a>)</span> and <span class="citation" data-cites="CarnehlSchneider2025">Carnehl and Schneider (<a href="#ref-CarnehlSchneider2025" role="doc-biblioref">2025</a>)</span> characterize the optimal strategy. Again we are not constrained on intelligence, only on data: the extrapolation algorithm is fairly simple.</li>
<li><strong>Regular landscape:</strong> Finally suppose the landscape has some deep latent structure. In this case the best-estimate of <span class="math inline">\(y(x)\)</span> will depend on the entire collection of previously-observed pairs <span class="math inline">\((x,y)\)</span>, and so we <em>do</em> expect that predictions could be improved with more intelligence, and so AI should have a big impact.<a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a></li>
</ol>
</dd>
<dt>Implications of landscape regularity.</dt>
<dd>
<p>If the world has a regular landscape then we are not primarily constrained on facts, we are constrained on intelligence. Thus if we build a sufficiently powerful pattern-matching machine our progress might accelerate rapidly, without any new data collection.</p>
</dd>
<dd>
<p>Good examples of random landscapes are when we are mapping out specific features of the world. If we are making a list of specific objects (planets) or species (viruses), then the observations cannot be well-predicted from first principles, and we inevitably need new observations. Similarly, if we are mapping a genome then the exact sequence of base pairs requires individual observations, it cannot be accurately predicted from already-available data.</p>
</dd>
<dd>
<p>A good example of regular landscape is folding proteins: here we are learning a function from a sequence of base-pairs to a 3D shape. The function is high-dimensional but we have reason to expect a low-dimensional representation which would make it tractable - and AlphaFold found one.</p>
</dd>
<dt>AI R&amp;D has already lead to discontinuities.</dt>
<dd>
<p>Many fields which have been progressing slowly show a discrete change in the rate of progress when computers took over:</p>
<ul>
<li>Progress in solving optimization problems.</li>
<li>Progress in proving combinatorics theorems (four-color theorem in 1976)</li>
<li>Progress in chess strategy (Elo has fallen quicker since 1997)</li>
<li>Progress in protein folding.</li>
</ul>
<p>Some of these have hit provably global minima: the four-color them; sphere packing; Ramsey numbers; Nash equilibrium of checkers, connect 4, texas hold-em, and chess endgames.</p>
<p>These accelerations have occurred when computer intelligence has surpassed human intelligence for a particular type of pattern-matching. As computer intelligence becomes more general then we should expect more and more lines of progress to start accelerating.</p>
</dd>
<dt>Aristotle already had the jigsaw pieces.</dt>
<dd>
<p>There’s a nice analogy for this: suppose we resurrected Aristotle, is it enough to show him our <em>theories</em>, or do we also need to show him the data we’ve gathered? Was he constrained on facts or intelligence? Did he already have enough jigsaw pieces, he was just lacking the insight?</p>
</dd>
<dd>
<p>It seems to me plausible that we could persuade Aristotle of some of the following from noting connections among the facts he was already aware of: that the sun is a star, that the earth goes around it, that the whale is not a fish, that the human is a monkey, that force is mass times acceleration, that temperature is motion, that pitch is frequency.</p>
</dd>
<dt>Predicting the effect of AI on R&amp;D is <em>intrinsically</em> difficult.</dt>
<dd>
<p>The landscape model I described above implies that we should expect AI to have a big effect when some domain has a latent undiscovered structure. But in many cases this is very difficult to know in advance: we don’t know where the floor is. It seems conceivable that there are some very simple undiscovered principles explaining cancer, fluid motion, evolution. But maybe these domains are irreducibly complex.</p>
</dd>
</dl>



<aside id="footnotes-4" class="footnotes footnotes-end-of-section" role="doc-footnote">
<hr>
<ol start="10">
<li id="fn10"><p>The closest paper I know of is <span class="citation" data-cites="agrawal2019needles">Agrawal, McHale, and Oettl (<a href="#ref-agrawal2019needles" role="doc-biblioref">2019</a>)</span>.<a href="#fnref10" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</aside>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-acemoglu2024simple" class="csl-entry" role="listitem">
Acemoglu, Daron. 2024. <span>“The Simple Macroeconomics of AI.”</span> National Bureau of Economic Research. <a href="https://economics.mit.edu/sites/default/files/2024-04/The%20Simple%20Macroeconomics%20of%20AI.pdf">https://economics.mit.edu/sites/default/files/2024-04/The%20Simple%20Macroeconomics%20of%20AI.pdf</a>.
</div>
<div id="ref-aghion2024ai" class="csl-entry" role="listitem">
Aghion, Philippe, and Simon Bunel. 2024. <span>“AI and Growth: Where Do We Stand.”</span> <a href="https://www.frbsf.org/wp-content/uploads/AI-and-Growth-Aghion-Bunel.pdf">https://www.frbsf.org/wp-content/uploads/AI-and-Growth-Aghion-Bunel.pdf</a>.
</div>
<div id="ref-agrawal2019predictionjudgmentcomplexity" class="csl-entry" role="listitem">
Agrawal, Ajay, Joshua Gans, and Avi Goldfarb. 2019. <span>“Prediction, Judgment, and Complexity: A Theory of Decision-Making and Artificial Intelligence.”</span> In <em>The Economics of Artificial Intelligence: An Agenda</em>, edited by Ajay Agrawal, Joshua Gans, and Avi Goldfarb, 89–110. Chicago, IL: University of Chicago Press. <a href="http://www.nber.org/chapters/c14010.pdf">http://www.nber.org/chapters/c14010.pdf</a>.
</div>
<div id="ref-agrawal2019needles" class="csl-entry" role="listitem">
Agrawal, Ajay, John McHale, and Alexander Oettl. 2019. <span>“Finding Needles in Haystacks: Artificial Intelligence and Recombinant Growth.”</span> In <em>The Economics of Artificial Intelligence: An Agenda</em>, edited by Ajay Agrawal, Joshua Gans, and Avi Goldfarb, 149–74. Chicago, IL: University of Chicago Press. <a href="https://doi.org/10.7208/9780226613475-007">https://doi.org/10.7208/9780226613475-007</a>.
</div>
<div id="ref-bengio2013representation" class="csl-entry" role="listitem">
Bengio, Yoshua, Aaron Courville, and Pascal Vincent. 2013. <span>“Representation Learning: A Review and New Perspectives.”</span> <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em> 35 (8): 1798–828. <a href="https://doi.org/10.1109/tpami.2013.50">https://doi.org/10.1109/tpami.2013.50</a>.
</div>
<div id="ref-brynjolfsson2025agenda" class="csl-entry" role="listitem">
Brynjolfsson, Erik, Anton Korinek, and Ajay K. Agrawal. 2025. <span>“A Research Agenda for the Economics of Transformative AI.”</span> Working Paper 34256. National Bureau of Economic Research. <a href="https://doi.org/10.3386/w34256">https://doi.org/10.3386/w34256</a>.
</div>
<div id="ref-Callander2011" class="csl-entry" role="listitem">
Callander, Steven. 2011. <span>“Searching and Learning by Trial and Error.”</span> <em>American Economic Review</em> 101 (6): 2277–2308. <a href="https://doi.org/10.1257/aer.101.6.2277">https://doi.org/10.1257/aer.101.6.2277</a>.
</div>
<div id="ref-CarnehlSchneider2025" class="csl-entry" role="listitem">
Carnehl, Christoph, and Johannes Schneider. 2025. <span>“A Quest for Knowledge.”</span> <em>Econometrica</em> 93 (2): 623–59. <a href="https://doi.org/10.3982/ECTA22144">https://doi.org/10.3982/ECTA22144</a>.
</div>
<div id="ref-caselli2019robot" class="csl-entry" role="listitem">
Caselli, Francesco, and Alan Manning. 2019. <span>“Robot Arithmetic: New Technology and Wages.”</span> <em>American Economic Review: Insights</em> 1 (1): 1–12. <a href="https://doi.org/10.1257/aeri.20170036">https://doi.org/10.1257/aeri.20170036</a>.
</div>
<div id="ref-chen2014day" class="csl-entry" role="listitem">
Chen, Yan, Grace YoungJoo Jeon, and Yong-Mi Kim. 2014. <span>“A Day Without a Search Engine: An Experimental Study of Online and Offline Searches.”</span> <em>Experimental Economics</em> 17 (4): 512–36. <a href="https://doi.org/10.1007/s10683-013-9381-9">https://doi.org/10.1007/s10683-013-9381-9</a>.
</div>
<div id="ref-collis2025welfare" class="csl-entry" role="listitem">
Collis, Avinash, and Erik Brynjolfsson. 2025. <span>“AI’s Overlooked $97 Billion Contribution to the Economy.”</span> <em>Wall Street Journal</em>, August. <a href="https://www.wsj.com/opinion/ais-overlooked-97-billion-contribution-to-the-economy-users-service-da6e8f55">https://www.wsj.com/opinion/ais-overlooked-97-billion-contribution-to-the-economy-users-service-da6e8f55</a>.
</div>
<div id="ref-coyle2025measurement" class="csl-entry" role="listitem">
Coyle, Diane, and John Lourenze Poquiz. 2025. <span>“Making AI Count: The Next Measurement Frontier.”</span> Draft chapter for NBER volume {\it Economics of Transformative AI: A Research Agenda}. National Bureau of Economic Research. <a href="https://conference.nber.org/conf_papers/f227496.pdf">https://conference.nber.org/conf_papers/f227496.pdf</a>.
</div>
<div id="ref-garicano2006organization" class="csl-entry" role="listitem">
Garicano, Luis, and Esteban Rossi-Hansberg. 2006. <span>“Organization and Inequality in a Knowledge Economy.”</span> <em>The Quarterly Journal of Economics</em> 121 (4): 1383–1435. <a href="https://doi.org/10.1162/qjec.121.4.1383">https://doi.org/10.1162/qjec.121.4.1383</a>.
</div>
<div id="ref-ide2024artificialintelligenceknowledgeeconomy" class="csl-entry" role="listitem">
Ide, Enrique, and Eduard Talamas. 2024. <span>“Artificial Intelligence in the Knowledge Economy.”</span> <a href="https://doi.org/10.1086/737233">https://doi.org/10.1086/737233</a>.
</div>
<div id="ref-korinek2024scenarios" class="csl-entry" role="listitem">
Korinek, Anton, and Donghyun Suh. 2024. <span>“Scenarios for the Transition to AGI.”</span> National Bureau of Economic Research. <a href="https://arxiv.org/pdf/2403.12107.pdf">https://arxiv.org/pdf/2403.12107.pdf</a>.
</div>
<div id="ref-kortum1997research" class="csl-entry" role="listitem">
Kortum, Samuel. 1997. <span>“Research, Patenting, and Technological Change.”</span> <em>Econometrica</em> 65 (6): 1389–419. <a href="https://doi.org/10.2307/2171741">https://doi.org/10.2307/2171741</a>.
</div>
<div id="ref-kwa2025longtasks" class="csl-entry" role="listitem">
Kwa, Thomas, Ben West, Joel Becker, Amy Deng, Katharyn Garcia, Max Hasin, Sami Jawhar, et al. 2025. <span>“Measuring AI Ability to Complete Long Tasks.”</span> <em>arXiv Preprint arXiv:2503.14499</em>. <a href="https://doi.org/10.48550/arXiv.2503.14499">https://doi.org/10.48550/arXiv.2503.14499</a>.
</div>
<div id="ref-muth1986search" class="csl-entry" role="listitem">
Muth, John F. 1986. <em>Search Theory and the Manufacturing Progress Function</em>. Columbus: Ohio State University. <a href="https://doi.org/10.1287/mnsc.32.8.948">https://doi.org/10.1287/mnsc.32.8.948</a>.
</div>
<div id="ref-restrepo2025missed" class="csl-entry" role="listitem">
Restrepo, Pascual. 2025. <span>“We Won’t Be Missed: Work and Growth in the Era of AGI.”</span> <em>NBER Chapters</em>. <a href="https://www.semanticscholar.org/search?q=We%20Won%27t%20Be%20Missed%3A%20Work%20and%20Growth%20in%20the%20Era%20of%20AGI">https://www.semanticscholar.org/search?q=We%20Won%27t%20Be%20Missed%3A%20Work%20and%20Growth%20in%20the%20Era%20of%20AGI</a>.
</div>
<div id="ref-smith2024" class="csl-entry" role="listitem">
Smith, Noah. 2024. <span>“Plentiful, High-Paying Jobs in the Age of AI.”</span> <a href="https://www.noahpinion.blog/p/plentiful-high-paying-jobs-in-the">https://www.noahpinion.blog/p/plentiful-high-paying-jobs-in-the</a>.
</div>
<div id="ref-varian2011economic" class="csl-entry" role="listitem">
Varian, Hal. 2011. <span>“Economic Value of Google.”</span> <a href="https://dl.icdst.org/pdfs/files1/f87de5ba3c43760ebcbc2a1d90950dbc.pdf">https://dl.icdst.org/pdfs/files1/f87de5ba3c43760ebcbc2a1d90950dbc.pdf</a>.
</div>
</div></section><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{cunningham2025,
  author = {Cunningham, Tom},
  title = {Economics and {Transformative} {AI}},
  date = {2025-10-02},
  url = {tecunningham.github.io/posts/2025-09-19-transformative-AI-notes.html},
  langid = {en}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-cunningham2025" class="csl-entry quarto-appendix-citeas" role="listitem">
Cunningham, Tom. 2025. <span>“Economics and Transformative AI.”</span>
October 2, 2025. <a href="https://tecunningham.github.io/posts/2025-09-19-transformative-AI-notes.html">tecunningham.github.io/posts/2025-09-19-transformative-AI-notes.html</a>.
</div></div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("tecunningham\.github\.io");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->
<script>var lightboxQuarto = GLightbox({"closeEffect":"zoom","descPosition":"bottom","loop":false,"openEffect":"zoom","selector":".lightbox"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>




</body></html>