<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Tom Cunningham">
<meta name="description" content="Tom Cunningham blog">

<title>Fifty Opinions on Economics of AI | Tom Cunningham – Tom Cunningham</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

<script type="text/javascript">

(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-12027453-1', 'auto');

ga('send', {
  hitType: 'pageview',
  'anonymizeIp': true,
});
</script>
<script>window.MathJax = {
   loader: { load: ["https://cdn.jsdelivr.net/gh/sonoisa/XyJax-v3@3.0.1/build/xypic.js"]},
   tex: {packages: {'[+]': ['xypic','bm']},
         macros: {  bm: ["\\boldsymbol{#1}", 1],
                    ut: ["\\underbrace{#1}_{\\text{#2}}", 2],
                    utt: ["\\underbrace{#1}_{\\substack{\\text{#2}\\\\\\text{#3}}}", 3] }
   }
};
</script>
<style>
   h1 {  border-bottom: 8px solid #557;}
   h2 {  border-bottom: 1px solid #ccc;}
   .greyproof {
      background-color: #f5f5f5;
      padding: 1em;
      margin: 1em 0;
      border-radius: 4px;
   }
</style>
<meta name="quarto:status" content="draft">


<link rel="stylesheet" href="../styles.css">
<meta name="twitter:title" content="Fifty Opinions on Economics of AI | Tom Cunningham">
<meta name="twitter:description" content="Tom Cunningham blog">
<meta name="twitter:card" content="summary">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner"><div id="quarto-draft-alert" class="alert alert-warning"><i class="bi bi-pencil-square"></i>Draft</div>
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Tom Cunningham</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href=".././about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/testingham"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/tom-cunningham-a9433/"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://tecunningham.github.io/index.xml"> <i class="bi bi-rss-fill" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://scholar.google.com/citations?user=MDB_DgkAAAAJ"> 
<span class="menu-text">scholar</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Fifty Opinions on Economics of AI</h1>
                      </div>
  </div>
    
  
  <div class="quarto-title-meta">

      
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<style>
   h2 { text-align: center; border-bottom: 8px solid black; padding-below: 0px; margin-below: 0px; }
   dl {display: grid; grid-template-columns: max-content auto;
       }
   dt {grid-column-start: 1; width: 5cm;  padding-bottom: 30px;
      margin-right: 0px;
      padding-right: 5px;
      border-top: 1px solid black; }
   dd {grid-column-start: 2; margin-left: 2em;  padding-bottom: 30px; 
      margin-left: 0px;
      padding-left: 5px;
      border-top: 1px solid black; }
</style>
<p>I do my best to give reasons, but some have just bubbled up from my unconscious &amp; now I can’t find reasons to dislodge them. I have tried to write not about the discourse but about the world. It’s always tempting to complain about other peoples’ mistakes, I’ve given in to that temptation in the last section.</p>
<section id="todays-impact-of-ai" class="level2">
<h2 class="anchored" data-anchor-id="todays-impact-of-ai">Today’s impact of AI</h2>
<dl>
<dt>The welfare impact in 2025 is around 1% of GDP.</dt>
<dd>
<p>The impact is through (A) using chatbots to solve everyday problems (home production); (B) increased productivity at work.</p>
<p>The former doesn’t show up in measured GDP at all, the latter will only partly be reflected in GDP because it primarily increases productivity in services, and much of the GDP of services is imputed from the input costs (i.e.&nbsp;wages paid to service-providers).</p>
</dd>
<dt>The welfare impact has been increasing at around 4X/year.</dt>
<dd>
Adoption has been growing around 2X/year, and the value/user has been growing around 2X/year. This growth can be decomposed into growth in capabilities and diffusion, I’d say it’s been roughly 50-50.
</dd>
</dl>
</section>
<section id="what-llms-do" class="level2">
<h2 class="anchored" data-anchor-id="what-llms-do">What LLMs do</h2>
<dl>
<dt>Neural nets extract the low-dimensional structure of the world.</dt>
<dd>
Our pre-conscious brains extract low-dimensional representations from high-dimensional inputs. We have finally we’ve taught computers to do the same thing (AKA the manifold hypothesis, <span class="citation" data-cites="bengio2013representation">Bengio, Courville, and Vincent (<a href="#ref-bengio2013representation" role="doc-biblioref">2013</a>)</span>).
</dd>
<dt>LLMs imitate human answers to questions.</dt>
<dd>
<p>A simple model of LLMs is that they provide answers to questions, based on a large training set of questions &amp; answers. This has a number of implications:</p>
<ol type="1">
<li><p>LLMs will be used for <em>new-to-you</em> questions, i.e.&nbsp;questions that you have not encountered before, but someone else has.</p></li>
<li><p>LLMs will be used for tasks which are <em>routine</em> in the sense that there’s relatively little variation, and input space is relatively low-dimensional.</p></li>
<li><p>The performance of an LLM on a task depends not on the intrinsic properties of that task, but just on the density of similar tasks in the training data (<span class="citation" data-cites="vonwerra2025jaggeddata">Werra (<a href="#ref-vonwerra2025jaggeddata" role="doc-biblioref">2025</a>)</span>).</p></li>
<li><p>LLMs exhibit superhuman performance (“transcendence”) when the task requires combining the answers to two questions (<span class="citation" data-cites="cunningham2023imitation">Cunningham (<a href="#ref-cunningham2023imitation" role="doc-biblioref">2023</a>)</span>, <span class="citation" data-cites="abreu2025taxonomytranscendence">Abreu et al. (<a href="#ref-abreu2025taxonomytranscendence" role="doc-biblioref">2025</a>)</span>).</p></li>
</ol>
</dd>
<dt>LLMs are worse at generalization than humans.</dt>
<dd>
<p>The model above treated knowledge as binary: either you know the answer or you don’t. We can extend this to extrapolation, and it seems clear that</p>
<ol type="1">
<li>LLMs are less sample-efficient learners than humans</li>
<li>LLMs are relatively worse at questions that are farther from their training data (compared to humans).</li>
</ol>
</dd>
<dt>We are moving from human-supervised to world-supervised AI.</dt>
<dd>
<p>LLMs very quickly caught up with human abilities because they’re trained on human judgments (human generated text, paid rater judgment, LLM user preferences). This led to a plateau around expert-human level.</p>
<p>However we can hook them up directly to the real world &amp; they can learn from that, &amp; so we are starting to see them break out of that plateau. (A nice analogy: suppose you play chess by looking up each position in the history of recorded games, and otherwise playing randomly; then you will rapidly become a competent player, but then hit a ceiling).</p>
<p>The properties you need to make progress on world-supervised problems: (1) cheap real-world feedback; (2) .</p>
</dd>
<dt>Unlike humans, computers can use their representations to synthesize new artefacts.</dt>
<dd>
<p>Human judgment has a notable asymmetry between recognition and production. There are many properties of objects which we can immediately recognize, but it’s far more difficult to synthesize a new object that has that property. We can judge whether a joke is funny, or a poem rhymes, or a picture looks realistic, but we find it far harder to create a funny joke, a rhyming poem, or a realistic picture. This is sometimes attributed to the hierarchical and feed-foward nature of how the brain processes information.</p>
<p>Artificial neural nets do not suffer from the same degree of asymmetry. They can be reversed to synthesize new objects that satisfy a given property. This means computers will be able to do qualitatively different things that humans cannot do, even with the same amount of knowledge.</p>
</dd>
<dt>LLM capabilities are highly correlated.</dt>
<dd>
Many studies find that benchmark scores are highly correlated across LLMs. This could be due for <em>supply</em> reasons or <em>demand</em> reasons.
</dd>
<dt>LLM capabilities are qualitatively different from human capabilities.</dt>
<dd>
The crispest representation is that LLMs can pass all exams, and pass all interview questions, but they cannot do the associated jobs. There is still a substantial bottleneck. Loosely I would characterize the bottleneck as failure to generalize, difficulty with off-distribution tasks. Concretely this manifests in weakness in unusual situations, interactive decision-making, or continual learning.
</dd>
</dl>
</section>
<section id="economic-effects-of-ai" class="level2">
<h2 class="anchored" data-anchor-id="economic-effects-of-ai">Economic Effects of AI</h2>
<dl>
<dt>LLMs make private knowledge public.</dt>
<dd>
We can apply the question-answering model of LLMs described above to economic equilibrium. Suppose each person has a set of questions which they know the answer to, &amp; this determines their economic capabilities (i.e.&nbsp;they earn rents off their private knowledge). If we treat LLMs as pooling all that private knowledge to make it public, this has clear implications: (A) greater welfare; (B) lower inequality; (C) less trade (i.e.&nbsp;lower GDP).
</dd>
<dt>Market power is not a big deal.</dt>
<dd>
I think you could get a good approximation of the static economic effect of AI assuming that the market is competitive, i.e.&nbsp;the competition questions are second-order. The market today is highly competitive: there’s a small gap in capabilities among the frontier labs, and open models are, at worst, 12 months behind. It’s possible that one lab will jump ahead, but it seems reasonable to treat the market as competitive as an approximation.
</dd>
<dt>AI companies will capture a small share of the surplus.</dt>
<dd>
This follows from the above. It’s easy to fall into the trap of thinking “a lot of value is being created, so the AI companies must be getting that value.”
</dd>
<dt>Baumol effects are not a big deal.</dt>
<dd>
ABC
</dd>
<dt>We cannot direct technical change.</dt>
<dd>
.
</dd>
<dt>Jobs don’t decompose tasks with observable outputs.</dt>
<dd>
It’s notable that the vast majority of labor is paid by <em>inputs</em> by <em>outputs</em>. I.e. work is mostly paid by the hour, or by the month, not paid by output (performance pay, piece rate). This implies that observing peoples’ output is difficult, and so it’s likely that .
</dd>
<dd>
<p>Why is observing output difficult? (…)</p>
</dd>
<dt>Demand will shift towards intelligence over knowledge.</dt>
<dd>
LLMs make knowledge cheap.
</dd>
<dt>AI will benefit poorer countries relatively more.</dt>
<dd>
AI has a relatively larger effect on the cost of producing services than on physical goods, so it will change the terms of trade in favor of poorer countries.
</dd>
<dt>GDP as it’s currently measured will fall.</dt>
<dd>
A consequence: tax revenues will fall without changes to how taxes are levied.
</dd>
<dt>Real wages will fall.</dt>
<dd>

</dd>
<dt>The relative value of land will rise.</dt>
<dd>

</dd>
<dt>Occupations with additively separable outputs will get replaced.</dt>
<dd>

</dd>
<dt>Demand for human-produced goods is limited.</dt>
<dd>

</dd>
<dt>AI will significantly advance science.</dt>
<dd>
My very basic model of science: over thousands of years we’ve been gradually uncovering deeper and simpler latent structures of the world, progressively adding them to the textbooks. In retrospect those structures are obvious, it required the flash of insight.
</dd>
</dl>
</section>
<section id="safety-effects" class="level2">
<h2 class="anchored" data-anchor-id="safety-effects">Safety Effects</h2>
</section>
<section id="social-effects" class="level2">
<h2 class="anchored" data-anchor-id="social-effects">Social Effects</h2>
<dl>
<dt>It will dissolve the glue that holds everything together.</dt>
<dd>
abc
</dd>
<dt>Preferences will change in hard-to-predict ways.</dt>
<dd>
Tastes are labile – what you choose as an adult is highly influenced by what you saw people choosing when you were a child. AI suddenly opens up the landscape of what we can get, but it’s hard to predict where we will end up because choices themselves have their own effects.
</dd>
<dt>Computers will be able to make better art than humans.</dt>
<dd>
<p>The success of an artwork is often judged by its ability to satisfy multiple different criteria simultaneously, for example a good picture both (a) depicts a specific scene, and (b) is a harmonious arrangement of colours. A good poem both (a) tells a story, (b) rhymes, and (c) scans. A good piece of music is like a sudoku puzzle – simultaneously satisfying many constraints. It’s easy for humans to recognize when an artwork successfully satisfies multiple criteria but hard to create a new artwork that satisfies those criteria. Neural nets allow computers to learn to represent the characteristics of artworks, and so it seems plausible they would become better than humans in being able to find permutations that satisfy them.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
</dd>
<dt>The effect on adversarial problems: help the bad guys more than the good guys.</dt>
<dd>
<p>In adversarial situations like spam-detection computers will help both spammers and spam-detectors. However they seem likely to shift the balance in favor of the spammers because of the relative advantage computers have at synthesizing over recognizing content (compared to humans). Humans can intuitively discriminate between real and fake artefacts, but that ability will become less valuable when computers have learned the cues that humans use to make those discriminations.</p>
</dd>
<dt>Communication will rely relatively more on <em>provenance</em> than on <em>content</em>.</dt>
<dd>
<p>When evaluating a message we can use signals either from the content or the provenance (i.e.&nbsp;where the message come from). Many communication systems already rely heavily on provenance, e.g.&nbsp;spam detection relies heavily on the identity of the sender. As generative ML improves I think we should expect equilibrium to move even further in the direction of provenance and reputation and away from content (see my <a href="https://tecunningham.github.io/posts/2023-06-06-effect-of-ai-on-communication.html">post</a>).</p>
</dd>
<dt>The impact of AI on a domain will depend on the statistical structure of that domain.</dt>
<dd>
(see ai-big-picture and )
</dd>
<dt>Giving people more power could be good or bad.</dt>
<dd>
The basic argument in favor of AI is that it allows us to better achieve our ends (“solves hard problems”). In turn, historically having a longer lever has led to better things – more people, living longer, &amp; more comfortably.
</dd>
<dt>Our nominal ends are not our actual ends.</dt>
<dd>
Strauss, Berlin, MacIntyre.
</dd>
</dl>
<aside id="footnotes" class="footnotes footnotes-end-of-section" role="doc-footnote">
<hr>
<ol>
<li id="fn1"><p>Computers have been better than humans at solving well-specified combinatorial problems for 70 years. The difference with newer generations of algorithms is that they can now learn categories that humans learn unconsciously: harmony, rhythm, representation, semantics, etc.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</aside>
</section>
<section id="what-research-is-needed" class="level2">
<h2 class="anchored" data-anchor-id="what-research-is-needed">What Research is Needed</h2>
<dl>
<dt>We are constrained more on theory than on data.</dt>
<dd>
<p>We have many projects which are collecting data on AI impacts, we can organize them into a waterfall, from top to bottom:</p>
<ol type="1">
<li><strong>Data on AI capabilities</strong> – benchmarks that have representative tasks across the economy - e.g.&nbsp;GDP-val (<span class="citation" data-cites="patwardhan2025gdpval">Patwardhan et al. (<a href="#ref-patwardhan2025gdpval" role="doc-biblioref">2025</a>)</span>), APEX.</li>
<li><strong>Data on AI uplift</strong> – effect on productivity, e.g. <span class="citation" data-cites="becker2025uplift">Becker et al. (<a href="#ref-becker2025uplift" role="doc-biblioref">2025</a>)</span>.</li>
<li><strong>Data on AI adoption</strong> – adoption by occupations, by industry, by demographic, E.g. <span class="citation" data-cites="bick2024rapid">(<a href="#ref-bick2024rapid" role="doc-biblioref"><strong>bick2024rapid?</strong></a>)</span>.</li>
<li><strong>Data on AI usage</strong> – what types of economic tasks are LLMs used for, e.g. <span class="citation" data-cites="handa2025economicindex">Handa et al. (<a href="#ref-handa2025economicindex" role="doc-biblioref">2025</a>)</span>, <span class="citation" data-cites="chatterji2025chatgpt">Chatterji et al. (<a href="#ref-chatterji2025chatgpt" role="doc-biblioref">2025</a>)</span>.</li>
<li><strong>Data on AI economic effects</strong> – changes in hiring and wages by occupation, e.g. <span class="citation" data-cites="brynjolfsson2025canaries">Brynjolfsson, Chandar, and Chen (<a href="#ref-brynjolfsson2025canaries" role="doc-biblioref">2025</a>)</span>.</li>
</ol>
<p>Each of these is relatively <em>unopinionated</em>, they try to canvas AI impacts in general. But just collecting data isn’t very useful without theory.</p>
</dd>
<dt>Someone should organize a conference of junior people working on transformative AI.</dt>
<dd>

</dd>
<dt>We need to unbundle labor.</dt>
<dd>
.
</dd>
<dt>Randomized trials have limited value.</dt>
<dd>

</dd>
<dt>We need more work on the offense-defense balance</dt>
<dd>
<p>There are dozens of cases where there’s some offense-defense balance, and it’s no immediately clear how AI will affect that balance. Some examples that came up in the Curve:</p>
<ul>
<li>hacking</li>
<li>ransomware</li>
<li>spearfishing</li>
<li>media manipulation</li>
<li>drone assassinations</li>
<li>drone warfare.</li>
</ul>
<p>In each case it’s clear that AI could help both sides, but arguable how the equilibrium will be affected.</p>
</dd>
<dt>We should have some common theory.</dt>
<dd>
<p>It seems wasteful to treat each of these problems independently, there ought to be some general principles we can apply on how AI will affect offense-defense balance.</p>
<p>The closest I know is <span class="citation" data-cites="garfinkel2019offensedefense">Garfinkel and Dafoe (<a href="#ref-garfinkel2019offensedefense" role="doc-biblioref">2019</a>)</span>. The argue that when both sides get sufficiently strong then this will generally tend to favor the defender:</p>
<blockquote class="blockquote">
<p>“we offer a general formalization of the offense-defense balance in terms of contest success functions. Simple models of ground invasions and cyberattacks that exploit software vulnerabilities suggest that, in both cases, growth in investments will favor offense when investment levels are sufficiently low and favor defense when they are sufficiently high.”</p>
</blockquote>
<p>I also have a <a href="https://tecunningham.github.io/posts/2023-06-06-effect-of-ai-on-communication.html">note from 2023</a>, which argues that AI will favor the defender for “internal” properties (where human judgment is the ground truth), but favor the attacker for “external” properties (where external reality is the ground truth).</p>
<p>This seems an incredibly fertile area for economic theory but I have seen very little enagement from economists.</p>
</dd>
</dl>
</section>
<section id="opinions-on-the-discourse" class="level2">
<h2 class="anchored" data-anchor-id="opinions-on-the-discourse">Opinions on the Discourse</h2>
<dl>
<dt>Discourse is tangled because we don’t have a theory of capabilities.</dt>
<dd>
Many disagreements .
</dd>
<dt>Most disagreement about economic growth is really about capabilities growth.</dt>
<dd>

</dd>
<dt>We have no canonical model of AI’s impact on the economy.</dt>
<dd>

</dd>
<dt>LLMs expose some holes in classical economics.</dt>
<dd>
We can only explain the success of NNs &amp; LLMs by talking about the low-dimensional and high-dimensional structure of the world.
</dd>
<dt>Knife-edge explosion conditions are bogus.</dt>
<dd>
sadf
</dd>
<dt>Having explicit forecasts would be very useful.</dt>
<dd>
<p>What do we expect AI to do to these things?</p>
<ul>
<li>Wages &amp; employment, across sectors and tenure.</li>
<li>The price of land, the value of the capital stock.</li>
<li>Incomes across different countries.</li>
</ul>
<p>I feel it’s like early 2020 and COVID: if we’re trying to make a decision about whether to announce a lock-down it should be based on a clear idea about the counterfactual, which includes a lot of equilibrium effects.</p>
</dd>
</dl>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-abreu2025taxonomytranscendence" class="csl-entry" role="listitem">
Abreu, Natalie, Edwin Zhang, Eran Malach, and Naomi Saphra. 2025. <span>“A Taxonomy of Transcendence.”</span> <a href="https://arxiv.org/abs/2508.17669">https://arxiv.org/abs/2508.17669</a>.
</div>
<div id="ref-becker2025uplift" class="csl-entry" role="listitem">
Becker, Joel, Nate Rush, Elizabeth Barnes, and David Rein. 2025. <span>“Measuring the Impact of Early-2025 AI on Experienced Open-Source Developer Productivity.”</span> <a href="https://arxiv.org/abs/2507.09089">https://arxiv.org/abs/2507.09089</a>.
</div>
<div id="ref-bengio2013representation" class="csl-entry" role="listitem">
Bengio, Yoshua, Aaron Courville, and Pascal Vincent. 2013. <span>“Representation Learning: A Review and New Perspectives.”</span> <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em> 35 (8): 1798–828.
</div>
<div id="ref-brynjolfsson2025canaries" class="csl-entry" role="listitem">
Brynjolfsson, Erik, Bharat Chandar, and Daniel Chen. 2025. <span>“Canaries in the Coal Mine? Six Facts about the Recent Employment Effects of Artificial Intelligence.”</span> Stanford Digital Economy Lab. <a href="https://digitaleconomy.stanford.edu/wp-content/uploads/2025/08/Canaries_BrynjolfssonChandarChen.pdf">https://digitaleconomy.stanford.edu/wp-content/uploads/2025/08/Canaries_BrynjolfssonChandarChen.pdf</a>.
</div>
<div id="ref-chatterji2025chatgpt" class="csl-entry" role="listitem">
Chatterji, Aaron, Thomas Cunningham, David J. Deming, Zoe Hitzig, Christopher Ong, Carl Yan Shan, and Kevin Wadman. 2025. <span>“How People Use ChatGPT.”</span> Working Paper 34255. National Bureau of Economic Research. <a href="https://doi.org/10.3386/w34255">https://doi.org/10.3386/w34255</a>.
</div>
<div id="ref-cunningham2023imitation" class="csl-entry" role="listitem">
Cunningham, Tom. 2023. <span>“An <span>AI</span> <span>Which</span> <span>Imitates</span> <span>Humans</span> <span>Can</span> <span>Beat</span> <span>Humans</span>.”</span> October 6, 2023. <a href="https://tecunningham.github.io/posts/2023-09-05-model-of-ai-imitation.html">tecunningham.github.io/posts/2023-09-05-model-of-ai-imitation.html</a>.
</div>
<div id="ref-garfinkel2019offensedefense" class="csl-entry" role="listitem">
Garfinkel, Ben, and Allan Dafoe. 2019. <span>“How Does the Offense-Defense Balance Scale?”</span> <em>Journal of Strategic Studies</em> 42 (6): 736–63. <a href="https://doi.org/10.1080/01402390.2019.1631810">https://doi.org/10.1080/01402390.2019.1631810</a>.
</div>
<div id="ref-handa2025economicindex" class="csl-entry" role="listitem">
Handa, Kunal, Alex Tamkin, Miles McCain, Saffron Huang, Esin Durmus, Sarah Heck, Jared Mueller, et al. 2025. <span>“Which Economic Tasks Are Performed with AI? Evidence from Millions of Claude Conversations.”</span> <a href="https://arxiv.org/abs/2503.04761">https://arxiv.org/abs/2503.04761</a>.
</div>
<div id="ref-patwardhan2025gdpval" class="csl-entry" role="listitem">
Patwardhan, Tejal, Rachel Dias, Elizabeth Proehl, Grace Kim, Michele Wang, Olivia Watkins, Simón Posada Fishman, et al. 2025. <span>“GDPval: Evaluating AI Model Performance on Real-World Economically Valuable Tasks.”</span> <em>arXiv Preprint arXiv:2510.04374</em>.
</div>
<div id="ref-vonwerra2025jaggeddata" class="csl-entry" role="listitem">
Werra, Leandro von. 2025. <span>“The Jagged AI Frontier Is a Data Frontier.”</span> 2025. <a href="https://huggingface.co/spaces/lvwerra/jagged-data-frontier">https://huggingface.co/spaces/lvwerra/jagged-data-frontier</a>.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("tecunningham\.github\.io");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>