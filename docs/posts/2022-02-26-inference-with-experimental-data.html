<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.357">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Tom Cunningham">
<meta name="description" content="Tom Cunningham blog">

<title>Inference on Experiments | Tom Cunningham</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

<script type="text/javascript">

(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-12027453-1', 'auto');

ga('send', {
  hitType: 'pageview',
  'anonymizeIp': true,
});
</script>
<script>window.MathJax = {
   loader: { load: ["https://cdn.jsdelivr.net/gh/sonoisa/XyJax-v3@3.0.1/build/xypic.js"]},
   tex: {packages: {'[+]': ['xypic','bm']},
         macros: {  bm: ["\\boldsymbol{#1}", 1],
                    ut: ["\\underbrace{#1}_{\\text{#2}}", 2],
                    utt: ["\\underbrace{#1}_{\\substack{\\text{#2}\\\\\\text{#3}}}", 3] }
   }
};
</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../styles.css">
<meta name="twitter:title" content="Inference on Experiments | Tom Cunningham">
<meta name="twitter:description" content="">
<meta name="twitter:image" content="tecunningham.github.io/posts/2022-02-26-inference-with-experimental-data_files/figure-html/unnamed-chunk-1-1.png">
<meta name="twitter:image-height" content="787">
<meta name="twitter:image-width" content="989">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="floating nav-fixed slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Tom Cunningham</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href=".././about.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/testingham" rel="" target=""><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/tom-cunningham-a9433/" rel="" target=""><i class="bi bi-linkedin" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://tecunningham.github.io/index.xml" rel="" target=""><i class="bi bi-rss-fill" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://scholar.google.com/citations?user=MDB_DgkAAAAJ" rel="" target="">
 <span class="menu-text">scholar</span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Inference on Experiments</h1>
                      </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Tom Cunningham </p>
            </div>
    </div>
      
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul class="collapse">
  <li><a href="#overview" id="toc-overview" class="nav-link active" data-scroll-target="#overview">Overview</a></li>
  <li><a href="#philosophical-remark-confounding-and-noise" id="toc-philosophical-remark-confounding-and-noise" class="nav-link" data-scroll-target="#philosophical-remark-confounding-and-noise">Philosophical Remark: Confounding and Noise</a></li>
  <li><a href="#setup" id="toc-setup" class="nav-link" data-scroll-target="#setup">Setup</a></li>
  <li><a href="#univariate-shrinkage-estimators" id="toc-univariate-shrinkage-estimators" class="nav-link" data-scroll-target="#univariate-shrinkage-estimators">Univariate Shrinkage Estimators</a></li>
  <li><a href="#multivariate-shrinkage-unfinished" id="toc-multivariate-shrinkage-unfinished" class="nav-link" data-scroll-target="#multivariate-shrinkage-unfinished">Multivariate Shrinkage [UNFINISHED]</a></li>
  <li><a href="#bivarate-normal-shrinkage" id="toc-bivarate-normal-shrinkage" class="nav-link" data-scroll-target="#bivarate-normal-shrinkage">Bivarate Normal Shrinkage</a>
  <ul class="collapse">
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary">Summary</a></li>
  </ul></li>
  <li><a href="#experiment-surrogacy" id="toc-experiment-surrogacy" class="nav-link" data-scroll-target="#experiment-surrogacy">Experiment Surrogacy</a></li>
  <li><a href="#causal-effects-instrumental-variables" id="toc-causal-effects-instrumental-variables" class="nav-link" data-scroll-target="#causal-effects-instrumental-variables">Causal Effects / Instrumental Variables</a></li>
  <li><a href="#observational-surrogacy" id="toc-observational-surrogacy" class="nav-link" data-scroll-target="#observational-surrogacy">Observational Surrogacy</a>
  <ul class="collapse">
  <li><a href="#setup-1" id="toc-setup-1" class="nav-link" data-scroll-target="#setup-1">Setup</a></li>
  <li><a href="#additional-issues" id="toc-additional-issues" class="nav-link" data-scroll-target="#additional-issues">Additional Issues</a></li>
  <li><a href="#surrogacy-examples" id="toc-surrogacy-examples" class="nav-link" data-scroll-target="#surrogacy-examples">Surrogacy Examples</a></li>
  </ul></li>
  <li><a href="#composite-metrics" id="toc-composite-metrics" class="nav-link" data-scroll-target="#composite-metrics">Composite Metrics</a></li>
  <li><a href="#launch-rules" id="toc-launch-rules" class="nav-link" data-scroll-target="#launch-rules">Launch Rules</a>
  <ul class="collapse">
  <li><a href="#comparing-launch-rules" id="toc-comparing-launch-rules" class="nav-link" data-scroll-target="#comparing-launch-rules">Comparing Launch Rules</a></li>
  </ul></li>
  <li><a href="#network-and-dynamic-effects" id="toc-network-and-dynamic-effects" class="nav-link" data-scroll-target="#network-and-dynamic-effects">Network and Dynamic Effects</a></li>
  <li><a href="#appendix-derivation-of-multivariate-gaussian-posterior" id="toc-appendix-derivation-of-multivariate-gaussian-posterior" class="nav-link" data-scroll-target="#appendix-derivation-of-multivariate-gaussian-posterior">Appendix: Derivation of Multivariate Gaussian Posterior</a></li>
  <li><a href="#recommendations" id="toc-recommendations" class="nav-link" data-scroll-target="#recommendations">Recommendations</a></li>
  <li><a href="#difficult-cases" id="toc-difficult-cases" class="nav-link" data-scroll-target="#difficult-cases">Difficult Cases</a>
  <ul class="collapse">
  <li><a href="#selection-of-experiments" id="toc-selection-of-experiments" class="nav-link" data-scroll-target="#selection-of-experiments">Selection of Experiments</a></li>
  </ul></li>
  <li><a href="#to-add" id="toc-to-add" class="nav-link" data-scroll-target="#to-add">To Add</a></li>
  <li><a href="#discussion-on-bayesian-vs-frequentist-interpretation" id="toc-discussion-on-bayesian-vs-frequentist-interpretation" class="nav-link" data-scroll-target="#discussion-on-bayesian-vs-frequentist-interpretation">Discussion on Bayesian vs Frequentist Interpretation</a>
  <ul class="collapse">
  <li><a href="#what-is-your-prior" id="toc-what-is-your-prior" class="nav-link" data-scroll-target="#what-is-your-prior">What is Your Prior?</a></li>
  <li><a href="#ideal-bayesianism-vs-quantitative-bayesianism" id="toc-ideal-bayesianism-vs-quantitative-bayesianism" class="nav-link" data-scroll-target="#ideal-bayesianism-vs-quantitative-bayesianism">Ideal Bayesianism vs Quantitative Bayesianism</a></li>
  <li><a href="#ideal-hypothesis-testing-vs-actual-hypothesis-testing" id="toc-ideal-hypothesis-testing-vs-actual-hypothesis-testing" class="nav-link" data-scroll-target="#ideal-hypothesis-testing-vs-actual-hypothesis-testing">Ideal Hypothesis Testing vs Actual Hypothesis Testing</a></li>
  <li><a href="#bayesian-and-classical-inferences-doing-different-things" id="toc-bayesian-and-classical-inferences-doing-different-things" class="nav-link" data-scroll-target="#bayesian-and-classical-inferences-doing-different-things">Bayesian and Classical Inferences Doing Different Things</a></li>
  <li><a href="#pain-comes-from-confusing-them" id="toc-pain-comes-from-confusing-them" class="nav-link" data-scroll-target="#pain-comes-from-confusing-them">Pain Comes from Confusing Them</a></li>
  <li><a href="#coverage" id="toc-coverage" class="nav-link" data-scroll-target="#coverage">Coverage</a></li>
  <li><a href="#ambiguous-statements" id="toc-ambiguous-statements" class="nav-link" data-scroll-target="#ambiguous-statements">Ambiguous Statements</a></li>
  <li><a href="#everything-affects-everything." id="toc-everything-affects-everything." class="nav-link" data-scroll-target="#everything-affects-everything.">Everything Affects Everything.</a></li>
  <li><a href="#paradoxes-from-interpreting-classical-inferences-as-bayesian-inferences" id="toc-paradoxes-from-interpreting-classical-inferences-as-bayesian-inferences" class="nav-link" data-scroll-target="#paradoxes-from-interpreting-classical-inferences-as-bayesian-inferences">Paradoxes from Interpreting Classical Inferences as Bayesian Inferences</a></li>
  <li><a href="#why-use-the-classical-methods" id="toc-why-use-the-classical-methods" class="nav-link" data-scroll-target="#why-use-the-classical-methods">Why Use the Classical Methods?</a></li>
  <li><a href="#selective-reporting" id="toc-selective-reporting" class="nav-link" data-scroll-target="#selective-reporting">Selective Reporting</a></li>
  <li><a href="#multiple-comparisons-corrections" id="toc-multiple-comparisons-corrections" class="nav-link" data-scroll-target="#multiple-comparisons-corrections">Multiple-comparisons Corrections</a></li>
  <li><a href="#winners-curse" id="toc-winners-curse" class="nav-link" data-scroll-target="#winners-curse">Winner’s Curse</a></li>
  <li><a href="#peeking" id="toc-peeking" class="nav-link" data-scroll-target="#peeking">Peeking</a></li>
  <li><a href="#can-you-get-a-stat-sig-posterior-from-a-non-sig-likelihood" id="toc-can-you-get-a-stat-sig-posterior-from-a-non-sig-likelihood" class="nav-link" data-scroll-target="#can-you-get-a-stat-sig-posterior-from-a-non-sig-likelihood">Can you get a Stat-Sig Posterior from a Non-Sig Likelihood?</a></li>
  <li><a href="#misc-questions-and-answers" id="toc-misc-questions-and-answers" class="nav-link" data-scroll-target="#misc-questions-and-answers">Misc Questions and Answers</a></li>
  </ul></li>
  <li><a href="#references-1" id="toc-references-1" class="nav-link" data-scroll-target="#references-1">References</a></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
    </div>
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full" id="quarto-document-content">




<style>
    h1 {  border-bottom: 4px solid black;}
    h2 {  border-bottom: 1px solid #ccc;}
    .example { border: 1px #ee9933 solid; background: #ffeecc; padding: 10px; }
   /* #quarto-document-content { width: 500px; } */
   /* .column-margin { width: 300px; } */
</style>
<hr>
<p><strong>Summary:</strong></p>
<ol type="1">
<li><p>Most problems related to experiment interpretation can be formalized as conditional expectations of treatment effects. This includes problems such as selection effects, shrinkage, surrogacy, meta-analysis, long-term effects, composite metrics, launch rules, peeking.</p></li>
<li><p>If we simplify to Gaussian priors over treatment effects then the conditional expectations have simple linear forms, depending only on the variances and covariances of treatment-effects and of noise.</p></li>
</ol>
<section id="overview" class="level2">
<h2 class="anchored" data-anchor-id="overview">Overview</h2>
<p>Suppose we observe treatment effects across a set of <span class="math inline">\(n\)</span> different metrics <span class="math inline">\(\hat{\bm{t}}=(\hat{t}_1,\ldots,\hat{t}_n)\)</span>. We can decompose these into the true effect and the noise: <span class="math display">\[\begin{aligned}
      \utt{\hat{\bm{t}}}{observed}{experiment effects}
         &amp;= \utt{\bm{t}}{true avg}{treatment effects} + \utt{\bm{e}}{noise}{(=user-level variation)} \\
      \bm{e}   &amp;= \utt{\frac{1}{N}\sum_{j\in T}\bm{x}^j}{users in}{treatment}
                  - \utt{\frac{1}{N}\sum_{j\in C}\bm{x}^j}{users in}{control}
   \end{aligned}
   \]</span></p>
<p>Here <span class="math inline">\(\bm{x}^j\)</span> represents the outcome of user <span class="math inline">\(j\)</span> without treatment. We generally want to infer the average treatment effect from the observed effect: <span class="math display">\[E[\bm{t}|\hat{\bm{t}}].\]</span></p>
<p>We know the variance and covariance of <span class="math inline">\(\bm{e}\)</span> from observational user data.</p>
<p>The observed effect will be our best-guess for the true effect (<span class="math inline">\(E[\bm{t}|\hat{\bm{t}}]\simeq\hat{\bm{t}}\)</span>) only when either our prior on <span class="math inline">\(t\)</span> is very broad (<span class="math inline">\(\sigma_t^2\simeq\infty\)</span>) or confidence intervals are very tight (<span class="math inline">\(\sigma_e^2\simeq0\)</span>). In most practical cases the interpretation of the experiment outcome will depend on our prior over treatment effects. We can write out some simple applications of this framework (for compactness we write everything as if we had a mean-zero prior, <span class="math inline">\(E[\bm{t}]=0\)</span>):</p>
<ol type="1">
<li><p><strong>With Gaussian treatment-effects we have closed-form posteriors.</strong> With Gaussian priors there is a linear relationship between observed estimates and posteriors, the coefficients depend just on the variance and covariance of treatment effects and noise (<span class="math inline">\(\Sigma_t\)</span> and <span class="math inline">\(\Sigma_e\)</span>): <span class="math display">\[\begin{aligned}
   \mathbb{E}[t|\hat{t}] &amp;= \frac{\sigma_t^2}{\sigma_t^2+\sigma_e^2}\hat{t}
      &amp;&amp; \text{(univariate)} \\
   \mathbb{E}[t_1|\hat{t}_2]  &amp;= \rho_t\frac{\sigma_{t1}}{\sigma_{t2}}\frac{\sigma_{t2}^2}{\sigma_{t2}^2+\sigma_{e2}^2}\hat{t}_2
      &amp;&amp; \text{(cross-univariate)}\\
   \mathbb{E}[t_1|\hat{t}_1,\hat{t}_2]  &amp;= \text{(see below)}
      &amp;&amp; \text{(bivariate)}\\
   \mathbb{E}[\bm{t}|\hat{\bm{t}}]   &amp;=\Sigma_t(\Sigma_t+\Sigma_e)^{-1}\hat{\bm{t}}
      &amp;&amp; \text{(multivariate)} \\
\end{aligned}
\]</span></p></li>
<li><p><strong>Experiment surrogacy.</strong> When we want to predict the treatment-effect on an unobserved outcome (e.g.&nbsp;a future outcome) we can write the problem as: <span class="math display">\[\begin{aligned}
   \mathbb{E}[t_2|\hat{t}_1]  &amp;= \frac{\rho_t\sigma_{t1}\sigma_{t2}}{\sigma_{t1}^2+\sigma_{e1}^2} \hat{t}_1 &amp;&amp; \text{(univariate)}
\end{aligned}
\]</span></p></li>
<li><p><strong>Causal relationships.</strong> Sometimes we want to know the relationship between two causal effects: <span class="math display">\[\mathbb{E}[t_2|t_1] = \rho_t\frac{\sigma_{t2}}{\sigma_{t1}}t_1.\]</span></p>
<p>The naive solution of running a regression on observed experiment outcomes (<span class="math inline">\(\frac{cov(\hat{t}_1,\hat{t}_2)}{var(\hat{t}_1)}\)</span>) will yield a coefficient that has both (1) attenuation bias (because we observe <span class="math inline">\(\hat{t}_2\)</span> instead of <span class="math inline">\(t_2\)</span>), and (2) activity bias (because there is correlation between <span class="math inline">\(e_1\)</span> and <span class="math inline">\(e_2\)</span>).</p></li>
<li><p><strong>Composite metrics.</strong> Sometimes we wish to define a single composite metric as a weighted average across all metrics, with <span class="math inline">\(\bm{w}=(w_1,\ldots,w_n)\)</span>, so total value is <span class="math inline">\(\bm{w}'\bm{t}\)</span>. We can estimate the full impact by applying these weights to our posteriors: <span class="math display">\[\mathbb{E}[\bm{w}'\bm{t}|\hat{\bm{t}}]=w'\mathbb{E}[\bm{t}|\hat{\bm{t}}].\]</span></p>
<p>However if we applied the weights directly to the raw estimates (<span class="math inline">\(\bm{w}'\hat{\bm{t}}\)</span>) this would be a poor guide to impact, in addition such a composite will often have high noise (low signal-noise ratio, lower power) because of positive covariance among the components of <span class="math inline">\(\bm{e}\)</span>.</p></li>
<li><p><strong>Launch rules.</strong> Many companies come up with “launch rules” which are functions of the observed experiment outcomes, <span class="math inline">\(f(\hat{\bm{t}})\in\{0,1\}\)</span>. However it’s often unclear the best way to define this function. It is useful to think of <span class="math inline">\(f(\cdot)\)</span> as a forecast of the long-term impact on fundamental business goals, which can then be calibrated based on the variances and covariances above. We should treat this forecast as a simple extrapolation, but one that can be overriden when we have additional information, especially when the forecast has a low <span class="math inline">\(R^2\)</span>.</p></li>
<li><p><strong>Other things to add:</strong></p>
<ul>
<li>High dimensionality.</li>
<li>Nonlinearity</li>
<li>SNR from fraction significant</li>
<li>AA tests</li>
</ul></li>
</ol>
</section>
<section id="philosophical-remark-confounding-and-noise" class="level1">
<h1>Philosophical Remark: Confounding and Noise</h1>
<p><span class="math display">\[\boxed{\substack{\text{best-estimate}\\\text{causal}\\\text{effect}}}
      = \underbrace{\vphantom{\boxed{\substack{a\\b\\c}}}\boxed{\substack{\text{correlation}}}}_{\text{directly observed}}
         + \underbrace{\boxed{\substack{\text{adjustment for}\\\text{confounding}}}
            }_{\text{requires judgment}}
         + \underbrace{\boxed{\substack{\text{adjustment for}\\\text{noise}}}
            }_{\text{requires judgment}}
\]</span></p>
<p><strong>Estimating causal effects from correlations requires two adjustments:</strong></p>
<ol type="1">
<li><strong>Adjustment for confounding:</strong> This is not necessary when we have a randomized experiment or another credible source of identification.</li>
<li><strong>Adjustment for noise:</strong> This is not necessary if studies have very large <span class="math inline">\(N\)</span> (and so tight confidence intervals).</li>
</ol>
<p><strong>Many fields sets a premium on evidence where there is low confounding (“identification”).</strong> E.g. RCTs, natural experiments, complex estimators. The downside is that these fields will ignore a lot of potentially interesting evidence, e.g.&nbsp;evidence-based medicine movement restricting itself to randomized trials, and economics restricted itself to evidence with identification.</p>
<p><strong>A lot of studies with no confounding problems fail to adjust for priors.</strong> Papers often just report the raw estimate or p-value. However unless N is very large this doesn’t reflect a good practical inference, we often need to substantially adjust towards our priors, which often means adjusting towards zero.</p>
</section>
<section id="setup" class="level1 page-columns page-full">
<h1>Setup</h1>
<div class="cell page-columns page-full" data-hash="2022-02-26-inference-with-experimental-data_cache/html/unnamed-chunk-1_990db8e188457de3a509d7eff3a71afa">

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<p><img src="2022-02-26-inference-with-experimental-data_files/figure-html/unnamed-chunk-1-1.png" class="img-fluid" width="288"></p>
</div></div></div>
<p><strong>A single metric.</strong> We observe <span class="math inline">\(\hat{t}\)</span> which is the true treatment effect plus noise, <span class="math inline">\(\hat{t}=t+e\)</span>. Then for any given <span class="math inline">\(t\)</span> our posterior probability will be:</p>
<p><span class="math display">\[\begin{aligned}
   \ut{f(t|\hat{t})}{posterior}=\ut{f(t)}{prior}\times \ut{f(\hat{t}|t)}{likelihood}
\end{aligned}
\]</span></p>
<p>If the prior is entirely flat then the posterior will be the likelihood, in other words the classical point-estimate and distribution will be exactly equal to the Bayesian posterior estimate and distribution.</p>
<p><strong>Two metrics.</strong> Suppose that you run an experiment with <span class="math inline">\(N\)</span> units assigned to treatment and control groups, and define <span class="math inline">\(\hat{t}_1\)</span> and <span class="math inline">\(\hat{t}_2\)</span> as the observed treatment effects for outcomes 1 and 2. We can decompose the observed outcomes into treatment-effects and noise:</p>
<p><span class="math display">\[ \underbrace{\binom{\hat{t}_1}{\hat{t}_2}}_\text{outcomes} = \underbrace{\binom{t_1}{t_2}}_\text{treatment effects}  +  \underbrace{\binom{e_1}{e_2}}_\text{noise} \]</span></p>
<p>In this paper we will be particularly interested in the covariances of the treatment effects, and of the noise.</p>
<p>The noise terms <span class="math inline">\(e_1\)</span> and <span class="math inline">\(e_2\)</span> represent the sampling error, and therefore will have variances and covariances corresponding to the variances and covariances of the individual units, multiplied by a factor of <span class="math inline">\(\frac{2}{N}\)</span>.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>.</p>
<p>The variances and covariances of <span class="math inline">\(t_1\)</span> and <span class="math inline">\(t_2\)</span> represent the experimenter’s priors, and so are often difficult to quantify. If we are willing to identify priors with some set of previously-run experiments, i.e.&nbsp;an “empirical-Bayes” technique, we can recover them from the data using this relationship between covariance matrices:</p>
<p><span class="math display">\[\Sigma_{\hat{t}}= \Sigma_t + \frac{2}{N}\Sigma_u,\]</span></p>
<p>where <span class="math inline">\(\Sigma_u\)</span> is the unit-level covariance matrix. The following graph illustrates a case with negatively-correlated treatment effects, positively correlated noise, and uncorrelated outcomes.</p>
<div class="cell page-columns page-full" data-hash="2022-02-26-inference-with-experimental-data_cache/html/unnamed-chunk-2_17ae1c2abb1658b4e9af7f0be1ce9fcc">

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<p><img src="2022-02-26-inference-with-experimental-data_files/figure-html/unnamed-chunk-2-1.png" class="img-fluid" width="192"></p>
</div></div></div>
<div class="cell page-columns page-full" data-hash="2022-02-26-inference-with-experimental-data_cache/html/unnamed-chunk-3_f204cccdd67fcb74af8c678033c14b0a">

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<p><img src="2022-02-26-inference-with-experimental-data_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid" width="192"></p>
</div></div></div>
<div class="cell page-columns page-full" data-hash="2022-02-26-inference-with-experimental-data_cache/html/unnamed-chunk-4_54f53bac2ed0eecd55ff66d22600f0cb">

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<p><img src="2022-02-26-inference-with-experimental-data_files/figure-html/unnamed-chunk-4-1.png" class="img-fluid" width="192"></p>
</div></div></div>
<p><strong>Many metrics.</strong> If we assume that everything has a normal distribution, we have a crisp expression for how the posterior expectations depend on the observed outcomes. For an arbitrary number of outcomes we can write this as:</p>
<p><span class="math display">\[\mathbb{E}[t|y]=\mu_t+\Sigma_t(\Sigma_t+\frac{1}{N}\Sigma_u)^{-1}(y-\mu_t).\]</span></p>
</section>
<section id="univariate-shrinkage-estimators" class="level1 page-columns page-full">
<h1>Univariate Shrinkage Estimators</h1>
<p>See survey of methods in <span class="citation" data-cites="montiel2019">Azevedo et al. (<a href="#ref-montiel2019" role="doc-biblioref">2019</a>)</span>. They also document the fat tailed distribution of effect-sizes.</p>
<div class="cell page-columns page-full" data-hash="2022-02-26-inference-with-experimental-data_cache/html/unnamed-chunk-5_9d15acfb34fb7310a809b411577f4a6d">

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<p><img src="2022-02-26-inference-with-experimental-data_files/figure-html/unnamed-chunk-5-1.png" class="img-fluid" width="288"></p>
</div></div></div>
<div class="cell page-columns page-full" data-hash="2022-02-26-inference-with-experimental-data_cache/html/unnamed-chunk-6_119c5fba84d502a5677861c16d7b06b1">

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<p><img src="2022-02-26-inference-with-experimental-data_files/figure-html/unnamed-chunk-6-1.png" class="img-fluid" width="288"></p>
</div></div></div>
<div class="cell page-columns page-full" data-hash="2022-02-26-inference-with-experimental-data_cache/html/unnamed-chunk-7_59d39d5102a73bd6e837792d8137ffd9">

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<p><img src="2022-02-26-inference-with-experimental-data_files/figure-html/unnamed-chunk-7-1.png" class="img-fluid" width="288"></p>
</div></div></div>
<div class="cell page-columns page-full" data-hash="2022-02-26-inference-with-experimental-data_cache/html/unnamed-chunk-8_707999b394b2e4f0120d0752b9be1bd9">

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<p><img src="2022-02-26-inference-with-experimental-data_files/figure-html/unnamed-chunk-8-1.png" class="img-fluid" width="288"></p>
</div></div></div>
<ol type="1">
<li><p><strong>James-Stein.</strong> With a Normal prior, <span class="math inline">\(t\sim N(\mu_t,\sigma_t^2)\)</span>, we get: <span class="math display">\[\mathbb{E}[t|y]=\mu_t+\utt{\frac{\sigma_t^2}{\sigma_t^2+\sigma_e^2}}{shrinkage}{factor}(y-\mu_t).\]</span> We can also use the share of experiments that are significant, <span class="math inline">\(p\)</span>: <span class="math display">\[\begin{aligned}
      E[t|y]=&amp; [ 1-(\frac{1}{1.96}\Phi^{-1}(\frac{p}{2}))^2 ]y.
   \end{aligned}\]</span> When <span class="math inline">\(p=5\)</span>% the shrinkage factor is 0, when <span class="math inline">\(p=15\)</span>% shrinkage is .5, when <span class="math inline">\(p=50\)</span>% shrinkage is .88.</p></li>
<li><p><strong>Tweedie’s Formula.</strong> Allow treatment-effects to have any distribution, <span class="math inline">\(t\sim g(\cdot)\)</span>, but still have Gaussian error. We can show that: <span class="math display">\[E[t|y]=y + \sigma^2_e\frac{f'(y)}{f(y)}.\]</span> Requires estimating a continuous density of outcomes <span class="math inline">\(\hat{f}(y)\)</span> – there are various nonparametric ways of doing that. Implication: shrink only when the density of <span class="math inline">\(y\)</span> is sloping, not where it’s flat. See <span class="citation" data-cites="efron2021computer">Efron and Hastie (<a href="#ref-efron2021computer" role="doc-biblioref">2021</a>)</span>.</p></li>
<li><p><strong>Experiment Splitting.</strong> See <span class="citation" data-cites="coey2019improving">Coey and Cunningham (<a href="#ref-coey2019improving" role="doc-biblioref">2019</a>)</span>.</p></li>
<li><p><strong>Deconvolution.</strong> If we can estimate the distribution <span class="math inline">\(t\sim g(\cdot)\)</span> from <span class="math inline">\(f(y)\)</span>, then we have: <span class="math display">\[\mathbb{E}[t|y]=\frac{\int_t t(g(t)+f(y-t))dt}{\int_t t(g(t)+f(y-t))dt}.\]</span> Discussed in <span class="citation" data-cites="efron2021computer">Efron and Hastie (<a href="#ref-efron2021computer" role="doc-biblioref">2021</a>)</span>.</p></li>
</ol>
</section>
<section id="multivariate-shrinkage-unfinished" class="level1">
<h1>Multivariate Shrinkage [UNFINISHED]</h1>
<ol type="1">
<li><p><strong>Multivariate Gaussian.</strong> (Curds &amp; Whey)</p></li>
<li><p><strong>L1 penalty.</strong> (Lasso)</p></li>
<li><p><strong>Experiment splitting.</strong> <span class="citation" data-cites="coey2019improving">Coey and Cunningham (<a href="#ref-coey2019improving" role="doc-biblioref">2019</a>)</span> found significant improvements by conditioning on other outcomes for Facebook experiments.</p></li>
<li><p><strong>PPL.</strong></p></li>
</ol>
</section>
<section id="bivarate-normal-shrinkage" class="level1">
<h1>Bivarate Normal Shrinkage</h1>
<p>We can write it like this: <span class="math display">\[\utt{\binom{\hat{t}_1}{\hat{t}_2}}{observed}{effects}
      =\utt{\binom{t_1}{t_2}}{true}{effects}
         +\ut{\binom{e_1}{e_2}}{noise}\]</span></p>
<p>With just two outcomes Normal shrinkage becomes:<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></p>
<p><span class="math display">\[\begin{aligned}
   \mathbb{E}[t_1| \hat{t}_1,\hat{t}_2] =&amp; \mu_1
         +\ut{|\Sigma_{\hat{t}}|^{-1}(\sigma^2_{t1}(\sigma^2_{t2} + \sigma^2_{e2})
            - \gamma_{t}(\gamma_{t}+\gamma_{e}))}{coeff on $\hat{t}_1$}(\hat{t}_1-\mu_1)
         + \ut{|\Sigma_{\hat{t}}|^{-1}(\gamma_{t}\sigma^2_{e1} - \gamma_{e}\sigma^2_{t1})}{coeff on $\hat{t}_2$} (\hat{t}_2-\mu_2)  \\
   |\Sigma_{\hat{t}}|  =&amp; (\sigma_{t1}^2+\sigma_{e1}^2) (\sigma_{t2}^2+\sigma_{e2}^2)
                     - (\gamma_t+\gamma_e)^2
\end{aligned}\]</span></p>
<p>Where <span class="math inline">\(\gamma_t=\text{cov}(t_1,t_2)\)</span> and <span class="math inline">\(\gamma_e=\text{cov}(e_1,e_2)\)</span>. The result can be visualized with a vector field showing the mapping from a pair of observed outcomes, <span class="math inline">\(\binom{\hat{t}_1}{\hat{t}_2}\)</span>, into a pair of inferred outcomes, <span class="math inline">\(E[{t_1\atop t_2}|{\hat{t}_1\atop \hat{t}_2}]\)</span>.</p>
<p>More traditionally we can split the treatment-effects and noise into common and orthogonal components:</p>
<p><span class="math display">\[\begin{aligned}
   \hat{t}_1 &amp;= t + \tilde{t}_1 + e + \tilde{e}_1 \\
   \hat{t}_2 &amp;= t + \tilde{t}_2 + e + \tilde{e}_2
\end{aligned}\]</span></p>
<p>And so do a DAG:</p>
<p><span class="math display">\[\xymatrix@R=.2cm{
      &amp; \tilde{t}_1\ar[d]
      &amp;
      &amp; \tilde{e}_1\ar[d]
      \\
      &amp; t_1 \ar[r]
      &amp; \hat{t}_1
      &amp; e_1 \ar[l]
      \\ t\ar[ur]\ar[dr]
      &amp;
      &amp;
      &amp;
      &amp; e\ar[ul]\ar[dl]
      \\
      &amp; t_2 \ar[r]
      &amp; \hat{t}_2
      &amp; e_2 \ar[l]
      \\
      &amp; \tilde{t}_2\ar[u]
      &amp;
      &amp; \tilde{e}_2\ar[u]
   }\]</span></p>
<p>The <span class="citation" data-cites="peysakhovich2018learning">Peysakhovich and Eckles (<a href="#ref-peysakhovich2018learning" role="doc-biblioref">2018</a>)</span> IV setup assumes <span class="math inline">\(\tilde{t}_1=\tilde{t}_2=0\)</span>, i.e.&nbsp;the causal effects on outcome 1 and 2 have a fixed relationship. This is necessary if we want to estimate the causal relationship of outcome 1 on outcome 2, but not for the simpler and more common problem of using outcome 1 as a proxy for estimating the effect on outcome 2.</p>
<p>We can make a few broad observations based on the equation above.</p>
<p>First, if there is no covariance either across treatment-effects (<span class="math inline">\(\gamma_t=0\)</span>), or across units (<span class="math inline">\(\gamma_e=0\)</span>), then the expression reduces to univariate shrinkage, i.e.:</p>
<p><span class="math display">\[\mathbb{E}[t_1|\hat{t}_1,\hat{t}_2]=\mathbb{E}[t_1|\hat{t}_1]=\mu_1+\frac{\sigma_{t1}^2}{\sigma_{t1}^2+\sigma_{e1}^2}(\hat{t}_1-\mu_1).\]</span></p>
<p>Some evidence on the importance of the covariance matrices comes from <span class="citation" data-cites="coey2019improving">Coey and Cunningham (<a href="#ref-coey2019improving" role="doc-biblioref">2019</a>)</span>, which finds that multivariate shrinkage of experiment results significantly outperforms univariate shrinkage, but was not able to establish how much of this was due to cross-outcome relationships in the treatment-effects vs the noise.</p>
<p>Second, if there is only covariance across treatment-effects, and that covariance is positive, (<span class="math inline">\(\gamma_t&gt;0,\gamma_e=0\)</span>), then each observed outcome is “good news” about the treatment-effect on the other outcome, i.e.: <span class="math display">\[\frac{dE[t_1| \hat{t}_1,\hat{t}_2]}{d\hat{t}_2} &gt; 0, \frac{dE[t_2| \hat{t}_1,\hat{t}_2]}{d\hat{t}_1} &gt; 0.\]</span> Intuitively – if you expect your experiment to shift both outcomes in the same direction, then seeing a positive effect on one outcome will positively reinforce your belief in the effect on the other outcome.</p>
<p><strong>Good News is Bad News (weak version).</strong> When the relative covariance of noise is stronger than the relative covariance of the treatment-effects, then we will find that a higher-than-expected outcome on outcome 2 will be a <em>negative</em> signal about the treatment-effect on outcome 1. Formally:</p>
<p><span class="math display">\[\frac{dE[t_1| \hat{t}_1,\hat{t}_2]}{d\hat{t}_2} &lt; 0
      \iff \frac{\gamma_{t}}{\sigma_{t1}^2} &lt; \frac{\gamma_{e}}{\sigma^2_{e1}}\]</span></p>
<p>In many contexts we believe that this condition is likely to hold. Most desirable outcomes tend to have positive covariance across experimentation units (<span class="math inline">\(\gamma_e&gt;0\)</span>), e.g.&nbsp;among people wealth, physical health, mental health, and education all tend to covary positively. Among users of online services, those who are more active on one dimension tend to be more active on all others. On the other hand, treatments tested in experiments often find trade-offs with other outcomes (<span class="math inline">\(\gamma_t&lt;0\)</span>): e.g.&nbsp;promoting one part of a product tends to cannibalize time spent on other parts.</p>
<div class="example">
<p><strong>Example.</strong> A school runs an experiment with a new English textbook, and they find an increase in English test-scores. Suppose they also find an increase in Maths test-scores: this would be bad news about the true impact on English ability if (a) there is strong positive correlation among students between English and Maths test-scores, (b) there is not a strong prior reason to believe that there would be a positive spillover on Maths test-scores.</p>
</div>
<p><strong>Good News is Bad News (strong version).</strong>In some cases an even stronger result holds: <span class="math inline">\(\hat{t}_1\)</span> is bad news about <span class="math inline">\(t_1\)</span> itself:</p>
<p><span class="math display">\[\begin{aligned}
   \frac{dE[t_1| \hat{t}_1,\hat{t}_2]}{d\hat{t}_1} &lt; 0
      \iff 1
             &lt;&amp; \frac{\gamma_{t}}{\sigma_{t1}^2}
                      \frac{\gamma_{t}+\gamma_{e}}{\sigma^2_{t2} + \sigma^2_{e2}}.
\end{aligned}\]</span></p>
<p>The condition requires there be non-zero covariance in <em>both</em> the treatment-effects and the unit-level outcomes (i.e., both <span class="math inline">\(\gamma_t\neq0\)</span> and <span class="math inline">\(\gamma_e\neq0\)</span>).<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> We also can see that the two covariances must have the same sign – either both positive or both negative. Intuitively, this will occur when treatment-effects are closely correlated, such that <span class="math inline">\(\hat{t}_2\)</span> is a relatively better signal for <span class="math inline">\(t_1\)</span> than <span class="math inline">\(\hat{t}_1\)</span> itself, and so <span class="math inline">\(\hat{t}_1\)</span> instead becomes a signal for the correlated noise.</p>
<div class="example">
<p><strong>Example.</strong> You run an experiment where you randomly select married households and provide the wife with vocational training and education, and measure the impact on both the wife’s income, and the overall household’s income. You find that average annual female labor income increased by $1,000. However, you also find that average annual household income increased by $3,000, implying the average male income in the treated group is $2,000 higher than in the control group. If you believe that (a) the spillover effect from wife’s income to husband’s income is likely to be small or negative, and (b) the correlation between wife’s and husband’s income is strong, then this evidence should cause you to decrease your estimate of the true impact on both the wife’s income and the total income.</p>
</div>
<p>The following vector-field illustrates the strong version of the “good news is bad news” effect: it can be seen that, for a given value of <span class="math inline">\(\hat{t}_2\)</span>, progressively higher values of <span class="math inline">\(\hat{t}_1\)</span> are mapped into relatively lower values of <span class="math inline">\(t_1\)</span>.</p>
<section id="summary" class="level2">
<h2 class="anchored" data-anchor-id="summary">Summary</h2>
<p>We can compare various quantities in the bivariate case. I put hats on the quantities that are functions of observable data:</p>
<p><span class="math display">\[\begin{aligned}
   \hat{\beta}^{OLS}
      =&amp;\frac{dE[\hat{t}_2|\hat{t}_1]}{d\hat{t}_1}
      &amp;=&amp; \text{Predicted observed effect given observed effect} \\
   \beta^{SURROGATE}
      =&amp; \frac{dE[t_2|\hat{t}_1]}{d\hat{t}_1}
      &amp;=&amp; \text{Predicted true effect given observed effect} \\
   \beta^{CAUSAL}
      =&amp; \frac{dE[t_2|t_1]}{dt_1}
      &amp;=&amp; \text{Predicted true effect given true effect (can be interpreted as causal if $t_1\rightarrow t_2$)} \\
   \hat{\beta}^{AA}
      =&amp; \frac{dE[e_2|e_1]}{de_1}
      &amp;=&amp; \text{Predicted noise given noise}
\end{aligned}\]</span></p>
<p><span class="math display">\[\begin{aligned}
   \hat{\beta}^{OLS} &amp;= \frac{\text{cov}(\hat{t}_1,\hat{t}_2)}{\text{var}(\hat{t}_1)}
                     = \frac{\gamma_t+\gamma_e}{\sigma_{t1}^2+\sigma_{e1}^2}
                     = \frac{\gamma_t+\gamma_e}{\sigma_{e1}^2(1+SNR_1)}\\
   \beta^{\text{SURROGATE}} &amp;= \frac{\text{cov}(t_2,\hat{t}_1)}{\text{var}(\hat{t}_1)}=\frac{\gamma_t}{\sigma_{t1}^2+\sigma_{e1}^2}
         =\frac{\gamma_t}{\sigma_{e1}^2(1+SNR_1)} \\
   \beta^{\text{CAUSAL}} &amp;= \frac{\text{cov}(t_2,t_1)}{\text{var}(t_1)}=\frac{\gamma_t}{\sigma_{t1}^2} \\
   \hat{\beta}^{AA}  &amp;= \frac{cov(e_2,e_1)}{var(e_1)} = \rho_e\frac{\sigma_{e2}}{\sigma_{e1}}
\end{aligned}\]</span></p>
<p>We can recover the surrogate relationship from the OLS. The terms on the right can be inferred from the distribution of user-level outcomes (or from <span class="math inline">\(\hat{\beta}^{AA}\)</span>) and from the distribution of experiment outcomes.<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a></p>
<p><span class="math display">\[\begin{aligned}
      \hat{\beta}^{\text{SURROGATE}}
         &amp;= \hat{\beta}^{\text{OLS}} - \frac{\gamma_e}{\sigma_{t1}^2+\sigma_{e1}^2}
         = \hat{\beta}^{\text{OLS}}
            - \ut{\rho_e\frac{\sigma_{e2}}{\sigma_{e1}}\frac{1}{(1+SNR_1)}}{correct for activity}.
   \end{aligned}\]</span></p>
<p>We can also recover the causal relationship from the OLS: <span class="math display">\[\begin{aligned}
      \hat{\beta}^{\text{CAUSAL}}
         &amp;= \frac{\sigma_{e1}^2(1+SNR_1)\hat{\beta}^{OLS}-\gamma_e}{\sigma_{e1}^2SNR_1} \\
         &amp;=\underbrace{\frac{SNR_1+1}{SNR_1}}_{\text{correct for attenuation}}\hat{\beta}^{OLS}
         - \underbrace{\frac{\sigma_{e2}}{\sigma_{e1}}\frac{\rho_e}{SNR_1}}_{\text{correct for activity}}
   \end{aligned}\]</span></p>
<p>We can also recover effects of interest by splitting samples. We can think of splitting as giving us as an additional set of experiments with the same treatment effects but independent noise: <span class="math display">\[\binom{\hat{t}_1'}{\hat{t}_2'} = \binom{t_1}{t_2} + \binom{e_1'}{e_2'}\]</span></p>
<p>We can regress <span class="math inline">\(y'_2\)</span> on <span class="math inline">\(\hat{t}_1\)</span> and it will recover the surrogate relationship: <span class="math display">\[\begin{aligned}
   \hat{\beta}^{SPLIT}  &amp;= \frac{cov(\hat{t}_2',\hat{t}_1)}{cov(\hat{t}_1)}
      = \frac{\gamma_t}{\sigma_{t1}^2+\sigma_{e1}^2}
      = \hat{\beta}^{SURROGATE}
\end{aligned}
\]</span></p>
</section>
</section>
<section id="experiment-surrogacy" class="level1">
<h1>Experiment Surrogacy</h1>
<p>When we wish to estimate effects on a noisy outcome, investigators often try to find a “surrogate” outcome that is a good predictor of the primary outcome but more precisely measured. Sometimes surrogacy relationships are estimated by a simple regression across experiment outcomes. However this will give a biased estimate because the coefficient will pick up the covariance between units, as well as covariance between experiments:</p>
<p><span class="math display">\[\begin{aligned}
   \hat{\beta}^{OLS}= \frac{dE[\hat{t}_2|\hat{t}_1]}{d\hat{t}_1} =  \frac{\text{cov}(\hat{t}_1,\hat{t}_2)}{\text{var}(\hat{t}_1)}
   =\frac{\gamma_t+\gamma_e}{\sigma_{t1}^2+\sigma_{e1}^2}.
\end{aligned}
\]</span></p>
<p>Figure 1 plots a set of AA tests with no true treatment effect on either outcome. Despite the lack of any relationship between treatment-effects, we find a significant relationship between outcomes, due to covariance among units.</p>
<p>However the quantity of interest for a surrogate variable is instead:</p>
<p><span class="math display">\[\begin{aligned}
   \frac{dE[t_2|\hat{t}_1]}{d\hat{t}_1} = \frac{\text{cov}(t_2,\hat{t}_1)}{\text{var}(\hat{t}_1)}=\frac{\gamma_t}{\sigma_{t1}^2+\sigma_{e1}^2}.
\end{aligned}
\]</span></p>
<p>To calculate the correct quantity we can estimate the covariance across treatment-effects by taking the difference between observed covariances across experiments and that expected from AA-tests: <span class="math inline">\(\hat{\gamma_t}=\gamma_y-\frac{1}{N}\gamma_u\)</span>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/2022-04-08-09-34-41.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure 1: A simulated scatter-plot showing 20 experiments, with N=1,000,000, <span class="math inline">\(\sigma_{e1}^2=\sigma_{e2}^2=1\)</span>, with correlation 0.8. The experiments are all AA-tests, i.e.&nbsp;there are no true treatment effects, yet a regression of <span class="math inline">\(\hat{t}_2\)</span> on <span class="math inline">\(\hat{t}_1\)</span> will consistently yield statistically-significant coefficients of around 0.8.</figcaption>
</figure>
</div>
<p>The bias described will decline with sample-size N, but is invariant to the number of experiments. Additionally, if there is no true treatment-effect on outcome 1 (<span class="math inline">\(\sigma_{t1}^2=0\)</span>), as in the AA-tests illustrated in Figure 1, then the estimated <span class="math inline">\(\hat{\beta}\)</span> will always equal <span class="math inline">\(\frac{\gamma_e}{\sigma_e^2}\)</span>, even as the sample-size goes to infinity.</p>
</section>
<section id="causal-effects-instrumental-variables" class="level1">
<h1>Causal Effects / Instrumental Variables</h1>
<p>In other circumstances we wish to understand the relationship between treatment-effects, i.e.:<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a></p>
<p><span class="math display">\[\frac{dE[t_2|t_1]}{dt_1}=\frac{\gamma_t}{\sigma_{t1}^2}.\]</span></p>
<p>Again this does not correspond to the quantity recovered by a regression, <span class="math inline">\(\hat{\beta}\)</span> above. There are now two biases: (1) an “activity” bias due to <span class="math inline">\(\gamma_e\)</span> in the numerator of <span class="math inline">\(\hat{\beta}\)</span>; (2) an attenuation bias due to <span class="math inline">\(\sigma_{e1}^2\)</span> in the denominator of <span class="math inline">\(\hat{\beta}\)</span>.</p>
<div class="example">
<p><strong>Example.</strong> You run a series of A/B experiments meant to improve music recommendations and are interested in how these experiments impact time-spent on music, and potential cannibalization of time-spent on podcasts. Estimating a cannibalization rate by regressing <code>podcast_time</code> on <code>music_time</code>, across experiments, would lead to underestimating the true rates of cannibalization for two reasons: (1) positive unit-level covariance between the two outcomes causing positive correlation between the two outcomes, (2) noise in the estimate of the treatment-effects on <code>music_time</code>, causing attenuation towards zero.</p>
</div>
<p><span class="citation" data-cites="peysakhovich2018learning">Peysakhovich and Eckles (<a href="#ref-peysakhovich2018learning" role="doc-biblioref">2018</a>)</span> estimate a model in which <span class="math inline">\(t_2=\beta t_1\)</span> (i.e.&nbsp;they assume <span class="math inline">\(\rho_t=1\)</span>). They show that the weak-instrument bias will be small if they (1) regularize so that only experiments with high SNR are included, and (2) calibrate the regularization by splitting samples.</p>
</section>
<section id="observational-surrogacy" class="level1">
<h1>Observational Surrogacy</h1>
<p><strong>Summary:</strong> Suppose we want to know the effect of experiment <span class="math inline">\(t\)</span> on <span class="math inline">\(y\)</span>, but it’s too hard to measure either because (1) <span class="math inline">\(y\)</span> has very broad confidence intervals, or (2) <span class="math inline">\(y\)</span> takes a long time (e.g.&nbsp;it’s a long-run outcome). Then we can use the causal effect on <span class="math inline">\(x\)</span>, and the correlation between <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>. The key assumption is that the effect of <span class="math inline">\(t\)</span> on <span class="math inline">\(y\)</span> is mediated entirely through <span class="math inline">\(x\)</span>.</p>
<section id="setup-1" class="level2">
<h2 class="anchored" data-anchor-id="setup-1">Setup</h2>
<p>Let <span class="math inline">\(t\)</span> be the experiment, <span class="math inline">\(y\)</span> be the outcome, <span class="math inline">\(x\)</span> be the “surrogate” variable, and <span class="math inline">\(w\)</span> is the unobserved influences on <span class="math inline">\(x\)</span>. We can write this as:</p>
<p><span class="math display">\[\xymatrix@C=2cm{
   &amp;  *+[F-:&lt;6pt&gt;]{w}\ar[d]|{\alpha_w} \ar@{.&gt;}[dr]|{\beta_w} \\
      *+[F]{t} \ar[r]|{\alpha_t}  \ar@{.&gt;}@/_2pc/[rr]|{\beta_t}
   &amp;  *+[F]{x} \ar[r]|{\beta_x}
   &amp;  *+[F]{y}
}\]</span></p>
<p><span class="math display">\[\begin{aligned}
   x &amp;= \alpha_t t + \alpha_w w + u\\
   y &amp;= \beta_t t + \beta_w w + \beta_x x + v\\
\end{aligned}\]</span></p>
<p>We are interested in the effect of <span class="math inline">\(t\)</span> on <span class="math inline">\(y\)</span>. We can directly estimate that as: <span class="math display">\[\begin{aligned}
      \frac{cov(y,t)}{var(t)}=   \utt{\beta_t}{direct}{effect} + \utt{\alpha_t\beta_x}{effect}{thru $x$}
         &amp;&amp; \text{(effect of $t$ on $y$)}
   \end{aligned}\]</span></p>
<p>Alternatively we can estimate the effect in two stages with surrogacy:</p>
<p><span class="math display">\[\begin{aligned}
   \hat{\alpha}_t &amp;= \frac{cov(x,t)}{var(t)} = \alpha_t \\
   \hat{\beta}_x  &amp;= \frac{cov(t,x)}{var(x)}
      = \utt{\beta_x}{direct}{effect} + \ut{\frac{\beta_w\alpha_w\sigma_w^2 }{\sigma_x^2}}{confounding}
      &amp;&amp; \text{(setting $\sigma_t^2=0$)}
\end{aligned}\]</span></p>
<p>We can see that the surrogacy estimator (<span class="math inline">\(\hat{\alpha}\cdot\hat{\beta}\)</span>) will be equal to the true effect only if two conditions hold:</p>
<ol type="1">
<li><strong>Exclusion (<span class="math inline">\(\beta_t\simeq 0\)</span>):</strong> the experiment only affects <span class="math inline">\(y\)</span> via <span class="math inline">\(x\)</span>.</li>
<li><strong>Unconfoundedness (<span class="math inline">\(\beta_w\simeq 0\)</span>):</strong> there is no unobserved factor affects both <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> (i.e.&nbsp;all effects on <span class="math inline">\(y\)</span>)</li>
</ol>
<p><strong>Alternative way of stating the assumptions.</strong> <span class="citation" data-cites="athey2019estimating">Athey et al. (<a href="#ref-athey2019estimating" role="doc-biblioref">2019</a>)</span> state two assumptions: (1) unconfoundedness of treatment (i.e.&nbsp;<span class="math inline">\(t\)</span> is orthogonal to everything); (2) surrogacy: <span class="math inline">\(t \perp\!\!\!\perp y|x\)</span>, described as “the surrogates fully capture the causal link between the treatment and the primary outcome.” Their assumption (2) follows from my assumptions (1) and (2) above. I prefer separating out these assumption to add clarity. See appendix to their paper for discussion of alternative formulations of surrogacy assumptions.</p>
</section>
<section id="additional-issues" class="level2">
<h2 class="anchored" data-anchor-id="additional-issues">Additional Issues</h2>
<ol type="1">
<li><p><strong>Controls.</strong> You can improve precision by controlling for other variables, but you should be confident they’re independent of <span class="math inline">\(t\)</span>: either use demographics, or variables that are determined before treatment. (Also if the control variables have low explanatory power for <span class="math inline">\(w\)</span> then they could make the confidence intervals <em>worse</em>, so don’t just throw in any controls.)</p></li>
<li><p><strong>Noisy proxies.</strong> Suppose we observe only a noisy proxy of <span class="math inline">\(x\)</span>: <span class="math display">\[\xymatrix@C=2cm@R=.8cm{
      *+[F]{t} \ar[r]|{\alpha_t}  
   &amp;  *+[F-:&lt;6pt&gt;]{x} \ar[r]|{\beta_x}\ar[d]
   &amp;  *+[F]{y} \\
   &amp;  *+[F]{x^*}
}\]</span> <span class="math display">\[\begin{aligned}
   y  &amp;= \beta_x x + \varepsilon_y \\
   x^*  &amp;= x + \varepsilon_{x^*} \\
   x    &amp;= t + \varepsilon_x \\
\end{aligned}\]</span> The estimate of <span class="math inline">\(\beta_x\)</span> will be biased down a bit due to attenuation: <span class="math display">\[\begin{aligned}
   \frac{cov(y,x^*)}{var(x^*)} &amp;= \beta_x\frac{\sigma_x^2}{\sigma_x^2+\sigma_{\varepsilon_{x^*}}}
\end{aligned}\]</span> We can quantify bias with assumptions on signal-noise ratio (<span class="math inline">\(\frac{\sigma_e}{\sigma_x}\)</span>).</p></li>
<li><p><strong>Estimating causal effect.</strong> You can try to estimate effect of <span class="math inline">\(x\)</span> on <span class="math inline">\(y\)</span> with <span class="math inline">\(\frac{cov(y,t)}{cov(x,t)}\)</span>. This requires only the exclusion restriction, not unconfoundedness. However it’ll be biased towards the correlation, as discussed above.</p></li>
<li><p><strong>Other issues.</strong></p>
<ul>
<li><em>composite metrics.</em> Can try to estimate a rich proxy with many variables.</li>
</ul></li>
</ol>
</section>
<section id="surrogacy-examples" class="level2">
<h2 class="anchored" data-anchor-id="surrogacy-examples">Surrogacy Examples</h2>
<p>[see other doc for ranking]</p>
<ol start="2" type="1">
<li><p><strong>Impact of exposure on survey outcomes.</strong></p>
<p><span class="math display">\[\xymatrix{
   *+[F]{\text{ranking change}} \ar[r] \ar@/_2pc/[rr]
   &amp; *+[F]{\text{impressions of porn}}\ar[r]
   &amp; *+[F]{\text{self-reported porn-seen}}
}\]</span></p></li>
<li><p><strong>Impact of product change on survey outcomes.</strong></p>
<p><span class="math display">\[\xymatrix{
   *+[F]{\text{ranking change}} \ar[r] \ar@/_2pc/[rr]
   &amp; *+[F]{\text{user behaviour}}\ar[r]
   &amp; *+[F]{\text{survey results on satisfaction}}
}\]</span></p></li>
<li><p><strong>Long-run impact of employment program.</strong> Used in Athey paper:</p>
<p><span class="math display">\[\xymatrix{
      *+[F]{\text{training program}} \ar[r] \ar@/_2pc/[rr]
      &amp; *+[F]{\text{short-run employment}}\ar[r]
      &amp; *+[F]{\text{long-run employment}}
   }\]</span></p>
<ul>
<li>Exclusion: training program only affects long-run employment thru short-run employment.</li>
<li>Unconfoundedness: no factors affect long-run employment except thru short-run.</li>
<li>Dangers to identification: if the program <em>artificially</em> increases short-run employment.</li>
</ul></li>
</ol>
</section>
</section>
<section id="composite-metrics" class="level1">
<h1>Composite Metrics</h1>
<p><strong>TL;DR:</strong> unshrunk composite metrics often have worse SNR than their components.</p>
<p>We sometimes want to estimate the impact of an experiment on a “composite” outcome, a linear combination of <span class="math inline">\(n\)</span> outcomes with weights <span class="math inline">\(w=(w_1,\ldots,w_n)\)</span>. It is useful to calculate the <em>signal-to-noise ratio</em> (SNR) of the composite metric, <span class="math inline">\(\bar{y}\)</span>:</p>
<p><span class="math display">\[\begin{aligned}
   \text{SNR}_{\bar{y}}=&amp; \frac{Var[w't]}{Var[w'e]}= \frac{w'\Sigma_tw}{w'\Sigma_ew}.
\end{aligned}\]</span></p>
<p>The signal-noise ratio is a useful statistic to track because an outcome with a higher SNR will have (a) a lower shrinkage factor, i.e.&nbsp;the posterior <span class="math inline">\(E[t|y]\)</span> will be relatively closer to the observed <span class="math inline">\(y\)</span>, and (b) will have a higher fraction of experiments that are statistically significantly different from zero:<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a></p>
<p><span class="math display">\[\begin{aligned}
   \text{shrinkage factor}=&amp; 1-\frac{E[t|y]-\mu}{y-\mu}=\frac{1}{1+SNR},\\
   \text{fraction significant}=&amp; P(|y-\mu|&gt;1.96\sigma_e) \\=&amp; 2\Big(1-\Phi(\frac{1.96}{1+SNR})\Big).
\end{aligned}\]</span></p>
<p>Where <span class="math inline">\(\Phi\)</span> is the CDF of a standard Normal distribution.</p>
<p>We can make two observations about the signal-noise ratio of a composite metric:</p>
<ol type="1">
<li><p>If all covariance terms are zero, across treatments and units, then the SNR of <span class="math inline">\(\bar{y}\)</span> will be a weighted average of the SNR of each of the components: <span class="math display">\[\text{SNR}_{\bar{y}}= \frac{\sum w_i^2\sigma_{ti}^2}{\sum w_i^2\sigma_{ei}^2}
            = \sum_i \frac{w_i^2\sigma_{ei}^2}{\sum_j w_j^2\sigma_{ej}^2} \text{SNR}_{y_i}.\]</span> This implies that adding a new component to a composite metric will increase its SNR (and so increase the fraction of statistically-significant experiments) if and only if the new component has a higher SNR than the existing composite metric.</p></li>
<li><p>If the outcomes have positive covariance across units, but zero covariance across treatments, the composite’s signal-noise ratio will be <em>below</em> the weighted-average SNR. This can be seen in the first equation for <span class="math inline">\(\text{SNR}_{\bar{y}}\)</span>: the covariance terms in the error will show up in the denominator, causing the SNR to decline.</p></li>
</ol>
<p>These observations are consistent with the general observation that tech companies often struggle when dealing with metrics that are designed to reflect the full business impact of an experiment: if they add all outcomes of interest into the composite metric, the composite will be relatively noisy for two reasons: (1) because some components are noisy, and (2) because of positive covariance in the noise components.</p>
<p>An optimally shrunk composite metric will take into account the noise. If there is no covariance then we have:</p>
<p><span class="math display">\[\mathbb{E}[t|\hat{t}_1,\ldots,y_n]=\sum_{i=1}^n \frac{\text{SNR}_i}{1+\text{SNR}_i}w_iy_i.\]</span></p>
<p>This estimate of the composite will appropriately shrink noisy components, and so there is no longer a penalty for adding additional components to the composite. If there is covariance then the full expression will be:</p>
<p><span class="math display">\[\mathbb{E}[\bar{t}|y]=w'\mathbb{E}[t|y].\]</span></p>
</section>
<section id="launch-rules" class="level1 page-columns page-full">
<h1>Launch Rules</h1>
<p><strong>Launch rules contain many considerations.</strong> Many companies have “launch rules” which map experiment outcomes into a launch decision. In practice there are many considerations that affect launch rules:</p>
<ol type="1">
<li><strong>Fundamental tradeoffs.</strong> A launch rule expresses the company’s fundamental values: e.g.&nbsp;willingness to trade-off revenue against the quality of service provided. In addition launch rules are often adjusted to help reach specific goals for a team, e.g.&nbsp;increasing DAU by 0.2% while not harming quality.</li>
<li><strong>Inference.</strong> A launch rule is based on noisy signals of true causal effects, thus it incorporates inference, often putting weight on metrics that not valuable in themselves but proxies for valuable things that are hard to measure.</li>
<li><strong>Forecasting.</strong> A launch rule is aiming at long-run effects while usually based on short-run experimental results, thus incorporates a forecast.</li>
<li><strong>Network effects.</strong> A launch rule based on user-level experiment results, but aiming to maximize aggregate outcomes, must account for network effects.</li>
<li><strong>Commitment/Fairness.</strong> Engineers and Data Scientists will often ask for an explicit commitment to a launch rule to help their own decision-making. A launch rule is typically expected to be <em>fair</em> in some sense: e.g.&nbsp;to be independent of the identity of the person who ran the experiment, even if the person’s identity is in fact good predictor of the long-run outcome.</li>
</ol>
<p><strong>Recommendation: treat launch rules as forecasts.</strong> I think it’s best to divide launch decisions into three parts:</p>
<ol type="1">
<li><p><strong>Choose a set of <em>proximal</em> metrics.</strong> These are the metrics on which we are confident we can detect our experiment’s effect, meaning the measured impact will be close to the true impact. The proximal metrics will vary depending on the experiment, e.g.&nbsp;Notifications experiments have reliable effects on DAU, other experiments do not. To determine whether a metric is moved we can use the fraction of a given class of experiments that have a statistically-significant effect on that metric: if the share is greater than 50% then we can be confident that the estimated effect is close to the true effect.<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a></p></li>
<li><p><strong>Identify <em>conversion factors</em> between proximal and final metrics.</strong> These tell us the best-estimate impact on final metrics given the impact on proximal metrics. Conversion factors can be estimated either from (a) long-running tuning experiments; (b) a meta-analysis of prior experiments with similar designs. This is essentially a <em>forecast</em> (you could call it a “shipping forecast”) and the quality of the forecast can be evaluated statistically from prior experiments, and sometimes it will be appropriate to over-ride the forecast on the basis of additional information. Additionally the <span class="math inline">\(R^2\)</span> of prior forecasts helps calibrate how confident we should be about future forecasts.</p></li>
<li><p><strong>Establish conversion factors between final metrics.</strong> E.g. we might say we’d put an equal weight on 1% DAU, 2% minutes/DAU, 5% posts/DAU, and 100% prevalence of spam.</p></li>
</ol>
<section id="comparing-launch-rules" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="comparing-launch-rules">Comparing Launch Rules</h2>
<div class="cell page-columns page-full" data-hash="2022-02-26-inference-with-experimental-data_cache/html/unnamed-chunk-10_0242de50116b3f3f626c9be00990a30a">

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="2022-02-26-inference-with-experimental-data_files/figure-html/unnamed-chunk-10-1.png" class="img-fluid figure-img" width="288"></p>
<figcaption class="figure-caption">Ship if either stat-sig positive and neither stat-sig negative.</figcaption>
</figure>
</div>
</div></div></div>
<p>Suppose we have two metrics, 1 and 2, and we care about them equally much: <span class="math display">\[U(t_1,t_2)=t_1+t_2.\]</span></p>
<p>But we only observe noisy estimates <span class="math inline">\(\hat{t}_1,\hat{t}_2\)</span>.</p>
<p>A stat-sig shipping rule (either stat-sig positive, neither stat-sig negative) has some strange consequences: it will recommend shipping things even with <em>negative</em> face-value utility (<span class="math inline">\(U(\hat{t}_1,\hat{t}_2)&lt;0\)</span>), when there’s a negative outcome on the relatively noisier metric. This will still hold if we evaluate utility with shrunk estimates, when there’s equal proportional shrinkage on the two metrics, but if there’s greater shrinkage on the noisier metric it will not hold.</p>
<p>Kohavi, Tang &amp; Xu (2020) <em>Trustworthy Online Controlled Experiments</em> recommends a stat-sig shipping rule (p105): “(1) If no metrics are positive-significant then do not ship; (2) if some are positive-significant and none are negative-significant then ship; (3) if some are positive-significant and some are negative-significant then”decide based on the tradeoffs.” I think this is bad advice: the statistical significance of an estimate is only loosely related to the informativeness of that estimate. The decision should be made based on your best estimates of the impact on the overall goal metrics.</p>
<p><br><br><br><br></p>
<div class="cell page-columns page-full" data-hash="2022-02-26-inference-with-experimental-data_cache/html/unnamed-chunk-11_c2a027024590c26234acdba8b73bb2d3">

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="2022-02-26-inference-with-experimental-data_files/figure-html/unnamed-chunk-11-1.png" class="img-fluid figure-img" width="288"></p>
<figcaption class="figure-caption">Ship if sum is positive</figcaption>
</figure>
</div>
</div></div></div>
<p><br><br><br><br></p>
<div class="cell page-columns page-full" data-hash="2022-02-26-inference-with-experimental-data_cache/html/unnamed-chunk-12_78337e13a6c34e1b77891eae23e8a2ec">

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="2022-02-26-inference-with-experimental-data_files/figure-html/unnamed-chunk-12-1.png" class="img-fluid figure-img" width="288"></p>
<figcaption class="figure-caption">Ship if sum stat-sig positive. I have drawn it assuming that <span class="math inline">\(cov(\hat{t}_1,\hat{t}_2)=0\)</span>. With a positive covariance the threshold would be higher.</figcaption>
</figure>
</div>
</div></div></div>
</section>
</section>
<section id="network-and-dynamic-effects" class="level1">
<h1>Network and Dynamic Effects</h1>
<p>Given an observed experimental outcome, <span class="math inline">\(y\)</span>, the relevant policy question is typically the aggregate long-run effect on outcomes, and there are three important considerations: (1) adjusting for experimental noise, as we have discussed in this paper, (2) adjusting for network-effects, and (3) adjusting for dynamic effects. Here we briefly show how all three can be expressed in a very simplifed model. Suppose the behaviour of unit <span class="math inline">\(i\)</span> at time <span class="math inline">\(t+1\)</span> depends on (i) some user-specific constant term, <span class="math inline">\(a_i\)</span>, (ii) their own prior behaviour, <span class="math inline">\(x_{t,i}\)</span>, and (iii) the global average <span class="math inline">\(\bar{x}_t=\frac{1}{n}\sum x_{i,t}\)</span>, as:</p>
<p><span class="math display">\[\begin{aligned}
         x_{i,t+1} =&amp; a_i + Bx_{i,t} + C\bar{x}_t.
\end{aligned}\]</span></p>
<p>Solving for equilibrium, setting <span class="math inline">\(x_{i,t+1}=x_{i,t}\)</span> we get:</p>
<p><span class="math display">\[\bar{x} = (I-B-C)^{-1}\bar{a}.\]</span></p>
<p>Where <span class="math inline">\(\bar{a}=\frac{1}{n}\sum_i a_i\)</span>. If we assume that all treatment-effects operate additively on each unit, i.e., through the term <span class="math inline">\(a_i\)</span>, then we can combine this with multivariate shrinkage to get an overall mapping from experiment-level results to long-term aggregate impact, <span class="math inline">\(\Delta \bar{x}\)</span>:</p>
<p><span class="math display">\[\begin{aligned}
         \Delta\bar{x} =&amp; (I-B-C)^{-1}\Big(\mu_t+\Sigma_t(\Sigma_t+\frac{1}{N}\Sigma_x)^{-1}(y-\mu_y)\Big).
\end{aligned}\]</span></p>
</section>
<section id="appendix-derivation-of-multivariate-gaussian-posterior" class="level1">
<h1>Appendix: Derivation of Multivariate Gaussian Posterior</h1>
<p>We start with the most general formula for updating one vector of variables, <span class="math inline">\(t\)</span>, having observed the realization of some other vector, <span class="math inline">\(y\)</span>, given they have a Gaussian joint distribution:</p>
<p><span class="math display">\[\begin{aligned}
   V\binom{t}{y}=&amp; \begin{pmatrix} \Sigma_t &amp; \Sigma_{t,y}\\
                              \Sigma_{t,y}^{T} &amp; \Sigma_{\hat{t}} \end{pmatrix}.
\end{aligned}\]</span></p>
<p>Using the Schur complement we have:</p>
<p><span class="math display">\[\begin{aligned}
  \mathbb{E}[t|y] =&amp; \mu_t+\Sigma_{t,y}\Sigma_{\hat{t}}^{-1}(y-\mu_y) \\
  \mathbb{V}[t|y] =&amp; \Sigma_t-\Sigma_{t,y}\Sigma_{t,y}^{-1}\Sigma_{t,y}^{T}.
\end{aligned}\]</span></p>
<p>Intuitively, updating to infer <span class="math inline">\(\mathbb{E}[t|y]\)</span>, can be thought of in three steps: (1) we take the unexpected part of the results, <span class="math inline">\(y-\mu_y\)</span>, (2) we normalize it by dividing it by its own covariance matrix, <span class="math inline">\(\Sigma_{\hat{t}}\)</span>, and (3) we transpose it into the <span class="math inline">\(t\)</span>-space by multiplying it by the covariance between signal and truth <span class="math inline">\(\Sigma_{t,y}\)</span>.<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a></p>
<p>When we know that <span class="math inline">\(y\)</span> represents the results of an experiment with sample-size <span class="math inline">\(N\)</span>, we can write:</p>
<p><span class="math display">\[\begin{aligned}
   y=&amp; t+\sum_i^N x_i \\
  \mathbb{V}\binom{t}{y}=&amp; \begin{pmatrix} \Sigma_t &amp; \Sigma_t \\  \Sigma_t^{T} &amp; \Sigma_t+\frac{1}{N}\Sigma_x \end{pmatrix}
\end{aligned}\]</span></p>
<p>Then the optimal Bayesian inference about the treament effects, <span class="math inline">\(t\)</span>, from the observed outcomes <span class="math inline">\(y\)</span>, will be:</p>
<p><span class="math display">\[\mathbb{E}[t|y]=\mu_t+\Sigma_t(\Sigma_t+\frac{1}{N}\Sigma_x)^{-1}(y-\mu_y).\]</span></p>
<p>We can also write the solution with respect to the <em>precision</em> matrix, <span class="math inline">\(\Phi=V\binom{t}{y}^{-1}\)</span>:</p>
<p><span class="math display">\[\mathbb{E}[t|y]=\mu_t-\sum_{j=1}^n\frac{\Phi_{t1,y1}}{\Phi_{t1,t1}}(y_j-\mu_{y,j}),\]</span></p>
<p>If <span class="math inline">\(\Phi_{t1,y1}=0\)</span> then <span class="math inline">\(t_1\)</span> and <span class="math inline">\(\hat{t}_1\)</span> are conditionally independent, and so <span class="math inline">\(\hat{t}_1\)</span> has no informational content relevant to <span class="math inline">\(t_1\)</span>.</p>
</section>
<section id="recommendations" class="level1">
<h1>Recommendations</h1>
<ol type="1">
<li><p><strong>Most experimental estimates are over-estimates.</strong> This is because most true effects are near zero and we measure effects with noise.</p></li>
<li><p><strong>You should <em>shrink</em> most estimates towards zero.</strong> E.g. if the measured effect is +2% the true effect is likely lower, if it’s -1% the true effect is likely higher. Effect-sizes in backtests are typically around half as large as effect-sizes in pre-tests.</p></li>
<li><p><strong>You should shrink less if the effect was expected.</strong> If this effect is exactly what you expected, do not shrink at all. If you had no reason to expect a non-zero effect, shrink a lot.</p></li>
<li><p><strong>You should shrink less if the effect is very significant.</strong> E.g. if the p-value is less than .01 then the estimate is more likely to be accurate, and you don’t need to shrink the effect-size proportionately as much (because effect-sizes tend to have fat tails).</p></li>
<li><p><strong>You should shrink more if the <em>class</em> of experiments doesn’t move this metric much.</strong> You can look at a class of experiments, e.g.&nbsp;those run by a given team, and see the distribution of effect-sizes. If only 10% of effects are significant it implies that the experiments are not moving the metric much, and so any individual estimate should be shrunk pretty heavily.</p></li>
<li><p><strong>Write Down Your Priors.</strong> E.g., “We’re expecting this feature to impact time-spent by ~+0.5%, and posting by ~0%.” This makes it much easier to be principled about interpreting the outcomes.</p></li>
<li><p><strong>Calibrate Priors From Previous Experiments.</strong></p>
<ol type="1">
<li>Calculate the fraction of experiments that move a metric significantly.</li>
<li>Calculate the average drop-off between pre-tests and back-tests.</li>
</ol></li>
<li><p><strong>Incentivize by Impact on Back-Tests, not Pre-Tests.</strong></p>
<ul>
<li>If you incentivize by <em>pretest</em>, the rational response is to run a lot of experiments, including crappy ones, and just ship those that look positive.</li>
<li>If you incentivize by <em>backtest</em>, then engineers will be much more careful to ship changes which genuinely improve metrics.</li>
</ul></li>
</ol>
</section>
<section id="difficult-cases" class="level1">
<h1>Difficult Cases</h1>
<section id="selection-of-experiments" class="level2">
<h2 class="anchored" data-anchor-id="selection-of-experiments">Selection of Experiments</h2>
<div class="example">
<p><strong>Example: Selection of experiments.</strong> Your team goal is to maximize <code>podcast_time</code>, and you want to know what other teams are hurting that metric. You query the experiment DB and find the 10 experiments with the biggest negative effect. How should you interpret them?</p>
</div>
<ol type="1">
<li><p><strong>Classical advice is to adjust p-values for the number of experiments you selected from (Bonferroni correction).</strong> But from a Bayesian point of view it’s irrelevant whether these 10 experiments are taken from a pool of 10 or 1000 experiments.</p>
<p>Bonferroni not about testing multiple outcomes, it’s about testing the <em>most extreme</em> outcome.</p></li>
<li><p><strong>The set of experiments <em>is</em> informative about appropriate shrinkage.</strong> As discussed look at (i) the average effect, and (ii) the fraction that are significant.</p></li>
<li><p><strong>Shrinkage should depend on plausibility of the effect.</strong> Can look at how much the experiment moves its <em>primary</em> outcome. Suppose a music-ranking experiment decreases podcast time-spent by 0.4s, and increases music time-spent by 0.2s: the side-effect seems unlikely so shrink the outcome heavily.</p></li>
<li><p><strong>Appropriate shrinkage should depend on how significant the effect is.</strong> E.g. if the effect-size is 4 standard-errors it doesn’t need much shrinkage.</p></li>
</ol>
<div class="example">
<p><strong>Example: Selection of Experiments #2.</strong> An engineer has an experiment with effect +1% ($$0.5%) on your goal metric. They mention that they ran 20 other experiments, and this is the experiment with the biggest effect.</p>
</div>
<p><strong>Recommendation: shrink heavily towards the average effect.</strong></p>
<ol type="1">
<li><p><strong>Finding out about other experiments with smaller effects means you should shrink more.</strong> Finding out about the 20 other experiments is evidence about the size of the typical effect, and you should shrink towards that average. If the engineers are only showing you their best ones, that is reason to shrink your estimates.</p></li>
<li><p><strong>It matters how selection was done.</strong> Suppose the engineer chose the highest-effect one by chance, not intention. You should still shrink by the same amount: the distribution is evidence, not the selection rule. However if they had some independent reason for expecting this experiment would be the most effective, that is relevant evidence.</p></li>
</ol>
<div class="example">
<p><strong>Example: Subgroup Outcomes.</strong> You see that the overall time-spent of a feature holdout is -3.5% ($<span class="math inline">\(0.5%), but in Korea it's -9%(\)</span>$2%). How seriously should you take the Korean effect?</p>
</div>
<p><strong>Recommendation: take it seriously, because (a) very significant, and (b) there is high between-country variance.</strong></p>
<ol type="1">
<li><p><strong>Is this effect plausible?</strong> I.e., do we have reason to expect the effect of this feature to vary a lot by country, and in particular in Korea? We <em>do</em> generally think user behaviour varies a lot by country.</p></li>
<li><p><strong>How significance is this effect?</strong> The effect is 9 standard-errors – i.e., extremely significant – which makes it much less likely to be noise (<span class="math inline">\(p\)</span>=.00001).</p></li>
<li><p><strong>How much variance in effect is between-country vs within-country?</strong> Suppose we see that 1/2 of the countries have effects that are significantly different from the global average effect, this implies that there is a fair amount of variance in effect-sizes, and so reasonable that Korea should be such an outlier.</p></li>
</ol>
<div class="example">
<p><strong>Example.</strong>Your experiment increases <code>music_time</code>, which you expected, and increases <code>podcast_time</code>, which you did not expect.</p>
</div>
<p><strong>Implication:</strong> The positive effect on <code>podcast_time</code> is <em>bad</em> news about <code>music_time</code>. If outcomes are positively correlated across units but not across treatments then: <span class="math display">\[\frac{dE[t_1| \hat{t}_1,\hat{t}_2]}{d\hat{t}_2} &lt; 0.\]</span> In this case good news about one outcome is bad news about the other.</p>
<div class="example">
<p><strong>Example: Multiple Outcomes.</strong> You run an experiment on movie ranking intended to increase watches, and it works. You additionally see an increase in comments-given. Should the increase in comments give you more confidence or less confidence in the increase in likes?</p>
</div>
<p><strong>Recommendation: Good news is bad news, if the side-effect is unexpected.</strong></p>
<ul>
<li><strong>If the experiment was expected to increase both metrics</strong> - e.g.&nbsp;by increasing overall time spent on feed - then this is good news: it is additional evidence for the effect on likes.</li>
<li><strong>If the experment was expected to have a null or negative effect on comments</strong> – e.g.&nbsp;by boosting like-able posts at the expense of comment-able posts – then this is bad news: the positive effect on comments is likely due to noise, and it should make us expect greater noise in the measure of likes.</li>
</ul>
<p>Given two treatment effects <span class="math inline">\(t_1\)</span> and <span class="math inline">\(t_2\)</span>, and two outcomes, <span class="math inline">\(\hat{t}_1,\hat{t}_2\)</span>, and two noise variables, <span class="math inline">\(e_1,e_2\)</span> then we have the following (in the Gaussian case):</p>
<p><span class="math display">\[\frac{dE[t_1|\hat{t}_1,\hat{t}_2]}{d\hat{t}_2} \propto \text{covariance}_{t_1,t_2}-\text{covariance}_{e_1,e_2}.\]</span></p>
</section>
</section>
<section id="to-add" class="level1">
<h1>To Add</h1>
<ul>
<li>Pareto frontier from experiments</li>
<li>Variance reduction</li>
<li>Bandit strategy for experiments</li>
<li>Design of holdbacks (whether it’s an agency problem or a bandit problem)</li>
<li>Heterogeneous treatment effects</li>
<li>List of difficult examples.</li>
<li>Practical recommendations
<ol type="1">
<li>Calculate share of experiments that are statistically-significant.</li>
<li>Calculate covariance matrix of user-level and experiment-level data.</li>
</ol></li>
</ul>
</section>
<section id="discussion-on-bayesian-vs-frequentist-interpretation" class="level1">
<h1>Discussion on Bayesian vs Frequentist Interpretation</h1>
<section id="what-is-your-prior" class="level2">
<h2 class="anchored" data-anchor-id="what-is-your-prior">What is Your Prior?</h2>
<p><strong>In an ideal world you could specify exactly your prior beliefs about an experiment’s effect</strong> – e.g., you could say that you believe this experiment will have a +1.2% effect on time-spent, with a standard deviation of 2%. In that case you could exactly calculate how much an experiment shifts your belief: e.g., seeing a 2% outcome in the experiment shifts your belief from +1.2% to 1.6%.</p>
<p><strong>In practice it’s very difficult to quantify your prior beliefs.</strong> Think of gambling: would you bet at 2:1 odds that your experiment has an effect-size greater than 3%?</p>
<p><strong>In practice we use judgment, but it’s good to be explicit.</strong></p>
</section>
<section id="ideal-bayesianism-vs-quantitative-bayesianism" class="level2">
<h2 class="anchored" data-anchor-id="ideal-bayesianism-vs-quantitative-bayesianism">Ideal Bayesianism vs Quantitative Bayesianism</h2>
<p>There are two interpretations of Bayesian statistics:</p>
<ol type="1">
<li><strong>Ideal Bayesianism.</strong> – Bayesian relationships between degrees of beliefs are <em>ideals</em>, exactly as logical consistency is an ideal for relations between absolute beliefs. We tweak our everyday judgments to try to conform to that ideal.</li>
<li><strong>Quantitative Bayesianism.</strong> – We fit a quantitative Bayesian model by specifying a prior and calculating the implied posterior given the evidence.</li>
</ol>
<p>This document is almost entirely about the first point – it’s typically difficult to quantify your prior beliefs, but thinking about things through the Bayesian lens helps clarify some of the paradoxes of classical/frequentist statistics.</p>
<p>There are lots of smart people who do the second – when you do this it’s obviously important to remember that the prior you write down is very rarely your full prior, and so you should still do model-checking, e.g.&nbsp;as described in Gelman (2013) <a href="http://www.stat.columbia.edu/~gelman/research/published/philosophy.pdf">Philosophy and the practice of Bayesian statistics</a>.</p>
</section>
<section id="ideal-hypothesis-testing-vs-actual-hypothesis-testing" class="level2">
<h2 class="anchored" data-anchor-id="ideal-hypothesis-testing-vs-actual-hypothesis-testing">Ideal Hypothesis Testing vs Actual Hypothesis Testing</h2>
<p><strong>p-Values</strong></p>
<p>Common interpretation (<em>not</em> accurate):</p>
<blockquote class="blockquote">
<p>Given this estimate, the p-value represents the probability that the true effect is zero.</p>
</blockquote>
<p>Correct interpretation:</p>
<blockquote class="blockquote">
<p>Assuming the true effect is zero then the p-value represents the probability that you’d observe this effect-size in an experiment.</p>
</blockquote>
<p><strong>Confidence Intervals</strong></p>
<p>Common interpretation (<em>not</em> accurate):</p>
<blockquote class="blockquote">
<p>Given this estimate, there is a 95% chance that the true effect lies within this confidence interval.</p>
</blockquote>
<p>Correct interpretation:</p>
<blockquote class="blockquote">
<p>Assuming that the true value is equal to the effect, there is a 95% chance that the estimate would lie within this confidence interval.</p>
</blockquote>
</section>
<section id="bayesian-and-classical-inferences-doing-different-things" class="level2">
<h2 class="anchored" data-anchor-id="bayesian-and-classical-inferences-doing-different-things">Bayesian and Classical Inferences Doing Different Things</h2>
<p><span class="math display">\[\text{Evidence} \overset{\text{Bayesian}}{\underset{\text{Classical}}\rightleftarrows} \text{Truth} \]</span></p>
<p><strong>Classical inference is about calculating the likelihood of the evidence from the truth.</strong> We make inferences like this: <em>“Assuming the true effect was zero, then there is a less than 5% chance we would have observed this evidence.”</em></p>
<p><strong>Bayesian inference is about calculating the likelihood of the truth from the evidence.</strong> We make inferences like this: <em>“Given the evidence, there is a less than 5% chance of the true effect being less than zero.”</em></p>
<p><strong>When we are making decisions which depend on the truth, we need to do the Bayesian operation.</strong> The classical inference is still of interest:</p>
<ol type="1">
<li>Classical quantities (e.g.&nbsp;p-values) can be useful summaries of strength of evidence, which can then be combined with priors.</li>
<li>The classical inference can be thought of as a <em>restricted</em> version of the Bayesian inference – e.g.&nbsp;often coincide when prior is uniform.</li>
</ol>
</section>
<section id="pain-comes-from-confusing-them" class="level2">
<h2 class="anchored" data-anchor-id="pain-comes-from-confusing-them">Pain Comes from Confusing Them</h2>
<p>Compare the following two decision-rules:</p>
<ol type="1">
<li><strong>Bayesian rule:</strong> Your best estimate of <span class="math inline">\(t\)</span> is a weighted average of the experimental effect and your prior expectation, weighted by relative confidence in each.</li>
<li><strong>Classical rule (caricature):</strong> If the experiment is significant then treat <span class="math inline">\(t\)</span> as if <span class="math inline">\(t=y\)</span>, otherwise treat <span class="math inline">\(t=0\)</span>.</li>
</ol>
<p>The second rule is bad and it’s not advocated in any serious textbook, hwever it is a good representation of how many people <em>act</em>, and it causes perverse outcomes:</p>
<ol type="1">
<li>If people keep checking-in on the same experiment, they’re very likely to find a statistically significant finding eventually, and so the experiment will get launched.</li>
<li>If people run a lot of experiments, they’ll eventually find that a lot of them will be significant, and this would be so even if none of the experiments truly moved the metric.</li>
</ol>
</section>
<section id="coverage" class="level2">
<h2 class="anchored" data-anchor-id="coverage">Coverage</h2>
<p>Suppose we know the experimental outcome (<span class="math inline">\(y\)</span>) is equal to the true treatment-effect (<span class="math inline">\(t\)</span>) plus mean-zero Gaussian noise (<span class="math inline">\(e\)</span>):</p>
<p><span class="math display">\[y = t+e, \ \ \ \  e \sim N(0,1), \ \ \ \  t \sim f(.).\]</span></p>
<p>And let the <strong>estimator</strong> <span class="math inline">\(\hat{t}=y\)</span>. The following statements are the basis of the standard frequentist theory treatment of this situation:</p>
<p><span class="math display">\[\begin{aligned}
   E[\hat{t}|t] =&amp; t  
      &amp;&amp; \text{(unbiased)}\\
   P(\hat{t}-1.96 &lt; t &lt; \hat{t}+1.96) =&amp; 0.95
      &amp;&amp; \text{(coverage guarantee)}
\end{aligned}\]</span></p>
<p>However when we condition on the outcome itself, <span class="math inline">\(y=\hat{t}\)</span>, then things change:</p>
<p><span class="math display">\[\begin{aligned}
   E[t|\hat{t}] \neq&amp; \hat{t}, \text{ in general} \\
   P(\hat{t}-1.96 &lt; t &lt; \hat{t}+1.96|\hat{t}) \neq&amp; 0.95, \text{ in general}
\end{aligned}\]</span></p>
<p><strong>This is a very subtle distinction:</strong> Both of the following statements are true:</p>
<ol type="1">
<li>Before observing the estimator, on average the true treatment effect is equal to the estimated treatment effect, and the CIs cover the truth with 95% probability.</li>
<li>After observing the estimator, on average the true treatment effect is <em>not</em> equal to the estimated treatment effect, and the CIs will <em>not</em> cover the truth with 95% probability (except in special cases).</li>
</ol>
<p><strong>An example:</strong> Suppose that treatment effects are clustered near zero, <span class="math inline">\(t\sim N(0,1)\)</span>, then for given any realization of <span class="math inline">\(y\)</span>: (1) On average the truth will be <em>half</em> as large as the estimator: <span class="math inline">\(E[t|y]=\frac{y}{2}\neq \hat{t}.\)</span> (2) The truth will <em>not</em> fall within the confidence intervals 95% of the time. When <span class="math inline">\(y\)</span> is close to zero, the truth will fall within <span class="math inline">\(\pm 1.96\)</span> of <span class="math inline">\(y\)</span> more often than 95% of the time, and when <span class="math inline">\(y\)</span> is far from zero, the truth will fall within <span class="math inline">\(\pm 1.96\)</span> of <span class="math inline">\(y\)</span> less often than 95% of the time.</p>
<p><strong>Note:</strong> In the special case when we think it’s equally likely the truth is at any point on the real line, i.e.&nbsp;<span class="math inline">\(t\sim U[-\infty,\infty]\)</span>, then <span class="math inline">\(E[t|y]=y\)</span>, and likewise the confidence intervals, conditional on <span class="math inline">\(y\)</span>, will be well-calibrated.</p>
</section>
<section id="ambiguous-statements" class="level2">
<h2 class="anchored" data-anchor-id="ambiguous-statements">Ambiguous Statements</h2>
<p>To avoid spending all day arguing about classical vs Bayesian inference you need to be very careful about qualifying your statements. The following statements are ambiguous, and the ambiguity has led to much suffering:</p>
<blockquote class="blockquote">
<p>“The classical estimator is unbiased: it will be equal to the true value on average”</p>
</blockquote>
<p>This statement is true when you don’t condition on the evidence, but is false when you condition on the evidence. I.e., when you don’t know the experimental outcome then it’s fair to say it will be equal to the true outcome, on average. But as soon as you see what that outcome is, whether -5% or +1%, your best estimate of the truth will update and it will <em>not</em> be equal to the observed outcome.</p>
<blockquote class="blockquote">
<p>“the classical estimator has a coverage guarantee: the true value will be within the confidence interval 95% of the time.”</p>
</blockquote>
<p>Again this is true if unconditional, false if conditional. (See Gelman).</p>
</section>
<section id="everything-affects-everything." class="level2">
<h2 class="anchored" data-anchor-id="everything-affects-everything.">Everything Affects Everything.</h2>
<p>We sometimes talk about whether an experiment has a real effect or not, but in fact everything affects everything. Even an experiment on Android users will affect iPhone users, it’s just that the effect-size will be small.</p>
<p>So talking about “true positives” and “false positives” in tech experimentation confusing – nothing is a true negative.</p>
<section id="references" class="level3">
<h3 class="anchored" data-anchor-id="references">References</h3>
<ul>
<li>Gelman &amp; Carlin (20??) “Beyond power calculations: Assessing Type S (sign) and Type M (magnitude) errors”</li>
<li>McShanet et al.&nbsp;(2019) “Abandon Statistical Significance”</li>
</ul>
</section>
</section>
<section id="paradoxes-from-interpreting-classical-inferences-as-bayesian-inferences" class="level2">
<h2 class="anchored" data-anchor-id="paradoxes-from-interpreting-classical-inferences-as-bayesian-inferences">Paradoxes from Interpreting Classical Inferences as Bayesian Inferences</h2>
<p>Once you commit the original sin of testing for statistical significance you enter upside-down world where good is bad, bad is good:</p>
<ul>
<li>It’s bad to check-in on studies before you’ve finished them,</li>
<li>It’s bad to test for things that you thought of after the data was collected,</li>
<li>It’s bad to talk about an effect which has p=0.06, but fine to talk about one which has p=.05.</li>
<li>The significance of a test depends on how many other tests you ran that day.</li>
</ul>
<p>Each of these is a consequence of treating a classical-inference (truth-&gt;evidence) as if it was a Bayesian-inference (evidence-&gt;truth).</p>
</section>
<section id="why-use-the-classical-methods" class="level2">
<h2 class="anchored" data-anchor-id="why-use-the-classical-methods">Why Use the Classical Methods?</h2>
<p><strong>Why do we still teach &amp; use the classical framework?</strong></p>
<p><strong>They are useful inputs.</strong> Classical estimates, confidence intervals, and p-values are good summary statistics of the evidence, and we can use them to update our priors.</p>
<p><strong>Sometimes there’s reason to constrain the use of priors.</strong> When you treat the classical estimate as if it was a Bayesian estimate, i.e.&nbsp;a best-inference about the underlying value, this is similar in many ways to Bayesian inference with a completely flat prior. The Bayesian interpretation requires you to come up with a prior, but the shape of the prior is essentially a judgment call about what you think of as the nature of the existing evidence. The classical setup removes that judgment call and replaces it with a rigid rule. This can have two justifications:</p>
<ol type="1">
<li><strong>The psychological justification</strong> is that people have a weakness for misremembering their expectations, and thinking they predicted what actually happened – the classical rule prevents you from doing that.</li>
<li><strong>The organizational justification</strong> is that people will tend to misrepresent to others their priors – and people who run experiments face very strong incentives in interpreting their outcomes – shipping &amp; promotion, publication &amp; tenure – and so they can’t be trusted to be neutral reporters of what is a reasonable prior.</li>
</ol>
<p>Like plastic cutlery, we often use significance-testing as a way of protecting you from hurting yourself and others.</p>
<p>I personally think this is a reasonable way of trying to soften these psychological and organizational problems – but it’s super-important to understand that: hypothesis testing is motivated by psychological &amp; organizational constraints, it’s not motivated by statistical considerations.</p>
<p>You should think of the rules of significance-testing (insofar as they are used as inference, rather than inputs into Bayesian inference) as etiquette, not as statistics: i.e.&nbsp;we consider certain practices “bad form,” not because they’re statistical malpractice, but because they’re socially harmful.</p>
</section>
<section id="selective-reporting" class="level2">
<h2 class="anchored" data-anchor-id="selective-reporting">Selective Reporting</h2>
<p>Both Classical &amp; Bayesian setups can be misled by <em>selective</em> reporting, i.e.&nbsp;when people report only a subset of the data, and that subset depends on the realized outcomes.</p>
<p>In both cases you can essentially say that the estimators are misspecified because the data is not generated at random.</p>
</section>
<section id="multiple-comparisons-corrections" class="level2">
<h2 class="anchored" data-anchor-id="multiple-comparisons-corrections">Multiple-comparisons Corrections</h2>
<ol type="1">
<li><p><strong>It’s a source of confusion that we think about the <em>number</em> of tests, while the number is actually irrelevant, it’s actually about the strength of our priors.</strong></p></li>
<li><p><strong>Bonferroni p-values aren’t <em>“adjustments”</em>, they’re testing a different hypothesis.</strong> The classical p-values remain correct, independent of how many tests you do. Bonferroni p-values measure a different thing: the probability, for a set of tests, that <em>at least one</em> mean exceeds a certain threshold, conditional on the true effects all being zero.</p></li>
<li><p><strong>So why do we do Bonferroni adjustments? Because it approximates shrinkage with weak priors.</strong> The Bonferroni test is rarely of direct interest – i.e., we rarely care about the statistic “maximum t-stat” as a measure of the hypothesis “all effects are zero.” Nevertheless the technique is popular because it helps, indirectly, to address a different problem with multiple tests: that we typically have weak priors when we’re doing a lot of tests, and so heavy shrinkage is appropriate. Calculating Boneferroni p-values, <em>effectively</em> applies something like heavy shrinkage: they tell you to apply relatively stricter thresholds to your individual tests. In short: the number of experiments – whether 2, 20, or 50 – is irrelevant, the appropriate inference should depend only on the strength of priors about experimental effects.</p></li>
<li><p><strong>The reason we worry about false positives when looking at all experiments</strong> is because when we take a random experiment we think it’s <em>unlikely</em> that it will move a given metric, and so requires heavy shrinkage.</p></li>
<li><p><strong>Concentrating on the <em>number</em> of tests generates the well-known paradoxes:</strong> e.g., should you calculate p-values differently if you split a paper into two papers? If the investigator planned to run 20 tests, but died after running 10 of them? These all disappear when thought about through the Bayesian lens.</p></li>
<li><p><strong>Q: Why do we do False-Discovery-Rate adjustments? A: Because it approximates empirical-Bayes shrinkage.</strong> Another type of classical “adjustment” is to generate p-values which hold fixed false-discovery-rates. These are, again, tests of a different hypothesis. But they approximate empirical Bayes – i.e., what we discussed above, that you can shrink more effectively if you can estimate the distribution of true effect-sizes.</p></li>
</ol>
</section>
<section id="winners-curse" class="level2">
<h2 class="anchored" data-anchor-id="winners-curse">Winner’s Curse</h2>
<p>In short: frequentists observe that the best-performing treatment usually is an over-estimate, and so they derive an estimator that is unbiased conditional on the treatment being the best out of a group (Andrews (2021) “Inference on Winners”).</p>
<p>See discussion in <code>2023-01-12 Giorgio / Inference on Winners</code>.</p>
</section>
<section id="peeking" class="level2">
<h2 class="anchored" data-anchor-id="peeking">Peeking</h2>
<div class="example">
<p><strong>Example: Peeking.</strong> A presenter was showing a statistically significant result she found in an experiment. An audience-member asked “how did you choose your sample size?” She answered “we initially had a smaller sample, and didn’t find a significant result, so we collected 100 more samples, and found it was significant.”</p>
<p>Q: should this information change your belief about the likely effect-size?</p>
</div>
<p>This information should <em>not</em> change your beliefs about the likely effect-size. Gelman:</p>
<blockquote class="blockquote">
<p>“All Bayesian methods with proper priors have “biased effect sizes.” From a Bayesian standpoint, bias is not a problem because it is conditional on the true parameter value, which is never known. A Bayesian method (if the underlying model is true) will be calibrated. Calibration is conditional on the data, not on the unknown true effect size.</p>
</blockquote>
<blockquote class="blockquote">
<p>“You can see this by running a simulation of data collected with a data-dependent stopping rule. If you simulate from the model you’re fitting, the Bayesian inferences will be calibrated. If the model is wrong, you can get miscalibration, but we always have to worry about the model being wrong; that’s another story.</p>
</blockquote>
</section>
<section id="can-you-get-a-stat-sig-posterior-from-a-non-sig-likelihood" class="level2">
<h2 class="anchored" data-anchor-id="can-you-get-a-stat-sig-posterior-from-a-non-sig-likelihood">Can you get a Stat-Sig Posterior from a Non-Sig Likelihood?</h2>
<p>In the simplest case, if you have a Gaussian prior with mean of zero, then all effect-sizes will be shrunk towards zero. The confidence intervals will also get smaller but they will shrink at a slower rate, and so the p-values will get larger (here comparing the posterior distribution to the likelihood distribution).</p>
<p>Posterior point estimate: <span class="math display">\[ E[t|\hat{t}]=\frac{\sigma_t^2}{\sigma_t^2+\sigma_e^2}\hat{t}\]</span></p>
<p>Posterior variance: <span class="math display">\[\begin{aligned}
   V[t|\hat{t}]&amp; =\frac{1}{\sigma_t^{-2}+\sigma_e^{-2}}=\frac{\sigma_t^2\sigma_e^2}{\sigma_e^2+\sigma_t^2} \\
   \frac{V[t|\hat{t}]}{V[e]} &amp;=
      \frac{\sigma_t^2}{\sigma_e^2+\sigma_t^2} \\
   \frac{SD[t|\hat{t}]}{SD[e]} &amp;= \sqrt{\frac{\sigma_t^2}{\sigma_e^2+\sigma_t^2}}
\end{aligned}
\]</span></p>
<p>I think this result likely generalizes to most reasonable mean-zero priors, if they are single-peaked (i.e.&nbsp;not bimodal).</p>
<p>If you have a non-zero mean then it’s quite possible for shrinkage to cause the posterior to become statistically-significantly different from zero.</p>
</section>
<section id="misc-questions-and-answers" class="level2">
<h2 class="anchored" data-anchor-id="misc-questions-and-answers">Misc Questions and Answers</h2>
<blockquote class="blockquote">
<p><strong>Q: Suppose I flip a coin 10 times and see THTHTHTHTT, and conclude that the coin always comes up THTHTHTHTT in every sequence of 10 coin flips, because the probability of this sequence happening by chance is 1/1024. This seems like a bad practice, so under what circumstances are we justified in coming up with hypotheses ex post?</strong></p>
</blockquote>
<p>The prior you should use is the prior you would’ve stated before seeing the result.</p>
<p>Realistically you have a very tight zero prior over the hypothesis that “the coin always comes up THTHTHTHTT.” And so after you update you’ll still have an extremely low posterior probability on this. (This is harder to rationalize in the classical framework: they would just say “don’t run the test.”)</p>
<p>Often we only consider some pattern after we see the data. to assess how much we should update we can ask ourselves what our prior would’ve been before seeing the data. Often this is not easy to answer, at worst we can ask a colleague who hasn’t seen the data yet.</p>
<blockquote class="blockquote">
<p><strong>Q: I think even Bayesians would defend some uses of null hypothesis testing, e.g.&nbsp;A/A tests, tests of exposure imbalance in experiments, assessing fit of bayesian models with “bayesian p-values” (is the posterior distribution significantly different from the observed data).</strong></p>
</blockquote>
<p>I would say that Bayesians still want to generate summary statistics (e.g.&nbsp;p-values), esp.&nbsp;insofar as they are sufficient statistics of the data, but they wouldn’t take the classical point-estimates for granted, they would shrink them: e.g.&nbsp;for an AA test, if I’d run many previous AA tests and they were all well-calibrated, then when I run a new one I’d probably not worry if it was just significant, i.e.&nbsp;p=0.04.</p>
<blockquote class="blockquote">
<p><strong>Q: If the 95% CI only covered the true effect in 80% of cases, I (and I suspect others) would be upset. But this kind of coverage guarantee is a frequentist, not bayesian property, as Larry Wasserman notes <a href="https://normaldeviate.wordpress.com/2012/11/17/what-is-bayesianfrequentist-inference/">here</a>.</strong></p>
</blockquote>
<p>There are two very different properties:</p>
<ol type="1">
<li>Conditional on the true effect, what’s probability that the estimator is within 95% CI of that true effect.</li>
<li>Conditional on the estimate observed, what’s the probability that the true effect is within the 95% CI of that estimator.</li>
</ol>
<p>Your statement is the first, but I’m going to say we only really care about the second. Testing the second statement is significantly harder, because it requires knowing the true effect, but we can test it with a set of exeriments, essentially our shrinkage setup. And we find that the classical point estimates consistently over-estimate effect sizes, and 95% of true effects do not fall in the confidence intervals.</p>
<blockquote class="blockquote">
<p><strong>Q: I think I would agree that if you take a Bayesian perspective and do a lot of work assessing that your prior is reasonable, checking the fit of the posterior distribution etc, then you are in pretty good shape for multiple comparisons and early stopping problems. That second step is non-trivial and relatively few people have the time and ability to do it. And if you don’t do it then you’re in a potentially worse situation than the frequentist, to the extent that your attitude is “I don’t need to worry about these issues because I’m a Bayesian”.</strong></p>
</blockquote>
<p>For this argument to work I think you have to assume that Bayesians are hubristic – i.e., when you give them freedom, they do worse than when they are constrained. I’m sure this is true in some times and places, but I think the argument is essentially psychological, not statistical.</p>
</section>
</section>
<section id="references-1" class="level1">




</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" role="list">
<div id="ref-athey2019estimating" class="csl-entry" role="listitem">
Athey, Susan, Raj Chetty, Guido Imbens, and Hyunseung Kang. 2019. <span>“Estimating Treatment Effects Using Multiple Surrogates: The Role of the Surrogate Score and the Surrogate Index.”</span> <em>arXiv Preprint arXiv:1603.09326</em>.
</div>
<div id="ref-montiel2019" class="csl-entry" role="listitem">
Azevedo, Eduardo, Alex Deng, Jose Montiel Olea, and Glen Weyl. 2019. <span>“Empirical Bayes Estimation of Treatment Effects with Many a/b Tests: An Overview.”</span> <em>American Economic Review P&amp;P</em>, 43–47.
</div>
<div id="ref-coey2019improving" class="csl-entry" role="listitem">
Coey, Dominic, and Tom Cunningham. 2019. <span>“Improving Treatment Effect Estimators Through Experiment Splitting.”</span> In <em>The World Wide Web Conference</em>, 285–95. ACM.
</div>
<div id="ref-efron2021computer" class="csl-entry" role="listitem">
Efron, Bradley, and Trevor Hastie. 2021. <em>Computer Age Statistical Inference, Student Edition: Algorithms, Evidence, and Data Science</em>. Vol. 6. Cambridge University Press.
</div>
<div id="ref-peysakhovich2018learning" class="csl-entry" role="listitem">
Peysakhovich, Alexander, and Dean Eckles. 2018. <span>“Learning Causal Effects from Many Randomized Experiments Using Regularized Instrumental Variables.”</span> In <em>Proceedings of the 2018 World Wide Web Conference</em>, 699–707. International World Wide Web Conferences Steering Committee.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>Throughout we assume that the treatments change only the mean, not the variance, of outcomes.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>I’m working on finding a simpler way of writing this expression. I have a version in <code>multivariate-shrinkage-offcuts</code> using signal-noise ratio (SNR) which might be a bit easier to interpretd.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>If <span class="math inline">\(\gamma_e=0\)</span> the condition will never hold, because we know that <span class="math inline">\(\frac{\gamma_t}{\sigma_{t1}^2\sigma_{t2}^2}\)</span> represents the correlation in treatment effects, which is bounded between 0 and 1.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>I’m not certain how important the assumption of normal effect-sizes is for these relationships.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>One example would be when we have reason to believe that <span class="math inline">\(t_1\)</span> causes <span class="math inline">\(t_2\)</span>, and we wish to use experiments as instruments to estimate the causal relationship, see <span class="citation" data-cites="peysakhovich2018learning">Peysakhovich and Eckles (<a href="#ref-peysakhovich2018learning" role="doc-biblioref">2018</a>)</span> for more on this.<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>Under the assumption that <span class="math inline">\(t\)</span> is mean-zero.<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>Precisely: if the distribution of effect-sizes is Normal with zero mean then having a statistically-significant effect in 50% of your experiments implies a shrinkage rate of just 10%.<a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8"><p>Note that the matrix <span class="math inline">\(\Sigma_{t,y}\Sigma_{\hat{t}}^{-1}\)</span> represents the expected regression coefficients one would find from regressing <span class="math inline">\(t\)</span> on <span class="math inline">\(y\)</span>.<a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>