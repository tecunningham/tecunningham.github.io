<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Tom Cunningham">
<meta name="description" content="Tom Cunningham blog">

<title>Landscape Shrouded in Clouds | Tom Cunningham – Tom Cunningham</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

<script type="text/javascript">

(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-12027453-1', 'auto');

ga('send', {
  hitType: 'pageview',
  'anonymizeIp': true,
});
</script>
<script>window.MathJax = {
   loader: { load: ["https://cdn.jsdelivr.net/gh/sonoisa/XyJax-v3@3.0.1/build/xypic.js"]},
   tex: {packages: {'[+]': ['xypic','bm']},
         macros: {  bm: ["\\boldsymbol{#1}", 1],
                    ut: ["\\underbrace{#1}_{\\text{#2}}", 2],
                    utt: ["\\underbrace{#1}_{\\substack{\\text{#2}\\\\\\text{#3}}}", 3] }
   }
};
</script>
<style>
   h1 {  border-bottom: 4px solid black;}
   h2 {  border-bottom: 1px solid #ccc;}
</style>
<meta name="quarto:status" content="draft">

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../styles.css">
<meta name="twitter:title" content="Landscape Shrouded in Clouds | Tom Cunningham">
<meta name="twitter:description" content="Tom Cunningham blog">
<meta name="twitter:card" content="summary">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner"><div id="quarto-draft-alert" class="alert alert-warning"><i class="bi bi-pencil-square"></i>Draft</div>
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Tom Cunningham</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href=".././about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/testingham"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/tom-cunningham-a9433/"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://tecunningham.github.io/index.xml"> <i class="bi bi-rss-fill" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://scholar.google.com/citations?user=MDB_DgkAAAAJ"> 
<span class="menu-text">scholar</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Landscape Shrouded in Clouds</h1>
                      </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Tom Cunningham </p>
            </div>
    </div>
      
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
        
    </div>
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full" id="quarto-document-content">





<style>
   h1 {  border-bottom: 4px solid black; }
   h2 {  border-bottom: 1px solid gray; padding-bottom: 0px; color: black; }
   dl {display: grid;}
   dt {grid-column-start: 1; width: 4cm;}
   dd {grid-column-start: 2; margin-left: 2em;}
</style>
<section id="new-introduction" class="level1 page-columns page-full">
<h1>New Introduction</h1>
<div class="cell page-columns page-full">

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="2025-08-02-landscape-shrouded-in-clouds_files/figure-html/unnamed-chunk-1-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption><strong>Random landscape.</strong> Here there’s no structure: every <span class="math inline">\(x\)</span> is an independent random draw.</figcaption>
</figure>
</div>
</div></div></div>
<dl>
<dt>The effect of AI on innovation will depend on the shape of the landscape.</dt>
<dd>
<p>It seems like AI ought to dramatically accelerate innovation, but many people argue that we will be constrained by our physical ability to <em>test</em> any new ideas, e.g.&nbsp;we need GPUs to test new algorithms, we need labs and studies to test new drugs.</p>
<p>Here’s a nice observation: the value of AI depends on the shape of the innovation landscape. If the landscape is random then AI won’t help at all, if the landscape has latent structure then AI will help a great deal.</p>
</dd>
</dl>
<div class="cell page-columns page-full">

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="2025-08-02-landscape-shrouded-in-clouds_files/figure-html/unnamed-chunk-2-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption><strong>Rugged landscape.</strong> This shows a Weiner process (random walk). Here there’s local correlation but no long-distance dependence.</figcaption>
</figure>
</div>
</div></div></div>
<div class="cell page-columns page-full">

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="2025-08-02-landscape-shrouded-in-clouds_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption><strong>Regular landscape.</strong> Here there’s some latent structure, implying that you can make long-distance predictions from local observations.</figcaption>
</figure>
</div>
</div></div></div>
<dl>
<dt>Three types of landscape.</dt>
<dd>
<p>Suppose each period we choose an <span class="math inline">\(x\)</span> to minimize <span class="math inline">\(y(x)\)</span>, where <span class="math inline">\(y(\cdot)\)</span> is unknown. This is a well-defined explore-exploit problem, and we can characterize the expected progression of efficiency over time (the decline in <span class="math inline">\(y(.)\)</span> over time) as a function of the statistical structure of the landscape:</p>
<ol type="1">
<li><strong>Random landscape:</strong> If each <span class="math inline">\(y(x)\)</span> is completely independent there’s no intelligence needed in choosing <span class="math inline">\(x\)</span> (beyond keeping track of which locations you’ve already tried). The growth in efficiency as a function of <span class="math inline">\(N\)</span> draws depends on the distribution of values of <span class="math inline">\(y\)</span> (Muth, 1986).</li>
<li><strong>Rugged landscape:</strong> If <span class="math inline">\(y(x)\)</span> is correlated across <span class="math inline">\(x\)</span> but the correlation is local (e.g.&nbsp;if <span class="math inline">\(y(x)\)</span> is a Weiner process) then the best-estimate of <span class="math inline">\(y(x)\)</span> for a new <span class="math inline">\(x\)</span> will depend only on the neighboring values of <span class="math inline">\(x\)</span>. Callander (2011) and Carnehl &amp; Schneider (2025) characterize the optimal strategy. Again we are not constrained on intelligence: the extrapolation algorithm is fairly simple.</li>
<li><strong>Regular landscape:</strong> Finally suppose the landscape has some deep latent structure. In this case the best-estimate of <span class="math inline">\(y(x)\)</span> will depend on the entire collection of previously-observed pairs <span class="math inline">\((x,y)\)</span>, and so we <em>do</em> expect that predictions could be improved with more intelligence, and so AI should have a big impact.</li>
</ol>
</dd>
<dt>Random lanscapes: we expect little impact of AI.</dt>
<dd>
<ul>
<li><em>Discovering species.</em> Discovering viruses, discovering planets. When discovering new objects the observations cannot be well-predicted from first principles, we inevitably need new observations.</li>
<li><em>Plant breeding.</em> Suppose we breed plants just by selecting the highest-yield mutations. The statistical problem is trivial, and AI won’t help at all.</li>
<li><em>Mapping a genome.</em> The exact base pairs in a genome require individual observations.</li>
</ul>
</dd>
<dt>Regular landscapes, where we expect a large impact.</dt>
<dd>
<ul>
<li><em>Folding proteins.</em></li>
<li><em>Discovering candidate drugs.</em></li>
</ul>
</dd>
</dl>
</section>
<section id="old-introduction" class="level1">
<h1>Old Introduction</h1>
<dl>
<dt>A model of the world as accumulating knowledge.</dt>
<dd>
Suppose we’re all farmers and we’re gradually discovering the most efficient way of growing crops through trial and error – choosing how deep to plant the seeds and how far apart, how often to water, what fertilizer to add. We all can observe each others’ choices.
</dd>
<dt>Think of this as a model of all economic history.</dt>
<dd>
<p>We can interpret “growing crops” as all economic choices – building cars, treating diseases, writing novels. Implications:</p>
<ol type="1">
<li>Knowledge accumulates over time.</li>
<li>People tend to all adopt the same technique (herding), and there are some non-market forces to encourage exploration (public investment, intellectual property laws).</li>
<li>There will be specialization – if experience is imperfectly observable then some people will know relatively more about their particular field, and so have higher productivity, and we’ll get endogenous specialization.</li>
</ol>
</dd>
<dt>The ruggedness of the landscape determines the economics.</dt>
<dd>
<p>The ruggedness of the landscape means the degree of non-convexity, and so existence of local optimums. A high degree of ruggedness implies:</p>
<ul>
<li>Rugged domains will have steep growth with experience/time (as we discover progressively higher peaks)</li>
<li>Rugged domains will show higher efficiency in larger societies</li>
<li>Rugged domains will require more education/apprenticeship to learn best practices (rather than discover them on the job)</li>
</ul>
</dd>
</dl>
<table class="caption-top table">
<thead>
<tr class="header">
<th>smooth</th>
<th>rugged</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>cutting hair</td>
<td>agriculture</td>
</tr>
<tr class="even">
<td>cooking food</td>
<td>medical treatment</td>
</tr>
<tr class="odd">
<td>entertainment (music, writing, movies)</td>
<td>chip design</td>
</tr>
<tr class="even">
<td>teaching</td>
<td></td>
</tr>
<tr class="odd">
<td>nursing care</td>
<td></td>
</tr>
</tbody>
</table>
<dl>
<dt>The effect of AI depends on the ruggedness of the landscape</dt>
<dd>
<ul>
<li>If rugged, and AI helps illuminate the landscape, then expect rapid discovery improvements.</li>
<li>If smooth then we’re probably already close to global optimum, so AI doesn’t help much.</li>
</ul>
<p>Thus the best proxy for future productivity growth is past productivity growth.</p>
</dd>
<dt>AI will have two effects.</dt>
<dd>
<ol type="1">
<li><em>Share knowledge</em> – suppose knowledge is characterized by prior experiences, then AI could pool all experiences.</li>
</ol>
</dd>
<dd>
<ol start="2" type="1">
<li><em>Generate knowledge</em> – in some cases AI can reveal the landscape, i.e.&nbsp;gain knowledge that no human has.</li>
</ol>
</dd>
<dt>Implications for media.</dt>
<dd>
Suppose <span class="math inline">\(x\)</span> represents a piece of media and <span class="math inline">\(f(x)\)</span> represents its entertainment-value. We expect a slow process of discovery. (Notable that here <span class="math inline">\(f(x)\)</span> represents our own knowledge).
</dd>
</dl>
</section>
<section id="model-exploring-a-landscape." class="level1 page-columns page-full">
<h1>Model: Exploring a Landscape.</h1>
<div class="cell page-columns page-full" data-caption="caption">

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="2025-08-02-landscape-shrouded-in-clouds_files/figure-html/unnamed-chunk-4-1.png" class="img-fluid figure-img" width="288"></p>
</figure>
</div>
</div></div></div>
<p>Assumptions:</p>
<ol type="1">
<li><p><strong>You choose some <span class="math inline">\(x\)</span> and get payoff <span class="math inline">\(y(x)\)</span>.</strong> The function <span class="math inline">\(y(.)\)</span> is unknown, so you don’t observe the payoff until you try it out. You can interpret the action as a blueprint for a house, a business plan, a computer program, an agricultural practice, a novel, a song. Everything below also applies when the payoff depends on the state, <span class="math inline">\(v(x|z)\)</span>, and so the action is context-specific, e.g.&nbsp;replying to an email, operating a car, operating a machine, writing copy to advertise some product.</p></li>
<li><p><strong>You keep making the same choice over time.</strong></p></li>
<li><p><strong>Everyone is playing an independent game, but can observe each other.</strong> We’re all subsistence farmers living side-by-side, our actions don’t directly affect each other. Suppose we can all observe each others’ choices but not their payoffs.</p></li>
</ol>
<p>Implications:</p>
<ol type="1">
<li><p><strong>Exploration will decrease over time.</strong>With a single agent they will stop exploring at some point, and choose <span class="math inline">\(x\)</span> every period. E.g. we see that societies adopt certain practices in agriculture, architecture, clothes, cooking, and then settle on those once they have exhausted local improvements.</p></li>
<li><p><strong>Everyone will do the same thing (herding).</strong> If actions are observable then it is rational for each person to imitate others’ actions, and so within a society everyone’s actions will tend to be clustered in a neighborhood (if you’re walking through a minefield, you want to follow someone else’s footsteps).<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p></li>
<li><p><strong>There will be inefficiently little exploration.</strong> When you try out a new <span class="math inline">\(x\)</span> then your neighbors benefit because they can learn from your experience. We will thus have a million farmers all doing the same thing, it would be better if some of them experimented. We can collectively organize this: (A) sponsor people to run experiments; (B) let people register a claim on some <span class="math inline">\(x\)</span> and charge others to use it (intellectual property protection).</p></li>
<li><p><strong>Bigger societies will find better designs.</strong> Bigger societies will have (A) more random variation to learn from; (B) more ability to collectively organize to explore.</p></li>
<li><p><strong>People will become experts.</strong> Some people will learn the local neighbhorhood of their payoff-space and can charge for that expertise: artisans, architects, artists, doctors.</p></li>
</ol>
<section id="assumptions-on-landscape" class="level2">
<h2 class="anchored" data-anchor-id="assumptions-on-landscape">Assumptions on landscape</h2>
<p><strong>Assume <span class="math inline">\(v(\bm{x})\)</span> is non-convex.</strong> If it’s convex then you’ll gradually converge to the global maximum by local exploration.</p>
</section>
<section id="observations" class="level2">
<h2 class="anchored" data-anchor-id="observations">Observations</h2>
<ul>
<li><p><strong>Agricultural Yield is Exploration.</strong> Agricultural societies slowly accumulated crop management practices that have raised yields (irrigation, rotation, fertilizers). The invention of printing made knowledge diffuse more quickly, &amp; so more people caught up to the knowledge frontier (e.g.&nbsp;Diderot’s encyclopedia). Organized research advanced the frontier. People argue over whether intellectual property was a positive or negative for innovation.</p></li>
<li><p><strong>Technologies of Reproduction.</strong> You could extend the model such that you pay a lower cost when your action is an exact copy of an existing action (a reproduction). Certain technologies made it cheap to reproduce existing things: writing, printing, photography, audio recording, video recording. This increases welfare but makes outcomes more homogenous, the distribution of actions becomes very spikey.</p></li>
<li><p><strong>Science Maps out the Landscape.</strong> Normal progress consists of mapping out individual points on the landscape. Scientific progress is different - it maps out big areas. Newtonian mechanics tells you the stability of any bridge; modern chemistry tells you the properties of any combination of ingredients.</p></li>
</ul>
</section>
<section id="applications-to-ai" class="level2">
<h2 class="anchored" data-anchor-id="applications-to-ai">Applications to AI</h2>
<p>There are multiple things AI can do here: (1) predict the outcome given each context and action (<span class="math inline">\(v(\bm{z},\bm{x})\)</span>); (2) find an action <span class="math inline">\(\bm{x}\)</span> which maximizes <span class="math inline">\(v(\bm{z},\bm{x})\)</span>; (3) predict the typical human action (<span class="math inline">\(\bm{x}\)</span>) given the context (<span class="math inline">\(\bm{z}\)</span>). The last is imitative.</p>
<ul>
<li><p><strong>Human-level classification (content moderation, radiologists).</strong> You train a model on human labels to classify inputs. Now classification becomes very cheap. Expect this to be a substitute for low-skilled employees: borderline cases would still be escalated to the high-skilled employees.</p></li>
<li><p><strong>Super-human classification (sexing chickens; MRI).</strong> You see a chick <span class="math inline">\(z\)</span>, you choose whether to raise it to a chicken (<span class="math inline">\(x\in\{0,1\}\)</span>), and you get payoff if the chicken is female. Humans can’t tell the difference between male and female chicks by sight, but suppose AI models figure out how to do it. This is a pure yield increase for chicken ranchers because you save the cost of raising male chicks.</p></li>
<li><p><strong>Synthesize media (text, music, video, ads).</strong> Here the function <span class="math inline">\(v(\cdot)\)</span> represents human appreciation. Thus the function is known in a certain sense but the knowledge is implicit, and so in practice we explore the space and we we have experts: writers, musicians, artists, who can create content that gets a good reaction.</p></li>
<li><p><strong>Playing chess.</strong></p></li>
<li><p><strong>Folding proteins.</strong></p></li>
<li><p><strong>Writing code (imitative).</strong></p></li>
<li><p><strong>Face recognition.</strong></p></li>
<li><p><strong>Creating pictures.</strong></p></li>
<li><p><strong>Driving a car.</strong></p></li>
<li><p><strong>Writing boilerplate text.</strong></p></li>
<li><p><strong>Suggesting responses to customer queries.</strong></p></li>
<li><p><strong>Satisfying constraints.</strong></p></li>
<li><p><strong>LLM answering factual questions.</strong></p></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 70%">
<col style="width: 13%">
<col style="width: 15%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th>linear fit?</th>
<th>skill-biased?</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>estimating probability of death (or loan default)</td>
<td>yes</td>
<td></td>
</tr>
<tr class="even">
<td>agricultural management (irrigation, rotation, fertilizer)</td>
<td>yes</td>
<td></td>
</tr>
<tr class="odd">
<td>classifying whether photo is porn</td>
<td>no</td>
<td></td>
</tr>
<tr class="even">
<td>classifying whether text is hate speech, spam, etc.</td>
<td>no</td>
<td></td>
</tr>
<tr class="odd">
<td>classifying sex of chicken</td>
<td>no</td>
<td></td>
</tr>
<tr class="even">
<td>answering a customer question about a product</td>
<td>no</td>
<td></td>
</tr>
<tr class="odd">
<td>driving a car</td>
<td>no</td>
<td></td>
</tr>
<tr class="even">
<td>answering a factual question</td>
<td>no</td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<section id="applications" class="level3">
<h3 class="anchored" data-anchor-id="applications">applications</h3>
<dl>
<dt>Types of designs.</dt>
<dd>
<ul>
<li><em>design for consumption</em>: a story, a novel, a song, a picture, a wood-carving.</li>
</ul>
</dd>
<dd>
<ul>
<li><em>design for function</em>: computer code, agricultural practice (what to use as fertilizer, when to water plants), a letter, conversation with a customer, blueprint for a building.</li>
</ul>
</dd>
<dd>
<ul>
<li><em>tacit knowledge of practices.</em> How to operate a machine, how to stitch a collar, how to pitch a sale to a client.</li>
</ul>
</dd>
<dt>LLMs aggregate existing knowledge.</dt>
<dd>
LLMs don’t map out new points on the landscape, but aggregate existing knowledge. They are similar to encyclopedias or search engines. We’d expect each of these decisions to raise the quality of decisions, but also lower the returns to expertise: e.g.&nbsp;experts on Cobol, on rare diseases, on asbestos management.
</dd>
<dt>LLMs translate between two idioms.</dt>
<dd>
They can serve as interfaces between business logic and humans. They can write emails &amp; probably soon will have telephone conversations.
</dd>
</dl>
<p>Much human work can be thought of as <em>translation</em>: (1) customer support tells you how your situation fits into the policy; (2) insurance adjuster translates your bent fender into policy language; (3) literal translators/interpreters.</p>
<p>Many occupations are translating between human and machine. People who serve as interfaces between a mainframe and the customer: call center agents, gate agents, insurance adjusters, bank tellers, tax agents, rental car service clerk. They talk to the customer and type stuff into a computer.</p>
<p>Slow replacement with self-service: ATMs, self-service kiosks, automated phone systems, websites, phone apps.</p>
<p>It’s been difficult to automate policy agents, but some societies have been successful: Sweden tax by SMS, Japanese vending machines, ATMs instead of bank tellers.</p>
</section>
</section>
</section>
<section id="application-to-intellectual-property" class="level1">
<h1>Application to Intellectual Property</h1>
<p><strong>Key points:</strong></p>
<ol type="1">
<li><p><strong>We have IP protection because the landscape is shrouded in clouds.</strong></p></li>
<li><p><strong>AI illuminates the whole landscape.</strong> An implication is we should substantially loosen IP law, so it’s not just a race to acquire land.</p></li>
<li><p><strong>Copying occurs in a pre-AI world, but in the post-AI world there’s no real distinction between creation and copying.</strong></p></li>
<li><p><strong>LLMs could be prevented from producing exact matches with a hash function.</strong> (bloom filter?)</p></li>
</ol>
<hr>
<dl>
<dt>We should carefully distinguish <em>current IP law</em> or <em>future IP law</em> or <em>ideal IP law</em>.</dt>
<dd>
Much of the debate is about how to interpret current IP law, but current IP law was written as a response to a specific situation, we should ask how do we expect IP law and interpretation likely to change, and what would be the ideal IP law?
</dd>
<dt>Artefacts that can have intellectual protection.</dt>
<dd>
<ul>
<li>Chemical composition of a drug</li>
<li>Process used to manufacture a light bulb</li>
<li>The likeness of a cartoon character</li>
<li>A brand name</li>
<li>A photograph</li>
<li>The text of a news article</li>
<li>The lyrics of a song</li>
<li>The facts reported in a news article (sometimes)</li>
<li>A software algorithm</li>
</ul>
</dd>
<dt>We can make two assumptions about the landscape:</dt>
<dd>
<ol type="1">
<li>Snowflake/atomic: <span class="math inline">\(y(x)\)</span> has no structure, each <span class="math inline">\(y(x)\)</span> is a random draw.</li>
</ol>
</dd>
<dd>
<ol start="2" type="1">
<li>Smooth: <span class="math inline">\(y(x)\)</span> has structure, so as you observe more you’ll make better decisions.</li>
</ol>
</dd>
<dt>Model: unique snowflakes.</dt>
<dd>
Suppose each work is its own unique snowflake, this is a common way of modelling intellectual property (I think the Josh Gans paper assumes this). Implications: 1. <em>Copying is binary.</em> you either copy or you don’t, there’s no partial copying. 2. <em>The marginal value of information is equal to the average value.</em> (???)
</dd>
<dt>With AI everything is illuminated.</dt>
<dd>
Now suppose that AI illuminates the entire landscape, i.e.&nbsp;the mapping <span class="math inline">\(v(x)\)</span> becomes fully known to everybody.
</dd>
<dd>
E.g. we can suddenly observe (1) of all possible drugs, how effective is each; (2) of all possible lyrics, how resonant is each; (3) of all possible paintings, how attractive is each.
</dd>
<dt>Distinction: whether the value is the world, or human response.</dt>
<dd>
It’s worth distinguishing two sources of uncertainty in v(x): whether v(.) measures the effect of x on the outside world, or the effect of x on human responses.
</dd>
<dd>
<ol type="1">
<li>About the world: <span class="math inline">\(v(x)\)</span> represents efficacy of a drug, or the speed of a sorting algorithm.</li>
</ol>
</dd>
<dd>
<ol start="2" type="1">
<li>About human responses: <span class="math inline">\(v(x)\)</span> represents memorability of a poem, the click-through-rate of an advertisement, the beauty of an image.</li>
</ol>
</dd>
<dt>Prediction: there will be less imitation in the post-AI world.</dt>
<dd>
If the full landscape is disclosed then there’s no longer a <em>reason</em> to imitate. You can just choose the x which maximizes v(x). We will still see <em>clustering</em>, people will choose similar values of x, but just because they maximize v(.), not because they’re imitating each other.
</dd>
</dl>
<hr>
<dl>
<dt>Twist: familiarity changes the value.</dt>
<dd>
In some cases the use of an input x will change the output v(x). E.g. after people have been exposed to a particular phrase or a particular cartoon character then that particular realization becomes more attractive in the future. As a consequence the landscape will have ridges, creases bearing the imprint of particular cases (distinct from the ridges due to finite training data).
</dd>
<dt>Good application: genre novels.</dt>
<dd>
Suppose we have a set of 10,000 novels which are romance or western or fantasy. We can think of the probability distribution from which they’re drawn.
</dd>
<dd>
The probability distribution will have a ridge around actual novels but also a lot of structure off that; trained on 10,000 novels from a trillion; could just avoid direct quotes (bloom filter) but still pick up the sense.
</dd>
<dt>The marginal value of information is close to zero.</dt>
<dd>
The returns to information are highly concave: think about the value of each dot on the landscape, the value decreases with something like sqrt(N). As a consequence if we pay people for the marginal value of their information the payments will be very small. (Euler’s theorem: if a function has constant returns to scale, then sum of payments to factors will exactly equal total product).
</dd>
<dd>
This result only holds in the <em>landscape</em> world, not in the <em>snowflake</em> world.
</dd>
</dl>
<hr>
<blockquote class="blockquote">
<p>“Data are considered discoverable”Facts,” not original works in themselves, and are thus not copyrightable. The methods of compilation, analysis, annotation arrangement, or selection of data, which may be novel, unique, or proprietary, can be protected under copyright.</p>
</blockquote>
</section>
<section id="other-candidate-metaphors" class="level1">
<h1>Other Candidate Metaphors</h1>
<p>I want a good metaphor but not sure which is best.</p>
<dl>
<dt>Crop management [BEST].</dt>
<dd>
We’re all farmers and gradually discovering better ways to grow our crops – how deep to plant the seeds and how far aprat, what to put on as fertilizer, how often to water.
</dd>
<dt>Drug design.</dt>
<dd>
We’re choosing a combination of ingredients to maximize effectiveness in treating some condition. We generally follow others’ recipes very closely, occasionally adding a new one to the repertoire. Very likely there exist far more effective combinations that we’re not aware of.
</dd>
<dt>Drilling for water.</dt>
<dd>
We have a huge desert &amp; we want to know the best spots to drill for water. We go around drilling spots, and gradually build up some theory about where the water is.
</dd>
</dl>
</section>
<section id="modelling-knowledge" class="level1">
<h1>Modelling Knowledge</h1>
<dl>
<dt>Knowledge is often treated implicitly in economic models.</dt>
<dd>
<p>Many economic models have some parameter described as representing the knowledge of the agent, and which acts as a productivity multiplier. This is how knowledge is represented in many growth models. This can be extended to a vector of productivities across different types of good, representing knowledge in different domains (e.g.&nbsp;Becker &amp; Murphy (1992)). A slightly richer model is in Garicano (Ide-Talamas), where each agent’s knowledge is a scalar which represents the most difficult problem they can solve.</p>
</dd>
<dt>It is useful to have an explicit model of knowledge.</dt>
<dd>
<p>Knowledge is modelled explicitly when the agent has some beliefs about the state of the world, and update those beliefs based on experience. Having an explicit model of knowledge allows us to derive equilibrium behaviors as a function of the statistical structure of the world:</p>
<ol type="1">
<li>The returns to experience – and from that the equilibrium degree of specialization.</li>
<li>The incentives for exploration – and from that social learning, herding, &amp; the effects of IP protection.</li>
<li>The relative performance of computers vs humans across different domains (or the relative performance of different algorithms).</li>
</ol>
</dd>
<dt>General model of knowledge.</dt>
<dd>
<p>The simplest model of knowledge has an unobserved state of the world <span class="math inline">\(\theta\)</span>, an action <span class="math inline">\(x_t\)</span>, and the agent receives payoff <span class="math inline">\(u(x_t|\theta)\)</span>. This a basic bandit problem, where knowledge of <span class="math inline">\(\theta\)</span> accumulates over time.</p>
<p>Some models additionally have a dynamic signal <span class="math inline">\(z_t\)</span>, so payoff is <span class="math inline">\(u(x_t,z_t|\theta)\)</span>. These can be reduced to simpler state-action models by interpreting the action as a function going from signal to action <span class="math inline">\(x(z_t)\)</span>.</p>
</dd>
</dl>
<section id="summary-of-models" class="level2">
<h2 class="anchored" data-anchor-id="summary-of-models">Summary of Models</h2>
<table class="caption-top table">
<thead>
<tr class="header">
<th>model</th>
<th style="text-align: center;">signal</th>
<th style="text-align: center;">action</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>BANDIT / LANDSCAPE</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td>- K-arm bandit</td>
<td style="text-align: center;">none</td>
<td style="text-align: center;">categorical</td>
</tr>
<tr class="odd">
<td>- Jovanovic &amp; Nyarko</td>
<td style="text-align: center;">none</td>
<td style="text-align: center;">categorical</td>
</tr>
<tr class="even">
<td>- Callander rugged landscape</td>
<td style="text-align: center;">none</td>
<td style="text-align: center;">scalar</td>
</tr>
<tr class="odd">
<td>- NK fitness</td>
<td style="text-align: center;">none</td>
<td style="text-align: center;">vector</td>
</tr>
<tr class="even">
<td>- Bayesian optimization (GP-UCB/TS)</td>
<td style="text-align: center;">none</td>
<td style="text-align: center;">vector</td>
</tr>
<tr class="odd">
<td></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td>SUPERVISED LEARNING</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td>- gaussian process regression</td>
<td style="text-align: center;">vector</td>
<td style="text-align: center;">scalar</td>
</tr>
<tr class="even">
<td>- nonparametric regression</td>
<td style="text-align: center;">vector</td>
<td style="text-align: center;">scalar</td>
</tr>
<tr class="odd">
<td>- question-answering</td>
<td style="text-align: center;">vector</td>
<td style="text-align: center;">scalar</td>
</tr>
<tr class="even">
<td></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td>CONTEXTUAL BANDIT</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td>- Linear contextual bandit</td>
<td style="text-align: center;">vector</td>
<td style="text-align: center;">vector</td>
</tr>
<tr class="odd">
<td>- Contextual Bayes optimization</td>
<td style="text-align: center;">vector</td>
<td style="text-align: center;">vector</td>
</tr>
<tr class="even">
<td>- Optimal control (Kalman filter)</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td>- Reinforcement learning</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
</tbody>
</table>
</section>
<section id="models-of-knowledge" class="level2">
<h2 class="anchored" data-anchor-id="models-of-knowledge">Models of Knowledge</h2>
<dl>
<dt>Binary action (bandits).</dt>
<dd>
<p>There is a big literature studying “strategic experimentation” where the action is binary, often with one safe and one risky arm. See a good survey in Hörner &amp; Skrzypacz (2016) <a href="https://web.stanford.edu/~skrz/survey_learning_Horner_Skrzypacz.pdf">Strategic experimentation, learning, information design</a>.</p>
<ul>
<li>They distinguish between two types of bandits: whether a null outcome is good news or bad news.</li>
<li>2.1: strategic bandits. everyone has to play a bandit game, but they observe others’ choices and payoffs, so there are informational externalities. They say that equilibrium is generally <em>complex</em> so it’s often studied in simplified settings. Each player can choose either safe or risky arm. We can compare compare choice of risky when playing alone vs when you observe someone else: there are free-riding effects, but also encouragement effects – if you’re successful then it will provoke more experimentation by the other guy.</li>
<li>2.2: imperfect observation. They say “observed actions, unobserved outcomes remains largely unsolved … but .. unobservable actions, observed outcomes is better understood.”</li>
<li>They note that most of the literature has just two actions. The discuss the Callander setup – where beliefs over W(p) are a Weiner process. This has the nice property that beliefs will depend only on nearest neighbors.</li>
</ul>
</dd>
<dt>Continuous action, Gaussian-quadratic outcome.</dt>
<dd>
<p>Jovanovic &amp; Nyarko (1996) have a model with <span class="math inline">\(K\)</span> different technologies, for each there’s some unobserved <span class="math inline">\(\theta\)</span>, you have Gaussian priors over each, and as you operate the technology longer you update your beliefs. This can be reduced to a model where you just choose which technology to use (<span class="math inline">\(k\)</span>), and your productivity in that technology increases over time. Implications:</p>
<ol type="1">
<li>Exploration is front-loaded – the value of information falls with experience.</li>
<li>Hysteresis – the mroe experience you have with one technology the less likely you are to switch.</li>
</ol>
</dd>
<dt>Continuous action, Weiner outcome.</dt>
<dd>
<p>Callander (2011, AER) “Searching and Learning by Trial and Error.”: Outcomes are the realized path of a Brownian motion over the choice space; optimal experimentation is history‑dependent and can settle at local optima.</p>
<blockquote class="blockquote">
<p>“Innovation in this market is irregular with frequent changes of direction and cycles between frontier and niche innovation. We show how the ruggedness of the technological landscape itself deters innovation, generating less entry and product diﬀerentiation, narrower markets, and more intense competition than in a world of certainty.”</p>
</blockquote>
</dd>
<dd>
<p>Carnehl &amp; Schneider (2025, Ecma) “A Quest for Knowledge”</p>
<blockquote class="blockquote">
<p>“Researchers select a question and how intensely to study it. The novelty of a question determines both the value and difficulty of discovering its answer. We show that the benefits of discoveries are nonmonotone in novelty. Knowledge expands endogenously step-by-step over time.”</p>
</blockquote>
</dd>
<dt>Atomic actions.</dt>
<dd>
<ul>
<li>Kortum (1997) <a href="https://egc.yale.edu/sites/default/files/Kortum_1997.pdf">“Research, Patenting, and Technological Change”</a>. He assumes that technological progress comes from taking random draws from a distribution (undirected search). Then growth over time will be characterized by the extreme value distribution of the underlying distribution, &amp; returns to experience will depend on the thickeness of tails: (1) Bounded: (hits a ceiling) ; (2) exponential (thin tails): <span class="math inline">\(A=\ln n\)</span>; (3) Pareto (thick tails): <span class="math inline">\(A = n^\gamma\)</span>. Note that completely random (undirected) search seems a poor fit for most innovation processes. Examples: Edison testing filaments, high-through drug discovery, evaluating mutations. The theory has a clear implication: that over time the share of trials that are failures increases very strongly; but in fact it’s not clear this is true.</li>
</ul>
</dd>
<dd>
<ul>
<li>Agrawal, McHale and Oettl (2023) model a finite distribution of alternatives, and the inventor has a prior probability of success for each. They let AI change the distribution of priors, and they show that this change will decrease time-to-success and increase R&amp;D effort.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></li>
</ul>
</dd>
<dt>Vector action.</dt>
<dd>
See a good discussion of evolutionary fitness landscapes <a href="https://www.ggi.infn.it/talkfiles/slides/talk3333.pdf">here</a>. They draw beautiful models of fitness landscapes in a 2^n space, and they have a bunch of empirical findings from bacteria about ruggedness of those landscapes: <img src="images/2025-08-12-21-02-24.png" class="img-fluid" alt="Fitness landscape">
</dd>
<dd>
<p>Models:</p>
<ol type="1">
<li><em>House-of-cards.</em> The fitness of each genotype is a random draw. You can get nice clean expressions for the expected number of local optima.</li>
<li><em>Mount Fuji</em> – The function is entirely separable.</li>
<li><em>NK model</em> Total fitness <span class="math inline">\(W\)</span> is the arithmetic mean of the <span class="math inline">\(N\)</span> component contributions: <span class="math display">\[W(s) = \frac{1}{N} \sum_{i=1}^N w_i(s_i, s_{i_1}, \dots, s_{i_K}),\]</span> Note that component <span class="math inline">\(w_i\)</span> depends on <span class="math inline">\(s_i\)</span> plus up to <span class="math inline">\(K\)</span> other components. This model is highly cited in management, but less in economics. (Kauffman &amp; Weinberger (1989))</li>
<li><em>Rugged Mount Fuji</em> - <span class="math inline">\(f(\sigma) =−cd(\sigma,\sigma^*)+\eta(\sigma)\)</span>, where <span class="math inline">\(d(.,.)\)</span> is Hamming distance between <span class="math inline">\(\sigma\)</span> and the global optimum <span class="math inline">\(\sigma^*\)</span>.</li>
</ol>
</dd>
<dd>
Levinthal (1997) applies Kauffman’s NK model to business decision-making.
</dd>
</dl>
<dl>
<dt>General action (nonparametric learning).</dt>
<dd>
<p>Finally we can talk quite generally about nonparametric estimation of a function, AKA supervised learning. There we have some nice expressions of learning rates (how error trends with N), and how it relates to the function’s curvature and dimensionality. We can treat this as a maximization problem, consistent with the cases above: suppose you receive a series of cases from some distribution <span class="math inline">\(f(x)\)</span> and you have to classify each case, given some loss function.</p>
</dd>
</dl>
</section>
</section>
<section id="data-on-progress-over-time" class="level1">
<h1>Data on Progress Over Time</h1>
<section id="cost-reductions-from-our-world-in-data" class="level2">
<h2 class="anchored" data-anchor-id="cost-reductions-from-our-world-in-data">Cost Reductions from Our World in Data</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/2025-08-16-18-03-35.png" class="img-fluid figure-img"></p>
<figcaption>From Our World in Data</figcaption>
</figure>
</div>
<ul>
<li>https://ourworldindata.org/grapher/costs-of-66-different-technologies-over-time</li>
<li>Most are around 1%/year, outliers: DNA sequencing, photovoltaics, hard disk drive, DRAM, transistor.</li>
</ul>
</section>
<section id="data-on-algorithmic-progress" class="level2">
<h2 class="anchored" data-anchor-id="data-on-algorithmic-progress">Data on Algorithmic Progress</h2>
<p>Sherry &amp; Thompson (2021) <a href="https://ide.mit.edu/wp-content/uploads/2021/09/How_Fast_Do_Algorithms_Improve.pdf">“How Fast do Algorithms Improve?”</a></p>
<blockquote class="blockquote">
<p>“We find enormous heterogeneity in algorithmic progress, with nearly half of algorithm families experiencing virtually no progress, while 14% experienced improvements orders of magnitude larger than hardware improvement (including Moore’s law).</p>
</blockquote>
<p><img src="images/2025-08-30-12-16-37.png" class="img-fluid"></p>
<p>Others:</p>
<ul>
<li><em>Channel coding efficiency:</em> we are very close to the Shannon lower bound.</li>
<li><em>Compression efficiency:</em> compression has been getting better consistently better over time, &amp; LLM perplexity is essentially a model of copmression (the Hutter prize). LLM-based compression is far more efficient.</li>
</ul>
</section>
<section id="learning-curves" class="level2">
<h2 class="anchored" data-anchor-id="learning-curves">Learning Curves</h2>
<dl>
<dt>Learning curves</dt>
<dd>
McNerny (2022) talk about Wright’s law: cost falls exponentially with quantity, <span class="math inline">\(c\propto Q^{-\alpha}\)</span>. They say typical <span class="math inline">\(\alpha\)</span> = 0.32, so 10X quantity gets 50% reduction in cost. (They note that it’s hard to distinguish between effects of scale vs effects of time; also there could be reverse causation from scale to cost.)
</dd>
</dl>
</section>
</section>
<section id="appendix" class="level1">
<h1>Appendix</h1>
<p>Some other literature.</p>
<ul>
<li>Rational herding / cascades: Banerjee (1992); Bikhchandani, Hirshleifer &amp; Welch (1992); Chamley (2004, Rational Herds).</li>
<li>Social learning and networks: Vives (2008, Information and Learning in Markets); Bala &amp; Goyal (1998); Jackson &amp; Yariv (2011).</li>
<li>Learning‑by‑doing / technique choice: Jovanovic &amp; Nyarko (1996).</li>
<li>Path dependence / specialization: Arthur (1989); Polya urn processes.</li>
</ul>
</section>
<section id="offcuts" class="level1">
<h1>Offcuts</h1>
<section id="what-conditions-are-required-for-ai-progress" class="level2">
<h2 class="anchored" data-anchor-id="what-conditions-are-required-for-ai-progress">2025-08-23 | what conditions are required for AI progress?</h2>
<dl>
<dt>Basic model: you choose between <span class="math inline">\(N\)</span> alternatives, costs <span class="math inline">\(c\)</span> to evaluate each.</dt>
<dd>
For each alternative there is some true value, <span class="math inline">\(y(x)\)</span>, which you only observe by paying the cost. You thus rank all the alternatives according to your prior, <span class="math inline">\(E[y(x)]\)</span>, and take draws until the expected improvement is equal to the expected cost (to simplify, suppose that new draws don’t update the priors on other alternatives).
</dd>
<dd>
In this model computers can do two things.
</dd>
<dt>(1) Computers lower the cost of evaluation.</dt>
<dd>
<ul>
<li><em>Full evaluation.</em> In some domain the ground truth can be calculated by a computer: (A) efficiency of an algorithm; (B) the physical properties of a system (e.g.&nbsp;physics); (C) constraint satisfaction, e.g.&nbsp;Sudoku, chess. Note that LLMs and neural nets are <em>not</em> very good at these exact calculations.</li>
</ul>
</dd>
<dd>
<ul>
<li><em>Approximate evaluation.</em> E.g. (A) simulation of weather; (B) simulation of a building’s structural integrity; (C) whether a joke is funny; (D) predicting whether protein will fold.</li>
</ul>
</dd>
<dt>(2) Computers give information about alternatives.</dt>
<dd>
You can model this as .
</dd>
<dt>Implication: AI isn’t useful only in cheap-evaluation domains.</dt>
<dd>
Dean and Hassabis both say AI will be useful only when you can evaluate cheaply.
</dd>
<dd>
Places where evaluation is expensive: (1) drugs; (2) ;
</dd>
<dt>CLAIM: AI acceleration depends on the structure of the landscape.</dt>
<dd>
<ol type="1">
<li><em>Random landscape: discovering viruses.</em> – the landscape has irreducible complexity. It’s high-dimensional.</li>
</ol>
</dd>
<dd>
<ol start="2" type="1">
<li><em>Regular landscape: optimizing algorithms.</em> – can find patterns that others haven’t discovered. / Especially good at solving problems that are not deterministic, but borrow structure from other similar problems – e.g.&nbsp;crosswords, chess, sudoku. / And will likely find the <em>ground truth</em> for some algorithms, the best possible: e.g.&nbsp;efficiency bound for algorithm, or Nash strategy for a game.</li>
</ol>
</dd>
<dd>
<ol start="3" type="1">
<li><em>Regular landscape: .</em></li>
</ol>
</dd>
</dl>
<hr>
</section>
</section>
<section id="related-literature" class="level1">
<h1>Related Literature</h1>
<section id="jeff-dean-clear-reward-short-evaluation-cycle" class="level2">
<h2 class="anchored" data-anchor-id="jeff-dean-clear-reward-short-evaluation-cycle">Jeff Dean: clear reward, short evaluation cycle</h2>
<blockquote class="blockquote">
<p>“going to have to be an area that is amenable to a fully automated loop of generating some ideas, trying them out, getting some feedback, exploring essentially some very large space of possible solutions to some problem, and when you have that characteristic we’ve already seen that reinforcement learning algorithms and large-scale search with computation actually are quite effective … where you don’t have that characteristic … there’s no clear reward signal or the evaluation of this particular instantiation of an idea actually takes you two weeks instead of a minute, that kind of thing will hamper you.”</p>
</blockquote>
<ul>
<li><a href="https://youtu.be/OEuh89BWRL4">YouTube</a> ; <a href="https://x.com/slow_developer/status/1959046679845642552">Twitter</a></li>
</ul>
</section>
<section id="bouatta-et-al.-2021-protein-structure-prediction-by-alphafold2-are-attention-and-symmetries-all-you-need" class="level2">
<h2 class="anchored" data-anchor-id="bouatta-et-al.-2021-protein-structure-prediction-by-alphafold2-are-attention-and-symmetries-all-you-need">Bouatta et al.&nbsp;(2021) <a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC8329862/">“Protein structure prediction by AlphaFold2: are attention and symmetries all you need?”</a></h2>
<blockquote class="blockquote">
<p>“Last December, the organizers of … (CASP14) experiment made the surprising announcement that DeepMind … had ‘solved’ the protein-folding problem”</p>
</blockquote>
<blockquote class="blockquote">
<p>Three properties of Go and StarCraft2 made them amenable to machine-learning methods: the existence of a massive search space, a clear objective function (metric) for optimization and large amounts of data. Protein structure prediction shares some of these properties.</p>
</blockquote>
<blockquote class="blockquote">
<p>This end-to-end differentiability condition greatly simplifies learning by enabling all parameters to be adjusted jointly instead of relying on a patchwork of disconnected steps, each of which is optimized independently</p>
</blockquote>
</section>
<section id="hassabis-2024-nobel-lecture" class="level2">
<h2 class="anchored" data-anchor-id="hassabis-2024-nobel-lecture">Hassabis (2024) Nobel Lecture</h2>
<blockquote class="blockquote">
<p>What makes for a suitable problem for AI? (1) Massive combinatorial search space; (2) Clear objective function (metric) to optimise against; (3) Either lots of data and/or an accurate and efficient simulator.</p>
</blockquote>
<blockquote class="blockquote">
<p>Taking a step back, what is the essence of what our systems are doing? - Finding the optimal solution in an enormous combinatorial space - Learn a model of that environment (from data or simulation) - Use that model to guide a search according to an objective function - Turns out this is a very general solution and many problems fit this approach</p>
</blockquote>
<blockquote class="blockquote">
<p>My Proposed Conjecture: “Any pattern that can be generated or found in nature can be efficiently discovered and modelled by a classical learning algorithm”</p>
</blockquote>
<blockquote class="blockquote">
<p>If it turns out that classic systems can model certain types of quantum systems, it could potentially have big implications for complexity theory including P=NP, and maybe even fundamental physics!</p>
</blockquote>
<blockquote class="blockquote">
<p>AI for Science, Medicine &amp; Climate - Identifying eye disease from retinal scans - Genetic missense mutations - Fusion - plasma containment - Faster matrix multiplication - SOTA weather forecasting - Discovery of new materials</p>
</blockquote>
</section>
<section id="hassabit-lex-fridman-interview" class="level2">
<h2 class="anchored" data-anchor-id="hassabit-lex-fridman-interview">Hassabit Lex Fridman interview</h2>
<dl>
<dt>You need a latent structure, and all natural systems have a latent structure.</dt>
<dd>
<blockquote class="blockquote">
<p>“natural systems have structure because they were subject to evolutionary processes that shape them. And if that’s true, then you can maybe learn what that structure is.</p>
</blockquote>
</dd>
<dd>
<blockquote class="blockquote">
<p>“it may not be possible for man-made things or abstract things like factorizing large numbers because unless there’s patterns in the number space, which there might be, but if there’s not and it’s uniform, then there’s no pattern to learn, there’s no model to learn that will help you search. So you have to do brute force.</p>
</blockquote>
</dd>
</dl>
<p>https://lexfridman.com/demis-hassabis-2-transcript/</p>
</section>
<section id="agrawal-mchale-oettl-2023" class="level2">
<h2 class="anchored" data-anchor-id="agrawal-mchale-oettl-2023">Agrawal, McHale &amp; Oettl (2023)</h2>
<blockquote class="blockquote">
<p>What is the main testable implication of the model? It is simple to state but difficult to implement – <strong>access to AI-based prediction models will increase scientific discovery and innovation.</strong> We refer to this as the Hassabis hypothesis . Demis Hassabis, co-founder of DeepMind (now part of Google), has been an evangelist for the potential of AI to speed scientific discovery. He has noted three requirements that make a scientific problem amenable to an AI-aided solution: a combinatorial search space (too large for exhaustive search); a clear objective function for training the prediction model; and sufficient data or capability to simulate that data to train the model. We suggest adding a fourth – poor alternative predictive models for prioritizing search over the design space. When these conditions are present, the Hassabis hypothesis is essentially that the space of amenable problems that cannot be solved by other means is large. AlphaFold can reasonably be seen as a proof of concept – albeit one with significant real-world implications. Time – and empirical research – will tell if it is a fluke or a harbinger of a new era of discovery.</p>
</blockquote>
</section>
<section id="mcnerny-2022-role-of-design-complexity-in-technology-improvement" class="level2">
<h2 class="anchored" data-anchor-id="mcnerny-2022-role-of-design-complexity-in-technology-improvement">McNerny (2022) <a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC3107265/">“Role of design complexity in technology improvement”</a></h2>
<dl>
<dt>They try to fit learning curves to ruggedness.</dt>
<dd>
Models where the learning curve arrives endogenously: 1. Muth (1986): you take random draw each time. If underlying distribution is Weibull then minimum wll be power-law in number of draws. 2. McNerny (2022): you have a cluster of components with interdependence. If more interdependent then the learning curve is slower (like a landscape with higher epistasis). 3. Jovanovic &amp; Nyarko (….).
</dd>
</dl>
</section>
</section>
<section id="offcuts-1" class="level1">
<h1>offcuts</h1>
<ol type="1">
<li><p>The Fitness landscape leaves as impression - like a plaster cast ; you can figure out from petals of a flower where it lives and who else lives nearby.</p></li>
<li><p>Examples of brute force exploration: (1) wildcat drilling; (2) high-throughput drug discovery; (3) growing seedlings looking for beneficial mutations.</p></li>
</ol>


</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>Define equilibrium as when everyone chooses the same <span class="math inline">\(x\)</span> every period. This follows if there’s common priors, common-knowledge-of-rationality, and a regularity assumption on beliefs. Choosing some <span class="math inline">\(\cap{x}\)</span> implies that, for every <span class="math inline">\(x\neq\cap{x}\)</span>, that <span class="math inline">\(E[y(\cap{x})] - E[y(x)]\geq 0\)</span>. Assume these inequalities are always strict, meaning every <span class="math inline">\(E[y(x)]\)</span> is one-to-one (injective). Then if two people choose different <span class="math inline">\(x\)</span> they must disagree about one of those inequalities, violating common knowledge of rationality (Aumann’s agreeing-to-disagree).<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>Note that they set up the landscape as a combination of N elements, but by email they confirm that the combinatorial structure isn’t actually used. They say their earlier paper on needles-in-haystack does use that structure.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{cunningham,
  author = {Cunningham, Tom},
  title = {Landscape {Shrouded} in {Clouds}},
  url = {tecunningham.github.io/posts/2025-08-02-landscape-shrouded-in-clouds.html},
  langid = {en}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-cunningham" class="csl-entry quarto-appendix-citeas" role="listitem">
Cunningham, Tom. n.d. <span>“Landscape Shrouded in Clouds.”</span> <a href="https://tecunningham.github.io/posts/2025-08-02-landscape-shrouded-in-clouds.html">tecunningham.github.io/posts/2025-08-02-landscape-shrouded-in-clouds.html</a>.
</div></div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("tecunningham\.github\.io");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>