[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Blog Posts",
    "section": "",
    "text": "Knowledge-Creating LLMs\n\n\n\n\n\n\n\n\n\n\n\nFeb 6, 2026\n\n\nTom Cunningham\n\n\n\n\n\n\n\n\n\n\n\nLLM verification\n\n\n\n\n\n\n\n\n\n\n\nDec 30, 2025\n\n\nTom Cunningham\n\n\n\n\n\n\n\n\n\n\n\nForecasts of AI & Economic Growth\n\n\n\n\n\n\n\n\n\n\n\nNov 6, 2025\n\n\nTom Cunningham\n\n\n\n\n\n\n\n\n\n\n\nEconomics and Transformative AI\n\n\n\n\n\n\n\n\n\n\n\nOct 2, 2025\n\n\nTom Cunningham\n\n\n\n\n\n\n\n\n\n\n\nOn Deriving Things\n\n\n\n\n\n\n\n\n\n\n\nJan 30, 2025\n\n\nTom Cunningham\n\n\n\n\n\n\n\n\n\n\n\nToo Much Good News is Bad News\n\n\n\n\n\n\n\n\n\n\n\nDec 26, 2024\n\n\nTom Cunningham\n\n\n\n\n\n\n\n\n\n\n\nPremature Optimization and the Valley of Confusion\n\n\n\n\n\n\n\n\n\n\n\nMay 10, 2024\n\n\nTom Cunningham\n\n\n\n\n\n\n\n\n\n\n\nPeer Effects, Culture, and Taxes\n\n\n\n\n\n\n\n\n\n\n\nApr 28, 2024\n\n\nTom Cunningham\n\n\n\n\n\n\n\n\n\n\n\nBloodhounds and Bulldogs\n\n\nOn Perception, Judgment, & Decision-Making\n\n\n\n\n\n\n\n\nApr 27, 2024\n\n\nTom Cunningham\n\n\n\n\n\n\n\n\n\n\n\nThe Influence of AI on Content Moderation and Communication\n\n\n\n\n\n\n\n\n\n\n\nDec 11, 2023\n\n\nTom Cunningham\n\n\n\n\n\n\n\n\n\n\n\nThe History of Automated Text Moderation\n\n\n\n\n\n\n\n\n\n\n\nNov 18, 2023\n\n\nIntegrity Institute collaborators: Alex Rosenblatt, Jeff Allen, Ejona Varangu, Dave Sullivan, Tom Cunningham\n\n\n\n\n\n\n\n\n\n\n\nThinking About Tradeoffs? Draw an Ellipse\n\n\n\n\n\n\n\n\n\n\n\nOct 25, 2023\n\n\nTom Cunningham, OpenAI.\n\n\n\n\n\n\n\n\n\n\n\nExperiment Interpretation and Extrapolation\n\n\n\n\n\n\n\n\n\n\n\nOct 17, 2023\n\n\nTom Cunningham\n\n\n\n\n\n\n\n\n\n\n\nAn AI Which Imitates Humans Can Beat Humans\n\n\n\n\n\n\n\n\n\n\n\nOct 6, 2023\n\n\nTom Cunningham\n\n\n\n\n\n\n\n\n\n\n\nSushi-Roll Model of Online Media\n\n\nPreviously: “pizza model”, “salami model”\n\n\n\n\n\n\n\n\nSep 8, 2023\n\n\nTom Cunningham, Integrity Institute\n\n\n\n\n\n\n\n\n\n\n\nHow Much has Social Media affected Polarization?\n\n\n\n\n\n\n\n\n\n\n\nAug 7, 2023\n\n\nTom Cunningham, Integrity Institute\n\n\n\n\n\n\n\n\n\n\n\nThe Paradox of Small Effects\n\n\n\n\n\n\n\n\n\n\n\nAug 2, 2023\n\n\nTom Cunningham, Integrity Institute\n\n\n\n\n\n\n\n\n\n\n\nRanking by Engagement\n\n\n\n\n\n\n\n\n\n\n\nMay 8, 2023\n\n\nTom Cunningham\n\n\n\n\n\n\n\n\n\n\n\nSocial Media Suspensions of Prominent Accounts\n\n\n\n\n\n\n\n\n\n\n\nJan 31, 2023\n\n\nTom Cunningham\n\n\n\n\n\n\n\n\n\n\n\nOptimal Coronavirus Policy Should be Front-Loaded\n\n\n\n\n\n\n\n\n\n\n\nApr 5, 2020\n\n\n\n\n\n\n\n\n\n\n\nOn Unconscious Influences (Part 1)\n\n\n\n\n\n\n\n\n\n\n\nDec 8, 2017\n\n\n\n\n\n\n\n\n\n\n\nThe Work of Art in the Age of Mechanical Production\n\n\n\n\n\n\n\n\n\n\n\nSep 27, 2017\n\n\n\n\n\n\n\n\n\n\n\nRepulsion from the Prior\n\n\n\n\n\n\n\n\n\n\n\nMay 26, 2017\n\n\n\n\n\n\n\n\n\n\n\nThe Repeated Failure of Laws of Behaviour\n\n\n\n\n\n\n\n\n\n\n\nApr 15, 2017\n\n\nTom Cunningham\n\n\n\n\n\n\n\n\n\n\n\nEconomist Explorers\n\n\n\n\n\n\n\n\n\n\n\nFeb 25, 2017\n\n\n\n\n\n\n\n\n\n\n\nSamuelson & Expected Utility\n\n\n\n\n\n\n\n\n\n\n\nFeb 25, 2017\n\n\n\n\n\n\n\n\n\n\n\nWeber’s Law Doesn’t Imply Concave Representations or Concave Judgments\n\n\n\n\n\n\n\n\n\n\n\nFeb 25, 2017\n\n\n\n\n\n\n\n\n\n\n\nRelative Thinking\n\n\n\n\n\n\n\n\n\n\n\nApr 30, 2016\n\n\nTom Cunningham\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2025-10-19-forecasts-of-AI-growth.html",
    "href": "posts/2025-10-19-forecasts-of-AI-growth.html",
    "title": "Forecasts of AI & Economic Growth",
    "section": "",
    "text": "Validation Checks\n\nOverall: ⚠️ Warning\n\n✅ [35/35] Cited sources exist in posts/ai.bib (programmatic)\n✅ [25/25] Table rows have required fields (programmatic)\n✅ [25/25] QMD quotes match posts/ai.bib (programmatic)\n✅ [25/25] QMD growth values match posts/ai.bib (programmatic)\n⚠️ [33/35] Abstracts present for all cited sources (programmatic)\n❌ [15/18] Bib quotes present in local fulltext version (programmatic)\n\nLast checked: 2026-02-20"
  },
  {
    "objectID": "posts/2025-10-19-forecasts-of-AI-growth.html#footnotes",
    "href": "posts/2025-10-19-forecasts-of-AI-growth.html#footnotes",
    "title": "Forecasts of AI & Economic Growth",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nI classified Epoch’s GATE model (Erdil et al. (2025)) as by “AI people”, though the authors are a mixture of academic economists and people who work in AI.↩︎\nIt seems to me quite plausible that these papers over-estimate the productivity impact of existing LLMs: (1) the AB tests showing productivity improvements are on unrepresentatively self-contained tasks and are likely distorted by publication selection; (2) the Eloundou et al. (2023) estimates of very large time-savings from GPT-4 are based just on intuitions.↩︎\nComin and Mestieri (2014) say “the average adoption lag across all technologies (and countries) is 44 years,” but since the 1950s it has been 7-18 years.↩︎\n“Between 1 and 5% of all work hours are currently assisted by generative AI, and respondents report time savings equivalent to 1.4% of total work hours. … implies a potential productivity gain of 1.1%.”↩︎\nSuppose the total valuation of AI-related companies is $10T, which is perhaps around 10% of all capital stock. Using P/E of 15, a $10T valuation implies a stream of $600B in earnings/year, which is 2% of GDP.↩︎"
  },
  {
    "objectID": "posts/2025-12-30-llm-verification.html",
    "href": "posts/2025-12-30-llm-verification.html",
    "title": "LLM verification",
    "section": "",
    "text": "A prediction: people will move towards producing documents that are machine-verified. A document will come with a checklist so you can see that it satisfies certain properties, as verified by LLMs:\n\n\n\n\n\nClaude\nGemini\nGPT\n\n\n\n\nFactual claims are accurate\n✅\n✅\n✅\n\n\nLogically consistent\n✅\n✅\n✅\n\n\nCentral idea is novel\n✅\n✅\n✅\n\n\nThe writing is readable\n✅\n✅\n✅\n\n\n\n\nIf your blog post starts with this checklist I’ll be more likely to read it.\nThis is already happening for mathematicians and programmers: they verify LLM-produced proofs with a formal verification tool (e.g. Lean), and LLM-produced code with unit tests. I’m predicting that this pattern will spread to all other areas of knowledge work, as LLMs get better at verifying correctness.\n\nNotes\n\nA corollary: there’s a magic prompt.\n\nInstead of saying “answer question Q”, it’s better to say “answer question Q, and give me a way of verifying that the answer is correct.”\nYou want the LLM to give you a checklist like the one above, decomposing the verification into many subproblems. Programmers have learnt to prompt “write a program to do P, and a set of tests to verify that it does P.”\n\nExamples of criteria you want to check:\n\n\nAn infection prevention plan: verify that the plan is consistent with the relevant protocols.\nA tax return: verify that each of the IRS rules are satisfied.\nA legal memo: verify that citations are accurate.\nAn insurance claim: verify that the claim answers all relevant questions.\nAn insurance decision: verify that the decision is consistent with close precedents.\n\n\nAn analogy with two friends.\n\nYou have one friend who is full of new ideas, you have another friend who can tell whether an idea is good or bad. Each friend is somewhat useful, but when you combine them they’re amazing. (I think this is the case for mathematicians: LLMs will produce a fountain of proofs, and Lean can distinguish which are sound or unsound).\n\nImplication: credentials become less important.\n\nMany people are saying that LLMs will make credentials more important, because they make it harder to superficially distinguish high-quality and low-quality work. Ryan Briggs says:\n\n“Prediction: in the short-to-medium term LLMs will make the reputation of the researcher matter more for whether or not we view results as credible because it will become too hard to read everything and people will want shortcuts for filtering. Again, this hits juniors hardest.”\n\nIt’s possible this is true but there’s a countervailing force: LLMs are better paper-writers, but also better referees. In fact they may be relatively better referees than they are authors, which would shift balance in favor of the less-credentialed. If we had a perfect test for the quality of work, we wouldn’t need to rely on reputation at all.\nIf someone entirely unqualified makes a breakthrough in ML or mathematics they can verify it. Historically this has been much harder in soft disciplines like economics, but if the cost of verification falls to zero.\nA related point: in an old post on AI and communication I argued that with LLMs reputation will become less important for internal properties (where the ground truth is human judgment, i.e. verification is cheap), more important for external properties (where the ground truth is in the world, i.e. verification is expensive).\n\n\n\n\nA More Precise Story\n\nDifferent domains have different costs of verification:\n\nCheap to verify: whether an image looks good, whether a joke is funny, whether a sudoku solution is valid, whether a formalized proof is sound, whether code passes a specific test.\nCostly to verify: whether a medical paper works, whether an academic paper is high quality, whether a human-written proof is sound, whether code fulfills a specification.\n\nLLM-verification will be a big benefit in domains where it’s costly to verify.\nThere is a complementarity between LLM-generation and LLM-verification, the value of both is more than the sum of the value of each.\nWhen doing LLM-generation it’s useful to ask the LLM to self-verify. E.g. by (1) generating a Lean proof and validating it; (2) generating unit tests and running them; (3) generating a checklist and asking an independent LLM to check each box.\nLLM-generation can hurt communication equilibria where verification is costly, when LLM generation lowers the cost of accidental attributes (not essential attributes). E.g. if LLMs make it cheap to fix spelling errors, or to adopt idioms of the discipline, then there will be less separation in equilibrium.\n\n\n\nFormal Models\nA couple of very hasty models to sketch how to formalize this. It would be nice to have a single model which incorporates all the mechanisms above.\n\nModel 1: quality vs polish.\n\nSuppose you care just about intrinsic quality \\(q\\), but your signal is \\[s=q+p\\] where \\(p\\) is polish. You know that \\(q\\) and \\(p\\) are positively correlated (better books have better covers), so \\(s\\) is a highly reliable signa of quality.\nSuppose LLMs lower the cost of polish, so now everyone has high \\(p\\). This makes the signal-extraction problem worse, and you’ll rely relatively more on another signal, e.g. the author’s reputation (assuming it’s another signal correlated with \\(q\\)).\nSuppose instead that LLMs lower the cost of directly observing quality \\(q\\). This will then imply putting relatively less weight on the author’s reputation.\nImplications:\n\nLLMs lowering the cost of polish will cause more weight to be put on reputation.\nLLMs lowering the cost of verification will cause less weight to be put on reputation.\n\n\nModel 2: search.\n\nYou have \\(N\\) ideas with unobserved iid payoffs, and you can pay cost \\(c\\) to find the true payoff (AKA Weitzmann’s Pandora’s box problem).\nClaim: there’s a complementarity between the number of ideas you have (\\(N\\)) and the cheapness of verification (inverse of \\(c\\)). Formally:\n\\[\\begin{aligned}\n  V_n(c)   & =\\int_{0}^{\\sigma(c)} \\big(1-F(t)^n\\big)dt,\n     && \\text{(expected value from optimal strategy)}\\\\\n  E[(X-\\sigma)^+] &= c && \\text{(implicit definition of $\\sigma(c)$)}\n\\end{aligned}\\]\nFrom inspection we can see that the expression has a complementarity between \\(c\\) and \\(n\\)."
  },
  {
    "objectID": "posts/2026-01-29-knowledge-creating-llms.html",
    "href": "posts/2026-01-29-knowledge-creating-llms.html",
    "title": "Knowledge-Creating LLMs",
    "section": "",
    "text": "Thanks to Zoë Hitzig & Parker Whitfill, among others, for helpful comments."
  },
  {
    "objectID": "posts/2026-01-29-knowledge-creating-llms.html#footnotes",
    "href": "posts/2026-01-29-knowledge-creating-llms.html#footnotes",
    "title": "Knowledge-Creating LLMs",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nMany other technologies share knowledge – speaking, writing, printing, the internet – LLMs just continue this progression but further lower the costs of sharing.↩︎"
  },
  {
    "objectID": "posts/2026-02-14-tech-progress-dashboard.llm.html",
    "href": "posts/2026-02-14-tech-progress-dashboard.llm.html",
    "title": "Technical Progress Dashboard for AI Impact Tracking",
    "section": "",
    "text": "This dashboard tracks multi-domain technical progress (with emphasis on AI/ML and optimization) using a unified long-format panel, provenance metadata, and per-series log-linear trend fits. The rendered chart reads window.TPD_DATA from a generated local bundle so updates are reproducible and pipeline-driven."
  },
  {
    "objectID": "posts/2026-02-14-tech-progress-dashboard.llm.html#overview",
    "href": "posts/2026-02-14-tech-progress-dashboard.llm.html#overview",
    "title": "Technical Progress Dashboard for AI Impact Tracking",
    "section": "",
    "text": "This dashboard tracks multi-domain technical progress (with emphasis on AI/ML and optimization) using a unified long-format panel, provenance metadata, and per-series log-linear trend fits. The rendered chart reads window.TPD_DATA from a generated local bundle so updates are reproducible and pipeline-driven."
  },
  {
    "objectID": "posts/2026-02-14-tech-progress-dashboard.llm.html#data-flow",
    "href": "posts/2026-02-14-tech-progress-dashboard.llm.html#data-flow",
    "title": "Technical Progress Dashboard for AI Impact Tracking",
    "section": "Data flow",
    "text": "Data flow\n\n\n\n\n\nflowchart TD\n  A[\"seed-series.llm.csv&lt;br/&gt;manual + curated seed rows\"] --&gt; B[\"ingest_tech_progress_dashboard.py\"]\n  R[\"raw/*.csv&lt;br/&gt;downloaded source extracts\"] --&gt; B\n  E[\"derived AI/ML trend indexes&lt;br/&gt;(Epoch growth-rate based)\"] --&gt; B\n  B --&gt; C[\"normalized-series.llm.csv&lt;br/&gt;canonical long-format panel\"]\n  B --&gt; D[\"tpd-data.llm.js&lt;br/&gt;window.TPD_DATA bundle\"]\n  B --&gt; L[\"ingest-log.llm.md\"]\n  D --&gt; Q[\"2026-02-14-tech-progress-dashboard.llm.qmd\"]\n  Q --&gt; V[\"Interactive Plotly dashboard + provenance table\"]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDomain \n\n\nMetric type \n\n\nFrontier scope  Frontier only Frontier + informative average Average only \nY-value mode  Indexed (first visible year = 1) Raw values \nY-axis scale  Log scale Linear scale \n\n\nStart year \nEnd year \nMin points per series \n\n\nSeries name filter \n  Show log-linear trend fit"
  },
  {
    "objectID": "posts/2026-02-14-tech-progress-dashboard.llm.html#provenance-visible-series",
    "href": "posts/2026-02-14-tech-progress-dashboard.llm.html#provenance-visible-series",
    "title": "Technical Progress Dashboard for AI Impact Tracking",
    "section": "Provenance (visible series)",
    "text": "Provenance (visible series)\n\n\n\n\nSeries\n\n\nDomain\n\n\nType\n\n\nFrontier class\n\n\nDirection (displayed)\n\n\nPoints shown\n\n\nSource\n\n\nProvenance note"
  },
  {
    "objectID": "posts/2026-02-14-tech-progress-dashboard.llm.html#notes-on-data-quality",
    "href": "posts/2026-02-14-tech-progress-dashboard.llm.html#notes-on-data-quality",
    "title": "Technical Progress Dashboard for AI Impact Tracking",
    "section": "Notes on data quality",
    "text": "Notes on data quality\n\nDashboard data is generated via tools/ingest_tech_progress_dashboard.py from canonical seed + derived series.\nAI/ML trend-index series sourced from Epoch growth-rate statements are model-based derived indexes (not raw point extracts).\nSeveral frontier series remain seed-level and should be replaced with direct machine-readable source pulls over time.\nAll displayed series are transformed to lower-is-better (1/value for originally higher-is-better metrics).\nBecause units differ across technologies, indexed mode is the main comparison mode.\n\nThis dashboard is built to support forecasting and measuring AI’s impact on technological progress using a frontier-first lens."
  },
  {
    "objectID": "posts/2026-02-14-tech-progress-dashboard.llm.html#scope-choices",
    "href": "posts/2026-02-14-tech-progress-dashboard.llm.html#scope-choices",
    "title": "Technical Progress Dashboard for AI Impact Tracking",
    "section": "Scope choices",
    "text": "Scope choices\n\nGoal: support forecasting and monitoring of AI-driven acceleration in technical efficiency trends.\nIncluded domains: compute hardware, compute storage, energy, energy storage, biotech, agriculture, AI/ML, optimization algorithms, compression, and communications channels.\nIncluded metric classes: cost efficiency, physical productivity, energy efficiency, training-scale indexes, algorithmic speed, compression efficiency, and channel efficiency.\nFrontier rule: include frontier series by default; include average series when they are informative or frontier data is sparse.\nData inclusion threshold: at least 4 time points, direction-of-improvement defined, source URL recorded.\nFitting method: per-series log-linear fit on historical data (log(value) = a + b * year).\nv1 excludes causal attribution and forecasting beyond observed history.\nData refresh path: rerun python tools/ingest_tech_progress_dashboard.py to regenerate normalized CSV, JS bundle, and ingestion log."
  }
]