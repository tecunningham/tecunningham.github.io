{
  "hash": "5b29055b9dce1cd2703c3cd52df372af",
  "result": {
    "markdown": "---\ntitle: Thinking About Tradeoffs? Draw an Ellipse\nauthor: Tom Cunningham, OpenAI.\nexecute:\n   echo: false\n   cache: true # caches chunk output\n   warning: false\n   error: false\ndate: 2023-10-25\nupdated: 2024-05-25\nengine: knitr\nreference-location: margin\nfigure-location: margin\nformat:\n   html:\n      toc: true\n      toc-depth: 2\n      toc-location: left\n      code-tools:\n         source: true\n   revealjs:\n      fig-width: 2\n      font-size: 12\n---\n\n<style>\n    h1 {  border-bottom: 4px solid black;  }\n    h2 {  border-bottom: 1px solid #ccc;}\n    .reveal section p {\n      display: inline-block;\n      font-size: 2em;\n      #line-height: 1.2em;\n      #vertical-align: top;\n   }\n</style>\n\n<!-- See also: 2019-12-13-a-market-for-impact \n   TODO: state the implications about company strategy upfront\n   TODO: add a note about presenting at CODE\n   https://tecunningham.github.io/posts/2023-10-23-pareto-frontiers-experiments-ranking.html\n--> \n\n::: {.column-margin}\n   This material was first presented at MIT CODE 2021. Thanks to [Sean Taylor](https://www.linkedin.com/in/seanjtaylor/) among others for comments.\n:::\n\n<!-- Tweets\n\nNEW POST: Thinking about tradeoffs? draw an ellipse. With applications to (1) experiment launch rules; (2) ranking weights in a recommender; and (3) allocating headcount in a company.\n\nChoosing launch criteria? You can think of the set of experiments as pairs (ΔX,ΔY) from some joint distribution, and if additive it's easy to calculate the Pareto frontier, and if (ΔX,ΔY) are Gaussian then the Pareto frontier is an ellipse.\n\nChoosing ranking weights? You can think of the set of classifier scores (pClick,pRetweet) as drawn from a distribution, and if additive it's easy to calculate the Pareto frontier, and if Gaussian then the Pareto frontier is an ellipse.\n\nChoosing headcount? Increasing headcount on a team will shift out the Pareto frontier of a team, and so you can then sketch out the *combined* Pareto frontier across metrics as you reallocate headcount.\n-->\n\n**Thinking about tradeoffs? draw an ellipse.** When making a tradeoff between two outcomes, $X$ and $Y$, it's useful to sketch out what the tradeoff looks like, and an ellipse is often a good first-order approximation. The ellipse helps visualize the most interesting parameter: the *tightness*, i.e. how much the rate of tradeoff between $X$ and $Y$ varies as you increase $X$.\n\nIn addition we can show that if the Pareto frontier is formed by the sum of vectors, and the vectors are drawn from a joint Normal distribution, then the expected frontier will be exactly an ellipse.\n\n**Concrete Applications:**\n\n1. **Choosing launch criteria? draw an ellipse.** Suppose you have a set of features each of which has some metric impact, $\\Delta X$ and $\\Delta Y$. If we assume that the effects are additive then we can construct a Pareto frontier, i.e. a set of all the aggregate effects on $\\Delta X$ and $\\Delta Y$ achievable by selection from the set of features. The frontier will typically look like an ellipse. You can prove that the Pareto frontier will be exactly an ellipse if the set of experiment-effects have a joint Normal distribution.\n\n2. **Choosing ranking weights? draw an ellipse.** Suppose you are ranking items for a user using a set of features e.g. p(Like), p(Comment), etc. It is useful to sketch out the Pareto frontier, i.e. the set of outcomes achievable by different ranking algorithms. If the outcomes are additively separable functions of the item-features, and if the joint distribution of features is Normal, then the Pareto frontier will be an ellipse.\n\n3. **Allocating headcount? draw an ellipse.** When you shuffle headcount around a company it's hard to precisely measure the impact on different goals, however I have found it useful to sketch ellipses to make explicit the tradeoffs  you face. This is particularly useful for visualizing the differences between within-team vs between-team reallocation of effort.\n\n#                    Tight and Loose Tradeoffs\n\n\n\n::: {.cell .column-margin hash='2023-10-23-pareto-frontiers-experiments-ranking_cache/html/unnamed-chunk-1_4bb7e47c4ed41520e4c5aeae8fd12fce'}\n::: {.cell-output-display}\n![](2023-10-23-pareto-frontiers-experiments-ranking_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n:::\n\n::: {.cell .column-margin hash='2023-10-23-pareto-frontiers-experiments-ranking_cache/html/unnamed-chunk-2_48508bdd7f3e3c96af1e87a67367dc69'}\n::: {.cell-output-display}\n![](2023-10-23-pareto-frontiers-experiments-ranking_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\n**Suppose we care about two metrics, $X$ and $Y$.** E.g. suppose we care about DAU and time-spent, or revenue and retention, or engagement and misinformation.\n\n**It is useful to draw a Pareto frontier.** A Pareto frontier will show the set of achievable outcomes for X and Y, to make the tradeoff precise. If we have a well-defined objective function then we can visually represent the optimal choice where the indifference curve is tangent to the Pareto frontier.\n\n**If your frontier is \"tight\" then there is not much tradeoff.** The first figure shows a tight frontier, meaning that there is not much tradeoff available between X and Y. With a tight tradeoff it doesn't matter whether we maximize X or Y or a weighted average, we'll end up in roughly the same place anyway. Suppose we are choosing among experiments: if we observe a high positive correlation between $\\Delta X$ and $\\Delta Y$ then the choice of shipping criteria is relatively unimportant, most criteria would select the same experiments anyway. Suppose instead we are calibrating a recommender system: if we observe a high positive correlation between predictions of the two outcomes then the choice of weights is relatively unimportant, we would end up showing the same items anyway.\n\n**If your frontier is \"loose\" then there is a lot of tradeoff.** The second figure shows a loose tradeoff: in this case the outcome does depend substantially on the relative weight we put on $X$ and $Y$. \n\n\n\n#                Ellipses for Experiments\n\n\n\n::: {.cell .column-margin hash='2023-10-23-pareto-frontiers-experiments-ranking_cache/html/unnamed-chunk-3_58fce7016551619d2ab1f7892a1f0e4c'}\n::: {.cell-output-display}\n![](2023-10-23-pareto-frontiers-experiments-ranking_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n**Suppose we have a set of experiments.** Each experiment has some impact on two metrics, $\\Delta X$ and $\\Delta Y$. We visualize such a set of experiments at right.\n\nIf the set of features is *separable*, meaning that the impact of each feature is independent of what other features are launched, then a natural question will be the shape of the Pareto frontier formed by all possible combination of experiments.\n\nIf the distribution of experiments is mean zero and joint Normal then the Pareto frontier will be an *ellipse*, and it will have exactly the shape of an isovalue of the density of experiments. Thus knowing the variance and covariance of experiment results allows us to characterize the nature of the Pareto frontier we face.\n\n\n\n#                Ellipses for Ranking\n\n\n::: {.cell .column-margin hash='2023-10-23-pareto-frontiers-experiments-ranking_cache/html/unnamed-chunk-4_892222e0d622229a23671a8240941df9'}\n::: {.cell-output-display}\n![](2023-10-23-pareto-frontiers-experiments-ranking_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n\n**Suppose we are choosing a fixed set of items to show to a user, based on two metrics $x_1$ and $x_2$.** E.g. `pLike` and `pComment`, or `pDAU` and `quality` etc.  A natural question will be the shape of the Pareto frontier formed by alternative selections of items. \n\n**The Pareto frontier will be an ellipse.** We show below that, if the predictions are well calibrated, the outcomes are independent (i.e. additive), and the distribution of prediction obeys a joint Normal distribution, then the Pareto frontier will be an ellipse and it will have exactly the shape of an isovalue of the density of predictions.  Thus knowing the variance and covariance of predictions allows us to exactly characterize the nature of the aggregate tradeoffs we face.\n\n#              Ellipses for Company Strategy\n\n\n**Tradeoffs are looser higher in the decision hierarchy.** Suppose a company cares about two outcomes, $X$ and $Y$. Many different people will be making tradeoff decisions between X and Y, we can distinguish between four objectives used at different levels in the company hierarchy:\n   $$\\substack{\\text{company objective}\\\\\\text{(choose headcount)}}\n      > \\substack{\\text{team objective}\\\\\\text{(choose projects)}}\n      > \\substack{\\text{shipping objective}\\\\\\text{(choose experiments)}}\n      > \\substack{\\text{algorithm objective}\\\\\\text{(choose items)}}\n      $$\n\nWe can think of each successive level as holding more variables fixed, and so we expect the Pareto frontiers to become successively tighter (Le Chatelier principle). We thus expect the tradeoff to be loosest at the level of overall company objectives, where we reallocate headcount. For this reason we should expect that, if the company as a whole pivots form metric $X$ to metric $Y$, the principal effect will be a reallocation of effort *between* products rather than reallocation *within* products.\n\nWe now walk through some of the different levels of optimization:\n\n\n\n::: {.cell .column-margin hash='2023-10-23-pareto-frontiers-experiments-ranking_cache/html/unnamed-chunk-5_388a7f2862c721051ab6f7ad2d60f448'}\n::: {.cell-output-display}\n![](2023-10-23-pareto-frontiers-experiments-ranking_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n**Different product areas have different Pareto frontiers.** Typically two different product areas will have substantially different ability to affect different metrics, and we will often observe a situation like that shown on the right: team A's choices primarily affect metric $X$, team B's choices primarily affect metric $Y$.\n\n<br /><br /><br />\n\n\n::: {.cell .column-margin hash='2023-10-23-pareto-frontiers-experiments-ranking_cache/html/unnamed-chunk-6_e37db323a9db1d4dbce81ffd97af014a'}\n::: {.cell-output-display}\n![](2023-10-23-pareto-frontiers-experiments-ranking_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n**We can also draw a *combined* Pareto frontier.** Here we add up the Pareto frontiers of team A and B. In this case the combined frontier is somewhat tight, because the two constituent frontiers are tight. Neither individual Pareto frontier shows a substantial effect from changing weights (if we restrict weights to be positive), and so accordingly the combined Pareto frontier shows little response to a change in weights.\n\nNote that I have drawn the frontier only approximately, the frontier achieved by combining two ellipses does not have a simple representation. When the two constituent frontiers are straight lines then the combination will be a parallelogram. (Note also that when the two frontiers are circles then the combination will be a circle).\n\n<!-- \\marginnote{\\begin{tikzpicture}[scale=3]\n   \\draw (0,1) -- node[rotate=90,above] {$\\Delta$Y} (0,0)\n      -- node[below] {$\\Delta$X}(1,0) -- (1,1)  -- (0,1);\n   \\begin{scope}\n    \\clip(0,0) rectangle (1,1);\n    \\draw[color=red, dashed] (0,0) circle[x radius=.7, y radius=.05, rotate=80];\n    \\draw[color=blue, dashed] (0,0) circle[x radius=.7, y radius=.05, rotate=10];\n    \\draw[color=red, line width=2] (0,0) circle[x radius=.7, y radius=.1, rotate=80];\n    \\draw[color=blue, line width=2] (0,0) circle[x radius=.7, y radius=.1, rotate=10];\n   \\end{scope}\n   \\node at (.5,.25) {team A};\n   \\node at (.3,.8) {team B};\n\\end{tikzpicture}}\n**Pareto frontiers will expand if we allow for investment in different features.** Suppose we do not take the set of existing features as given (i.e. those chosen under the current weights) but instead allow a team to work on alternative features. Then we should expect a somewhat broader set of tradeoffs, i.e. the Pareto frontiers should expand. This reflects investing in new ideas: e.g. team A could come up with features that would have a larger-than-usual impact on Y, and team B might come up with features that would have a larger-than-usual impact on X. -->\n\n\n\n::: {.cell .column-margin hash='2023-10-23-pareto-frontiers-experiments-ranking_cache/html/unnamed-chunk-7_78f65e5d3fc6061482728ed58021bfb8'}\n::: {.cell-output-display}\n![](2023-10-23-pareto-frontiers-experiments-ranking_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n**Greater investment will shift Pareto frontiers out.** Here we visualize reallocating employees from team B (the frontier shifts in) to team A (the frontier shifts out).\n\n\n<br /><br /><br /><br /><br /><br /><br /><br />\n\n\n::: {.cell .column-margin hash='2023-10-23-pareto-frontiers-experiments-ranking_cache/html/unnamed-chunk-8_af7a2ac6d9570600948403f809aee92c'}\n::: {.cell-output-display}\n![](2023-10-23-pareto-frontiers-experiments-ranking_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n**A combined company Pareto frontier will be loose.** Here the green curve represents all the possible outcomes as you shift resources between team A and B:  we have now turned a tight tradeoff into a loose tradeoff. In this case this represents that a change in company objectives will be reflected mainly in reallocation of effort *between* teams rather than *within* teams.\n\n<br /><br /><br /><br />\n\n\n\n\n#                 Appendix: Model for Normal Distributions\n\nSuppose we have a set of items with, $x_1$ and $x_2$, distributed Normally:\n   $$\\binom{x_1}{x_2}\\sim N\\left(\\binom{0}{0},\n      \\begin{pmatrix}\\sigma_1^2 & \\rho\\sigma_1\\sigma_2 \\\\ \\rho\\sigma_1\\sigma_2 & \\sigma_2^2\\end{pmatrix}\\right).$$\n\nWe additionally let each item have a *score*, $v$, which is simply a weighted sum of the two characteristics (normalizing the weight on the first characteristic to be 1):\n   $$v=x_1 + wx_2.$$\n\nWe can write the covariance between the characteristics and the score as follows:\n\n$$Cov\\begin{bmatrix}x_1\\\\x_2\\\\v\\end{bmatrix}=\n \\begin{bmatrix}\n    \\sigma^2_1           & \\sigma_1\\sigma_2\\rho & \\sigma_1^2+ w\\rho\\sigma_1\\sigma_2 \\\\\n    \\sigma_1\\sigma_2\\rho &  \\sigma_2^2          & \\rho\\sigma_1\\sigma_2+w\\sigma_2^2 \\\\\n    \\sigma_1^2+w\\rho\\sigma_1\\sigma_2          &\n          \\rho\\sigma_1\\sigma_2+w\\sigma_2^2    &\n          \\sigma_1^2+w^2\\sigma_2^2 + 2\\rho w\\sigma_1\\sigma_2 \\\\\n \\end{bmatrix}$$\n\nWe wish to know the total number of actions of each type, $X_1$ and $X_2$, for a given score threshold $\\bar{v}$:\n\n$$\\begin{aligned}\n   X_1   &=P(v\\geq \\bar{v})E[x_1|v\\geq \\bar{v}] \\\\\n   X_2   &=P(v\\geq \\bar{v})E[x_2|v\\geq \\bar{v}].\n\\end{aligned}$$\n\nWe first calculate the conditional expectations:\n\n$$\\begin{aligned}\n E[x_1|v\\geq \\bar{v}]\n   =& \\sigma_1 \\frac{Cov(x_1,v)}{\\sqrt{Var(x_1)Var(v)}}\n      \\frac{\\phi(\\frac{\\bar{v}}{\\sqrt{Var(v)}})}{\\Phi(\\frac{\\bar{v}}{\\sqrt{Var(v)}})} \\\\\n   =& \\sigma_1\n      \\frac{\\sigma_1^2+w\\rho\\sigma_1\\sigma_2}\n         {\\sqrt{\\sigma_1^2(\\sigma_1^2+w^2\\sigma_2^2 + 2\\rho w\\sigma_1\\sigma_2)}}\n      \\frac{\\phi(\\frac{\\bar{v}}{\\sqrt{Var(v)}})}{\\Phi(\\frac{\\bar{v}}{\\sqrt{Var(v)}})}\\\\\n  =&  \\frac{\\sigma_1^2+w\\rho\\sigma_1\\sigma_2}\n           {\\sqrt{\\sigma_1^2+w^2\\sigma_2^2 + 2\\rho w\\sigma_1\\sigma_2}}\n   \\frac{\\phi(\\frac{\\bar{v}}{\\sqrt{Var(v)}})}{\\Phi(\\frac{\\bar{v}}{\\sqrt{Var(v)}})}\n\\end{aligned}$$\n\nNext we will assume that the expected quantity of items is fixed. This implies that both both $P(v\\geq \\bar{v})$ and $\\frac{\\bar{v}}{\\sqrt{Var(v)}}$ will be constant, and we will define: \n   $$\\begin{aligned}\n      \\gamma\\equiv\n         &\\frac{\\phi\\left(\\frac{\\bar{v}}{\\sqrt{Var(v)}}\\right)}\n            {\\Phi\\left(\\frac{\\bar{v}}{\\sqrt{Var(v)}}\\right)}P(v\\geq \\bar{v}) \\\\\n      X_1 =& \\frac{\\sigma_1^2+w\\rho\\sigma_1\\sigma_2}\n                  {\\sqrt{\\sigma_1^2+w^2\\sigma_2^2 + 2\\rho w\\sigma_1\\sigma_2}}\\gamma \\\\\n      X_2 =& \\frac{w\\sigma_2^2+\\rho\\sigma_1\\sigma_2}\n                  {\\sqrt{\\sigma_1^2+w^2\\sigma_2^2 + 2\\rho w\\sigma_1\\sigma_2}}\\gamma\n   \\end{aligned}$$\n\nWe thus have expressions for $X_1$ and $X_2$ as a function of the relative weight $w$. We wish to rearrange these to express $X_1$ directly in terms of $X_2$. To help we turn to Mathematica, with the following input:^[[see notebook](https://www.wolframcloud.com/env/tomcunningham/Ellipses.nb)]\n\n```\nF1[w_,p_,s1_,s2_,g_]:=g(s1^2+w p s1 s2 )/Sqrt[s1^2+w^2 s2^2+2w p s1 s2]\nF2[w_,p_,s1_,s2_,g_]:=g(w s2^2 +p s1 s2)/Sqrt[s1^2+w^2 s2^2+2w p s1 s2]\nSolve[{X1==F1[w,p,s1,s2,g],X2==F2[w,p,s1,s2,g]}, {X1,w}]\nSimplify[First[%1]]\n```\n\nThis returns a large expression:\n\n$$\\begin{aligned}\n   X_1(X_2) &= \n      \\frac{\n         \\gamma^2 \\rho \\sigma_1 \\sigma_2^3 X_2\n         - p \\sigma_1 \\sigma_2 X_2^3\n         + \\gamma^3 \\sigma_2^4\n            \\sqrt{\\frac{-\\gamma^2 (-1 + p^2) \\sigma_1^2 \\sigma_2^2}{\\gamma^2 \\sigma_2^2 - X_2^2}} \n         - \\gamma \\sigma_2^2 X_2^2\n            \\sqrt{-\\frac{\\gamma^2 (-1 + p^2) \\sigma_1^2 \\sigma_2^2}{\\gamma^2 \\sigma_2^2 - X_2^2}} \n         + X_2 \\sqrt{(-1 + p^2) \\sigma_1^2 \\sigma_2^2 X_2^2 (-\\gamma^2 \\sigma_2^2 + X_2^2)}\n      }{\\gamma^2 \\sigma_2^4 - \\sigma_2^2 X_2^2}\\end{aligned}$$\n\nWe can however substantially simplify this:\n$$\\begin{aligned}\n   X_1 &= \\frac{\n         \\sigma_1\\sigma_2X_2 (\\gamma^2 \\rho \\sigma_2^2  - p X_2^2)\n         + \\gamma^2\\sigma_2^2(\\gamma^2 \\sigma_2^2-  X_2^2)\n            \\sqrt{-\\frac{(-1 + p^2) \\sigma_1^2 \\sigma_2^2}{\\gamma^2 \\sigma_2^2 - X_2^2}} \n         - X_2^2\\sigma_1\\sigma_2 \\sqrt{(p^2-1) (\\gamma^2 \\sigma_2^2-X_2^2)}\n      }{\\gamma^2 \\sigma_2^4 - \\sigma_2^2 X_2^2} \\\\\n   &= \\frac{\n         \\sigma_1\\sigma_2X_2 p(\\gamma^2 \\sigma_2^2  - X_2^2)\n         + \\gamma \\sigma_2^3\\sigma_1 \\gamma\n            \\sqrt{(p^2-1)(\\gamma^2 \\sigma_2^2 - X_2^2)} \n         - X_2^2\\sigma_1\\sigma_2 \\sqrt{(p^2-1) (\\gamma^2 \\sigma_2^2-X_2^2)}\n      }{\\sigma_2^2(\\gamma^2 \\sigma_2^2 - X_2^2)} \\\\\n   &= \\frac{\\sigma_1}{\\sigma_2}X_2p + \\frac{\n         \\sigma_1\\sigma_2(\\gamma^2\\sigma_2^2 - X_2^2 )\n            \\sqrt{(p^2-1) (X_2^2-\\gamma^2 \\sigma_2^2)}\n      }{\\sigma_2^2(\\gamma^2 \\sigma_2^2 - X_2^2)} \\\\\n   &= X_2 \\rho \\frac{\\sigma_1}{\\sigma_2}\n      +\\frac{\\sigma_1}{\\sigma_2}\\sqrt{(p^2-1) (X_2^2-\\gamma^2 \\sigma_2^2)}.\n\\end{aligned}$$\n\n\n::: {.cell .column-margin hash='2023-10-23-pareto-frontiers-experiments-ranking_cache/html/unnamed-chunk-9_26d4c4976c38a54dadcfd2f074fe4bde'}\n::: {.cell-output-display}\n![](2023-10-23-pareto-frontiers-experiments-ranking_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\nWe now wish to show that this curve is equal to an isovalue of the joint distribution of $x_1$ and $x_2$ (illustrated at right). We can write the isovalue of the joint Normal distribution of $(x_1,x_2)$ for any given $k$ as follows:^[From Bertsekas and Tsitsiklis (2002) \"Introduction to Probability\", [Section 4.7](http://athenasc.com/Bivariate-Normal.pdf)]\n\n   $$k = \\frac{x_1^2}{\\sigma_1^2}+\\frac{x_2^2}{\\sigma_2^2}-2\\rho\\frac{x_1x_2}{\\sigma_1\\sigma_2}.$$\n\nSolving this quadratic we can write:\n   $$\\begin{aligned}\n      x_1 &= x_2 \\rho \\frac{\\sigma_1}{\\sigma_2} \n               \\pm \\frac{\\sigma_1}{\\sigma_2}\\sqrt{-x_2^2+x_2^2\\rho^2+k\\sigma_2^2} \\\\\n         &= x_2 \\rho \\frac{\\sigma_1}{\\sigma_2} \n               \\pm \\frac{\\sigma_1}{\\sigma_2}\\sqrt{k\\sigma_2^2-(1-\\rho^2)x_2^2}.\n   \\end{aligned}$$\n\nWe can see that this will be identical to the relationship between $X_1$ and $X_2$ above when $k=\\frac{\\sigma_2^2}{\\sigma_1^2}(\\rho^2-1)\\gamma^2$.\n\n<!-- \n#                    Additional Material\n\n##          Using Pareto Frontiers for Launch Decisions\n\n\n##          Pareto Frontiers and Network Effects\n\n\n::: {.cell .column-margin hash='2023-10-23-pareto-frontiers-experiments-ranking_cache/html/unnamed-chunk-10_79aa4f975102cfc6ce9ff64bc2feace2'}\n::: {.cell-output-display}\n![](2023-10-23-pareto-frontiers-experiments-ranking_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n::: {.cell .column-margin hash='2023-10-23-pareto-frontiers-experiments-ranking_cache/html/unnamed-chunk-11_ef8e38dd5a57020727d50bf81b67399d'}\n::: {.cell-output-display}\n![](2023-10-23-pareto-frontiers-experiments-ranking_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n-->\n\n\n\n#                       Appendix: Simulations for Non-Normal Distributions\n\nIn this section I compare Pareto frontiers generated from different distribution of $(X,Y)$ from different joint distribution, and then draw the Pareto frontiers. We will see that in many cases the Pareto frontier looks roughly *elliptical* though not precisely an ellipse.\n\nThe left-hand plot shows the raw distribution, the right-hand plot shows the Pareto frontier.\n\nThe first plots confirm the analytical solution for Gaussian outcomes. \n\n\n::: {.cell hash='2023-10-23-pareto-frontiers-experiments-ranking_cache/html/unnamed-chunk-12_cbe88336236af4692543d07b6da73956'}\n\n:::\n\n\n**Joint normal with positive correlation, small set:**\n\n::: {.cell hash='2023-10-23-pareto-frontiers-experiments-ranking_cache/html/unnamed-chunk-13_af094d4496b894f90166127fc7a66b06'}\n::: {.cell-output-display}\n![](2023-10-23-pareto-frontiers-experiments-ranking_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\n\n**Joint normal with positive correlation:**\n\n::: {.cell hash='2023-10-23-pareto-frontiers-experiments-ranking_cache/html/unnamed-chunk-14_1d8b080979ab3d87ab202999b260634c'}\n::: {.cell-output-display}\n![](2023-10-23-pareto-frontiers-experiments-ranking_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\n**Independent Laplace:**\n\n::: {.cell hash='2023-10-23-pareto-frontiers-experiments-ranking_cache/html/unnamed-chunk-15_992b1187eb38be63e9a57e3ebd7ed9e9'}\n::: {.cell-output-display}\n![](2023-10-23-pareto-frontiers-experiments-ranking_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\n**Common Laplace factor with independent Gaussian noise:**\n\n::: {.cell hash='2023-10-23-pareto-frontiers-experiments-ranking_cache/html/unnamed-chunk-16_a041f44066be53ab6a18a6b91e92a598'}\n::: {.cell-output-display}\n![](2023-10-23-pareto-frontiers-experiments-ranking_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\n**Independent uniform:**\n\n::: {.cell hash='2023-10-23-pareto-frontiers-experiments-ranking_cache/html/unnamed-chunk-17_0c013aae559f2ce9769e38ae4e732f36'}\n::: {.cell-output-display}\n![](2023-10-23-pareto-frontiers-experiments-ranking_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n\n**Common uniform factor plus independent uniform noise:**\n\n::: {.cell hash='2023-10-23-pareto-frontiers-experiments-ranking_cache/html/unnamed-chunk-18_e0d22b850cef4010b585fd00abdce76b'}\n::: {.cell-output-display}\n![](2023-10-23-pareto-frontiers-experiments-ranking_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\n<!-- \n#### OLD\n# ### Eigenvalues from covariance matrix\n# # seems that ellipse should use *sqrt* of eigenvalues, as here:\n# # https://stats.stackexchange.com/questions/9898/how-to-plot-an-ellipse-from-eigenvalues-and-eigenvectors-in-r\n# eigen1 <- eigen(Sigma)$values[1]\n# eigen2 <- eigen(Sigma)$values[2]\n\n\n# ggplot(pareto, aes(x, y)) +\n#     geom_point(data = points, alpha = .1) +\n#     geom_density_2d(data = points) +\n#     geom_point(data = pareto, color = \"red\", alpha = 1) +\n#     geom_ellipse(aes(\n#         x0 = 0, y0 = 0,\n#         a = 2 * sqrt(eigen1),\n#         b = 2 * sqrt(eigen2),\n#         # angle = angle\n#         angle = 0\n#     ),\n#     color = \"green\"\n#     ) +\n#     coord_fixed() +\n#     xlim(-5, 5) +\n#     ylim(-5, 5)\n-->",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}