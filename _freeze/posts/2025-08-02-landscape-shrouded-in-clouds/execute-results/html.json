{
  "hash": "9c6c6ba09d694299ed5f2123b43cac73",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Landscape Shrouded in Clouds\nauthor: Tom Cunningham\ncitation: true\n# date: 2025-08-02\n# date-modified: last-modified\nfig-align: center\nfig-height: 1\ndraft: true\nbibliography: ai.bib\nreference-location: document\n# reference-location: margin\nengine: knitr\nformat:\n   html\n      # toc: true\n      # toc-depth: 2\n      # toc-location: left\neditor:\n  render-on-save: true\n---\n\n\n<style>\n   h1 {  border-bottom: 4px solid black; }\n   h2 {  border-bottom: 1px solid gray; padding-bottom: 0px; color: black; }\n   dl {display: grid;}\n   dt {grid-column-start: 1; width: 4cm;}\n   dd {grid-column-start: 2; margin-left: 2em;}\n</style>\n\n#        New Introduction\n\n\n\n\n::: {.cell .column-margin}\n::: {.cell-output-display}\n![**Random landscape.** Here there's no structure: every $x$ is an independent random draw.](2025-08-02-landscape-shrouded-in-clouds_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n:::\n\n\n\nThe effect of AI on innovation will depend on the shape of the landscape.\n: It seems like AI ought to dramatically accelerate innovation, but many people argue that we will be constrained by our physical ability to *test* any new ideas, e.g. we need GPUs to test new algorithms, we need labs and studies to test new drugs.\n\n      Here's a nice observation: the value of AI depends on the shape of the innovation landscape. If the landscape is random then AI won't help at all, if the landscape has latent structure then AI will help a great deal.\n\n\n\n\n::: {.cell .column-margin}\n::: {.cell-output-display}\n![**Rugged landscape.** This shows a Weiner process (random walk). Here there's local correlation but no long-distance dependence.](2025-08-02-landscape-shrouded-in-clouds_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n::: {.cell .column-margin}\n::: {.cell-output-display}\n![**Regular landscape.** Here there's some latent structure, implying that you can make long-distance predictions from local observations.](2025-08-02-landscape-shrouded-in-clouds_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n\nThree types of landscape.\n: Suppose each period we choose an $x$ to minimize $y(x)$, where $y(\\cdot)$ is unknown. This is a well-defined explore-exploit problem, and we can characterize the expected progression of efficiency over time (the decline in $y(.)$ over time) as a function of the statistical structure of the landscape:\n   \n      1. **Random landscape:** If each $y(x)$ is completely independent there's no intelligence needed in choosing $x$ (beyond keeping track of which locations you've already tried). The growth in efficiency as a function of $N$ draws depends on the distribution of values of $y$ (Muth, 1986).\n      2. **Rugged landscape:** If $y(x)$ is correlated across $x$ but the correlation is local (e.g. if $y(x)$ is a Weiner process) then the best-estimate of $y(x)$ for a new $x$ will depend only on the neighboring values of $x$. Callander (2011) and Carnehl & Schneider (2025) characterize the optimal strategy. Again we are not constrained on intelligence: the extrapolation algorithm is fairly simple.\n      3. **Regular landscape:** Finally suppose the landscape has some deep latent structure. In this case the best-estimate of $y(x)$ will depend on the entire collection of previously-observed pairs $(x,y)$, and so we *do* expect that predictions could be improved with more intelligence, and so AI should have a big impact.\n\nRandom lanscapes: we expect little impact of AI.\n:     - _Discovering species._ Discovering viruses, discovering planets. When discovering new objects the observations cannot be well-predicted from first principles, we inevitably need new observations.\n      - _Plant breeding._ Suppose we breed plants just by selecting the highest-yield mutations. The statistical problem is trivial, and AI won't help at all.\n      - _Mapping a genome._ The exact base pairs in a genome require individual observations.\n\nRegular landscapes, where we expect a large impact.\n:     - _Folding proteins._\n      - _Discovering candidate drugs._\n      \n\n\n\n#           Old Introduction\n\nA model of the world as accumulating knowledge.\n: Suppose we're all farmers and we're gradually discovering the most efficient way of growing crops through trial and error -- choosing how deep to plant the seeds and how far apart, how often to water, what fertilizer to add. We all can observe each others' choices.\n\nThink of this as a model of all economic history.\n: We can interpret \"growing crops\" as all economic choices -- building cars, treating diseases, writing novels. Implications:\n   \n      1. Knowledge accumulates over time.\n      2. People tend to all adopt the same technique (herding), and there are some non-market forces to encourage exploration (public investment, intellectual property laws).\n      3. There will be specialization -- if experience is imperfectly observable then some people will know relatively more about their particular field, and so have higher productivity, and we'll get endogenous specialization.\n\nThe ruggedness of the landscape determines the economics.\n: The ruggedness of the landscape means the degree of non-convexity, and so existence of local optimums. A high degree of ruggedness implies:\n\n      - Rugged domains will have steep growth with experience/time (as we discover progressively higher peaks)\n      - Rugged domains will show higher efficiency in larger societies\n      - Rugged domains will require more education/apprenticeship to learn best practices (rather than discover them on the job)\n\n| smooth                                 | rugged            |\n| -------------------------------------- | ----------------- |\n| cutting hair                           | agriculture       |\n| cooking food                           | medical treatment |\n| entertainment (music, writing, movies) | chip design       |\n| teaching                               |                   |\n| nursing care                           |                   |\n\nThe effect of AI depends on the ruggedness of the landscape\n:     - If rugged, and AI helps illuminate the landscape, then expect rapid discovery improvements.\n      - If smooth then we're probably already close to global optimum, so AI doesn't help much.\n   \n      Thus the best proxy for future productivity growth is past productivity growth.\n\nAI will have two effects.\n: 1. _Share knowledge_ -- suppose knowledge is characterized by prior experiences, then AI could pool all experiences.\n: 2. _Generate knowledge_ -- in some cases AI can reveal the landscape, i.e. gain knowledge that no human has.\n\n\nImplications for media.\n: Suppose $x$ represents a piece of media and $f(x)$ represents its entertainment-value. We expect a slow process of discovery. (Notable that here $f(x)$ represents our own knowledge).\n\n\n\n#           Model: Exploring a Landscape.\n\n\n\n::: {.cell .column-margin caption='caption'}\n::: {.cell-output-display}\n![](2025-08-02-landscape-shrouded-in-clouds_files/figure-html/unnamed-chunk-4-1.png){width=288}\n:::\n:::\n\n\n\n\nAssumptions:\n\n1. **You choose some $x$ and get payoff $y(x)$.** The function $y(.)$ is unknown, so you don't observe the payoff until you try it out. You can interpret the action as a blueprint for a house, a business plan, a computer program, an agricultural practice, a novel, a song. Everything below also applies when the payoff depends on the state, $v(x|z)$, and so the action is context-specific, e.g. replying to an email, operating a car, operating a machine, writing copy to advertise some product.\n\n2. **You keep making the same choice over time.**\n\n3. **Everyone is playing an independent game, but can observe each other.** We're all subsistence farmers living side-by-side, our actions don't directly affect each other. Suppose we can all observe each others' choices but not their payoffs.\n\nImplications:\n\n1. **Exploration will decrease over time.**With a single agent they will stop exploring at some point, and choose $x$ every period. E.g. we see that societies adopt certain practices in agriculture, architecture, clothes, cooking, and then settle on those once they have exhausted local improvements.\n\n2. **Everyone will do the same thing (herding).** If actions are observable then it is rational for each person to imitate others' actions, and so within a society everyone's actions will tend to be clustered in a neighborhood (if you're walking through a minefield, you want to follow someone else's footsteps).[^Aumann] \n\n3. **There will be inefficiently little exploration.** When you try out a new $x$ then your neighbors benefit because they can learn from your experience. We will thus have a million farmers all doing the same thing, it would be better if some of them experimented. We can collectively organize this: (A) sponsor people to run experiments; (B) let people register a claim on some $x$ and charge others to use it (intellectual property protection).\n\n4. **Bigger societies will find better designs.** Bigger societies will have (A) more random variation to learn from; (B) more ability to collectively organize to explore.\n\n5. **People will become experts.** Some people will learn the local neighbhorhood of their payoff-space and can charge for that expertise: artisans, architects, artists, doctors.\n\n\n\n[^Aumann]: Define equilibrium as when everyone chooses the same $x$ every period. This follows if there's common priors, common-knowledge-of-rationality, and a regularity assumption on beliefs. Choosing some $\\cap{x}$ implies that, for every $x\\neq\\cap{x}$, that $E[y(\\cap{x})] - E[y(x)]\\geq 0$. Assume these inequalities are always strict, meaning every $E[y(x)]$ is one-to-one (injective). Then if two people choose different $x$ they must disagree about one of those inequalities, violating common knowledge of rationality (Aumann's agreeing-to-disagree).\n\n\n##          Assumptions on landscape\n\n**Assume $v(\\bm{x})$ is non-convex.** If it's convex then you'll gradually converge to the global maximum by local exploration.\n\n##          Observations\n\n- **Agricultural Yield is Exploration.** Agricultural societies slowly accumulated crop management practices that have raised yields (irrigation, rotation, fertilizers). The invention of printing made knowledge diffuse more quickly, & so more people caught up to the knowledge frontier (e.g. Diderot's encyclopedia). Organized research advanced the frontier. People argue over whether intellectual property was a positive or negative for innovation.\n\n- **Technologies of Reproduction.** You could extend the model such that you pay a lower cost when your action is an exact copy of an existing action (a reproduction). Certain technologies made it cheap to reproduce existing things: writing, printing, photography, audio recording, video recording. This increases welfare but makes outcomes more homogenous, the distribution of actions becomes very spikey.\n\n- **Science Maps out the Landscape.** Normal progress consists of mapping out individual points on the landscape. Scientific progress is different - it maps out big areas. Newtonian mechanics tells you the stability of any bridge; modern chemistry tells you the properties of any combination of ingredients.\n\n##          Applications to AI\n\nThere are multiple things AI can do here: (1) predict the outcome given each context and action ($v(\\bm{z},\\bm{x})$); (2) find an action $\\bm{x}$ which maximizes $v(\\bm{z},\\bm{x})$; (3) predict the typical human action ($\\bm{x}$) given the context ($\\bm{z}$). The last is imitative.\n\n   - **Human-level classification (content moderation, radiologists).** You train a model on human labels to classify inputs. Now classification becomes very cheap. Expect this to be a substitute for low-skilled employees: borderline cases would still be escalated to the high-skilled employees.\n   \n   - **Super-human classification (sexing chickens; MRI).** You see a chick $z$, you choose whether to raise it to a chicken ($x\\in\\{0,1\\}$), and you get payoff if the chicken is female. Humans can't tell the difference between male and female chicks by sight, but suppose AI models figure out how to do it. This is a pure yield increase for chicken ranchers because you save the cost of raising male chicks.\n\n   - **Synthesize media (text, music, video, ads).** Here the function $v(\\cdot)$ represents human appreciation. Thus the function is known in a certain sense but the knowledge is implicit, and so in practice we explore the space and we we have experts: writers, musicians, artists, who can create content that gets a good reaction.\n   \n   - **Playing chess.**\n   - **Folding proteins.**\n   - **Writing code (imitative).** \n   - **Face recognition.** \n   - **Creating pictures.**\n   - **Driving a car.**\n   - **Writing boilerplate text.**\n   - **Suggesting responses to customer queries.**\n   - **Satisfying constraints.**\n   - **LLM answering factual questions.** \n\n\n|                                                            | linear fit? | skill-biased? |\n| ---------------------------------------------------------- | ----------- | ------------- |\n| estimating probability of death (or loan default)          | yes         |               |\n| agricultural management (irrigation, rotation, fertilizer) | yes         |               |\n| classifying whether photo is porn                          | no          |               |\n| classifying whether text is hate speech, spam, etc.        | no          |               |\n| classifying sex of chicken                                 | no          |               |\n| answering a customer question about a product              | no          |               |\n| driving a car                                              | no          |               |\n| answering a factual question                               | no          |               |\n|                                                            |             |               |\n\n\n###            applications\n\nTypes of designs.\n: - *design for consumption*: a story, a novel, a song, a picture, a wood-carving.\n: - *design for function*: computer code, agricultural practice (what to use as fertilizer, when to water plants), a letter, conversation with a customer, blueprint for a building.\n: - *tacit knowledge of practices.* How to operate a machine, how to stitch a collar, how to pitch a sale to a client.\n\n\nLLMs aggregate existing knowledge.\n: LLMs don't map out new points on the landscape, but aggregate existing knowledge. They are similar to encyclopedias or search engines. We'd expect each of these decisions to raise the quality of decisions, but also lower the returns to expertise: e.g. experts on Cobol, on rare diseases, on asbestos management.\n\nLLMs translate between two idioms.\n: They can serve as interfaces between business logic and humans. They can write emails & probably soon will have telephone conversations.\n\n   Much human work can be thought of as *translation*: (1) customer support tells you how your situation fits into the policy; (2) insurance adjuster translates your bent fender into policy language; (3) literal translators/interpreters.\n\n\n   Many occupations are translating between human and machine. People who serve as interfaces between a mainframe and the customer: call center agents, gate agents, insurance adjusters, bank tellers, tax agents, rental car service clerk. They talk to the customer and type stuff into a computer.\n\n   Slow replacement with self-service: ATMs, self-service kiosks, automated phone systems, websites, phone apps.\n\n   It's been difficult to automate policy agents, but some societies have been successful: Sweden tax by SMS, Japanese vending machines, ATMs instead of bank tellers. \n\n\n#           Application to Intellectual Property\n\n\n**Key points:**\n\n   1. **We have IP protection because the landscape is shrouded in clouds.**\n\n   2. **AI illuminates the whole landscape.** An implication is we should substantially loosen IP law, so it's not just a race to acquire land.\n\n   3. **Copying occurs in a pre-AI world, but in the post-AI world there's no real distinction between creation and copying.**\n\n   4. **LLMs could be prevented from producing exact matches with a hash function.** (bloom filter?)\n\n\n--------------------------------------------\n\nWe should carefully distinguish *current IP law* or *future IP law* or *ideal IP law*.\n: Much of the debate is about how to interpret current IP law, but current IP law was written as a response to a specific situation, we should ask how do we expect IP law and interpretation likely to change, and what would be the ideal IP law?\n\nArtefacts that can have intellectual protection.\n\n:    - Chemical composition of a drug\n     - Process used to manufacture a light bulb\n     - The likeness of a cartoon character\n      - A brand name\n      - A photograph\n      - The text of a news article\n      - The lyrics of a song\n      - The facts reported in a news article (sometimes)\n      - A software algorithm\n\nWe can make two assumptions about the landscape:\n: 1. Snowflake/atomic: $y(x)$ has no structure, each $y(x)$ is a random draw.\n: 2. Smooth: $y(x)$ has structure, so as you observe more you'll make better decisions.\n\nModel: unique snowflakes.\n: Suppose each work is its own unique snowflake, this is a common way of modelling intellectual property (I think the Josh Gans paper assumes this). Implications:\n   1. _Copying is binary._ you either copy or you don't, there's no partial copying.\n   2. _The marginal value of information is equal to the average value._ (???) \n\n\nWith AI everything is illuminated.\n: Now suppose that AI illuminates the entire landscape, i.e. the mapping $v(x)$ becomes fully known to everybody.\n: E.g. we can suddenly observe (1) of all possible drugs, how effective is each; (2) of all possible lyrics, how resonant is each; (3) of all possible paintings, how attractive is each.\n\nDistinction: whether the value is the world, or human response.\n: It's worth distinguishing two sources of uncertainty in v(x): whether v(.) measures the effect of x on the outside world, or the effect of x on human responses.\n: 1. About the world: $v(x)$ represents efficacy of a drug, or the speed of a sorting algorithm.\n: 2. About human responses: $v(x)$ represents memorability of a poem, the click-through-rate of an advertisement, the beauty of an image.\n\nPrediction: there will be less imitation in the post-AI world.\n: If the full landscape is disclosed then there's no longer a *reason* to imitate. You can just choose the x which maximizes v(x). We will still see *clustering*, people will choose similar values of x, but just because they maximize v(.), not because they're imitating each other.\n\n--------------------------------------------\n\nTwist: familiarity changes the value.\n: In some cases the use of an input x will change the output v(x). E.g. after people have been exposed to a particular phrase or a particular cartoon character then that particular realization becomes more attractive in the future. As a consequence the landscape will have ridges, creases bearing the imprint of particular cases (distinct from the ridges due to finite training data).\n\nGood application: genre novels.\n: Suppose we have a set of 10,000 novels which are romance or western or fantasy. We can think of the probability distribution from which they're drawn.\n: The probability distribution will have a ridge around actual novels but also a lot of structure off that; trained on 10,000 novels from a trillion; could just avoid direct quotes (bloom filter) but still pick up the sense.\n\nThe marginal value of information is close to zero.\n: The returns to information are highly concave: think about the value of each dot on the landscape, the value decreases with something like sqrt(N). As a consequence if we pay people for the marginal value of their information the payments will be very small. (Euler's theorem: if a function has constant returns to scale, then sum of payments to factors will exactly equal total product).\n: This result only holds in the *landscape* world, not in the *snowflake* world.\n\n\n--------------------------------------------\n\n\n> \"Data are considered discoverable \"Facts,\" not original works in themselves, and are thus not copyrightable. The methods of compilation, analysis, annotation arrangement, or selection of data, which may be novel, unique, or proprietary, can be protected under copyright.\n\n\n\n#           Other Candidate Metaphors\n\nI want a good metaphor but not sure which is best.\n\nCrop management [BEST].\n: We're all farmers and gradually discovering better ways to grow our crops -- how deep to plant the seeds and how far aprat, what to put on as fertilizer, how often to water.\n\nDrug design.\n: We're choosing a combination of ingredients to maximize effectiveness in treating some condition. We generally follow others' recipes very closely, occasionally adding a new one to the repertoire. Very likely there exist far more effective combinations that we're not aware of.\n\nDrilling for water.\n: We have a huge desert & we want to know the best spots to drill for water. We go around drilling spots, and gradually build up some theory about where the water is.\n\n#           Modelling Knowledge\n\nKnowledge is often treated implicitly in economic models.\n\n: Many economic models have some parameter described as representing the knowledge of the agent, and which acts as a productivity multiplier. This is how knowledge is represented in many growth models. This can be extended to a vector of productivities across different types of good, representing knowledge in different domains (e.g. Becker & Murphy (1992)). A slightly richer model is in Garicano (Ide-Talamas), where each agent's knowledge is a scalar which represents the most difficult problem they can solve.\n\nIt is useful to have an explicit model of knowledge.\n\n: Knowledge is modelled explicitly when the agent has some beliefs about the state of the world, and update those beliefs based on experience. Having an explicit model of knowledge allows us to derive equilibrium behaviors as a function of the statistical structure of the world:\n\n      1. The returns to experience -- and from that the equilibrium degree of specialization.\n      2. The incentives for exploration -- and from that social learning, herding, & the effects of IP protection.\n      3. The relative performance of computers vs humans across different domains (or the relative performance of different algorithms).\n\nGeneral model of knowledge.\n\n: The simplest model of knowledge has an unobserved state of the world $\\theta$, an action $x_t$, and the agent receives payoff $u(x_t|\\theta)$. This a basic bandit problem, where knowledge of $\\theta$ accumulates over time.\n\n      Some models additionally have a dynamic signal $z_t$, so payoff is $u(x_t,z_t|\\theta)$. These can be reduced to simpler state-action models by interpreting the action as a function going from signal to action $x(z_t)$.\n\n##       Summary of Models\n\n| model                               | signal |   action    |\n| ----------------------------------- | :----: | :---------: |\n| BANDIT / LANDSCAPE                  |        |             |\n| - K-arm bandit                      |  none  | categorical |\n| - Jovanovic & Nyarko                |  none  | categorical |\n| - Brownian landscape (Callander)    |  none  |   scalar    |\n| - NK fitness                        |  none  |   vector    |\n| - Bayesian optimization (GP-UCB/TS) |  none  |   vector    |\n|                                     |        |             |\n| SUPERVISED LEARNING                 |        |             |\n| - gaussian process regression       | vector |   scalar    |\n| - nonparametric regression          | vector |   scalar    |\n| - question-answering                | vector |   scalar    |\n|                                     |        |             |\n| CONTEXTUAL BANDIT                   |        |             |\n| - Linear contextual bandit          | vector |   vector    |\n| - Contextual Bayes optimization     | vector |   vector    |\n| - Optimal control (Kalman filter)   |        |             |\n| - Reinforcement learning            |        |             |\n\n##     Models of Knowledge\n\nBinary action (bandits).\n\n: There is a big literature studying \"strategic experimentation\" where the action is binary, often with one safe and one risky arm. See a good survey in Hörner & Skrzypacz (2016) [Strategic experimentation, learning, information design](https://web.stanford.edu/~skrz/survey_learning_Horner_Skrzypacz.pdf).\n\n      - They distinguish between two types of bandits: whether a null outcome is good news or bad news. \n      - 2.1: strategic bandits. everyone has to play a bandit game, but they observe others' choices and payoffs, so there are informational externalities. They say that equilibrium is generally *complex* so it's often studied in simplified settings. Each player can choose either safe or risky arm. We can compare compare choice of risky when playing alone vs when you observe someone else: there are free-riding effects, but also encouragement effects -- if you're successful then it will provoke more experimentation by the other guy.\n      - 2.2: imperfect observation. They say \"observed actions, unobserved outcomes remains largely unsolved ... but .. unobservable actions, observed outcomes is better understood.\"\n      - They note that most of the literature has just two actions. The discuss the Callander setup -- where beliefs over W(p) are a Weiner process. This has the nice property that beliefs will depend only on nearest neighbors.\n\nContinuous action, Gaussian-quadratic outcome.\n\n: Jovanovic & Nyarko (1996) have a model with $K$ different technologies, for each there's some unobserved $\\theta$, you have Gaussian priors over each, and as you operate the technology longer you update your beliefs. This can be reduced to a model where you just choose which technology to use ($k$), and your productivity in that technology increases over time. Implications:\n\n      1. Exploration is front-loaded -- the value of information falls with experience.\n      2. Hysteresis -- the mroe experience you have with one technology the less likely you are to switch.\n\n\nContinuous action, Weiner outcome.\n\n: @bardhi2026learning review the literature on \"correlated learning.\"\n\n      Callander (2011, AER) \"Searching and Learning by Trial and Error.\": Outcomes are the realized path of a Brownian motion over the choice space; optimal experimentation is history‑dependent and can settle at local optima.\n\n      > \"Innovation in this market is irregular with frequent changes of direction and cycles between frontier and niche innovation. We show how the ruggedness of the technological landscape itself deters innovation, generating less entry and product diﬀerentiation, narrower markets, and more intense competition than in a world of certainty.\"\n\n: @CarnehlSchneider2025 use this setup to generally characterize science & discovery:\n\n      > \"Researchers select a question and how intensely to study it. The novelty of a question determines both the value and difficulty of discovering its answer. We show that the benefits of discoveries are nonmonotone in novelty. Knowledge expands endogenously step-by-step over time.\"\n\n\nAtomic actions.\n\n: - @kortum1997research assumes that technological progress comes from taking random draws from a distribution (undirected search). Then growth over time will be characterized by the extreme value distribution of the underlying distribution, & returns to experience will depend on the thickeness of tails: (1) Bounded: (hits a ceiling) ; (2) exponential (thin tails): $A=\\ln n$; (3) Pareto (thick tails): $A = n^\\gamma$. Note that completely random (undirected) search seems a poor fit for most innovation processes. Examples: Edison testing filaments, high-through drug discovery, evaluating mutations. The theory has a clear implication: that over time the share of trials that are failures increases very strongly; but in fact it's not clear this is true.\n\n: - Agrawal, McHale and Oettl (2023) model a finite distribution of alternatives, and the inventor has a prior probability of success for each. They let AI change the distribution of priors, and they show that this change will tend to decrease time-to-success and increase R&D effort.^[Note that they set up the landscape as a combination of N elements, but by email they confirm that the combinatorial structure isn't actually used. They say their earlier paper, @agrawal2019needles, does use the combinatorial structure.]\n\n\nVector action.\n: See a good discussion of evolutionary fitness landscapes [here](https://www.ggi.infn.it/talkfiles/slides/talk3333.pdf). They draw beautiful models of fitness landscapes in a 2^n space, and they have a bunch of empirical findings from bacteria about ruggedness of those landscapes:\n   ![Fitness landscape](images/2025-08-12-21-02-24.png)\n: Models:\n\n      1. _House-of-cards._ The fitness of each genotype is a random draw. You can get nice clean expressions for the expected number of local optima.\n      2. _Mount Fuji_ -- The function is entirely separable, i.e. no interaction (epistasis).\n      3. _NK model_ Total fitness $W$ is the arithmetic mean of the $N$ component contributions:\n     $$W(s) = \\frac{1}{N} \\sum_{i=1}^N w_i(s_i, s_{i_1}, \\dots, s_{i_K}),$$\n     Note that component $w_i$ depends on $s_i$ plus up to $K$ other components. This model is highly cited in management, but less in economics. (Kauffman & Weinberger (1989))\n      4. _Rugged Mount Fuji_ - $f(\\sigma) =−cd(\\sigma,\\sigma^*)+\\eta(\\sigma)$, where $d(.,.)$ is Hamming distance between $\\sigma$ and the global optimum $\\sigma^*$.\n: Levinthal (1997) applies Kauffman's NK model to business decision-making.\n\n<!-- NOTE: having a footnote breaks the two-column layout -->\n[^Kauffman]: Kauffman & Weinberger (1989, J Theo Bio). \"The NK model of rugged fitness landscapes and its application to adaptation.\"\n\nGeneral action (nonparametric learning).\n\n: Finally we can talk quite generally about nonparametric estimation of a function, AKA supervised learning. There we have some nice expressions of learning rates (how error trends with N), and how it relates to the function's curvature and dimensionality. We can treat this as a maximization problem, consistent with the cases above: suppose you receive a series of cases from some distribution $f(x)$ and you have to classify each case, given some loss function. \n\n#           Data on Progress Over Time\n\n\n##             Cost Reductions from Our World in Data\n\n![From Our World in Data](images/2025-08-16-18-03-35.png)\n\n- https://ourworldindata.org/grapher/costs-of-66-different-technologies-over-time\n- Most are around 1%/year, outliers: DNA sequencing, photovoltaics, hard disk drive, DRAM, transistor. \n\n##             Data on Algorithmic Progress\n\nSherry & Thompson (2021) [\"How Fast do Algorithms Improve?\"](https://ide.mit.edu/wp-content/uploads/2021/09/How_Fast_Do_Algorithms_Improve.pdf)\n\n   > \"We find enormous heterogeneity in algorithmic progress, with nearly half of algorithm families experiencing virtually no progress, while 14% experienced improvements orders of magnitude larger than hardware improvement (including Moore’s law).\n\n\n![](images/2025-08-30-12-16-37.png)\n\nOthers:\n\n- _Channel coding efficiency:_ we are very close to the Shannon lower bound.\n- _Compression efficiency:_ compression has been getting better consistently better over time, & LLM perplexity is essentially a model of copmression (the Hutter prize). LLM-based compression is far more efficient. \n\n\n##             Learning Curves\n\nLearning curves\n: McNerny (2022) talk about Wright's law: cost falls exponentially with quantity, $c\\propto Q^{-\\alpha}$. They say typical $\\alpha$ = 0.32, so 10X quantity gets 50% reduction in cost. (They note that it's hard to distinguish between effects of scale vs effects of time; also there could be reverse causation from scale to cost.)\n\n#          Appendix\n\nSome other literature.\n\n- Rational herding / cascades: Banerjee (1992); Bikhchandani, Hirshleifer & Welch (1992); Chamley (2004, Rational Herds).\n- Social learning and networks: Vives (2008, Information and Learning in Markets); Bala & Goyal (1998); Jackson & Yariv (2011).\n- Learning‑by‑doing / technique choice: Jovanovic & Nyarko (1996).\n- Path dependence / specialization: Arthur (1989); Polya urn processes.\n\n#           Offcuts\n\n## 2025-08-23 |                      what conditions are required for AI progress?\n\nBasic model: you choose between $N$ alternatives, costs $c$ to evaluate each.\n: For each alternative there is some true value, $y(x)$, which you only observe by paying the cost. You thus rank all the alternatives according to your prior, $E[y(x)]$, and take draws until the expected improvement is equal to the expected cost (to simplify, suppose that new draws don't update the priors on other alternatives).\n: In this model computers can do two things.\n\n(1) Computers lower the cost of evaluation.\n: - _Full evaluation._ In some domain the ground truth can be calculated by a computer: (A) efficiency of an algorithm; (B) the physical properties of a system (e.g. physics); (C) constraint satisfaction, e.g. Sudoku, chess. Note that LLMs and neural nets are *not* very good at these exact calculations.\n: - _Approximate evaluation._ E.g. (A) simulation of weather; (B) simulation of a building's structural integrity; (C) whether a joke is funny; (D) predicting whether protein will fold.\n\n(2) Computers give information about alternatives.\n: You can model this as .\n\nImplication: AI isn't useful only in cheap-evaluation domains.\n: Dean and Hassabis both say AI will be useful only when you can evaluate cheaply.\n: Places where evaluation is expensive: (1) drugs; (2) ;\n\n\nCLAIM: AI acceleration depends on the structure of the landscape.\n: 1. _Random landscape: discovering viruses._ -- the landscape has irreducible complexity. It's high-dimensional. \n: 2. _Regular landscape: optimizing algorithms._ -- can find patterns that others haven't discovered. / Especially good at solving problems that are not deterministic, but borrow structure from other similar problems -- e.g. crosswords, chess, sudoku. / And will likely find the *ground truth* for some algorithms, the best possible: e.g. efficiency bound for algorithm, or Nash strategy for a game.\n: 3. _Regular landscape: ._\n\n\n\n#                    Related Literature\n\n\n##    Jeff Dean: clear reward, short evaluation cycle\n\n   > \"going to have to be an area that is amenable to a fully automated loop of generating some ideas, trying them out, getting some feedback, exploring essentially some very large space of possible solutions to some problem, and when you have that characteristic we've already seen that reinforcement learning algorithms and large-scale search with computation actually are quite effective ... where you don't have that characteristic ... there's no clear reward signal or the evaluation of this particular instantiation of an idea actually takes you two weeks instead of a minute, that kind of thing will hamper you.\"\n\n   - [YouTube](https://youtu.be/OEuh89BWRL4) ; [Twitter](https://x.com/slow_developer/status/1959046679845642552)\n\n##    Bouatta et al. (2021) [\"Protein structure prediction by AlphaFold2: are attention and symmetries all you need?\"](https://pmc.ncbi.nlm.nih.gov/articles/PMC8329862/)\n\n   > \"Last December, the organizers of ... (CASP14) experiment made the surprising announcement that DeepMind ... had ‘solved’ the protein-folding problem\"\n\n   > Three properties of Go and StarCraft2 made them amenable to machine-learning methods: the existence of a massive search space, a clear objective function (metric) for optimization and large amounts of data. Protein structure prediction shares some of these properties.\n\n   > This end-to-end differentiability condition greatly simplifies learning by enabling all parameters to be adjusted jointly instead of relying on a patchwork of disconnected steps, each of which is optimized independently\n\n##    Hassabis (2024) Nobel Lecture\n\n\n> What makes for a suitable problem for AI? (1) Massive combinatorial search space; (2) Clear objective function (metric) to optimise against; (3) Either lots of data and/or an accurate and efficient simulator.\n\n> Taking a step back, what is the essence of what our systems are doing?\n   - Finding the optimal solution in an enormous combinatorial space\n   - Learn a model of that environment (from data or simulation)\n   - Use that model to guide a search according to an objective function\n   - Turns out this is a very general solution and many problems fit this approach\n\n> My Proposed Conjecture: “Any pattern that can be generated or found in nature can be efficiently discovered and modelled by a classical learning algorithm”\n\n> If it turns out that classic systems can model certain types of quantum systems, it could potentially have big implications for complexity theory including P=NP, and maybe even fundamental physics!\n\n> AI for Science, Medicine & Climate\n>  - Identifying eye disease from retinal scans\n>  - Genetic missense mutations\n>  - Fusion - plasma containment\n>  - Faster matrix multiplication\n>  - SOTA weather forecasting\n>  - Discovery of new materials\n\n\n##          Hassabis Lex Fridman interview\n\n\nYou need a latent structure, and all natural systems have a latent structure.\n\n: > \"natural systems have structure because they were subject to evolutionary processes that shape them. And if that’s true, then you can maybe learn what that structure is.\n\n: > \"it may not be possible for man-made things or abstract things like factorizing large numbers because unless there’s patterns in the number space, which there might be, but if there’s not and it’s uniform, then there’s no pattern to learn, there’s no model to learn that will help you search. So you have to do brute force. \n\n   https://lexfridman.com/demis-hassabis-2-transcript/\n\n\n\n##    Agrawal, McHale & Oettl (2023)\n\n   > What is the main testable implication of the model? It is simple to state but difficult to implement – **access to AI-based prediction models will increase scientific discovery and innovation.** We refer to this as the Hassabis hypothesis . Demis Hassabis, co-founder of DeepMind (now part of Google), has been an evangelist for the potential of AI to speed scientific discovery. He has noted three requirements that make a scientific problem amenable to an AI-aided solution: a combinatorial search space (too large for exhaustive search); a clear objective function for training the prediction model; and sufficient data or capability to simulate that data to train the model. We suggest adding a fourth – poor alternative predictive models for prioritizing search over the design space. When these conditions are present, the Hassabis hypothesis is essentially that the space of amenable problems that cannot be solved by other means is large. AlphaFold can reasonably be seen as a proof of concept – albeit one with significant real-world implications. Time – and empirical research – will tell if it is a fluke or a harbinger of a new era of discovery.\n\n##          McNerny (2022) [\"Role of design complexity in technology improvement\"](https://pmc.ncbi.nlm.nih.gov/articles/PMC3107265/) \n\nThey try to fit learning curves to ruggedness.\n: Models where the learning curve arrives endogenously:\n   1. Muth (1986): you take random draw each time. If underlying distribution is Weibull then minimum wll be power-law in number of draws.\n   2. McNerny (2022): you have a cluster of components with interdependence. If more interdependent then the learning curve is slower (like a landscape with higher epistasis).\n   3. Jovanovic & Nyarko (....).\n\n\n#                       offcuts\n\n1. The Fitness landscape leaves as impression - like a plaster cast ; you can figure out from petals of a flower where it lives and who else lives nearby.\n\n2. Examples of brute force exploration: (1) wildcat drilling; (2) high-throughput drug discovery; (3) growing seedlings looking for beneficial mutations.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}