{
  "hash": "f6a9c908091167da7bcb45938677d747",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Knowledge-Creating LLMs\ndate: today\nauthor:\n  - name: Tom Cunningham\n    affiliation: METR\n    affiliation-url: https://metr.org/\nreference-location: document\ncitation: true\nengine: knitr\nbibliography: ai.bib\ndraft: true\n---\n<!-- see also - 2026-01-31-knowledge-creating-model.md -->\n\n::: {.column-margin}\n   Thanks to Zoë Hitzig & Parker Whitfill for helpful comments.\n:::\n\nIt's useful to make a distinction between two types of LLMs:\n: 1. **Knowledge-sharing LLMs:** they are trained with human judgment as the ground truth. As such they rarely exhibit superhuman performance, their economic value mainly comes from sharing knowledge, and LLM-creators will sell access broadly.\n  1. **Knowledge-creating LLMs:** they are trained against the real world, and so can extend the limits of human knowledge. They expand the world's economic abilities, and LLM-creators will prefer to sell access *exclusively*.\n\n    Below I give a longer discussion of this distinction, and a simple economic model comparing the two types of LLMs.\n\n\nWhat will happen when LLMs create new knowledge?\n: It seems likely that in 2026 LLMs will start creating substantial amounts of new knowledge, & we will enter a new phase of the economics of AI. \n\n<!-- An LLM that shares existing knowledge will be adopted by people outside their area of expertise, and LLM-developers will want to sell access at a low cost. In contrast an LLM that can discover new knowledge will be adopted by experts, and LLM-developers will wish to strictly limit access. -->\n\nTo add:\n:     1. Better graph\n      2. Add some predictions about 2026\n      1. Parker point: compare with existing research labs, but much more on fixed costs.\n      2. Zoe point: \"ie i’m not sure about this distinction : “Thus labs will prefer to restrict output, e.g. by selling the knowledge to just one firm, instead of selling the ability to generate knowledge.”\"\n      3. Zoe point distillation:\n      4. Trade costs imply some home production just behind the frontier\n      5. Differences in benchmarks between old & new LLMs\n      6.  Quotes about how LLMs are now creating new knowledge\n      7.  Send to: Eddie, Erik B, Josh Gans.\n\n\n##       Model of LLMs for Discovery\n\n<!-- It's useful to distinguish between two types of LLMs:\n:   1. **Knowledge-sharing LLMs.**-- they are trained on human-produced and human-judged data.\n    1. **Knowledge-creating LLMs.** -- they are trained against new data directly from the real world, e.g. math, verifiable problems, computer use, actions in the world. -->\n\n\nKnowledge-sharing LLMs.\n:     Traditionally LLMs have been trained with human judgment as the ground truth, using labels from paid raters or from customers. As a consequence they can answer questions and solve problems up to the limits of human expertise but rarely beyond (with some exceptions, see the literature on LLM \"Transcendence\", @abreu2025taxonomytranscendence).\n\n      If we model the economic effects of LLMs as coming from sharing existing knowledge this has a number of implications that seem to fit the data.[^sharing] (See also some of my previous writing on this: [AI & Imitation](https://tecunningham.github.io/posts/2023-09-05-model-of-ai-imitation.html), [a pocket model of AI](https://tecunningham.github.io/posts/2025-09-19-transformative-AI-notes.html)).\n\n      - LLMs use will be higher among those junior in their careers, facing problems that are new to them.\n      - LLMs will be dispropportionately used by people outside their area of expertise, e.g. lawyers will use them for medical questions, doctors will use them for legal questions.\n      - LLMs will be disproportionately used in well-documented domains, e.g. for popular programming languages, which appear more in the training data.\n      - LLMs will decrease knowledge rents -- the premium earned by people and firms whose value comes from knowledge.\n      - LLMs will increase home production -- you can solve problems yourself instead of paying for it, and so potentially decrease GDP.\n      - LLMs decrease the returns to innovation and news-gathering, because they increase the speed of knowledge diffusion and thus diminish the rents that can earned from new knowledge.\n      - LLM use has high fixed costs (collecting the knowledge) and low marginal costs in sharing the knowledge. The returns to LLM-use on an individual problem rapidly diminish when you hit the frontier of existing knowledge.\n\n\n[^sharing]: Many other technologies share knowledge -- speaking, writing, printing, the internet -- LLMs just continue this progression but further lower the costs of sharing.\n\n      \n<!-- (more speculative) they decrease firm size, because you don't need an in-house specialist anymore. -->\n\nKnowledge-creating LLMs.\n:     Over the past 18 months it has become much more popular to train LLMs directly against a source of ground truth, e.g. Reinforcement Learning against Verifiable Rewards (RLVR). Accompanying this there has been a steadily increasing stream of announcements of new discoveries by LLMs.\n\n     Knowledge-creating LLMs are distinct from prior AI discovery applications (e.g. AlphaFold, AlphaTensor) in that they are *general* methods. E.g. @yuksekgonul2026learning describes a setup in which a general-purpose LLM iteratively explores any arbitrary optimization landscape, using a combination of weight-updates and an explicit scratchpad state.\n\n     Knowledge-creating LLMs will differ from knowledge-sharing LLMs in a number of ways:\n\n     - Knowledge-creating LLMs will have qualitatively different benchmarks: instead of seeing if they can answer questions which we already know the answer to (most existing benchmarks), we want them to answer *new* questions, e.g. solve an Erdős problem or set a new record on an optimization problem.\n\n     - Knowledge-creating LLMs have high returns to compute expenditure on individual problems, unlike knowledge-sharing LLMs for which returns asymptote quickly.\n\n     - Knowledge-creating LLMs will be adopted by leader firms more than followers.\n      \n     - The demand for new knowledge is much less elastic than the demand for existing knowledge, i.e. there are high returns to *exclusivity* of new knowledge. Thus LLM-providers are likely to license their technology exclusively rather than expose them through a general-purpose API.\n      \n      \n\n      **[Sarah Friar, OpenAI's CFO, January 2026.](https://openai.com/index/a-business-that-scales-with-the-value-of-intelligence/)** \n\n      > *\"As intelligence moves into scientific research, drug discovery, energy systems, and financial modeling, new economic models will emerge. Licensing, IP-based agreements, and outcome-based pricing will share in the value created.\"*\n\nApplications for knowledge-creating LLMs:\n\n:    - Drug discovery.\n     - Optimizing algorithms.\n     - AI R&D.\n     - Predict stock prices.\n     <!-- - Create a movie. -->\n\n#           A Visual Explanation\n\n\nHere we draw the cost for a set of 3 humans across a range of tasks, assuming each has a specialty area where they have the lowest labor-cost. The knowledge-sharing LLM aggregates knowledge, and so is the lower bound across all three agents.\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](2026-01-29-knowledge-creating-llms_files/figure-html/unnamed-chunk-1-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nWe can then illustrate a knowledge-creating LLM as pushing below the human frontier at some set of tasks:\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](2026-01-29-knowledge-creating-llms_files/figure-html/unnamed-chunk-2-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n\n<!-- |                                 | Knowledge-Sharing LLM          | Knowledge-Creating LLM        |\n| ------------------------------- | ------------------------------ | ----------------------------- |\n| Who uses it                     | Inexperienced                  | Experienced                   |\n| Types of use                    | Outside your area of expertise | Inside your area of expertise |\n| Effect on output                | Redistributes surplus          | Creates new surplus           |\n| Effect on inequality            | Decreases inequality           | Increases inequality          |\n| Value of exclusivity            | Low                            | High                          |\n| Cost structure                  | Low marginal costs             | High marginal costs           |\n| Effect on home production       | Increase                       | Decrease                      |\n| Effect on returns to innovation | Decrease                       | Increase                      |\n|                                 |                                |                               |\n -->\n\n#           An Economic Model\n\nA basic model of knowledge and output.\n: In a very simple model we have:\n\n      1. Aggregate output is determined by the best knowledge.\n      2. Aggregate profit is determined by the distance between the best and second-best knowledge.\n\n      Suppose there are $L$ people, each has 1 unit of labor, and there is just one good. Each person knows some subset of recipes $R_i\\subseteq R$, and each recipe yields some cost of producing the good from labor, $c(r)$. Then person $i$'s effective cost $c_i$ is the lowest cost among the recipes that they know. Each person can rent labor from others to produce the consumption good, and we assume labor is allocated via Bertrand wage competition among recipe-holders; workers are price-takers and work for the highest wage.\n\n      We can order the costs from lowest to highest, $c_{(1)}\\leq \\cdots \\leq c_{(L)}$. In equilibrium the lowest-cost agent will rent the labor of all others, produce the good at the lowest cost $c_{(1)}$, and then sell the good back at a price equal to the second-lowest cost ($c_{(2)}$), and keep the remainder as profit:\n: $$\\begin{aligned}\n      \\text{output} &= \\frac{1}{c_{(1)}}L  && \\text{(the best recipe)}\\\\\n      \\text{profit} &= \\left(\\frac{1}{c_{(1)}}-\\frac{1}{c_{(2)}}\\right)(L-1) \n         && \\text{(diff bw 1st and 2nd-best recipe)}\n   \\end{aligned}\n   $$\n\n\nKnowledge-sharing spreads output.\n:  Suppose we share the best recipe among the whole population, so now $c'_{(2)}=c'_{(1)}=c_{(1)}$. Now total output is unchanged, but profit is eliminated, and the output is spread equally among all actors.\n\nKnowledge-creation increases output.\n: Suppose we can improve the best recipe, $c'_{(1)}<c_{(1)}$. Total output will increase. The effect on profit will depend on (1) whether the identity of the lowest-cost producer changes; and (2) the degree of improvement.\n\nThe market for knowledge.\n: We now should turn to how knowledge-sharing and knowledge-creation is used. The answers are somewhat sensitive to the specifics of the market.\n\n      [XXXX]\n\n##          Additional Notes\n\nAdditional notes.\n: asdf\n\n<!-- notes on models: 2026-01-31-knowledge-creating-model.md -->\n\n\n\n#           More to Do\n\nThere are obvious implications for intellectual property.\n\n: A specific worry: if we maintain the same intellectual property law then there will be a land-grab, firms will rush to be the first to discover new technologies, and will then get an exclusive license, but that exclusivity will be inefficient (i.e. it wasn't necessary to motivate the research, the technology would've been discovered anyway).\n\n\nIt would be more satisfying to have a generative model.\n: I'd really like to sketch out a very simple model in which both humans and LLMs learn recipes from experimenting against the real world.\n\n\n\n#           Miscellaneous\n\n\n@yuksekgonul2026learning, \"Learning to Discover at Test Time\"\n: > \"We report results for every problem we attempted, across mathematics, GPU kernel engineering, algorithm design, and biology. TTT-Discover sets the new state of the art in almost all of them: (i) Erdős’ minimum overlap problem and an autocorrelation inequality; (ii) a GPUMode kernel competition (up to 2×faster than prior art); (iii) past AtCoder algorithm competitions; and (iv) denoising problem in single-cell analysis. Our solutions are reviewed by experts or the organizers.\"\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}