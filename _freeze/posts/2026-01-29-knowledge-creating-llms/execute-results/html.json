{
  "hash": "b819eea15188e1e63822347e4eb5902a",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Knowledge-Creating LLMs\ndate: today\nauthor:\n  - name: Tom Cunningham\n    affiliation: METR\n    affiliation-url: https://metr.org/\ncitation: true\nengine: knitr\nbibliography: ai.bib\ndraft: true\n---\n<!-- TODO:\n1. ~~Add references to my own work~~\n2. Better graph, fewer humans\n3. ~~Acknowledgements, thanks to Zoe, Parker~~\n4. Parker point: compare with existing research labs, but much more on fixed costs.\n5. Zoe point: \"ie i’m not sure about this distinction : “Thus labs will prefer to restrict output, e.g. by selling the knowledge to just one firm, instead of selling the ability to generate knowledge.”\"\n6. Zoe point distillation:\n7. Trade costs imply some home production just behind the frontier\n8. Differences in benchmarks between old & new LLMs\n9.  Quotes about how LLMs are now creating new knowledge\n10. Send to: Eddie ; \n -->\n::: {.column-margin}\n   Thanks to Zoë Hitzig & Parker Whitfill for helpful comments.\n:::\nWe are moving from knowledge-sharing LLMs to knowledge-creating LLMs.\n: Until recently LLMs have been primarily *sharing* existing knowledge, and have only approached human expert-level performance, rarely surpassing it.\n: But new ways of training models show signs of advancing the frontiers of human knowledge - e.g. proving new theorems, improving on existing algorithms, discovering new scientific theories.\n\nKnowledge-creating LLMs have distinct economic implications.\n: An LLM that shares existing knowledge will be adopted by people outside their area of expertise, and LLM-developers will want to sell access at a low cost. In contrast an LLM that can discover new knowledge will be adopted by experts, and LLM-developers will wish to strictly limit access.\n\n      Below I give some general observations about the implications, then a simple economic model comparing the two types of LLMs.\n\n      A notable implication for AI safety is that AI labs will have less incentive to release knowledge-creating models publicly, and so we may have less visibility into frontier progress.\n\n\n##       Model of LLMs for Discovery\n\nIt's useful to distinguish between two types of LLMs:\n:   1. **Knowledge-sharing LLMs.**-- they are trained on human-produced and human-judged data.\n    1. **Knowledge-creating LLMs.** -- they are trained against new data directly from the real world, e.g. math, verifiable problems, computer use, actions in the world.\n\nKnowledge-sharing LLMs.\n:     Traditionally LLMs are trained with human judgment as the ground truth, using labels from paid raters, or from LLM users. As a consequence they can answer questions and solve problems up to the limits of human expertise but rarely beyond.\n\n      I have elsewhere argued that it's useful to think of LLMs as sharing existing knowledge ([one](https://tecunningham.github.io/posts/2023-09-05-model-of-ai-imitation.html), [two](https://tecunningham.github.io/posts/2025-09-19-transformative-AI-notes.html)).\n\n      An implication: they will be used by people outside their areas of expertise, and by firms that are followers, to catch up to the frontier.\n      \n      As a consequence they decrease knowledge rents -- people and firms whose value is from their existing knowledge.\n      \n      They increase home production (you can solve problems yourself instead of paying for it), and so decrease GDP.\n      \n      They decrease the returns to innovation (and news-gathering), insofar as they cause new knowledge to diffuse more quickly.\n\n      This business has high fixed costs -- collecting all the knowledge to train the model -- and relatively low marginal costs in sharing that knowledge.\n\n      \n<!-- (more speculative) they decrease firm size, because you don't need an in-house specialist anymore. -->\n\nKnowledge-creating LLMs.\n:     Over the past year there have been various announcements of LLMs used to advance the state-of-the-art on various specific problems, i.e. creating new knowledge. \n\n      They will be mostly used by *leader* firms instead of followers, and will be used *inside* their area of expertise instead of at the fringes.\n      \n      We should expect much higher variable costs, i.e. expenditure on advancing the state of konwledge on a single problem.\n      \n      The demand for new knowledge is much less elastic than the demand for existing knowledge. Selling knowledge to one person is much more valuable than selling to two people. Thus labs will prefer to restrict output, e.g. by selling the knowledge to just one firm, instead of selling the ability to generate knowledge.\n      \n      Our benchmarks for new LLMs will be qualitatively different. Instead of seeing if they can answer questions which we already know the answer to, we want them to answer *new* questions, e.g. Erdos problems, or setting records on optimization benchmarks.\n\n      **[Sarah Friar, OpenAI's CFO, January 2026.](https://openai.com/index/a-business-that-scales-with-the-value-of-intelligence/)** \n\n      > *\"As intelligence moves into scientific research, drug discovery, energy systems, and financial modeling, new economic models will emerge. Licensing, IP-based agreements, and outcome-based pricing will share in the value created.\"*\n\n\n\n      Examples of knowledge-creating LLM applications:\n\n      - Predict stock prices\n      - Optimize algorithms\n      - Optimize technology\n      - Solve scientific problems\n      - Create a movie\n\nA visual explanation.\n: Below we illustrate a set of humans, and their cost to do different tasks. Here each human has a speciality, i.e. a set of tasks at which they have the lowest cost.\n\n      We can visualize a knowledge-sharing LLM assistant as equalizing knowledge, and therefore achieving the minimum-cost across all humans. However a knowledge-creating LLM achieves even lower costs.\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](2026-01-29-knowledge-creating-llms_files/figure-html/unnamed-chunk-1-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n\n#           Economic Model, Part 2\n\n<table>\n  <tr>\n  <td>\n   Assumptions\n  </td>\n  <td>\n   Implications\n  </td>\n </tr>\n <tr>\n  <td>\n   - $N$ agents, each has 1 unit of labor\n   - Each agent has a labor cost of producing good $c$\n  </td>\n  <td>\n   - Implication:\n  </td>\n </tr>\n</table>\n\n#           An Economic Model\n\n<!-- notes on models: https://chatgpt.com/share/697cd5b5-74f4-8013-a58d-e41dc7f3a319 -->\n\nBaseline: everyone buys from the person who knows the best recipe.\n: Everyone has a unit of labor. There's one consumption good, but various recipes for producing it, $r\\in R$, which determine the labor-cost of producing the good, $c(r)$. In equilibrium the person who knows the lowest-cost recipe ($c_1$) will sell the good in return for others' labor. Their margins are equal to the difference to the next-lowest-cost recipe, $c_2-c_1$ (assume Bertrand competition).\n\nKnowledge-sharing LLMs eliminate rents.\n: Now you invent a knowledge-sharing LLM, which can reveal the lowest-cost known recipe, $c_1$. You cannot make substantial profits from this knowledge: once two producers have the same cost then margins will be driven to zero. Assuming the recipe does diffuse, total output remains the same but the surplus is now distributed equally. If we additionally assumed some trade cost $\\delta$ then the knowledge will have value equal to $\\delta$, but notably there's no value to *exclusively* license your LLM. Also notably the returns to innovation fall: there's much less incentive to discover a new low-cost recipe if that knowledge will be immediately shared.\n\nKnowledge-creating LLMs generate additional surplus.\n: Next we introduce a knowledge-creating LLM, which generates a new recipe $c_0<c_1$. The inventor can monetize this either by producing the good themselves or licensing the recipe to a single producer. Now exclusivity is important: if they sold the recipe to *two* producers then profits will be driven to zero, and the value of the recipe will be zero. In equilibrium total output increases, the extra surplus is split between consumers and the owner of the new recipe.\n\n\nThe model can be extended to multiple goods. \n: If people have Cobb-Douglas preferences across goods then they will spend a fixed fraction of labor on each good, and so each good's market can be treated as independent.\n\n      You can visualize the distribution of costs as follows:\n\n      - Old LLMs are the minimum cost among existing humans.\n      - New LLMs *lower* the cost.\n\n<!-- Q: does this hold with exchange? -->\n\n<!-- \n|                         | LLM that shares knowledge | LLM creates knowledge  |\n| ----------------------- | ------------------------- | ---------------------- |\n|                         |                           |                        |\n| Superhuman performance? | Only in special cases     | Often                  |\n| Who uses it?            | Followers in an industry  | Leaders in an industry |\n| What types of use?      | Specializations           | Non-specializations    |\n|                         |                           |                        | \n-->\n\n\n#           More to Do\n\nThere are obvious implications for intellectual property.\n\n: A specific worry: if we maintain the same intellectual property law then there will be a land-grab, firms will rush to be the first to discover new technologies, and will then get an exclusive license, but that exclusivity will be inefficient (i.e. it wasn't necessary to motivate the research, the technology would've been discovered anyway).\n\n\nIt would be more satisfying to have a generative model.\n: I'd really like to sketch out a very simple model in which both humans and LLMs learn recipes from experimenting against the real world.\n\n\n\n#           Recent Examples of Knowledge-Advancing AI [UNFINISHED]\n\n\n@yuksekgonul2026learning, \"Learning to Discover at Test Time\"\n: > \"We report results for every problem we attempted, across mathematics, GPU kernel engineering, algorithm design, and biology. TTT-Discover sets the new state of the art in almost all of them: (i) Erdős’ minimum overlap problem and an autocorrelation inequality; (ii) a GPUMode kernel competition (up to 2×faster than prior art); (iii) past AtCoder algorithm competitions; and (iv) denoising problem in single-cell analysis. Our solutions are reviewed by experts or the organizers.\"\n\n\n# Literature Review: Economic Models\n\nThis post is trying to separate two economic objects that are often conflated:\n: (i) *diffusing existing knowledge* vs (ii) *creating new knowledge*. There are several modeling traditions that map naturally onto this distinction.\n\n## Knowledge diffusion and catch-up\n\nLucas & Moll (2014) treat knowledge growth as a time-allocation problem.\n: > \"Agents divide their time between two activities: producing goods and interacting with others in search of new, productivity-increasing ideas.\" [@lucas2014knowledge]\n\nBenhabib--Perla--Tonetti (2014) generate growth with an endogenous split between frontier innovation and imitation/catch-up.\n: > \"The resulting equilibrium is an endogenous segmentation between innovators and imitators.\" [@benhabib2014catchup]\n\nConnection to \"knowledge-sharing LLMs\":\n: These models make it natural to interpret \"old LLMs\" as reducing the effective costs/frictions of searching, matching, and imitating (and therefore compressing knowledge rents).\n\n## Endogenous growth: ideas as (partly) nonrival inputs\n\nRomer (1990) frames technology as a special kind of input.\n: > \"The distinguishing feature of the technology as an input is that it is a nonrival, partially excludable good.\" [@romer1990endogenous]\n\nJones (1995) emphasizes that many R\\&D-based models predict strong scale effects that are not borne out empirically.\n: > \"This paper argues that the \"scale effects\" prediction of many recent R\\&D-based models of growth is inconsistent with the time-series evidence from industrialized economies.\" [@jones1995rd]\n\nBloom--Jones--Van Reenen--Webb (2020) document declining research productivity (\"ideas getting harder to find\").\n: > \"More generally, everywhere we look we find that ideas, and the exponential growth they imply, are getting harder to find.\" [@bloom2020ideas]\n\nConnection to \"knowledge-creating LLMs\":\n: In this language, \"new LLMs\" plausibly shift the idea production function itself (not just the diffusion of existing ideas), which re-raises the standard questions of appropriability and market structure.\n\n## Appropriability, IP, and licensing\n\nArrow (1962) is a canonical statement of why private incentives and social value can diverge for invention/knowledge.\n: > \"INVENTION is here interpreted broadly as the production of knowledge.\" [@arrow1962welfare]\n\nKatz \\& Shapiro (1985) analyze when a patent holder chooses to license versus exclude.\n: > \"We find that major innovations will not be licensed, but that equally efficient firms will tend to license minor innovations.\" [@katz1985licensing]\n\nArora--Fosfuri--Gambardella (2001) describe how a market for technology changes firms' strategic choices.\n: > \"Markets for technology increase the strategy space: firms can choose to license in the technology instead of developing it in-house.\" [@arora2001markets]\n\nKamien--Oren--Tauman (1992) compare licensing mechanisms (e.g. auctions vs uniform royalties).\n: > \"Proposition 6 asserts that for both the patentee and consumers a uniform royalty is inferior to an auction.\" [@kamien1992licensing]\n\nConnection to this post's core claim:\n: If \"new LLMs\" reliably generate *valuable, appropriable* new recipes, then the equilibrium object may be closer to exclusive licensing / restricted access (or secrecy) than to wide diffusion of a general-purpose tool.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}