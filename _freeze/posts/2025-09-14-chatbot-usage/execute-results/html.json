{
  "hash": "81d086d0b8eeead1e46ebbbab5288cd5",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Chatbot Usage\nauthor: Tom Cunningham\ndate: today\nengine: knitr\ndraft: true\n#bibliography: ai-economics.bib\n# editor:\n#   render-on-save: true\nformat:\n  html:\n    html-math-method: \n      method: katex\n      options:\n        macros:\n          \"\\\\bm\": \"\\\\boldsymbol\"\n---\n\n\n\n<style>\n   h1 {  border-bottom: 4px solid black; }\n   h2 {  border-bottom: 1px solid gray; padding-bottom: 0px; color: black; }\n   dl {display: grid;}\n   dt {grid-column-start: 1; width: 4cm;}\n   dd {grid-column-start: 2; margin-left: 2em;}\n</style>\n\n#     thread\n\nA few interesting facts from our new paper about how people use ChatGPT (with @zoe, @carl, @chris, @ronnie, @deming, )\n\n(1) The biggest impact of LLMs so far appears to be an assistant helping to solve everyday problems. A few years ago many people expected the primary impact to be in business processes -- that is large and growing, but chatbots are even larger. ChatGPT's answers to questions are pretty dry, Wikipedia-level, but there turns out to be an enormous demand for that.\n\n\n(2) Use of ChatGPT has exploded, both in the number of users and the messages/user. An interesting question is how much of the growth is due to diffusion and how much to increase in capabilities. It's difficult to tease these apart, but the capabilities are clearly growing fast (by user preference over responses, at about 200 Elo points/year). If a large share of the growth in usage is due to capabilities growth this has a big impact on our forecasts of AI's impact: we're not primarily forecasting a diffusion process (Acemoglu & Aghion), but a growth process.\n\n(3) \n\n\n\n\n\n--------------------------------------------\n\nSummary\n:     1. Chatbot adoption has grown like crazy: 1/2 of adults in rich countries use chatbots.\n      1. Usage per user has also grown very steeply.\n      2. A large part of chatbot growth is likely due to growth in utility, not just diffusion of existing quality. This has implications for projections forward.\n      3. Most conversations on ChatGPT are about solving concrete practical problems.\n      4. Most conversations are not for paid work.\n\nInterpretation.\n:     1. **Autonomous use of LLMs is still niche.** The primary economic impact is through helping people (AKA augmentation, uplift, hybrid). There is some missing capability.\n      2. **Question-answering model.** People are using ChatGPT to solve problems (answer questions) that *they* have not encountered before, but other people have. Implies chatbots will raise welfare but lower exchange.\n      \n\n#           Chatbot Growth\n\nChatbot adoption has grown like crazy.\n: ChatGPT has 700M weekly active users, around 10% of the world adult population. In rich countries the reach is close to 30%. ChatGPT is the largest chatbot (others: Gemini, Meta.ai, Claude, DeepSeek, Grok).\n: ![](images/2025-09-14-20-20-00.png)\n\nUsage per user has also grown a lot.\n: ![](images/2025-09-14-20-21-48.png)\n\n#           Chatbot Usage\n\nPeople are mostly solving concrete practical problems.\n: ![](images/2025-09-14-20-43-21.png)\n      Note: a large share of writing, and image-generation, which doesn't perfectly fit the question-answering model discussed below.\n\nThe majority of conversations are not work-related.\n:     Prompt we used to classify whether work-related:\n\n      > - likely part of work (e.g. \"rewrite this HR complaint\") <br />\n      > - likely not part of work (e.g. \"does ice reduce pimples?\")\n\n      ![](images/2025-09-14-20-42-45.png)\n\n      Interpretation: ChatGPT is mostly *home production,* it's not final consumption, but it also won't show up in GDP because it's not exchange.\n\n\n#           Automation vs Augmentation\n\nLLMs are used far more for augmentation than automation.\n: Define automation as using the response without manually verifying it -- e.g. reading the answer,      validating the code.\n\n\n\n#           Question-Answering Model\n\nSummary: chatbots are for new-to-you questions.\n\n:     Chatbots give you answers to questions based on existing questions & answers in their training data.\n\n      Implication: Chatbots will be used when you face a question that is new to you but familiar to someone else.\n\nSetup.\n: \n      Every day you face a question $q$ and have to guess an answer $a$.\n         - You receive payoff\n         - You observe the true answer (this eliminates the explore-exploit tradeoff).\n         - Each guess will be an interpolation based on the questions you've faced before.\n      \n      You can consult ChatGPT, which guesses at answers based on its own set of questions. ChatGPT's training set is the set of question-answer pairs that exist on the internet.\n      \n      Prediction: ChatGPT used when you face a question that is new to you, but familiar to someone else.\n      \n      The same logic applies to other stores of information (books, search engines). Chatbots are distinctive in being able to interpolate answers to new questions.\n\nWhat people will use ChatGPT?\n:     1. _People with less experience:_ young people, people who've just changed careers.\n      1. _People in rugged occupations:_ -- occupations which face a stream of new questions, but where the answer is well-documented -- e.g. doctor, lawyer.\n\nWhat questions will ChatGPT be used for?\n:     1. _Questions similar to those in the training set_ -- e.g. common technologies, not idiosyncratic or proprietary technologies (usage should be convex in the popularity of a programming language).\n\nWhat combinations of people and question should we expect?\n:     1. _Questions outside your expertise._ Doctor/lawyer model - the doctor is more likely to ask a legal question, the lawyer is more likely to ask a medical question.\n      2. _Questions that ._\n\n##          Effects\n\nEffects on individual welfare.\n:     1. You give better answers to questions.\n      1. You spend less time on other information sources.\n      2. You change the set of questions you attempt.\n\nEffects on equilibrium.\n:     Suppose people trade based on their expertise. An LLM makes expertise common knowledge, it will increase welfare but reduce trade.\n\n      Effect on distribution is equivalent to catch-up growth in trade models, Wilson (1980):\n\n      > When the transfer of technology to the less efficient producers becomes complete, so that all differences in the technology among countries are eliminated, the welfare of that country which initially had the highest wage must have decreased. ... A similar argument can be used to show that the diffusion of technical knowledge must result in an increase in the welfare of the country which initially had the lowest relative wage\"\n\n\n\n\n<!-- ##          Model with Simple Questions\n\nSetup.\n: 1. Questions are $q\\in Q$, each has a true answer $a(q)\\in\\mathbb{R}$.\n1. Each day $t$ you face a new question, $q_t\\in Q$, drawn from a distribution $f(Q)$. \n2. \n\n: 1. Every day we face a question $q\\in Q$, have to guess an answer $a$, payoff $u(q,a)$, then observe correct answer $a(q)$.\n\n\n##          Model with Complex Questions\n\n- A question is drawn $\\bm{q}\\in\\{0,1\\}^n$, and the answer is $a(\\bm{q})=\\sum_{i=1}^n w_i q_i$.\n- You have a set of questions for which you have already observed the answers, $Q^A$.\n\n\n\n\n#           Interpretation\n\n: Simple model:\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](2025-09-14-chatbot-usage_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n:::\n\n\n\n -->\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}