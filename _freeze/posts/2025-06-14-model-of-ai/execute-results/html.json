{
  "hash": "c58df161add069fba0ccf77e8475a35c",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: A Model of ChatGPT\nauthor:\n  - name: Tom Cunningham\ncitation: true\ndate: 2025-06-14\ndate-modified: last-modified\nfig-align: center\nfig-height: 1\n# bibliography: ai.bib\nreference-location: margin\nengine: knitr\nexecute:\n  echo: false\n  warning: false\n  error: false\n  cache: true # caches chunk output\n  freeze: auto # ??? extra caching\neditor:\n  render-on-save: true\nformat:\n   typst: default          # produces a PDF via Typst\n   # html:\n   #    toc: true\n   #    toc-depth: 2\n   #    toc-location: left\n   #    html-math-method:\n   #       method: mathjax\n   #       url: \"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg-full.js\"\n   #       #     ^ this forces SVG instead of CHTML, otherwise xypic renders weird\n   #    include-in-header:\n   #       - text: |\n   #          <script>window.MathJax = {\n   #                   loader: { load: ['[custom]/xypic.js'],\n   #                               paths: {custom: 'https://cdn.jsdelivr.net/gh/sonoisa/XyJax-v3@3.0.1/build/'}},\n   #                tex: {packages: {'[+]': ['xypic']},\n   #                   macros: {\n   #                      bm: [\"\\\\boldsymbol{#1}\", 1],\n   #                      bmatrix: [\"\\\\begin{bmatrix}#1\\\\end{bmatrix}\", 1],\n   #                      smallmatrix: [\"\\\\begin{smallmatrix}#1\\\\end{smallmatrix}\", 1],\n   #                      ut: [\"\\\\underbrace{#1}_{\\\\text{#2}}\", 2],\n   #                      utt: [\"\\\\underbrace{#1}_{\\\\substack{\\\\text{#2}\\\\\\\\\\\\text{#3}}}\", 3]\n   #                   }}};\n   #          </script>\n   #          <style>\n   #             h1 {  border-bottom: 4px solid black; }\n   #             h2 {  border-bottom: 1px solid gray; padding-bottom: 0px; color: black; }\n   #             dl { margin-bottom: 0px; }\n   #             dt strong { font-weight: bold; }\n   #             dd { margin-left: 20px; }\n   #             .cell-output-display p {padding: 0 0 0cm 0; margin: 0 0 0 0;}\n   #          </style>\n---\n\n\n\n\nThis note gives a simple model of human and AI ability to answer questions.\n: Each question $\\bm{q}$ is a high-dimensional vector of bits, with a true scalar answer $a$. Each agent tries to estimate the answer by interpolating among previous questions $(\\bm{q}^i,a^i)_{i=1,\\ldots,n}$ that they have encountered.\n\nThis model gives a series of general implications:\n\n: 1. **The quality of answer to a new question depends on the distance from the training set.** Suppose a human and a computer both have to answer some question $q$, then the agent who performs better will be the agent where $q$ has a smaller projection onto their training set $Q$.\n\n: 2. **The average quality of answers will decrease linearly with $n$.**\n\n: 2. **The value of getting advice from another agent depends on distance between the two training sets.** (TBC)\n\n: 3. **An agent whose training set is the union of two other agents' training sets will outperform them.** This is for a couple of reasons:\n   1. Averaging many noisy labels lets the computer beat a single noisy human label.\n   2. Averaging many labels lets the computer *interpolate* in a superior way to humans.\n\n\n##       Implications for ChatGPT\n\nInterpreted as a model of ChatGPT, this gives a set of predictions.\n\n: We can interpret this model as one of ChatGPT use, there are three basic ingredients:\n   1. $p$ represents the dimensionality \n   2. Public questions -- these are the training questions that ChatGPT has observed. Roughly speaking we can say these consist of all the questions and answers on the public internet. ChatGPT's full training process is of course more complicated, we discuss below.\n   3. Private questions -- these are the questions that the human has themselves encountered (and observed the answer for). \n \n   A human will invoke ChatGPT if and only if the expected improvement in the answer exceeds some cost.\n\nChatGPT will be adopted for questions which contain novel components (outside of private question space) that are inside public question space.\n: \n\nCorollaries:\n: 1. ChatGPT will not be used for questions that the user has encountered before.\n: 2. ChatGPT will be more likely to be used for domains with higher *latent* dimensionality ($p$).\n: 3. ChatGPT will be more likely be used for domains with lower surface dimensionality -- because it takes more time to specify the question.\n: 3. ChatGPT will be more likely to be used for humans with less experience in a domain ($n_{\\text{private}}$).\n\n\n| occupation                   | dimensionality     |\n| ---------------------------- | --- |\n| junior contact center worker |     |\n| senior contact center worker |     |\n| physician                    |     |\n\n\n| task/question |     |\n| ------------- | --- |\n|               |     |\n\n\nAdditional things we'd like to add:\n: 1. ChatGPT will be more likely to be used for domains where humans have tacit knowledge.\n\n\n\n#           Model\n\nThe world is characterized by a set of $p$ weights, $\\bm{w}$. All agents have Gaussian priors over those weights:\n   $$\\bm{w}\\sim N(\\bm{0},\\sigma^2I_p)$$\n\nEach agent observes a matrix $Q$ of questions, each question has $p$ binary parameters:\n\n   $$\\begin{aligned}\n      Q      &\\in \\{-1,1\\}^{n\\times p}\n         && \\text{($n$ questions, each has $p$ binary parameters)}\\\\\n      \\bm{w} &\\sim N(0,\\Sigma) \n         && (p\\times 1\\text{ vector of true parameters of the world)}\\\\\n      \\ut{\\bm{a}}{$n\\times1$}   &= \\ut{Q}{$n\\times p$}\\ut{\\bm{w}}{$p\\times1$}\n         && \\text{(answers provided by the world)}\\\\\n   \\end{aligned}\n   $$\n\nWe can also write this out in matrix form:\n\n   $$\\begin{aligned}\n      Q &= \\bmatrix{q_1^1 & \\ldots & q^1_p \\\\ & \\ddots & \\\\ q^n_1 & \\ldots & q^n_p}\n         && \\text{(matrix of $n$ questions, each with $p$ parameters)} \\\\\n      \\bm{w}'  &= \\bmatrix{w_1 \\ldots w_p}\n         && \\text{(vector of $p$ unobserved weights)}\\\\\n      \\bm{a}    &= \\bmatrix{a^1 \\\\ \\vdots \\\\ a^n} \n         = \\bmatrix{q_1^1 w_1 + \\ldots q_p^1w_p \\\\ \\vdots \\\\ q_1^n w_1 + \\ldots q_p^n w_p}\n         && \\text{(vector of $n$ observed answers)}\\\\\n   \\end{aligned}\n   $$\n\n**Training Data.** Each agent $i$ has access to a set of observations, or \"training data,\" which consists of a set of questions $Q_i$ and their corresponding answers $\\bm{a}_i$.\n   \\begin{aligned}\n      \\mathcal{D}_i = \\{ (Q_i, \\bm{a}_i) \\}\n   \\end{aligned}\n\n#           Propositions\n\nProposition 1 (Posterior for a given question).\n: The agent's posterior mean and variance will be:\n   $$\\begin{aligned}\n      \\hat{\\bm w}&= \\Sigma Q^{\\top}(Q\\Sigma Q^{\\top})^{-1}\\bm a\\\\\n      \\Sigma_{\\mid a} &=\\Sigma-\\Sigma Q^{\\top}(Q\\Sigma Q^{\\top})^{-1}Q\\Sigma\n   \\end{aligned}\n   $$\n\n<details><summary>Proof (via Gaussian conditioning)</summary>\nThe derivation follows from the standard formula for conditional Gaussian distributions. We begin by defining the joint distribution of the weights $\\bm{w}$ and the answers $\\bm{a}$.\n\nThe weights and answers are jointly Gaussian:\n\\[\n   \\begin{pmatrix} \\bm{w} \\\\ \\bm{a} \\end{pmatrix} \\sim N\\left(\n      \\begin{pmatrix} \\bm{0} \\\\ \\bm{0} \\end{pmatrix},\n      \\begin{pmatrix} \n         \\Sigma & \\Sigma Q' \\\\\n         Q\\Sigma & Q\\Sigma Q'\n      \\end{pmatrix}\n   \\right)\n\\]\nwhere the covariance terms are derived as follows:\n- $Cov(\\bm{w}, \\bm{w}) = \\Sigma$ (prior covariance)\n- $Cov(\\bm{a}, \\bm{a}) = Cov(Q\\bm{w}, Q\\bm{w}) = Q Cov(\\bm{w}, \\bm{w}) Q' = Q\\Sigma Q'$\n- $Cov(\\bm{w}, \\bm{a}) = Cov(\\bm{w}, Q\\bm{w}) = Cov(\\bm{w}, \\bm{w})Q' = \\Sigma Q'$\n\nThe conditional mean $E[\\bm{w}|\\bm{a}]$ is given by the formula:\n\\[\nE[\\bm{w}|\\bm{a}] = E[\\bm{w}] + Cov(\\bm{w},\\bm{a})Var(\\bm{a})^{-1}(\\bm{a} - E[\\bm{a}])\n\\]\nSubstituting the values from our model ($E[\\bm{w}] = \\bm{0}$, $E[\\bm{a}] = \\bm{0}$):\n\\[\n\\hat{\\bm{w}} = \\bm{0} + (\\Sigma Q')(Q\\Sigma Q')^{-1}(\\bm{a} - \\bm{0}) = \\Sigma Q'(Q\\Sigma Q')^{-1}\\bm{a}\n\\]\nThis gives us the posterior mean of the weights. The posterior covariance is given by:\n\\[\nVar(\\bm{w}|\\bm{a}) = Var(\\bm{w}) - Cov(\\bm{w},\\bm{a})Var(\\bm{a})^{-1}Cov(\\bm{a},\\bm{w}) = \\Sigma - \\Sigma Q'(Q\\Sigma Q')^{-1}Q\\Sigma\n\\]\n∎\n</details>\n\nProposition 2 (Expected error for a given question).\n: The expected squared error for a new question $\\bm q$ is:\n  $$ \\mathbb{E}[(\\bm q'(\\bm w - \\hat{\\bm w}))^2] = \\bm q' \\Sigma_{\\mid a} \\bm q $$\n  For an isotropic prior where $\\Sigma = \\sigma^2 I$, the error is proportional to the squared distance of $\\bm q$ from the subspace spanned by the previously seen questions $Q$:\n  $$ \\mathbb{E}[(\\bm q'(\\bm w - \\hat{\\bm w}))^2] = \\sigma^2 \\|(I-P_Q)\\bm q\\|^2 $$\n  where $P_Q$ is the projection matrix onto the row-span of $Q$.\n\n<details><summary>Proof</summary>\nFrom Proposition 2, the expected error with an isotropic prior is $\\sigma^2 \\|(I-P_Q)\\bm q\\|^2$. Since $\\sigma^2 > 0$, the error is zero if and only if $\\|(I-P_Q)\\bm q\\|^2 = 0$. This is true if and only if $(I-P_Q)\\bm q = \\bm 0$, which means $\\bm q = P_Q \\bm q$. This condition holds if and only if $\\bm q$ is in the subspace onto which $P_Q$ projects, which is the row-span of $Q$. ∎\n</details>\n\nProposition 3 (Error decreases linearly with the number of independent questions).\n: The average expected squared error over all possible new questions $\\bm{q}$ decreases linearly with the number of linearly independent questions in the training set $Q$. Specifically, with an isotropic prior $\\Sigma = \\sigma^2 I$, the average error is:\n      $$\\mathbb{E}_{\\bm{q}}[\\text{error}(\\bm{q})] = \\sigma^2 (p - \\operatorname{rank}(Q))$$\n   where the expectation is taken over new questions $\\bm{q}$ with i.i.d. components drawn uniformly from $\\{-1,1\\}$.\n\n<details><summary>Proof</summary>\nThe proof proceeds in two steps. First, we write the expression for the error for a given new question $\\bm q$. Second, we average this error over the distribution of all possible questions.\n\n1.  **Predictive error for a fixed $\\bm q$.** From Proposition 2, the expected squared error for a specific new question $\\bm q$, given an isotropic prior $\\Sigma = \\sigma^2 I$, is:\n    \\[\n       \\text{error}(\\bm q) = \\mathbb{E}[(\\bm q'(\\bm w - \\hat{\\bm w}))^2] = \\sigma^2 \\bm q'(I-P_Q)\\bm q\n    \\]\n    where $P_Q = Q'(QQ')^{-1}Q$ is the projection matrix onto the row-span of $Q$.\n\n2.  **Average over random new questions.** We now take the expectation of this error over the distribution of new questions $\\bm q$. The components of $\\bm q$ are i.i.d. uniform on $\\{-1,1\\}$, which implies that $\\mathbb{E}[\\bm q] = \\bm 0$ and $\\mathbb{E}[\\bm q \\bm q'] = I_p$. The average error is:\n    \\[\\begin{aligned}\n       \\mathbb{E}_{\\bm q}[\\text{error}(\\bm q)] &= \\mathbb{E}_{\\bm q}[\\sigma^2 \\bm q'(I-P_Q)\\bm q] \\\\\n                                              &= \\sigma^2 \\mathbb{E}_{\\bm q}[\\operatorname{tr}(\\bm q'(I-P_Q)\\bm q)] \\\\\n                                              &= \\sigma^2 \\mathbb{E}_{\\bm q}[\\operatorname{tr}((I-P_Q)\\bm q \\bm q')] \\\\\n                                              &= \\sigma^2 \\operatorname{tr}((I-P_Q)\\mathbb{E}_{\\bm q}[\\bm q \\bm q']) \\\\\n                                              &= \\sigma^2 \\operatorname{tr}(I-P_Q) \\\\\n                                              &= \\sigma^2 (\\operatorname{tr}(I) - \\operatorname{tr}(P_Q))\n    \\end{aligned}\\]\n    The trace of the identity matrix is $p$. The trace of a projection matrix is the dimension of the subspace it projects onto, so $\\operatorname{tr}(P_Q) = \\operatorname{rank}(Q)$. Thus, the average error is:\n    \\[\n       \\mathbb{E}_{\\bm q}[\\text{error}(\\bm q)] = \\sigma^2 (p - \\operatorname{rank}(Q))\n    \\]\n    Since the rank of $Q$ increases with each linearly independent question added, the average error decreases linearly until $\\operatorname{rank}(Q)=p$, at which point it becomes zero. ∎\n</details>\n\n\nProposition 4 (Posterior in two-stage estimation).\n: We consider a two-stage process. First, an agent (the \"computer,\" $C$) with training data $(Q_C, \\bm{a}_C)$ forms an estimate for the answer to a new question $\\bm{q}$. Second, another agent (the \"human,\" $H$) with their own training data $(Q_H, \\bm{a}_H)$ observes the computer's estimate and updates their own belief.\n\n  The human has a prior over the weights $\\bm{w} \\sim N(\\bm{0}, \\Sigma)$. After observing their own data, the human's posterior for $\\bm{w}$ is $N(\\hat{\\bm{w}}_H, \\Sigma_H)$, where from Proposition 1:\n   $$\\begin{aligned}\n      \\hat{\\bm{w}}_H &= \\Sigma Q_H^{\\top}(Q_H\\Sigma Q_H^{\\top})^{-1}\\bm{a}_H \\\\\n      \\Sigma_H &= \\Sigma - \\Sigma Q_H^{\\top}(Q_H\\Sigma Q_H^{\\top})^{-1}Q_H\\Sigma\n   \\end{aligned}$$\n  The human's initial estimate for the answer to a new question $\\bm{q}$ is $\\mu_H = \\bm{q}'\\hat{\\bm{w}}_H$ with variance $\\sigma_H^2 = \\bm{q}'\\Sigma_H \\bm{q}$.\n\n  The computer has its own training data $(Q_C, \\bm{a}_C)$. It provides an estimate $\\hat{a}_C = \\bm{q}'\\hat{\\bm{w}}_C$ for the true answer $a = \\bm{q}'\\bm{w}$. The human observes $\\hat{a}_C$ and updates their posterior for $a$. We assume the computer's observations may be noisy, such that $\\bm{a}_C = Q_C\\bm{w} + \\bm{\\epsilon}_C$ with $\\bm{\\epsilon}_C \\sim N(0, s_C^2 I)$.\n\n  We analyze the human's final posterior for $a$ under different assumptions about what the human knows about the computer's process.\n\nProposition 4.1 (Minimal knowledge: \"Pure Kalman filter\").\n: **Assumption:** The human has no knowledge of the computer's training set $Q_C$ but believes the computer's estimate is unbiased with a known mean squared error $\\tau^2$. That is, $\\hat{a}_C = a + \\eta$, where $\\eta \\sim N(0, \\tau^2)$ and is independent of $\\bm{w}$.\n\n  **Result:** Upon observing $\\hat{a}_C$, the human's posterior for $a$ is:\n  $$ a \\mid \\hat{a}_C \\sim N\\left( \\mu_H + \\alpha(\\hat{a}_C - \\mu_H), (1-\\alpha)\\sigma_H^2 \\right) $$\n  where $\\alpha = \\frac{\\sigma_H^2}{\\sigma_H^2 + \\tau^2} \\in [0,1]$. The human's new estimate is a weighted average of their own initial estimate and the computer's estimate. The weight $\\alpha$ placed on the computer's estimate is higher when the computer is believed to be more accurate (smaller $\\tau^2$) or when the human's own estimate is more uncertain (larger $\\sigma_H^2$).\n\nProposition 4.2 (Knowledge of computer's questions).\n: **Assumption:** The human knows the computer's training questions $Q_C$ and its noise level $s_C^2$, but not the observed answers $\\bm{a}_C$.\n\n  **Result:** The human can model the computer's estimate as $\\hat{a}_C = \\bm{q}'P\\bm{w} + \\bm{q}'\\bm{\\zeta}$, where $P = \\Sigma Q_C'(Q_C\\Sigma Q_C' + s_C^2I)^{-1}Q_C$ and $\\bm{\\zeta} = \\Sigma Q_C'(Q_C\\Sigma Q_C' + s_C^2I)^{-1}\\bm{\\epsilon}_C$.\n  \n  The pair $(a, \\hat{a}_C)$ is jointly Gaussian, conditional on the human's data. The posterior for $a$ is:\n  $$ a \\mid \\hat{a}_C \\sim N\\left( \\mu_H + \\kappa(\\hat{a}_C - \\mu_C), \\sigma_H^2 - \\kappa\\sigma_{HC} \\right) $$\n  where:\n   - $\\mu_C = \\bm{q}'P\\hat{\\bm{w}}_H$ (human's expectation of computer's estimate)\n   - $\\sigma_{HC} = \\bm{q}'\\Sigma_H P' \\bm{q}$ (covariance)\n   - $\\sigma_C^2 = \\bm{q}'P\\Sigma_H P' \\bm{q} + \\bm{q}'\\Sigma_\\zeta \\bm{q}$ (variance of computer's estimate)\n   - $\\Sigma_\\zeta = s_C^2 P \\Sigma^{-1} P'$\n   - $\\kappa = \\frac{\\sigma_{HC}}{\\sigma_C^2}$ (the weight on the computer's prediction error)\n\n  The weight $\\kappa$ depends on the covariance structure, which is influenced by the overlap between the subspaces spanned by $Q_H$ and $Q_C$.\n\nProposition 4.3 (Limiting cases).\n: The framework of Proposition 4.2 nests two extreme cases:\n  1. **Oracle Trust:** If the human believes the computer's estimate is perfect (e.g., $s_C^2 \\to 0$ and $Q_C$ spans the relevant subspace), then $\\kappa \\to \\sigma_H^2 / (\\bm{q}'P\\Sigma_H P'\\bm{q})$, and the posterior variance collapses towards zero. In the simplified Kalman model, if $\\tau^2 \\to 0$, then $\\alpha \\to 1$, and the human adopts the computer's answer, $a \\mid \\hat{a}_C \\to N(\\hat{a}_C, 0)$.\n  2. **Total Skepticism:** If the human believes the computer provides no information (e.g., $\\sigma_{HC} \\to 0$ because $Q_C$ is irrelevant to $\\bm{q}$), then $\\kappa \\to 0$. In the Kalman model, if $\\tau^2 \\to \\infty$, then $\\alpha \\to 0$. In both cases, the human ignores the computer's estimate and reverts to their original posterior, $a \\mid \\hat{a}_C \\sim N(\\mu_H, \\sigma_H^2)$.\n\n\n#           Related Literature\n\n##          Agrawal et al. (2018) \"Exploring the Impact of Artificial Intelligence: Prediction versus Judgment\"\n\nhttps://www.nber.org/system/files/working_papers/w24626/w24626.pdf\n\n##          Kleinberg et al. (2017) \"Human Decisions and Machine Predictions\"\n\n\n\n\n\n\n#           References",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}